var store=[{title:"Hello Blog!",excerpt:"After finishing Learn Enough CSS &amp; Layout to Be Dangerous by Michael Hartl, where you create CSS styling and HTML templates for a Jekyll blog, I decided that it was probably for the best that I finally have my own site to write on, and also use as a sandbox to tinker with front-end programming languages.   The last time I attempted to start up a blog was after reading Technical Blogging a few years ago. Although it was a good read, I didn\u2019t feel much love for the Wordpress site I was left with after finishing, and probably didn\u2019t feel like I had much to write about anyway. It was left neglected, unloved, and eventually taken down with a single \u201cHello Blog!\u201d post to its name. Hopefully things will be a bit different this time as I have more manual control over this Github Pages-hosted Jekyll-powered blog.   I didn\u2019t want to throw away the result of the Learn Enough tutorial, as I made a few changes I think I will want to reference later, so I moved the codebase repository, took it off Github Pages, and instead deployed it using Heroku to its new home.   So, hello (again) blog, and here\u2019s to a new start :beers:   ",categories:[],tags:["jekyll"],url:"/blog/hello-blog/",teaser:"/assets/images/paul-teaser.jpg"},{title:"Setting up a Jekyll Blog",excerpt:'TL;DR      Use the Minima theme and customise it if you want to: it works out of the box   Live reload pages with Hawkins and Grip   Lint all files with Sass Lint, htmllint, and markdownlint   Run lints with Guard   Set up a custom domain for the blog   Set up SSL for the blog   You cannot use custom Jekyll plugins when deploying to Github Pages         Setting up this blog, and creating a development environment that I was happy with, took longer than I expected, so I thought I would document the process and other learnings gained along the way.   This assumes that you have read Jekyll\u2019s getting started guide and the quick start instructions on the Jekyll homepage, and have got your new blog generated.   NOTE: I used Jekyll 3.6.2 to originally generate this blog, so your mileage may vary depending on what version you use and when you read this post.   Choosing a theme   If you are hosting outside of Github, then you can get themes from many different sites, but if you are going to use Github Pages for hosting, then you are limited to their supported themes.   After generating a few different test blogs and applying different themes, I found that Minima, the default theme, is the one that works most seamlessly out-of-the-box: it includes all the layouts that a newly-generated site wants by default, as well as integrations for Disqus comments and Google Analytics. This ease of use, coupled with my desire to tinker with the CSS, made the minimalistic Minima a straightforward choice, but I would encourage you to experiment and pick one that best suits the look you want for your site.   Creating a Development Environment   Before starting any coding on the blog itself or making any content, I wanted to make sure I had a development environment I was comfortable with, so here is how I set mine up.   Live Reloading   Hitting refresh every time you want to see your changes reflected on a web page isn\u2019t fun, so let Hawkins and Grip handle that for you.   Hawkins   Hawkins\u2019 live reload applies to any content file in the Jekyll application itself.  Installation and usage of the Hawkins gem is well documented on its README file, so I will just simply add that I\u2019ve set it to watch draft blog posts (markdown files in the _drafts/ folder) as well by running my Jekyll server with the following command:   bundle exec jekyll liveserve --drafts   Grip   Hawkins does not cover any Markdown in a Jekyll application\u2019s README file, so if you change it often, or just want a process to monitor it, install Grip (I use Homebrew), and run it in a separate terminal window:   brew install grip grip --browser   The --browser flag will open a tab in your web browser immediately at http://localhost:6419/ and display the application README file. The page gets live-reloaded as changes are made, but just be warned that if you perform more than 60 live reloads per hour, you will need to authenticate your Github API requests with your Github credentials.   Linting   I\u2019m quite fastidious about code style and quality, but do not want to have to be too cognizant of it while developing, so I want a team of robots to look over my shoulder and let me know when the code I am writing is not up to \u201ccommunity standards\u201d. That team of robots, in this case, takes the form of a set of linters for each of the different file types primarily used in a Jekyll blog: CSS (SASS), HTML, and Markdown.   Find the lints   Since Jekyll is written in Ruby, I started searching for lints at Ruby Gems, where I found SCSS-Lint, Markdown Lint, and no options available for HTML. I found configuring Markdown Lint confusing, and SCSS-Lint recommends using other Javascript-based linting tools over itself, so I came to the conclusion that it was probably best to use front-end language linters that were actually written in front-end languages. They ended up being:      SCSS: Sass Lint   HTML: htmllint (via htmllint-cli)   Markdown: markdownlint (via markdownlint-cli)   Install the lints using npm, and then make sure to update your shims for Node if you\u2019re using a version manager for npm (I use asdf):   npm install -g sass-lint htmllint-cli markdownlint-cli asdf reshim nodejs   Run the lints   Now that the lints are all installed, there needs to be a way to run them when files change. For Ruby and Rails projects, I always use Guard, so I chose it due to my familiarity with it, and because I didn\u2019t want to have to learn how to use another front-end-based task runner at this time. Since the lints are not Ruby gems and hence do not have their own Guard plugins, I used Guard::Process to run the lints as command line processes.   To install Guard and Guard::Process, first add them to the Gemfile:   group :development do   gem "guard", "~&gt; 2.14"   gem "guard-process", "~&gt; 1.2" end   Next, install the gems, and then generate a Guardfile for task configuration:   bundle install bundle exec guard init   Open up the Guardfile with your favourite text editor and insert the following configuration:   guard "process",       command: ["htmllint", "_includes/*.html", "about.html"],       name: "htmllint" do   watch(%r{^_includes/.+\\.html$})   watch(%r{^about\\.html$}) end  guard "process",       command: ["markdownlint", "_posts", "_drafts", "README.md", "index.md"],       name: "markdownlint" do   watch(%r{^_posts/.+\\.md$})   watch(%r{^.+\\.md$}) end  guard "process",       command: ["sass-lint", "--verbose", "--no-exit"],       name: "sass-lint" do   watch(%r{^_sass/.+\\.scss$})   watch(%r{^assets/.+\\.scss$}) end   htmllint needs specificity on what HTML files to lint, otherwise Jekyll-generated HTML files in the _site/ directory also get linted, which just contributes unnecessary noise to the linter output. There are no Markdown files generated in the _site/ directory, but markdownlint also needs a list of files for command line arguments just the same, simply due to them being a required argument for the CLI.   Once configuration is complete, open up a terminal, and run Guard to have it watch your files:   bundle exec guard   Development Environment Summary   So, whenever I open up my Jekyll blog project, I will always currently have four processes running to help me along with development:      Editor: Vim (substitute out your favourite text editor here)   Server: bundle exec jekyll liveserve --drafts   Guard: bundle exec guard   Grip: grip --browser   Overriding Styling   Customising styling of a Jekyll theme is well documented in the Overriding theme defaults section of Jekyll\u2019s documentation, and in the Customization section of the Minima theme\u2019s documentation, so I will just add that since I want to have complete control over the SASS files, I did the following:      Copied over the contents of the Minima _sass/ directory to my local project (this, of course, means I don\u2019t benefit from any updates that may be done to the Minima gem\u2019s styles)   Linted the files with sass-lint, fixed any issues, and built up a set of SASS rules I wanted in a .sass-lint.yml file   Began adding my own minor tweaks to the styles   Overriding include files   I wanted to add an Apple Touch Icon and remove some footer links from the blog, which means I needed access to the application &lt;head&gt; and &lt;footer&gt; tags.   So, I created a local _includes/ directory and began copy and pasting the relevant files from Minima\u2019s _includes/ directory into it, selectively editing the files locally. I have no doubt I will continue to do this over the course of the blog\u2019s life.   Custom Domain Setup   Since I had my own custom name domain, I wanted to use it with the Jekyll blog on Github Pages rather than the default domain of &lt;username&gt;.github.io.   Luckily, Namecheap, my registrar for https://www.paulfioravanti.com, has a fantastic article in their knowledge base that took me through all the steps I needed to link my domain to Github Pages. Although specific to Namecheap, I would wager the information is generic enough to help anyone else wanting to do the same thing.   SSL Setup   At this point, the site may be on a custom domain, but not having the green secure padlock in the address bar, even for a static blog site, won\u2019t make the site look great in search rankings. So, at least for now, get Cloudflare to provide a signed SSL certificate on the blog\u2019s behalf.   Good instructions on creating a Cloudflare account and enabling SSL on a Jekyll site hosted on Github Pages can be found here and here.   No Foreign Plugins   As a post-script to this post, I thought I\u2019d share the result of my time barking up the wrong tree when wanting to have Jekyll use ENV variables.   I wanted to use icons from Font Awesome on my About page, and I wanted to load them from the Font Awesome CDN so I wouldn\u2019t have to download them all into my project directory. Loading them from the Font Awesome CDN requires registering an account, upon which you are allocated an Embed Code.   I mistakenly thought that the Embed Code was \u201csecret information\u201d, and hence should not be stored in the blog git repository but instead loaded into an environment variable using a Ruby gem like dotenv (this is, of course, not true since the Embed Code will be directly visible in HTML files and exists for these reasons).   Anyway, I followed a guide for using ENV variables with Jekyll that involved creating a Jekyll Plugin Generator which can inject values computed at build time into template variables. I deployed the additions out to Github Pages, but it did not seem to work.   Further internet searching led to the realisation that the Github Pages gem only supports a limited list of plugins and always starts Jekyll in safe mode, meaning user-defined plugins are never run.   So, as long as a Jekyll site is hosted up on Github Pages, no custom plugins can be used.   Conclusion   Who would have thought getting a static site and its development environment up and running \u201cproperly\u201d would be so much work? Not me, hence this post, so hopefully it can serve as some reference to someone else setting up their own Jekyll site.   ',categories:[],tags:["jekyll","ruby"],url:"/blog/set-up-jekyll-blog/",teaser:"/assets/images/2017-11-17/wesley-caribe-63610-unsplash.jpg"},{title:"Using Python's Bitcoin libraries in Elixir",excerpt:'I\u2019m currently attempting to learn about the technical details of Bitcoin and blockchains by reading Mastering Bitcoin: Programming the Open Blockchain.   All the code examples in the book are in C++ and Python, but I wanted to see if I could port them over to Elixir. There are Bitcoin libraries in Elixir, like bitcoin-elixir, but I could not seem to find equivalents to the ones used in the book. So, I thought that I would try to port as much of the code as possible into Elixir, and then see if I could make API-style callouts to code that I could not.   I have not been able to find a way to get Elixir to talk to C++ libraries like Libbitcoin, which are used in the book (if you have a good method, please let me know in the comments! [Update 14 Dec 2017: I figured it out. See Using C++ Bitcoin Libraries in Elixir]), so this post will focus on getting Elixir to talk to Python\u2019s Pybitcointools library, within the context of the Implementing Keys and Addresses section in Chapter 4 of the book, using the code in Example 4-5.   The Python example uses the Pybitcointools library to generate a private key, and then encode it into different formats like Wallet Import Format (WIF), and Bitcoin Address (which represents a destination for a Bitcoin payment). The full example code from the book is as follows, so see if you can draw some mental lines around what code can come over to Elixir, and what potentially needs to stay in Python:   # key-to-address-ecc-example.py  from __future__ import print_function import bitcoin  # Generate a random private key valid_private_key = False while not valid_private_key:     private_key = bitcoin.random_key()     decoded_private_key = bitcoin.decode_privkey(private_key, \'hex\')     valid_private_key = 0 &lt; decoded_private_key &lt; bitcoin.N  print("Private Key (hex) is: ", private_key) print("Private Key (decimal) is: ", decoded_private_key)  # Convert private key to WIF format wif_encoded_private_key = bitcoin.encode_privkey(decoded_private_key, \'wif\') print("Private Key (WIF) is: ", wif_encoded_private_key)  # Add suffix "01" to indicate a compressed private key compressed_private_key = private_key + \'01\' print("Private Key Compressed (hex) is: ", compressed_private_key)  # Generate a WIF format from the compressed private key (WIF-compressed) wif_compressed_private_key = bitcoin.encode_privkey(     bitcoin.decode_privkey(compressed_private_key, \'hex\'), \'wif\') print("Private Key (WIF-Compressed) is: ", wif_compressed_private_key)  # Multiply the EC generator point G with the private key to get a public key point public_key = bitcoin.fast_multiply(bitcoin.G, decoded_private_key) print("Public Key (x,y) coordinates is:", public_key)  # Encode as hex, prefix 04 hex_encoded_public_key = bitcoin.encode_pubkey(public_key, \'hex\') print("Public Key (hex) is:", hex_encoded_public_key)  # Compress public key, adjust prefix depending on whether y is even or odd (public_key_x, public_key_y) = public_key compressed_prefix = \'02\' if (public_key_y % 2) == 0 else \'03\' hex_compressed_public_key = compressed_prefix + bitcoin.encode(public_key_x, 16) print("Compressed Public Key (hex) is:", hex_compressed_public_key)  # Generate bitcoin address from public key print("Bitcoin Address (b58check) is:", bitcoin.pubkey_to_address(public_key))  # Generate compressed bitcoin address from compressed public key print("Compressed Bitcoin Address (b58check) is:",       bitcoin.pubkey_to_address(hex_compressed_public_key))   Isolate Pybitcointools API calls   At first glance, I would say that everything that is related to I/O (like print statements) and control flow (if/else statements), can safely make the journey over to Elixir-land, while any code that fetches a value from an API callout to Pybitcointools (ie bitcoin.anything) may have to remain in Python-land, which means we need to have Elixir be able to get return values for the following method calls:      bitcoin.random_key()   bitcoin.encode_privkey(decoded_private_key, encoder)   bitcoin.decode_privkey(private_key, decoder)   bitcoin.encode(public_key_x, hex_encoder)   bitcoin.encode_pubkey(public_key, encoder)   bitcoin.pubkey_to_address(public_key)   bitcoin.N   bitcoin.G   Generate Private Key                    Photo by Katy Belcher on Unsplash        To do this, we can use Export, an Elixir wrapper for Erlport, which allows Erlang to talk to Python and Ruby code. After creating a new mix project (mix new mastering_bitcoin) and installing Export, we can get Elixir to start talking to the key-to-address-ecc-example.py file by writing functions that wrap around Export callouts to it. For example, to get a random key from Pybitcointools, we could do the following:   defmodule MasteringBitcoin.KeyToAddressECCExample do   use Export.Python    @python_src :code.priv_dir(:mastering_bitcoin) |&gt; Path.basename()   @python_file "key-to-address-ecc-example"    def private_key do     {:ok, pid} = Python.start(python_path: @python_src)     private_key =       pid       |&gt; Python.call(@python_file, "bitcoin.random_key", [])       |&gt; to_string()     IO.puts("Private Key (hex) is: #{inspect(private_key)}")     Python.stop(pid)   end end   Running this function in a console (iex -S mix) yields the following result:   iex(1)&gt; MasteringBitcoin.KeyToAddressECCExample.private_key Private Key (hex) is: "e473f28e7c9dd8c46d2698ddc73af1017157f2e2979efe3c116dd35b013c0f2b" :ok   A few things to note here:      The @python_src :code.priv_dir(:mastering_bitcoin) |&gt; Path.basename() module attribute is telling Export.Python where to go looking for Python files, so here, the Python example file lives under the top level priv directory in priv/key-to-address-ecc-example.py (as is Elixir convention), so this attribute will evaluate to be simply "priv".   In Python.call(@python_file, "bitcoin.random_key", []), we\u2019re calling the bitcoin.random_key() method with no arguments, hence the empty argument list as the final function parameter.   Piping the result from Export to the to_string() function is needed due to Elixir reading back the string result from Python as a Binary (ie the above example comes back as \'e473f28e7c9dd8c46d2698ddc73af1017157f2e2979efe3c116dd35b013c0f2b\'). More information about this can be found in the \u201cData types mapping\u201d section of the Erlport documentation.   Decode Private Key   Now that we have a Python-side randomly generated private key as an Elixir string, the next step is to pass it back to Python again so we can get Pybitcointools to decode it to get its decimal value (ie call bitcoin.decode_privkey(private_key, "hex") from Elixir), so let\u2019s add that to the current code, refactoring slightly as we go along:   defmodule MasteringBitcoin.KeyToAddressECCExample do   use Export.Python    @python_src :code.priv_dir(:mastering_bitcoin) |&gt; Path.basename()   @python_file "key-to-address-ecc-example"   @hex "hex"    def run do     with {:ok, pid} &lt;- Python.start(python_path: @python_src),          private_key &lt;- random_key(pid),          decoded_private_key &lt;- decode_private_key(pid, private_key) do       IO.puts("Private Key (hex) is: #{inspect(private_key)}")       IO.puts("Private Key (decimal) is: #{inspect(decoded_private_key)}")       Python.stop(pid)   end    defp random_key(pid) do     pid     |&gt; Python.call(@python_file, "bitcoin.random_key", [])     |&gt; to_string()   end    defp decode_private_key(pid, private_key) do     pid     |&gt; Python.call(@python_file, "bitcoin.decode_privkey", [private_key, @hex])     |&gt; to_string()     |&gt; String.to_integer()   end end   The call to decode the private key is similar to generating the random key, except that we\u2019re now passing the parameters [private_key, @hex] to Python, and then doing further parsing of the result from binary -&gt; string -&gt; integer to get the decimal value of the result.   So, let\u2019s run this in a console:   iex(1)&gt; MasteringBitcoin.KeyToAddressECCExample.run ** (ErlangError) Erlang error: {:python, :"builtins.Exception", \'WIF does not represent privkey\', {:"$erlport.opaque", :python, &lt;&lt;128, 2, 99, 116, 114, 97, 99, 101, 98, 97, 99, 107, 10, 83, 116, 97, 99, 107, 83, 117, 109, 109, 97, 114, 121, 10, 113, 0, 41, 129, 113, 1, 40, 99, 116, 114, 97, 99, 101, 98, 97, 99, 107, 10, 70, ...&gt;&gt;}}   Oops! This incredibly cryptic error is actually telling us that Python 3 tried to call bitcoin.decode_privkey(private_key, &lt;a series of bytes instead of the string "hex"&gt;).   When Elixir/Erlang passes binary information to Python 3, it receives the information as b\'information\': a literal sequence of bytes (as opposed to Python 2, which would receive this data as a string; explanation from Erlport data types mapping documentation to the rescue here again), so it looks like we need to write a Python-side wrapper method that will parse Erlang strings before passing them through as parameters to bitcoin.decode_privkey, so let\u2019s do that:   # key-to-address-ecc-example.py  from __future__ import print_function import bitcoin  def decode_privkey(private_key, decoder):   decoder = decoder.decode()   return bitcoin.decode_privkey(private_key, decoder)  # ... the rest of the code ...   Here, we\u2019re using Python\u2019s bytes.decode() method to return a UTF-8 encoded string from the bytes contained in the decoder parameter, so it can then be passed on to bitcoin.decode_privkey safely.   Now, we need to change the Elixir-side Export call slightly so that we\u2019re calling this new Python-side decode_privkey method that we made, rather than call bitcoin.decode_privkey directly:   defmodule MasteringBitcoin.KeyToAddressECCExample do   # ...    defp decode_private_key(pid, private_key) do     pid     |&gt; Python.call(@python_file, "decode_privkey", [private_key, @hex])     |&gt; to_string()     |&gt; String.to_integer()   end end   Now, let\u2019s try that console run again:   iex(1)&gt; MasteringBitcoin.KeyToAddressECCExample.run Private Key (hex) is: "e5c98a1ed360ae5bf71878bc791422861ee73e0b045e53c4ecad7ecd84ed2a8e" Private Key (decimal) is: 103935731857643381135995335933887080576447253573766575295272791689921802611342 :ok   Success! There\u2019s just one more thing to take care of: references to Pybitcointools constant values.   Constants   Pybitcointools constant values like bitcoin.N are Secp256k1 parameters used in Bitcoin\u2019s Elliptic Curve Digital Signature Algorithm (ECDSA), and live in Pybitcointools\u2019 library here. For our purposes, what we need to know about bitcoin.N is that it helps us determine whether a valid private key has been generated or not (valid_private_key = 0 &lt; decoded_private_key &lt; bitcoin.N).   Export only supports calling methods in Python, so it can\u2019t send a request to fetch the value of a constant.  So, I see two choices:      Create a Python-side wrapper method that returns bitcoin.N   Port the constant to Elixir   I think the latter makes sense, so let\u2019s do that, and complete the correct generation of a private key:   defmodule MasteringBitcoin.KeyToAddressECCExample do   use Export.Python    # Elliptic curve parameters (secp256k1)   # REF: https://github.com/vbuterin/pybitcointools/blob/master/bitcoin/main.py   @n 115792089237316195423570985008687907852837564279074904382605163141518161494337    @python_src :code.priv_dir(:mastering_bitcoin) |&gt; Path.basename()   @python_file "key-to-address-ecc-example"   @hex "hex"    def run do     with {:ok, pid} &lt;- Python.start(python_path: @python_src),          [private_key, decoded_private_key] &lt;- generate_private_key(pid) do       IO.puts("Private Key (hex) is: #{inspect(private_key)}")       IO.puts("Private Key (decimal) is: #{inspect(decoded_private_key)}")       Python.stop(pid)     end   end    # Generate a random private key   defp generate_private_key(pid) do     with private_key &lt;- random_key(pid),          decoded_private_key &lt;- decode_private_key(pid, private_key) do       case decoded_private_key do         n when n in 0..@n -&gt;           [private_key, decoded_private_key]         _out_of_range -&gt;           generate_private_key(pid)       end     end   end    defp random_key(pid) do     pid     |&gt; Python.call(@python_file, "bitcoin.random_key", [])     |&gt; to_string()   end    defp decode_private_key(pid, private_key) do     pid     |&gt; Python.call(@python_file, "decode_privkey", [private_key, @hex])     |&gt; to_string()     |&gt; String.to_integer()   end end   Work in Progress   Note that the Elixir code above only actually covers the port of the first part of the original Python code:   from __future__ import print_function import bitcoin  # Generate a random private key valid_private_key = False while not valid_private_key:     private_key = bitcoin.random_key()     decoded_private_key = bitcoin.decode_privkey(private_key, \'hex\')     valid_private_key = 0 &lt; decoded_private_key &lt; bitcoin.N  print("Private Key (hex) is: ", private_key) print("Private Key (decimal) is: ", decoded_private_key)   The Elixir code that covers the rest of this particular Python code can be found at my Mastering Bitcoin Github repository:      Elixir code   Python wrapper methods   The repository is still a work in progress as I read through the book and attempt to port over more code, so keep an eye out for updates!   ',categories:[],tags:["elixir","bitcoin","python"],url:"/blog/python-bitcoin-libraries-elixir/",teaser:"/assets/images/2017-12-04/drew-stock-628985-unsplash.jpg"},{title:"Using C++ Bitcoin libraries in Elixir",
excerpt:'Following up from my previous blog post about Using Python\u2019s Bitcoin libraries in Elixir, I initially mentioned that I was having trouble figuring out a way to get Elixir talking to C++ code, specifically to use the Libbitcoin toolkit. After looking through a bunch of libraries that purport to solve this problem, some using Native Implemented Functions (NIFs) under the hood, others using Ports, I finally got the results I was after using an Elixir library called Cure (which uses Ports).   This blog post will focus on getting Elixir to talk to C++ code that will interface with Libbitcoin, within the context of the Creating a Base58Check-encoded bitcoin address from a private key section in Chapter 4 of Mastering Bitcoin: Programming the Open Blockchain, using the code in Example 4-3. We\u2019ll create a new project and create a solution in two main steps:      Confirm that we can simply compile and run the C++ code as-is (read: as a shell command) within Elixir using the Porcelain library, collect the output, and print it to screen: creating essentially an Elixir wrapper around running the C++ code.   Introduce Cure to actually get Elixir and C++ to be able to handle message passing between each other, which will require significant changes to the C++ code.      Disclaimer: I am not a C/C++ programmer and am likely Doing It Wrong when I\u2019m on that side of the fence, so please don\u2019t consider any code there to be in any way idiomatic or the way it Should Be Done.    Install Libbitcoin   Before starting with Elixir, let\u2019s install the Libbitcoin toolkit. For Mac OS, you can simply install it using Homebrew:   brew install libbitcoin   For other operating systems, please refer to Libbitcoin\u2019s installation instructions.   New Project   Create a new mix project:   mix new libbitcoin cd libbitcoin   Install and configure Porcelain   Open up the project in your favourite text editor, and add Porcelain as a dependency to your mix.exs file:   defmodule Libbitcoin.Mixfile do   # ...   defp deps do     [       # Work with external processes       {:porcelain, "~&gt; 2.0"}     ]   end end   Install Porcelain:   mix deps.get   Then, configure the driver to use for Porcelain by adding the following line in config/config.exs:   config :porcelain, driver: Porcelain.Driver.Basic   Porcelain can also be used with the Goon driver, which is not something that seems to be needed for this project, so we just tell Porcelain to use its basic driver.   Confirm C++ code can be compiled and run   Next, create a c_src/ directory in the project, and copy the code from the book\u2019s addr.cpp file into c_src/addr.cpp, and create a priv/ directory, which is where we will output compiled C++ executable files.   Having C source code in a c_src/ directory is Erlang convention for the location of C source code, but for artefacts that are needed in production (ie those compiled C++ executables), the Elixir convention is to have them in a priv/ folder, so that\u2019s how we\u2019ll roll.   According to the book, we should be able to compile the code using g++ in the following way:   g++ -o priv/addr c_src/addr.cpp $(pkg-config --cflags --libs libbitcoin)   If running this command as-is works for you, then that\u2019s great, but on my computer, that runs Mac OS High Sierra, I got a screen full of errors. In order to fix this, I had to add the -std= flag, to determine the standard language for compilation, which in my case needed to be c++11: The 2011 ISO C++ standard plus amendments (see Options Controlling C Dialect for more information). So, the compilation command needed to be changed to:   g++ -std=c++11 -o priv/addr c_src/addr.cpp $(pkg-config --cflags --libs libbitcoin)   Running the generated priv/addr executable outputs the following result:   ./priv/addr Public key: 0202a406624211f2abbdc68da3df929f938c3399dd79fac1b51b0e4ad1d26a47aa Address: 1PRTTaJesdNovgne6Ehcdu1fpEdX7913CK   Create Elixir wrapper around C++ file   Now that we\u2019ve confirmed we can run the C++ file, let\u2019s write the Elixir wrapper that will compile the file and run the executable. Create a lib/libbitcoin directory in your project and then create an addr.ex file inside of it:   defmodule Libbitcoin.Addr do   @moduledoc """   Example 4-3. Creating a Base58Check-encoded bitcoin address from a   private key.   """    @cpp_compile """   g++ -std=c++11 $(pkg-config --cflags --libs libbitcoin) \\   c_src/addr.cpp -o priv/addr   """   @cpp_executable "priv/addr"    def run do     Porcelain.shell(@cpp_compile)      @cpp_executable     |&gt; Porcelain.shell()     |&gt; Map.fetch!(:out)     |&gt; IO.write()   end end   Then, open up an iex console and run the module:   iex -S mix iex(1)&gt; Libbitcoin.Addr.run() Public key: 0202a406624211f2abbdc68da3df929f938c3399dd79fac1b51b0e4ad1d26a47aa Address: 1PRTTaJesdNovgne6Ehcdu1fpEdX7913CK :ok   It works! We\u2019ve now been able to get Elixir to output the result of running the C++ executable, but Elixir isn\u2019t really talking directly (sending and receiving messages) to the code yet, so let\u2019s work on that next.   Install and configure Cure   Add Cure as a dependency to your mix.exs file, and then run mix deps.get:   defp deps do   [     # Interface C-code with Erlang/Elixir using Ports     {:cure, "~&gt; 0.4.0"},     # Work with external processes     {:porcelain, "~&gt; 2.0"}   ] end   Then, get Cure to generate the necessary base files to communicate between C++ and Elixir:   mix cure.bootstrap   This command will add the following files to the c_src directory:   c_src \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 main.c \u2514\u2500\u2500 main.h      Makefile: a template to automatically build a C++ executable including Cure\u2019s libraries. We\u2019ll leave this for now, but get back to it later on.   main.c: Cure\u2019s base C file to communicate between C/C++ and Elixir.   main.h: The header file for main.c   Hello C++   Before going straight into talking to Libbitcoin, let\u2019s do a quick spike to confirm that we are able to pass messages back and forth from Elixir to C++.   We are going to need the original addr.cpp code for reference, so let\u2019s first store a copy of the original:   mv c_src/addr.cpp c_src/addr.cpp.orig   Next, we\u2019ll move over the Cure-generated files to the be the new addr files:   mv c_src/main.h c_src/addr.h mv c_src/main.c c_src/addr.cpp   Yes, it\u2019s okay for the .c file to become a .cpp file for our purposes.   Next, open up each of the files and change them so that they look like the following:   c_src/addr.h   #ifndef ADDR_H #define ADDR_H #include &lt;elixir_comm.h&gt;  // TODO put your own functions/includes here.  #endif   c_src/addr.cpp   #include &lt;string&gt; #include "addr.h"  int main(void) {   int bytes_read;   byte buffer[MAX_BUFFER_SIZE];    while ((bytes_read = read_msg(buffer)) &gt; 0) {     std::string param = (char*) &amp;buffer;     std::string greeting = "Hello " + param + " from C++";      memcpy(buffer, greeting.data(), greeting.length());     send_msg(buffer, greeting.size());   }    return 0; }   The code here reads in the message (an array of bytes) that gets brought in from Elixir via the read_msg function that Cure provides, stores it in a buffer, copies it into a C++ param string, interpolates it into a greeting message, copies the greeting back into the buffer, and finally sends it back to Elixir via the send_msg function, also provided by Cure. More information about the I/O functions provided by Cure can be found here.   Next, change the Elixir code to use Cure to send messages to C++:   defmodule Libbitcoin.Addr do   @moduledoc """   Example 4-3. Creating a Base58Check-encoded bitcoin address from a   private key.   """    alias Cure.Server, as: Cure    @cpp_compile """   g++ -std=c++11 -I./deps/cure/c_src -L./deps/cure/c_src -O3 \\   $(pkg-config --cflags --libs libbitcoin) \\   -x c++ ./deps/cure/c_src/elixir_comm.c \\   c_src/addr.cpp -o priv/addr   """   @cpp_executable "priv/addr"    def run do     Porcelain.shell(@cpp_compile)      with {:ok, pid} &lt;- Cure.start_link(@cpp_executable),          greeting &lt;- hello_world(pid) do       IO.puts(greeting)       :ok = Cure.stop(pid)     end   end    defp hello_world(pid) do     Cure.send_data(pid, "Elixir", :once)     receive do       {:cure_data, response} -&gt;         response     end   end end   Some things to note about this code:      The compile command has changed quite significantly, and getting it to work was mostly a case of going through the c_src/Makefile that Cure generated as part of its bootstrapping process, and reconstructing the compilation command to include all the necessary Cure headers and libraries.   -x c++ ./deps/cure/c_src/elixir_comm.c is telling the compiler to treat Cure\u2019s generated elixir_comm.c file as a C++ file (otherwise the g++ compiler will output warnings).   Cure\u2019s default way of opening a port to a C++ program is by the use of the Cure.load() API, which \u201cstarts a supervisor which supervises all of its children (a child in this case is a GenServer that communicates with a C/C++ program). That seemed like overkill for this situation, so I simply used Cure.Server.start_link() instead to just start a GenServer.   Cure.send_data(pid, "Elixir", :once) will only allow one response to be received back from the C++ code, which is all we need for this case. However, if multiple responses from C++ need to be processed by Elixir, then the :permanent mode flag could be used instead. More examples of the different kinds of modes can be found on Cure\u2019s README.   Let\u2019s now open up an iex console again and see if we have a conversation going:   iex -S mix iex(1)&gt; Libbitcoin.Addr.run() Hello Elixir from C++ :ok   Excellent! Now that we have Elixir and C++ talking to each other, it\u2019s time to actually get Elixir talking with Libbitcoin.   Working with Libbitcoin   Looking at the code in c_src/addr.cpp.orig (the original code from the book), it would seem that it performs two main actions:      Generate a public key from a private key   Create a bitcoin address from a public key   So, let\u2019s separate those two concerns into their own functions in our C++ code, porting over the code mostly as-is:   c_src/addr.h   #ifndef ADDR_H #define ADDR_H #include "elixir_comm.h"  std::string generate_public_key(std::string priv_key); std::string create_bitcoin_address(std::string pub_key);  #endif   c_src/addr.cpp   #include &lt;string&gt; #include "addr.h"  int main(void) {  // ... }  std::string generate_public_key(std::string priv_key) {   bc::ec_secret decoded;   bc::decode_base16(decoded, priv_key);    bc::wallet::ec_private secret(decoded, bc::wallet::ec_private::mainnet_p2kh);    // Get public key.   bc::wallet::ec_public public_key(secret);   return public_key.encoded(); }  std::string create_bitcoin_address(std::string pub_key) {   bc::wallet::ec_public public_key = bc::wallet::ec_public::ec_public(pub_key);   // Compute hash of public key for P2PKH address.   bc::data_chunk public_key_data;   public_key.to_data(public_key_data);   const auto hash = bc::bitcoin_short_hash(public_key_data);    bc::data_chunk unencoded_address;   // Reserve 25 bytes   //   [ version:1  ]   //   [ hash:20    ]   //   [ checksum:4 ]   unencoded_address.reserve(25);   // Version byte, 0 is normal BTC address (P2PKH).   unencoded_address.push_back(0);   // Hash data   bc::extend_data(unencoded_address, hash);   // Checksum is computed by hashing data, and adding 4 bytes from hash.   bc::append_checksum(unencoded_address);   // Finally we must encode the result in Bitcoin\'s base58 encoding.   assert(unencoded_address.size() == 25);   const std::string address = bc::encode_base58(unencoded_address);   return address; }   So, that\u2019s all well and good (probably), but how can we get Elixir to tell C++ to call these functions? It would be nice if there was some kind of Export-style interface where we could pass the C++ function name that we want called as a string from Elixir.  Alas, there aren\u2019t any (that I know of), so we\u2019ll have to get a bit more creative.   While searching Github for examples that used Cure, I came across the elixir-interop-examples repo, which provided me with some inspiration on how to tackle this problem: get Elixir to send an integer as the first byte of the message to C++. This integer will represent the function to be called, and C++ can switch on it to determine what action needs to be performed. Elixir binaries make it straightforward to be able to tinker with the innards of a sequence of bytes, so that\u2019s how we can proceed by updating the C++ code as follows:   c_src/addr.h   // ...  // Helper functions // REF: https://github.com/asbaker/elixir-interop-examples/blob/master/serial_ports/c_src/serial.c void process_command(byte* buffer, int bytes_read); // REF: https://github.com/asbaker/elixir-interop-examples/blob/master/serial_ports/c_src/erl_comm.h void get_string_arg(byte* buffer, char* string, int bytes_read);  #endif   c_src/addr.cpp   #include &lt;bitcoin/bitcoin.hpp&gt; #include "addr.h"  const int GENERATE_PUBLIC_KEY = 1; const int CREATE_BITCOIN_ADDRESS = 2;  int main(void) {   int bytes_read;   byte buffer[MAX_BUFFER_SIZE];    while ((bytes_read = read_msg(buffer)) &gt; 0) {     process_command(buffer, bytes_read);   }    return 0; }  // Process the command dependent on the integer value given in the message // sent from Elixir void process_command(byte* buffer, int bytes_read) {   int function = buffer[0];   char arg[1024];   get_string_arg(buffer, arg, bytes_read);   std::string retval;    if (bytes_read &gt; 0) {     switch (function) {       case GENERATE_PUBLIC_KEY:         retval = generate_public_key(arg);         break;       case CREATE_BITCOIN_ADDRESS:         retval = create_bitcoin_address(arg);         break;       default:         fprintf(stderr, "not a valid function %i\\n", function);         exit(1);     }     memcpy(buffer, retval.data(), retval.length());     send_msg(buffer, retval.size());   } else {     fprintf(stderr, "no command given");     exit(1);   } }  void get_string_arg(byte* buffer, char* arg, int bytes_read) {   buffer[bytes_read] = \'\\0\';   strcpy(arg, (char*) &amp;buffer[1]); }  std::string generate_public_key(std::string priv_key) {   // ... }  std::string create_bitcoin_address(std::string pub_key) {   // ... }   The main function now immediately delegates off to process_command, which extracts the function indicator and arg argument from the bytes passed to it by Elixir, calls the appropriate function, and sends its return value (retval) back to Elixir.   On the Elixir side, the code looks like the following:   defmodule Libbitcoin.Addr do   @moduledoc """   Example 4-3. Creating a Base58Check-encoded bitcoin address from a   private key.   """    alias Cure.Server, as: Cure    @cpp_compile """   g++ -std=c++11 -I./deps/cure/c_src -L./deps/cure/c_src -O3 \\   $(pkg-config --cflags --libs libbitcoin) \\   -x c++ ./deps/cure/c_src/elixir_comm.c \\   c_src/addr.cpp -o priv/addr   """   @cpp_executable "priv/addr"   # Private secret key string as base16   @private_key """   038109007313a5807b2eccc082c8c3fbb988a973cacf1a7df9ce725c31b14776\\   """    # Integers representing C++ methods   @generate_public_key 1   @create_bitcoin_address 2    def run do     Porcelain.shell(@cpp_compile)      with {:ok, pid} &lt;- Cure.start_link(@cpp_executable),          public_key &lt;- generate_public_key(pid),          bitcoin_address &lt;- create_bitcoin_address(pid, public_key) do       IO.puts("Public key: #{inspect(public_key)}")       IO.puts("Address: #{inspect(bitcoin_address)}")       :ok = Cure.stop(pid)     end   end    defp generate_public_key(pid) do     cure_data(pid, &lt;&lt;@generate_public_key, @private_key&gt;&gt;)   end    defp create_bitcoin_address(pid, public_key) do     cure_data(pid, &lt;&lt;@create_bitcoin_address, public_key :: binary&gt;&gt;)   end    defp cure_data(pid, data) do     Cure.send_data(pid, data, :once)     receive do       {:cure_data, response} -&gt;         response     end   end end      Both generate_public_key and create_bitcoin_address send separate requests out to the C++ code via Cure, in the same way that you might call some other external service. Each of the binary messages has an integer as its first byte, and a string taking up the rest of the message.   The @generate_public_key 1 and @create_bitcoin_address 2 module attributes mirror the similarly named constants in the C++ code, so they are coupled quite tightly out of necessity.   We\u2019re now keeping the private key on the Elixir side and passing in to C++ as a parameter, rather than have its definition be on the C++ side.   Before seeing if this actually works, for clarity\u2019s sake, here are the full C++ code samples:   c_src/addr.h   #ifndef ADDR_H #define ADDR_H #include "elixir_comm.h"  std::string generate_public_key(std::string priv_key); std::string create_bitcoin_address(std::string pub_key);  // Helper functions // REF: https://github.com/asbaker/elixir-interop-examples/blob/master/serial_ports/c_src/serial.c void process_command(byte* buffer, int bytes_read); // REF: https://github.com/asbaker/elixir-interop-examples/blob/master/serial_ports/c_src/erl_comm.h void get_string_arg(byte* buffer, char* string, int bytes_read);  #endif   c_src/addr.cpp   #include &lt;bitcoin/bitcoin.hpp&gt; #include "addr.h"  const int GENERATE_PUBLIC_KEY = 1; const int CREATE_BITCOIN_ADDRESS = 2;  int main(void) {   int bytes_read;   byte buffer[MAX_BUFFER_SIZE];    while ((bytes_read = read_msg(buffer)) &gt; 0) {     process_command(buffer, bytes_read);   }    return 0; }  // Process the command dependent on the integer value given in the message // sent from Elixir void process_command(byte* buffer, int bytes_read) {   int function = buffer[0];   char arg[1024];   get_string_arg(buffer, arg, bytes_read);   std::string retval;    if (bytes_read &gt; 0) {     switch (function) {       case GENERATE_PUBLIC_KEY:         retval = generate_public_key(arg);         break;       case CREATE_BITCOIN_ADDRESS:         retval = create_bitcoin_address(arg);         break;       default:         fprintf(stderr, "not a valid function %i\\n", function);         exit(1);     }     memcpy(buffer, retval.data(), retval.length());     send_msg(buffer, retval.size());   } else {     fprintf(stderr, "no command given");     exit(1);   } }  void get_string_arg(byte* buffer, char* string, int bytes_read) {   buffer[bytes_read] = \'\\0\';   strcpy(string, (char*) &amp;buffer[1]); }  std::string generate_public_key(std::string priv_key) {   bc::ec_secret decoded;   bc::decode_base16(decoded, priv_key);    bc::wallet::ec_private secret(decoded, bc::wallet::ec_private::mainnet_p2kh);    // Get public key.   bc::wallet::ec_public public_key(secret);   return public_key.encoded(); }  std::string create_bitcoin_address(std::string pub_key) {   // Create Bitcoin address.   // Normally you can use:   //    bc::wallet::payment_address payaddr =   //        public_key.to_payment_address(   //            bc::wallet::ec_public::mainnet_p2kh);   //  const std::string address = payaddr.encoded();    bc::wallet::ec_public public_key = bc::wallet::ec_public::ec_public(pub_key);   // Compute hash of public key for P2PKH address.   bc::data_chunk public_key_data;   public_key.to_data(public_key_data);   const auto hash = bc::bitcoin_short_hash(public_key_data);    bc::data_chunk unencoded_address;   // Reserve 25 bytes   //   [ version:1  ]   //   [ hash:20    ]   //   [ checksum:4 ]   unencoded_address.reserve(25);   // Version byte, 0 is normal BTC address (P2PKH).   unencoded_address.push_back(0);   // Hash data   bc::extend_data(unencoded_address, hash);   // Checksum is computed by hashing data, and adding 4 bytes from hash.   bc::append_checksum(unencoded_address);   // Finally we must encode the result in Bitcoin\'s base58 encoding.   assert(unencoded_address.size() == 25);   const std::string address = bc::encode_base58(unencoded_address);   return address; }   Now, the moment of truth. Open up an iex console and let\u2019s see if we can talk to Libbitcoin:   iex -S mix iex(1)&gt; Libbitcoin.Addr.run() Public key: "0202a406624211f2abbdc68da3df929f938c3399dd79fac1b51b0e4ad1d26a47aa" Address: "1PRTTaJesdNovgne6Ehcdu1fpEdX7913CK" :ok   Success! This may not be the most elegant way to talk to C++ code, but, for this use case, it works!   Improve Build Automation with a Makefile   Now that we have everything working as expected, we can make the build process more maintainable for the future if we take the compile command that we currently have in the Elixir @cpp_compile module attribute, and put it back in C-land inside the Makefile. So, building on the Makefile that Cure bootstrap provided for us, add some more code so it looks like the following:   c_src/Makefile   CC = g++ -std=c++11 APP_DIR = $(shell dirname $(shell pwd)) CURE_DEPS_DIR = $(APP_DIR)/deps/cure/c_src CURE_DEPS = -I$(CURE_DEPS_DIR) -L$(CURE_DEPS_DIR) ELIXIR_COMM_C = -x c++ $(CURE_DEPS_DIR)/elixir_comm.c LIBBITCOIN_DEPS = $(shell pkg-config --cflags --libs libbitcoin) C_FLAGS = $(CURE_DEPS) $(ELIXIR_COMM_C) $(LIBBITCOIN_DEPS) -O3 PRIV_DIR = $(APP_DIR)/priv C_SRC_DIR = $(APP_DIR)/c_src EXECUTABLES = addr  all: $(EXECUTABLES) # REF: https://www.gnu.org/software/make/manual/html_node/Static-Usage.html#Static-Usage # $&lt; - prerequisite file, $@ - executable file $(EXECUTABLES): %: %.cpp \t$(CC) $(C_FLAGS) $(C_SRC_DIR)/$&lt; -o $(PRIV_DIR)/$@   A few notes about this Makefile that I learned when figuring out its correct incantations:      When you want to call a shell function inside a Makefile that would normally look something like $(ls) on the command line, since the $() syntax is used for Makefile internal variable referencing, the syntax then becomes $(shell ls) (see The shell function).   Set up of the EXECUTABLES statement, and the code below it, means that when make all is run, for each of the filenames in that EXECUTABLES list (ie this list could be added to: EXECUTABLES = addr foo bar), the $(CC) $(C_FLAGS) $(C_SRC_DIR)/$&lt; -o $(PRIV_DIR)/$@ command gets run for each of them (for example $&lt; gets subbed out for addr.cpp and $@ gets subbed out for addr). More information about this code structure for a Makefile can be found in Makefile\u2019s Static Usage documentation.   Now, you can get Cure to compile all your C++ executables for you via mix:   mix compile.cure   If you want to have this done automatically when you compile your Elixir code, you can add the Cure compiler to the list of your project\u2019s compilers in mix.exs:   defmodule Libbitcoin.Mixfile do   use Mix.Project    def project do     [       # ...       compilers: Mix.compilers ++ [:cure, :"cure.deps"]     ]   end    # ... end   Note, though, that if you do this, every time a process calls mix compile, the C++ executables will be re-compiled. So, it may end up slowing down, say, the running of a set of tasks in a mix test.watch process, as each task will end up re-compiling the C++ code (potentially unnecessarily) before it runs. In this case, it may be best to just add a compile.cure task to run before any of the others. For other Cure-based compilation options see its README.   Since we\u2019ve now moved all the responsibility for C compilation into the Makefile, we can cull some code from addr.ex to create the final file:   defmodule Libbitcoin.Addr do   @moduledoc """   Example 4-3. Creating a Base58Check-encoded bitcoin address from a   private key.   """    alias Cure.Server, as: Cure    @cpp_executable "priv/addr"   # Private secret key string as base16   @private_key """   038109007313a5807b2eccc082c8c3fbb988a973cacf1a7df9ce725c31b14776\\   """    # Integers representing C++ methods   @generate_public_key 1   @create_bitcoin_address 2    def run do     with {:ok, pid} &lt;- Cure.start_link(@cpp_executable),          public_key &lt;- generate_public_key(pid),          bitcoin_address &lt;- create_bitcoin_address(pid, public_key) do       IO.puts("Public key: #{inspect(public_key)}")       IO.puts("Address: #{inspect(bitcoin_address)}")       :ok = Cure.stop(pid)     end   end    defp generate_public_key(pid) do     cure_data(pid, &lt;&lt;@generate_public_key, @private_key&gt;&gt;)   end    defp create_bitcoin_address(pid, public_key) do     cure_data(pid, &lt;&lt;@create_bitcoin_address, public_key :: binary&gt;&gt;)   end    defp cure_data(pid, data) do     Cure.send_data(pid, data, :once)     receive do       {:cure_data, response} -&gt;         response     end   end end   Elixir now needs to know nothing about C++ source code compilation: only that it needs to target a @cpp_executable file when it wants to talk with C++. Porcelain also now has nothing specifically to do any more, so it can be safely removed from the project mix.exs file, and its configuration removed from config.exs.   Final Thoughts   This blog post was borne out of a lot of trial and error and frustration, mostly due to me not being able to C++ my way out of a paper bag without a Stack Overflow safety net. Regardless, I hope it at least assists someone who may be attempting to try something similar, or is reading Mastering Bitcoin as well. I have no doubt that I\u2019m doing it wrong when it comes to C++, so if you have any improvement suggestions, please leave a comment. If you want to keep tabs on my gradual port over of Mastering Bitcoin code over to Elixir, check out my Mastering Bitcoin repo.   ',categories:[],tags:["elixir","bitcoin","clang"],url:"/blog/c-plus-plus-bitcoin-libraries-elixir/",teaser:"/assets/images/2017-12-14/matt-antonioli-734745-unsplash.jpg"},{title:"Wii Remote is Best Presentation Remote",excerpt:"   I use a Nintendo Wii Remote as my controller whenever I do a presentation.   In my opinion, its form factor, number of configurable buttons, and general whimsiness, make it way more interesting to use than any other commercial remote on the market. It also helps with being remembered after the presentation is finished (\u201cYou\u2019re using a video game controller with your slides\u2026?!\u201d).   However, it took a surprising amount of time and effort to finally figure out how to get a Wiimote connected to my Macbook Pro in 2017, and like plenty of developer tools, the process is certainly not straightforward. So, it is this process that I will attempt to shed some light on.   Old Skool Wiimotes Only   When I first thought about the potential of connecting a Wiimote to my laptop via Bluetooth to use as a presentation remote, I immediately went out and bought a new Wii Remote Plus, because that was what was available at game stores.   Since the connection and configuration of a Wiimote is not a native feature of Mac OS, I bought Remote Buddy to help me with that, since it seemed to be the most fully-featured software of the potential options I found.   I assumed that since the Wii Remote Plus was a superior model to the original Wii Remote, once I got Remote Buddy working, connecting via Bluetooth would be plug \u2018n\u2019 play smooth. That assumption was completely incorrect, and the Wiimote was promptly ignored by Mac OS when I tried to connect it.   Searching the web led me to the site for the Dolphin Emulator, an emulator for the Gamecube and Wii on PC hardware, which has a Wii Remote Plus connection guide. Reading it, I came to the understanding that standard (earlier-model) Wii Remotes and the first batch of released Wii Remote Pluses (both known by their device code RVL-CNT-01), seemed to have different (and incompatible) Bluetooth connection drivers to later batches of Wii Remote Pluses (device code RVL-CNT-01-TR). My Wii Remote Plus registered as the latter device code, so it looked like I\u2019d just purchased a Wii Remote-shaped paperweight since I did not even have a Wii console to use it with.   I was just about to go hunting on auction sites and in second-hand game shops, when a friend reached out via Twitter who was willing to graciously swap his old Wiimote for my latest version.  When we made the swap and I attempted a Bluetooth connection, it showed device code RVL-CNT-01, so it looked like I was perhaps in with a chance.   How to Connect   So, if you\u2019ve managed to get an old RVL-CNT-01 Wiimote and have bought Remote Buddy, here\u2019s how you can get connected (tested on Mac OS High Sierra):      Open Remote Buddy and you will be greeted with the message above telling you to \u201cPlease press 1 and 2 simultaneously on your Wiimote\u201d. You should do so.      Then, you will get a dialog box asking you to put in a passcode to use the Wiimote. This is, of course, impossible since Wiimotes do not have built in keyboards.  Do not attempt to use your keyboard to type anything in, or bother to look up whether there is some kind of master password of button-pressing combination that you should use when you see this dialog box, as there is literally nothing here that you should do with that text box.   Rather, the following options should work (as in, I have had success doing either of the following):      Ignore the dialog box and it will eventually go away   Press the \u201cCancel\u201d button      Regardless of which option you choose, assuming everything goes well, you should get a successful connection dialog, and you can begin configuring the Wiimote button functionality within Remote Buddy.   Troubleshooting   There may be times where the Wii Remote just does not want to connect or re-connect, so here are some things to watch out for that I have experienced:      If, while the Wiimote is connected, the Mac goes to sleep, upon waking up, I have found that the Wiimote connection gets lost and cannot be regained. In this case, either restarting Remote Buddy, restarting Bluetooth, or restarting Mac OS as a last resort, have resulted in being able to connect again.   If, while the Wiimote is connected, you turn off the Wiimote, or it runs out of battery, the Mac tends to not seem to notice and thinks it is still connected. Resetting Bluetooth did not seem to work, but sometimes restarting Remote Buddy did. Otherwise, restart Mac OS.   Overall, I\u2019ve generally found it difficult to re-connect a Wiimote with Remote Buddy after a connection has been lost, so I have pretty much always needed to restart Remote Buddy to do so.   Solutions to other issues can probably be found on Remote Buddy\u2019s Wiimote Support Page.   Do you have a better way to connect a Wii Remote to a computer to use as a Bluetooth remote, or have a favourite non-standard remote you like using for presentations? If so, then please leave a comment as I would love to hear about it!   ",categories:[],tags:["presentations"],url:"/blog/wii-remote-best-presentation-remote/",teaser:"/assets/images/2017-12-19/wii-remote.jpg"},{title:"Setting up a Ruby development environment for Exercism",
excerpt:'I\u2019m extremely late to the Exercism party, but I\u2019ve been having lots of fun working my way through its Ruby track (see my Exercism profile). The only thing I have missed while working on the exercises is the automated workflows that I would normally have: specifically, having tests and Rubocop run automatically after any file has changed.   When I work on any Ruby or Rails project, I immediately reach for Guard to help me out with running these kinds of processes, and this time will be no different. However, the structure of a (completed) Ruby Exercism exercise (located by default under ~/exercism/ruby/) does not look like a typical Ruby project:   my_exercise \u251c\u2500\u2500 README.md \u251c\u2500\u2500 my_exercise.rb \u2514\u2500\u2500 my_exercise_test.rb   It is a single directory with both the implementation and test file in it, which is not the kind of project setup that Guard expects will be used with Ruby. So, Guard will need some extra help on the configuration side of things to figure out how to deal with this. But first, let\u2019s install some gems to get started.   Install Gems   As well as Guard itself, we\u2019re going to want to install the following other gems:      Guard::Minitest: Tests in Exercism are written using Minitest, so this gem will make sure Guard launches the tests with the Minitest framework.   guard-rubocop: Runs Rubocop when files are modified.   Since there is no Bundler or Gemfile in sight, we will be installing these gems globally:      If you use the asdf version manager, add these gems to your default gems file so that you don\u2019t need to worry about manually installing them globally again if you update your Ruby version.    gem install guard guard-minitest guard-rubocop   Generate Guardfile   After installing the gems, change into your exercism/ruby directory (wherever it is installed on your system), and generate the Guardfile:   guard init      If you find this command does not work, depending on your Ruby version manager, you may need to perform a reshim of Ruby executables.    Typically, you will have one Guardfile per Ruby project, but rather than have one per Exercism exercise, which will get old very fast, the plan is to have a single Guardfile that any Ruby exercise can use, and that\u2019s why we generated it in the top level Ruby directory.   The generated Guardfile will look something like this:   guard :minitest do   # with Minitest::Unit   watch(%r{^test/(.*)\\/?test_(.*)\\.rb$})   watch(%r{^lib/(.*/)?([^/]+)\\.rb$}) { |m| "test/#{m[1]}test_#{m[2]}.rb" }   watch(%r{^test/test_helper\\.rb$})  { \'test\' }    # with Minitest::Spec   # watch(%r{^spec/(.*)_spec\\.rb$})   # ...    # Rails 4   # watch(%r{^app/(.+)\\.rb$}) { |m| "test/#{m[1]}_test.rb" }   # ...    # Rails &lt; 4   # ... end  guard :rubocop do   watch(%r{.+\\.rb$})   watch(%r{(?:.+/)?\\.rubocop(?:_todo)?\\.yml$}) { |m| File.dirname(m[0]) } end   Guard Minitest configuration   First, delete all the non-Minitest::Unit configuration to get that out of the way, and let\u2019s take a closer look at exactly what the remaining configuration does:   guard :minitest do   # When a test file (defined as a Ruby file that starts with `test_`)   # located under the `test/` directory is modified, run that test.   watch(%r{^test/(.*)\\/?test_(.*)\\.rb$})   # When a Ruby file located under the `lib/` directory is modified,   # run the test file located under the `test/` directory for that Ruby file.   watch(%r{^lib/(.*/)?([^/]+)\\.rb$}) { |m| "test/#{m[1]}test_#{m[2]}.rb" }   # When the `test/test_helper.rb` file is modified, run the entire test suite.   watch(%r{^test/test_helper\\.rb$})  { \'test\' } end   Unfortunately, it looks like we cannot use any of Guard\u2019s default configuration here as-is because:      In Exercism, everything is in the same directory, so there are no lib/ or test/ directories to go looking in.   The naming for Exercism test files is *_test.rb, not test_*.rb.   There is no test_helper.rb file.   So, we\u2019re going to have to re-write the configuration from scratch, but before we do that, let\u2019s determine what we actually want Guard to do for us within an Exercism exercise directory. For me at least, what I would want is:      If I modify the test file under the exercise root directory, run it again   If I modify the implementation file under the exercise root directory, run its test file, which is also located under the exercise root directory   To do that, I came up with the following:   guard :minitest, test_folders: ["."] do   # Re-test test files when they\'re modified.   watch(%r{\\A.+_test\\.rb\\z}) { |m| "./#{m[1]}" }   # Run the test file of the implementation (non-test) file that was modified.   watch(%r{\\A(.+)(?&lt;!_test)\\.rb\\z}) { |m| "./#{m[1]}_test.rb" } end   Let\u2019s examine some of the reasons behind these lines:      The test_folders flag was added to specifically tell Guard::Minitest that test files are located in the current directory (".") because by default it will look inside test or spec directories.   The string values in the blocks for both watch functions need to resemble a path, otherwise no processes would run. For example, watch(%r{\\A.+_test\\.rb\\z}) { |m| "#{m[1]}" } would not work: the block value needs to be "./#{m[1]}" (figuring this out was a painful gotcha).   Since both implementation and test file are in the same directory, the last statement uses a negative lookbehind assertion ((?&lt;!_test)) to make sure that when ./bob.rb is modified, ./bob_test.rb is run, but when ./bob_test.rb is modified, Guard does not attempt to run a non-existent ./bob_test_test.rb file.   Guard Rubocop configuration   Much like it is easier to have one Guardfile that can be used for all Exercism exercises, the same is true for your Rubocop configuration file (.rubocop.yml). If you have a specific .rubocop.yml file that you want to use just for Exercism, then place it under your exercism/ruby directory, and it will get found when you run the rubocop command.   For the guard-rubocop configuration, we will need to re-write the first rule slightly (watch(%r{.+\\.rb$})) because it currently will run Rubocop over all Ruby files, including the Exercism test file, which is not written by us (and therefore we are not responsible for whether it is written to Rubocop\u2019s standards). So, we\u2019ll use a similar negative lookbehind assertion to fix that problem:   guard :rubocop do   # Only run Rubocop over implementation files   # as test files are not written by students.   watch(%r{\\A(.+)(?&lt;!_test)\\.rb\\z})   watch(%r{(?:.+/)?\\.rubocop\\.yml\\z}) { |m| File.dirname(m[0]) } end   Putting it all together   My final ~/exercism/ruby/Guardfile, with some extra bits of configuration, looks like the following:   # frozen_string_literal: true  group :red_green_refactor, halt_on_fail: true do   guard :minitest, all_on_start: false, test_folders: ["."] do     # Re-test test files when they\'re edited.     watch(%r{\\A.+_test\\.rb\\z}) { |m| "./#{m[1]}" }     # Run the test file of the file that was edited.     watch(%r{\\A(.+)(?&lt;!_test)\\.rb\\z}) { |m| "./#{m[1]}_test.rb" }   end    guard :rubocop, all_on_start: false, cli: ["--display-cop-names"] do     # Only run Rubocop over implementation files     # as test files are not written by me.     watch(%r{\\A(.+)(?&lt;!_test)\\.rb\\z})     watch(%r{(?:.+/)?\\.rubocop\\.yml\\z}) { |m| File.dirname(m[0]) }   end end   The optional red_green_refactor group idea is lifted directly from the guard-rubocop README file, and makes perfect sense to me: get your tests passing first, and only then worry about whether your code looks nice.   This configuration might change over time, so you can always get the latest version from my Exercism Github repo.   Running Guard   Now that the Guardfile is set up with Minitest and Rubocop, you will need to make sure to tell Guard where to find this configuration when you run it:   guard --guardfile ~/exercism/ruby/Guardfile   And that should be it! You should now have a pair of friendly robots looking over your shoulder while you\u2019re solving the exercises, helping you to submit the best solution that you can.   ',categories:[],tags:["exercism","ruby","guard","rubocop"],url:"/blog/ruby-development-environment-exercism/",teaser:"/assets/images/2018-01-11/toa-heftiba-183789-unsplash.jpg"},{title:"Tmuxinator for Exercism",excerpt:'Vim and tmux are the backbone of all my development environments. tmuxinator is a Ruby gem that enables me to configure sets of terminal windows and panes for tmux sessions in YAML files, resulting in being able to use a single command, mux [project_name], to bring up a terminal-based development environment personalised exactly to me.   I\u2019m currently infatuated with Exercism (see this post about my Exercism setup for Ruby exercises), and I wanted to use tmux with it so that for any exercise I do, I could always open up a project that would provide me windows for:      a text editor   a window for the exercise tests, preferably with a process runner that would run the tests automatically whenever I modified a file   a console   Creating a YAML template that provides this kind of setup is something I do with tmuxinator for every project that I work on, but I did not want to have to create and maintain a new template for every Exercism exercise I pull down: I just wanted a single template that would work for any exercise in any language that I would potentially use on Exercism.   Dynamic tmuxinator templates   tmuxinator supports using ERB and handling command-line arguments in project files, which is something that I initially thought was interesting when I first started using it, but did not have a valid reason to use\u2026until now. The support of command-line arguments would mean that I could use a single template for Exercism that takes a programming language and an exercise name as parameters, and results in being able to use a command like:   mux exercism &lt;programming_language&gt; &lt;exercise_name&gt;   I am currently doing exercises in Ruby, Elixir, and Elm, so the template below reflects that, but you should be able to adapt it to whatever language you may be using (and I\u2019m sure I will adapt it to use others in the future):   ~/.tmuxinator/exercism   &lt;% lang = @args[0] %&gt; &lt;% exercise = @args[1] %&gt;  name: exercism # Eg: mux exercism ruby hello-world =&gt; exercism/ruby/hello-world root: ~/exercism/&lt;%= lang %&gt;/&lt;%= exercise %&gt;  on_project_first_start:   &lt;% if lang == "elm" %&gt;   - npm install   &lt;% end %&gt;  pre_window:   &lt;% if lang == "ruby" %&gt;   - asdf local ruby 2.5.0   &lt;% elsif lang == "elixir" %&gt;   - asdf local elixir 1.5.3   - asdf local erlang 20.2   &lt;% elsif lang == "elm" %&gt;   - asdf local elm 0.18.0   &lt;% end %&gt;  startup_window: editor  windows:   - editor: vim   &lt;% if lang == "ruby" %&gt;   - tests: guard --guardfile ~/exercism/ruby/Guardfile   - console: irb   &lt;% elsif lang == "elixir" %&gt;   - tests: # placeholder window to run tests   - console: iex   &lt;% elsif lang == "elm" %&gt;   - tests: npm run watch   - console: elm repl   &lt;% end %&gt;   A couple of notes on this setup:      @args is the array available in the template where passed-in command line arguments get stored. Arguments can also be taken in as key-value pairs (eg mux exercism lang=ruby exercise=hello-world), which would then be available via a @settings variable (eg @settings["lang"]), but I think the basic array works best for this template.   I use asdf for managing the versions of all languages, but you could use whatever version manager you would like in the pre_window config.   I keep all my tmuxinator templates in my dotfiles repo, so feel free to use them as examples to build on for your own templates, and good luck with your future Exercism-ing!   ',categories:[],tags:["exercism","ruby","tmux","tmuxinator"],url:"/blog/tmuxinator-exercism/",teaser:"/assets/images/2018-01-12/rawpixel-788527-unsplash.jpg"},{title:"Connecting Elm to Phoenix 1.3",excerpt:'Want to start using Elm 0.18 on the front end of a Phoenix app (in this case, Phoenix 1.3)? This blog post will go over the steps I use to get these two talking to each other.      Looking to connect Elm to a Phoenix 1.4 app? Go and check out the update to this blog post: Connecting Elm to Phoenix 1.4 with webpack    Assuming you have already installed Phoenix 1.3, let\u2019s kick things off with a new application.   Generate Phoenix app   mix phx.new phoenix_with_elm cd phoenix_with_elm mix ecto.create mix phx.server   Navigate to http://localhost:4000/ and you should see the familiar Phoenix welcome screen.      No surprises here. Close down the server, and let\u2019s move on.   Generate Elm app   First, install Elm if you haven\u2019t already:   npm install elm --global   Next, in order to help us generate an Elm app with a default structure and sensible configuration, we\u2019ll use Create Elm App (inspired by Create React App):   npm install create-elm-app --global   Generate the new Elm app inside the \u201cfront end\u201d of the Phoenix application, which in this case means the assets/ directory:   cd assets create-elm-app elm   You should now have an elm folder alongside your js and css folders. Let\u2019s make sure it works as we expect:   cd elm elm-app start   Starting the Elm app should then automatically open a browser window for you at http://localhost:3000/, and you should see a message saying that\u2026      Note that the Elm app is running independently here: it knows nothing about the Phoenix environment that it\u2019s located in, and is happily using assets, like the image that you see, from its own assets/elm/public/ directory.   Now that we\u2019ve confirmed that both the Phoenix app and the Elm app work of their own accord, it\u2019s time to connect them together. Close down the Elm server and let\u2019s write some config.   Connect Elm to Phoenix   Phoenix uses Brunch out of the box as its asset build tool, so that\u2019s what we\u2019ll use to compile the Elm code. In order to do that, we\u2019ll need the elm-brunch plugin, so let\u2019s install that and get it configured.   First, navigate back to the assets/ folder and install elm-brunch:   npm install --save-dev elm-brunch   Then, open up brunch-config.js in a text editor and make the following changes:   exports.config = {   // ...    // Step 1: Add "elm" to the list of paths being watched.   paths: {     watched: ["static", "css", "elm", "js", "vendor"],   },    // Step 2: Add the elm-brunch plugin configuration.   plugins: {     elmBrunch: {       elmFolder: "elm",       mainModules: ["src/Main.elm"],       outputFolder: "../vendor",       outputFile: "elm.js",       makeParameters: ["--warn"]     },     // ...   }   // ... }   Note here specifically the line outputFolder: "../vendor": this is to ensure that the generated elm.js file gets compiled and imported before the js/app.js file (it is Brunch convention that files in the assets/vendor directory get compiled before code in other folders; see Brunch\u2019s file config documentation for more details).      The brunch-config.js configuration does apparently allow for before and after statements to specify that some files should be compiled before or after others, but I have not had any luck getting them to work, so please consider having the Elm files compiled out into the vendor folder a hack/workaround for now (since code that we write in the elm directory does not constitute an external library). If you have been able to use before/after compilation order statements in a Phoenix/Elm project, please leave a comment with a link to your config! [Update 2018-02-16] See the update below that puts your code back in the js/ directory, where it belongs:    Display Elm app in Phoenix template   So that we show both Phoenix and Elm working together, let\u2019s keep the default generated Phoenix layout template as-is, and replace the content of the page index template with a &lt;div&gt; tag for the Elm app:   lib/phoenix_with_elm_web/templates/page/index.html.eex   &lt;div id="elm-main"&gt;&lt;/div&gt;   Next, we\u2019ll target that &lt;div&gt; tag in the app Javascript file and get it to replace it with the content of the Elm app, so add the following to the end of the file:   assets/js/app.js   const elmDiv = document.getElementById("elm-main"); Elm.Main.embed(elmDiv);   Now, run mix phx.server again and navigate to http://localhost:4000 to see if we\u2019re in business:      Not quite yet, it would seem: we can see that the Elm app is being rendered in the template, but we\u2019ve got a broken image. This is because that image currently lives inside the Elm app at assets/elm/public/logo.svg, and Phoenix doesn\u2019t know anything about compilation of static image assets within Elm applications: it\u2019s looking for assets under its own assets/static/ directory.   The path of least resistance here is, I think, to move all assets to where Phoenix is expecting to find them, and change the Elm code to point to them.   So, first, move the logo image into Phoenix\u2019s image assets directory:   mv assets/elm/public/logo.svg assets/static/images/logo.svg   Then, change the Elm code to look for the image in Phoenix (/images/logo.svg), rather than in Elm (/logo.svg):   assets/elm/src/Main.elm   module Main exposing (..)  -- ...  view : Model -&gt; Html Msg view model =     div []         [ img [ src "/images/logo.svg" ] []         , h1 [] [ text "Your Elm App is working!" ]         ]   Now, at http://localhost:4000/, you should see the following:      Great! You\u2019re now successfully bootstrapped to start building out your new Phoenix-and-Elm powered app!             Update 2018-02-16   To put the Elm-generated Javascript file into the js directory (rather than in vendor, which should only be for third-party code), and then have the app use it properly, edit the codebase in the following way:   assets/brunch-config.js   exports.config = {   // ...   plugins: {     // Specify outputFolder to be in the js/ directory, along with app.js     elmBrunch: {       elmFolder: "elm",       mainModules: ["src/Main.elm"],       outputFolder: "../js",       outputFile: "elm.js",       makeParameters: ["--warn"]     },      // Do not use ES6 compiler in vendor or Elm-generated Javascript code.     babel: {       ignore: [         /vendor/,         "js/elm.js"       ]     },     // ...   }   // ... }   Then, specifically import the Elm variable in from elm.js, now located in the same directory as app.js, rather than just assuming it is available to use:   assets/js/app.js   import Elm from "./elm"  const elmDiv = document.getElementById("elm-main"); Elm.Main.embed(elmDiv);   Back to \u201cDisplay Elm app in Phoenix template\u201d   ',categories:[],tags:["elixir","phoenix","elm"],url:"/blog/elm-phoenix-13/",teaser:"/assets/images/2018-02-09/functional_web_wallpaper.jpg"},{title:"Migrating a Phoenix and Elm app from REST to GraphQL",
excerpt:'GraphQL enables consumers of an API to ask for the exact data they want from it. This is as opposed to REST, where the API provider dictates what and how data will be served, and it is up to the consumer to make sense of whatever data it receives.   In an app that uses Phoenix for the back end and Elm for the front end, the flow of data via APIs for a query will usually take the form of:      Elm requests Phoenix for data via an API call   Phoenix provides the requested data via a JSON response   Elm decodes the data from the response and displays it   This blog post will cover migrating the APIs of an existing Phoenix/Elm from using REST to using GraphQL, including:      Adding GraphQL schemas and types to the Phoenix back end   Migrating from Phoenix controllers to resolvers   Migrating Elm-side JSON response decoding from using JSON.Decode to ValueSpec from the elm-graphql Elm package.   Translating GraphQL requests created in GraphiQL into Elm code, and sending them to Phoenix   Starting Point   The app that we are going to use as a baseline to migrate from REST to GraphQL is an Address Book app that was originally created by Ricardo Garc\xeda Vega over a series of blog posts (Ricardo\u2019s Github repo).      I learned a lot from coding up the app while reading those posts, and I thank Ricardo sincerely for putting the time into his write-ups! Afterwards, I upgraded the app to Phoenix 1.3, played around with the codebase, and put my version of it in its own Github repository, so it is this version of the app that we will use. If you are following along at home, please clone my repo and follow the README instructions to get up and running, or you can skip straight to the finished product, which is in the repo\u2019s graphql branch.   Current State of Play   Before jumping into migrating to GraphQL, let\u2019s take a look at some of the application\u2019s current structure and see how communication is done via REST requests.   Back End   First, let\u2019s have a look at the router:   lib/phoenix_and_elm_web/router.ex   defmodule PhoenixAndElmWeb.Router do   # ...   scope "/api", PhoenixAndElmWeb do     pipe_through :api      scope "/v1", V1 do       resources "/contacts", ContactController, only: [:index, :show]     end   end    scope "/", PhoenixAndElmWeb do     pipe_through :browser      get "/*path", AddressBookController, :index   end end   In this app, AddressBook is the Phoenix context behind which Contacts live. So, the AddressBookController\u2019s purpose is solely to render the HTML tag where the Elm app will be embedded:   lib/phoenix_and_elm_web/templates/address_book/index.html.eex   &lt;div id="elm-main"&gt;&lt;/div&gt;   Once the Elm app is embedded, it can make calls out to the versioned (/v1) contact APIs to fetch contact information, which will be handled by the ContactController:   lib/phoenix_and_elm_web/controllers/v1/contact_controller.ex   defmodule PhoenixAndElmWeb.V1.ContactController do   use PhoenixAndElmWeb, :controller   alias PhoenixAndElm.AddressBook    def index(conn, params) do     contacts = AddressBook.list_contacts(params)     json(conn, contacts)   end    def show(conn, %{"id" =&gt; id}) do     contact = AddressBook.get_contact!(id)     json(conn, contact)   end end   There are two APIs that Phoenix provides: listing contacts and showing (retrieving) information for a contact. Each function talks only to the AddressBook context, leaving the responsibility of determining how the information requested is provided up to the Address Book \u201csub-system\u201d: as far as the controller functions are concerned, they provide some parameter to an AddressBook function, and get returned some value which they then serialize into JSON. So, this controller is effectively our REST boundary, and it is these few lines of functionality that will need to be replicated when migrating over to GraphQL.   Front End   The contact API URL (api/v1/contacts), that maps to the ContactController in the Phoenix app, is defined in a common Commands.elm file so that it can be easily shared between the different API calls coming from Elm:   assets/elm/src/Commands.elm   module Commands exposing (contactsApiUrl)   contactsApiUrl : String contactsApiUrl =     "/api/v1/contacts"   The two main models in the Elm app are Contact and ContactList, and code related to how to fetch information to fill the records of these models is kept in Commands files under directories named after the model itself.   Contact via REST   Let\u2019s see how information for a single contact is retrieved:   assets/elm/src/Contact/Commands.elm   module Contact.Commands exposing (fetchContact)  import Commands exposing (contactsApiUrl) import Contact.Decoder as Decoder import Contact.Messages exposing (ContactMsg(FetchContact)) import Http import Messages exposing (Msg(ContactMsg))   fetchContact : Int -&gt; Cmd Msg fetchContact id =     let         apiUrl =             contactsApiUrl ++ "/" ++ toString id     in         Decoder.decoder             |&gt; Http.get apiUrl             |&gt; Http.send FetchContact             |&gt; Cmd.map ContactMsg   When Contact.Commands.fetchContact is called within the Elm app, a Cmd is sent to the Elm Runtime, with a Msg type of ContactMsg FetchContact, telling it to send a request to the apiUrl (looking something like api/v1/contacts/5), and decode the response using Contact.Decoder.   The decoder used for a Contact looks like the following:   assets/elm/src/Contact/Decoder.elm   module Contact.Decoder exposing (decoder)  import Contact.Model exposing (Contact) import Json.Decode as Decode exposing (field, int, string) import Json.Decode.Extra exposing ((|:))   decoder : Decode.Decoder Contact decoder =     Decode.succeed         Contact         |: (field "id" int)         |: (field "first_name" string)         |: (field "last_name" string)         |: (field "gender" int)         |: (field "birth_date" string)         |: (field "location" string)         |: (field "phone_number" string)         |: (field "email" string)         |: (field "headline" string)         |: (field "picture" string)   The ContactMsg FetchContact message gets handled in Contact.Update, which updates the Contact model record:   assets/elm/src/Contact/Update.elm   module Contact.Update exposing (update)  import Contact.Messages exposing (ContactMsg(FetchContact)) import Messages exposing (Msg) import Model exposing (Model, RemoteData(Failure, Success))   update : ContactMsg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         FetchContact (Ok response) -&gt;             ( { model | contact = Success response }, Cmd.none )          FetchContact (Err error) -&gt;             ( { model | contact = Failure "Contact not found" }, Cmd.none )   The use of Cmd.map ContactMsg in Contact.Commands is what enables the FetchContact message to be handled in a \u201cchild\u201d update function (in this case Contact.Update is considered a child of Update), which can help reduce the size of the \u201cparent\u201d update function:   module Update exposing (update, urlUpdate)  import Contact.Update import Messages exposing (Msg(ContactMsg, ContactListMsg, NavigateTo, ...)) import Model exposing (Model, RemoteData(NotRequested, Requesting)) -- ...   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         ContactMsg msg -&gt;             Contact.Update.update msg model          ContactListMsg msg -&gt;             ContactList.Update.update msg model          UpdateSearchQuery value -&gt;             ( { model | search = value }, Cmd.none )          -- ... -- ...   Here, in the \u201cparent\u201d update function, there are messages that are handled directly, like UpdateSearchQuery, while messages that are wrapped in a ContactMsg message, for example, are delegated straight off to the Contact.Update.update function.      See this blog post about \u201cThe Translator Pattern\u201d in Elm for more information about this style of message passing.    Contact List via REST   Now that we know about fetching a single contact to populate a Contact record, what about fetching a list of contacts to populate a ContactList record?   assets/elm/src/ContactList/Commands.elm   module ContactList.Commands exposing (fetchContactList)  import Commands exposing (contactsApiUrl) import ContactList.Messages exposing (ContactListMsg(FetchContactList)) import ContactList.Decoder as Decoder import Http import Messages exposing (Msg(ContactListMsg))   fetchContactList : Int -&gt; String -&gt; Cmd Msg fetchContactList page search =     let         apiUrl =             contactsApiUrl                 ++ "?search="                 ++ search                 ++ "&amp;page="                 ++ (toString page)     in         Decoder.decoder             |&gt; Http.get apiUrl             |&gt; Http.send FetchContactList             |&gt; Cmd.map ContactListMsg   Fetching a list of contacts looks very similar to fetching a single contact from an API callout point of view, except that we are now providing page and search parameters, resulting in an apiUrl that looks something like api/v1/contacts?search=paul&amp;page=2.   Just like with the contact API call, we decode the response, this time using the ContactList.Decoder, and then send a Cmd with a Msg of type ContactListMsg FetchContactList, which will then be handled in the ContactList.Update.update function.   The ContactList.Decoder itself delegates its Contact-decoding logic to Contact.Decoder, defining only fields related to data about a paginated list of records:   assets/elm/src/ContactList/Decoder.elm   module ContactList.Decoder exposing (decoder)  import Contact.Decoder import ContactList.Model exposing (ContactList) import Json.Decode as Decode exposing (field, int, list) import Json.Decode.Extra exposing ((|:))   decoder : Decode.Decoder ContactList decoder =     let         contact =             Contact.Decoder.decoder     in         Decode.succeed             ContactList             |: (field "entries" (list contact))             |: (field "page_number" int)             |: (field "total_entries" int)             |: (field "total_pages" int)   The reason that the field for a list of contacts is specifically named "entries" is due to the Phoenix app using Scrivener.Ecto for pagination. Paginated contact lists are provided in a Scrivener.Page struct, that contains the list of items its paginating under an :entries map key.   And I think that about covers the request/response handling code on the front end. So, it looks like we will need to:      Change the URL in Commands.elm to reference a different GraphQL endpoint URL   Switch out the Http package for a GraphQL client package   Remove decoders, and replace with GraphQL request builders   Migrate Back End to GraphQL   Phew, that is a fair bit to take in for what is a tour of only one conceptual part of a toy app, but at least now we have an idea of the API-related parts of the app that are targets for change in both the front and back ends.   So, without further ado, let\u2019s tackle migration of the back end first.   Absinthe   Absinthe is the go-to toolkit for using GraphQL in Elixir, with its authors pretty much writing the book on the subject, hence we will be use it in this project. So, open up mix.exs, and add the following libraries:   mix.exs   defmodule PhoenixAndElm.Mixfile do   # ...   defp deps do     [       # ...       {:absinthe, "~&gt; 1.4"},       {:absinthe_plug, "~&gt; 1.4"}     ]   end end      Note that even though this is a Phoenix app, for this example we will not need the Absinthe.Phoenix package since we will be sending messages via HTTP, and not via Phoenix channels/websockets.    Types   Once you have run mix deps.get, create a new lib/phoenix_and_elm_web/schema/ directory and let\u2019s create some GraphQL types to describe the data we want to query:   lib/phoenix_and_elm_web/schema/types.ex   defmodule PhoenixAndElmWeb.Schema.Types do   use Absinthe.Schema.Notation   import_types(Absinthe.Type.Custom)    object :contact_list do     field(:total_entries, :integer)     field(:total_pages, :integer)     field(:page_number, :integer)     field(:page_size, :integer)     field(:entries, list_of(:contact))   end    object :contact do     field(:id, :integer)     field(:first_name, :string)     field(:last_name, :string)     field(:gender, :integer)     field(:birth_date, :date)     field(:location, :string)     field(:phone_number, :string)     field(:email, :string)     field(:headline, :string)     field(:picture, :string)   end end   The :contact object almost directly mirrors the contact database schema, with the one small caveat here being that the GraphQL specification does not provide a :date type for the :birth_date field, so the Absinthe.Type.Custom module provides one that we can use.   The :contact_list object essentially describes a Scrivener.Page, though for simplicity\u2019s sake, we are limiting entries to only containing a list_of(:contact) (Scrivener can, of course, paginate other types of things!).   Schema   Now, we need the schema itself to describe the queries we will allow into the Phoenix app, what arguments each query takes, and what execution should happen for each valid query (done here in the form of resolvers).   lib/phoenix_and_elm_web/schema/schema.ex   defmodule PhoenixAndElmWeb.Schema do   use Absinthe.Schema   alias PhoenixAndElmWeb.ContactResolver   import_types(PhoenixAndElmWeb.Schema.Types)    query do     field :contacts, type: :contact_list do       arg(:search, non_null(:string))       arg(:page, non_null(:integer))       resolve(&amp;ContactResolver.list_contacts/3)     end      field :contact, type: :contact do       arg(:id, non_null(:id))       resolve(&amp;ContactResolver.get_contact/3)     end   end end   Resolvers   Resolvers can tend to get quite long, so it is considered good practice to put them into their own top level directory under the web app, so let\u2019s do that and create a ContactResolver:   lib/phoenix_and_elm_web/resolvers/contact_resolver.ex   defmodule PhoenixAndElmWeb.ContactResolver do   alias PhoenixAndElm.AddressBook    def list_contacts(_parent, args, _resolution) do     contacts = AddressBook.list_contacts(args)     {:ok, contacts}   end    def get_contact(_parent, %{id: id}, _resolution) do     contact = AddressBook.get_contact!(id)     {:ok, contact}   end end   This resolver looks suspiciously like the original REST ContactController, and this is mainly thanks to having the AddressBook context hide away all of the complexity around preparing contact data sets for delivery to the front end. Handy!   One extra tiny change that needs to happen before we move on: did you notice in the get_contact() function that the map that comes through as the args parameter has atoms for keys, as opposed to the ContactController, where the keys are strings? We\u2019re handling that fine in the get_contact function, but in list_contacts(), we\u2019re passing args straight through to AddressBook.list_contacts(), which is expecting a map with string keys, so we will have to update it to expect one with atom keys:   lib/phoenix_and_elm/address_book/address_book.ex   defmodule PhoenixAndElm.AddressBook do   # ...   def list_contacts(%{search: query} = params) do     # ...   end end   This small change is the only time we should have to climb over the AddressBook context wall.   Router   Finally, let\u2019s expose our new GraphQL API to the world by changing the router to send /api requests to the new schema, and /api/graphiql requests to GraphiQL.   lib/phoenix_and_elm_web/router.ex   defmodule PhoenixAndElmWeb.Router do   # ...   scope "/api" do     pipe_through :api      forward "/graphiql", Absinthe.Plug.GraphiQL,       schema: PhoenixAndElmWeb.Schema,       interface: :simple      forward "/", Absinthe.Plug, schema: PhoenixAndElmWeb.Schema   end    scope "/", PhoenixAndElmWeb do     pipe_through :browser      get "/*path", AddressBookController, :index   end end   Testing with GraphiQL   Speaking of GraphiQL, let\u2019s use it to help us build the queries that we\u2019re going to want to have Elm send to it. Navigating to http://localhost:4000/api/graphiql will bring up the GraphiQL interface, so let\u2019s start with a GraphQL query for a single contact.   We need a query that will take in a contact ID parameter, and will return all the fields that we currently have defined in the Contact.Decoder Elm file:   query($contactID: ID!) {   contact(id: $contactID) {     id     firstName     lastName     gender     birthDate     location     phoneNumber     email     headline     picture   } }      The exclamation mark on ID! means that the field is non-nullable, so you have to provide an ID or the query will error out.    Let\u2019s now input that in GraphiQL and fire it off to the Phoenix app, along with a contactID parameter:      Looks pretty good to me! Now, how about for a list of contacts?   We need a query that will take in search and page number parameters, and return all the fields that we currently have defined in the ContactList.Decoder Elm file:   query($searchQuery: String!, $pageNumber: Int!) {   contacts(search: $searchQuery, page: $pageNumber) {     entries {       id       firstName       lastName       gender       birthDate       location       phoneNumber       email       headline       picture     },     pageNumber,     totalEntries     totalPages,   } }   And for a search query of "Barn", the results are\u2026      \u2026all of the users with a first name of Barney! Great! We now know the GraphQL queries that we want the front end to send to the back end, and now, it\u2019s time to get them translated into Elm code! (At this point, now that the migration from controllers to resolvers is complete, it is safe to delete ContactController from the app.)   Migrate Front End to GraphQL   Before we start, we will need a GraphQL package for Elm, and for this project, we will use elm-graphql. Let\u2019s install it directly in the Elm app:   cd assets/elm elm-package install jamesmacaulay/elm-graphql   Now, since the Phoenix-side API URL has changed, the first thing we need to do is make our easiest edit, and tell Elm the new location to send requests to:   assets/elm/src/Commands.elm   module Commands exposing (apiUrl)   apiUrl : String apiUrl =     "/api"   Contact via GraphQL   Now, let\u2019s begin the process of getting the display of a single contact working again, starting with changing Contact.Commands to use GraphQL when sending requests:   assets/elm/src/Contact/Commands.elm   module Contact.Commands exposing (fetchContact)  import Commands exposing (apiUrl) import Contact.Messages exposing (ContactMsg(FetchContact)) import Contact.Request as Request import GraphQL.Client.Http as Http import Messages exposing (Msg(ContactMsg)) import Task exposing (Task)   fetchContact : Int -&gt; Cmd Msg fetchContact id =     id         |&gt; Request.fetchContact         |&gt; Http.sendQuery apiUrl         |&gt; Task.attempt FetchContact         |&gt; Cmd.map ContactMsg   Once we\u2019ve built the GraphQL request to fetch a contact (whose Contact.Request module we will create next), we:      use GraphQL.Client.Http.sendQuery to create a Task to send the query off to the apiUrl   ask the Elm runtime to attempt to run that Task   send a Msg of type ContactMsg FetchContact, which gets handled just like before in Contact.Update (no changes needed to that file)   Now, let\u2019s create that Contact.Request module to replace the Contact.Decoder.  Unlike in GraphiQL, we cannot use raw GraphQL queries in Elm-land, so we will have to port the content of the query to Elm (but let\u2019s keep the GraphQL query that we want generated as a comment, just so we can keep our bearings):   assets/elm/src/Contact/Request.elm   module Contact.Request exposing (fetchContact, contactSpec)  import Contact.Model exposing (Contact) import GraphQL.Request.Builder as Builder     exposing         ( Document         , NonNull         , ObjectType         , Query         , Request         , ValueSpec         , field         , int         , object         , string         , with         ) import GraphQL.Request.Builder.Arg as Arg import GraphQL.Request.Builder.Variable as Var   {-| query($contactID: ID!) {   contact(id: $contactID) {     id     firstName     lastName     gender     birthDate     location     phoneNumber     email     headline     picture   } } -} fetchContact : Int -&gt; Request Query Contact fetchContact id =     let         contactID =             Arg.variable (Var.required "contactID" .contactID Var.int)          contactField =             Builder.extract                 (field                     "contact"                     [ ( "id", contactID ) ]                     contactSpec                 )          params =             { contactID = id }     in         contactField             |&gt; Builder.queryDocument             |&gt; Builder.request params   contactSpec : ValueSpec NonNull ObjectType Contact vars contactSpec =     Contact         |&gt; object         |&gt; with (field "id" [] int)         |&gt; with (field "firstName" [] string)         |&gt; with (field "lastName" [] string)         |&gt; with (field "gender" [] int)         |&gt; with (field "birthDate" [] string)         |&gt; with (field "location" [] string)         |&gt; with (field "phoneNumber" [] string)         |&gt; with (field "email" [] string)         |&gt; with (field "headline" [] string)         |&gt; with (field "picture" [] string)   The content of the contactSpec function pretty much lines up logically with the code that we have in Contact.Decoder, while fetchContact:      builds the query step by step with the let expressions   creates a GraphQL.Request.Builder.Document for the query   creates a GraphQL.Request.Builder.Request from the Document that gets sent to the apiUrl in Contact.Commands   One final small change is to make sure that the Contact.Messages file, which has been referencing the Http library, now needs to reference GraphQL.Client.Http instead:   assets/elm/src/Contact/Messages.elm   module Contact.Messages exposing (ContactMsg(..))  import Contact.Model exposing (Contact) import GraphQL.Client.Http as Http   type ContactMsg     = FetchContact (Result Http.Error Contact)   At this point, individual contact detail pages should be displaying, so navigate to the URL of a known contact (eg http://localhost:4000/contacts/4), and you should see a page that looks something like:      The sample data in the app is generated randomly, so the contact you see from the URL above will most likely be different, but, it works! Performing a search, or navigating to the root page of the app, or doing anything that results in displaying a list of contacts will not work just yet, though, so let\u2019s polish that task off and finish up this migration.   Contact List via GraphQL   This process will look (and be) very similar to how we migrated the contacts, so let\u2019s briskly get through how the files will change:   assets/elm/src/ContactList/Commands.elm   module ContactList.Commands exposing (fetchContactList)  import Commands exposing (apiUrl) import ContactList.Messages exposing (ContactListMsg(FetchContactList)) import ContactList.Request as Request import GraphQL.Client.Http as Http import Messages exposing (Msg(ContactListMsg)) import Task exposing (Task)   fetchContactList : Int -&gt; String -&gt; Cmd Msg fetchContactList pageNumber search =     search         |&gt; Request.fetchContactList pageNumber         |&gt; Http.sendQuery apiUrl         |&gt; Task.attempt FetchContactList         |&gt; Cmd.map ContactListMsg   assets/elm/src/ContactList/Messages.elm   module ContactList.Messages exposing (ContactListMsg(..))  import ContactList.Model exposing (ContactList) import GraphQL.Client.Http as Http   type ContactListMsg     = FetchContactList (Result Http.Error ContactList)     | Paginate Int     | ResetSearch     | SearchContacts   assets/elm/src/ContactList/Request.elm   module ContactList.Request exposing (fetchContactList)  import Contact.Request import ContactList.Model exposing (ContactList) import GraphQL.Request.Builder as Builder     exposing         ( NonNull         , ObjectType         , Query         , Request         , ValueSpec         , field         , int         , list         , object         , with         ) import GraphQL.Request.Builder.Arg as Arg import GraphQL.Request.Builder.Variable as Var   {-| query($searchQuery: String!, $pageNumber: Int!) {   contacts(search: $searchQuery, page: $pageNumber) {     entries {       id       firstName       lastName       gender       birthDate       location       phoneNumber       email       headline       picture     },     pageNumber,     totalEntries,     totalPages   } } -} fetchContactList : Int -&gt; String -&gt; Request Query ContactList fetchContactList page search =     let         searchQuery =             Arg.variable (Var.required "searchQuery" .searchQuery Var.string)          pageNumber =             Arg.variable (Var.required "pageNumber" .pageNumber Var.int)          contactsField =             Builder.extract                 (field                     "contacts"                     [ ( "search", searchQuery ), ( "page", pageNumber ) ]                     contactListSpec                 )          params =             { searchQuery = search             , pageNumber = page             }     in         contactsField             |&gt; Builder.queryDocument             |&gt; Builder.request params   contactListSpec : ValueSpec NonNull ObjectType ContactList vars contactListSpec =     let         contact =             Contact.Request.contactSpec     in         ContactList             |&gt; object             |&gt; with (field "entries" [] (list contact))             |&gt; with (field "pageNumber" [] int)             |&gt; with (field "totalEntries" [] int)             |&gt; with (field "totalPages" [] int)   Pretty similar set of changes, right?  The only real differences are the number of parameters for the query, and the contactSpec nesting inside contactListSpec, which is in a similar vein to the nesting of the Contact.Decoder inside a ContactList.Decoder.   Now, you should be able to view any page in the app that displays a list of contacts. The GraphQL migration is complete, and you can safely remove the Decoder files from the application.      Any issues getting things to work? Have a look at the graphql branch and see if there are any differences from your code.    Wrapping Up   There is so much more to GraphQL than what I\u2019ve managed to fit into this admittedly long blog post. We only dealt with queries, and did not even touch other GraphQL fundamentals like mutations, which cover modifying server-side data (though take a look at the Elm hipster stack repo for some good examples of that).   However, I hope that you enjoyed this small taste of Phoenix, Elm, and GraphQL working together, and if you join me in making further inroads with this fully functional tech stack moving forward, I would love to hear about it!   ',categories:[],tags:["elixir","phoenix","elm","rest","graphql","api"],url:"/blog/migrate-phoenix-elm-app-rest-graphql/",teaser:"/assets/images/2018-03-07/address-book-contacts-index.png"},{title:"Graph-driven Refactoring in Elm",
excerpt:'After completing the \u201cPhoenix and Elm, a real use case\u201d tutorial by Ricardo Garc\xeda Vega, I went back and refactored parts of the codebase in order to help me really understand it, and get everything straight in my head (I wrote about this in Migrating a Phoenix and Elm app from REST to GraphQL, and you can see the results in my repository versus the original).   Architecting in the Dark   I could not seem to find any generally-accepted ways to architect Elm code in the same way as I would architect Elixir/Phoenix or Ruby/Rails code, so I just let my instincts guide the code architecture direction, which currently lean towards small(er) modules and functions.   So, I thought it would be a good idea to break out code from big Elm files into individual smaller files located under conceptual concerns directories. For example, I extracted application code that looked like it was mostly concerned with a Contact out into a structure like this:   Contact/   Commands.elm   Decoder.elm   Messages.elm   Model.elm   Update.elm   View.elm   Messages to update a Contact would be wrapped in a top level Msg type called ContactMsg, and when that came through the main update function, handling of the update would be immediately delegated out to Contact.Update.   assets/elm/src/Update.elm   module Update exposing (update, ...)  import Messages exposing (Msg(ContactMsg, ...)) import Model exposing (Model, ...) -- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         ContactMsg msg -&gt;             Contact.Update.update msg model  -- ...   The nested message inside a ContactMsg, is completely opaque to Update, and it was only Contact.Update that knew what should happen when, in this case, a FetchContact message is received:   assets/elm/src/Contact/Update.elm   module Contact.Update exposing (update)  import Contact.Messages exposing (ContactMsg(FetchContact)) import Messages exposing (Msg) import Model exposing (Model, RemoteData(Failure, Success))   update : ContactMsg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         FetchContact (Ok response) -&gt;             ( { model | contact = Success response }, Cmd.none )          FetchContact (Err error) -&gt;             ( { model | contact = Failure "Contact not found" }, Cmd.none )   This sort of thing seemed like a good pattern to me in the absence of any others, but there was no way I could really tell if it was actually any good, or if there would be any issues, performance or otherwise, related to coding Elm in this way.   Graphing Dependencies   Until, that is, I was introduced to elm-module-graph, which enables you to visually explore package and module dependencies in an Elm project. It helped me understand that:      My code was not really properly separated out into the concerns I thought it was.   I had the Elm equivalent of a God object-in-the-making: a module that too many other modules had knowledge about. These modules, given enough other modules that have it as a dependency, can lead to longer Elm compile times every time a change is made on them.   Create Graph File   Here is how I generated the needed module-graph.json for the Address Book app (adapt the commands as necessary for your own project, and make sure you have Python installed):   cd assets/elm wget https://raw.githubusercontent.com/justinmimbs/elm-module-graph/master/elm-module-graph.py chmod 744 elm-module-graph.py ./elm-module-graph.py src/Main.elm   Display Graph   Next, navigate to https://justinmimbs.github.io/elm-module-graph/ and upload the generated module-graph.json file, and you will see something like this:      The default graph display includes modules from external libraries, so let\u2019s hide them (by toggling the display of the external packages at the top) so that we can focus on the application code:      Find Long Bars   If a module has a long bar with attached lines in the graph, that means that it is imported by many modules. Here, it is clear that the Messages module, displayed right in the middle of the graph, has the longest bar, so let\u2019s take a clearer look at its dependencies by clicking on it:         The modules in red are the modules that Messages imports into itself. These are not the relationships we need to worry about.   The modules in blue are the modules that import Messages into themselves. Here, we can see that a great many \u201cchild\u201d modules like Contact.Update, have knowledge about \u201cparent\u201d Messages, but Contact.Update should really only know about the type of message it deals with directly, the ContactMsg, and leave knowledge about (and handling of) Msg type messages to the Messages module.   We have some leaking of encapsulation within the concerns, so, let\u2019s see what can be done to fix them, with the initial goal of not having any modules under the Contact concern import the Messages module. The starting point for this refactor will be the rest branch of the Address App, so if you\u2019re following along at home, clone the repo and let\u2019s get refactoring!      If you get stuck while refactoring at any step of the way, have a look at the rest-refactor branch of the Address App for guidance.    Initial Preparation   Extract RemoteData into its own Module   Currently, the RemoteData type is contained in the top-level Model module. Since Contact concern modules needs to know about RemoteData, but not Model (they should only need to know about Contact.Model), let\u2019s remove RemoteData out from Model and into its own top level module:   assets/elm/src/RemoteData.elm   module RemoteData exposing (RemoteData(..))   type RemoteData e a     = Failure e     | NotRequested     | Requesting     | Success a   The Elm compiler should let you know the modules in which you need to change RemoteData references to this new one, but most of the edits will consist of changing references like:   import Model     exposing         ( Model         , RemoteData(NotRequested, Requesting, Failure, Success)         )   to something like:   import Model exposing (Model) import RemoteData     exposing         ( RemoteData(NotRequested, Requesting, Failure, Success)         )   Create Routing Concern   In Contact.View, there is the following line:   assets/elm/src/Contact/View.elm   import Messages exposing (Msg(NavigateTo))   NavigateTo is a message that is sent in onClick link attributes in HTML inside multiple view files. When this message is handled in Update, it only runs a command to navigate to a new URL, and does not return a new model:   assets/elm/src/Update.elm   module Update exposing (update, ...)  import Navigation import Routing exposing (Route(...)) -- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         -- ...          NavigateTo route -&gt;             ( model, Navigation.newUrl (Routing.toPath route) ) -- ...   So, in order to de-couple Contact.View from Messages, it looks like a new extraction of a Routing concern will be in order, so let\u2019s start with defining messages and update handling for Routing:   assets/elm/src/Routing/Messages.elm   module Routing.Messages exposing (RoutingMsg(..))  import Routing exposing (Route)   type RoutingMsg     = NavigateTo Route   assets/elm/src/Routing/Update.elm   module Routing.Update exposing (update)  import Navigation import Routing import Routing.Messages exposing (RoutingMsg(NavigateTo))   update : RoutingMsg -&gt; Cmd msg update msg =     case msg of         NavigateTo route -&gt;             Navigation.newUrl (Routing.toPath route)   We will also need to allow for a RoutingMsg to be handled by the top-level Messages module, so let\u2019s add that (while removing NavigateTo from Messages), and fix Update so it can handle these new RoutingMsg messages:   assets/elm/src/Messages.elm   module Messages exposing (Msg(..))  import Contact.Messages exposing (ContactMsg) import ContactList.Messages exposing (ContactListMsg) import Navigation import Routing.Messages exposing (RoutingMsg)   type Msg     = ContactMsg ContactMsg     | ContactListMsg ContactListMsg     | RoutingMsg RoutingMsg     | UpdateSearchQuery String     | UrlChange Navigation.Location   assets/elm/src/Update.elm   module Update exposing (update, ...)  import Routing.Update -- ...   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         -- ...          RoutingMsg msg -&gt;             ( model, Routing.Update.update msg ) -- ...   Use RoutingMsg in Contact Views   Once this is done, we will start focusing on Contact-related modules. You will find that a number of different view files have been affected by the creation of the RoutingMsg, so some references and type signatures will need to change.   The Elm compiler should let you know about which modules need to have their NavigateTo references changed, but most of the edits will consist of changing references like:   import Messages exposing (Msg(NavigateTo))   to something like:   import Messages exposing (Msg(RoutingMsg))   or (depending on the file):   import Routing.Messages exposing (RoutingMsg(NavigateTo))   as well as changing function declarations to return a RoutingMsg, rather than a Msg:   assets/elm/src/Contact/View.elm   -- ...  import Routing.Messages exposing (RoutingMsg(NavigateTo)) -- ...  view : Model -&gt; Html RoutingMsg -- ...  showView : Contact -&gt; ( String, Html RoutingMsg ) -- ...  -- etc etc change Msg to RoutingMsg for all the functions in this file ...   Again, the Elm compiler will guide you on where the references need to be changed.   Next, there will be some messages across multiple concerns that will need to be Html.mapped into RoutingMsg messages:   assets/elm/src/ContactList/View.elm   module ContactList.View exposing (view)  import Messages exposing (Msg(RoutingMsg, ...)) -- ...  contactsList : Model -&gt; ContactList -&gt; Html Msg contactsList model page =     if page.totalEntries &gt; 0 then         page.entries             |&gt; List.map Contact.View.showView             |&gt; Keyed.node "div" [ class "cards-wrapper" ]             |&gt; Html.map RoutingMsg     else       -- ...   assets/elm/src/View.elm   module View exposing (view)  import Messages exposing (Msg(RoutingMsg)) -- ...   page : Model -&gt; Html Msg page model =     case model.route of         -- ...          ShowContactRoute id -&gt;             model                 |&gt; Contact.View.view                 |&gt; Html.map RoutingMsg          NotFoundRoute -&gt;             Shared.View.warningMessage                 "fa fa-meh-o fa-stack-2x"                 "Page not found"                 (Html.map RoutingMsg Shared.View.backToHomeLink)   One final minor view-related change is in the signature for Shared.View.warningMessage:   assets/elm/src/Shared/View.elm   warningMessage : String -&gt; String -&gt; Html msg -&gt; Html msg warningMessage iconClasses message content =     div [ class "warning" ]         [ span [ class "fa-stack" ]             [ i [ class iconClasses ] [] ]         , h4 []             [ text message ]         , content         ]   The change is ever-so-subtle: Html Msg to Html msg. This function is used in both Contact and ContactList views, and the message wrapped inside the Html could be a ContactMsg or a Msg type. Since the type of message is not consequential for the rendering of the warning message, we make the type signature ambivalent to the type of message provided and then returned back.   And that should take care of View-related code, so on to Contact.Update!   Hide Model from Contact.Update   Currently, in Update, we\u2019re passing the whole Model off to Contact.Update when we receive a ContactMsg, and Contact.Update.update returns back a (Model, Cmd Msg).   However, Contact.Update should only be concerned with returning a new Contact: it does not need to know about the rest of the Model.  Also, Contact.Update should only know how to return messages of its own type: ContactMsg. So, we want:      Contact.Update.update to return back a (Contact, Cmd ContactMsg)   Have the Update module return a model with the new Contact   Have the Update module convert the ContactMsg into a Msg.   assets/elm/src/Update.elm   module Update exposing (update, ...)  import Messages exposing (Msg(ContactMsg, ...)) import Model exposing (Model, ...) -- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         ContactMsg msg -&gt;             let                 ( contact, cmd ) =                     Contact.Update.update msg             in                 ( { model | contact = contact }, Cmd.map ContactMsg cmd )  -- ...   Now that Contact.Update.update doesn\u2019t receive a Model any more, let\u2019s change it so that it returns the (Contact, Cmd ContactMsg) that Update now wants:   assets/elm/src/Contact/Update.elm   module Contact.Update exposing (update)  import Contact.Messages exposing (ContactMsg(FetchContact)) import Contact.Model exposing (Contact) import RemoteData exposing (RemoteData, RemoteData(Failure, Success))   update : ContactMsg -&gt; ( RemoteData String Contact, Cmd ContactMsg ) update msg =     case msg of         FetchContact (Ok response) -&gt;             ( Success response, Cmd.none )          FetchContact (Err error) -&gt;             ( Failure "Contact not found", Cmd.none )   Contact.Commands should return ContactMsgs   Currently, the Contact.Commands.fetchContact function returns a top-level Cmd Msg type. What we want to do is have it instead return a Cmd ContactMsg, and have the caller of the function (in this case Update.urlUpdate) be responsible for Cmd.mapping the ContactMsg to a Msg.   So, this is what we currently have:   assets/elm/src/Contact/Commands.elm   module Contact.Commands exposing (fetchContact)  import Commands exposing (contactsApiUrl) import Contact.Decoder as Decoder import Contact.Messages exposing (ContactMsg(FetchContact)) import Http import Messages exposing (Msg(ContactMsg))   fetchContact : Int -&gt; Cmd Msg fetchContact id =     let         apiUrl =             contactsApiUrl ++ "/" ++ toString id     in         Decoder.decoder             |&gt; Http.get apiUrl             |&gt; Http.send FetchContact             |&gt; Cmd.map ContactMsg   assets/elm/src/Update.elm   module Update exposing (update, urlUpdate)  -- ...  urlUpdate : Model -&gt; ( Model, Cmd Msg ) urlUpdate model =     case model.route of         -- ...          ShowContactRoute id -&gt;             ( { model | contact = Requesting }             , Contact.Commands.fetchContact id             )  -- ...   And this is what we need to change the files to:   assets/elm/src/Contact/Commands.elm   module Contact.Commands exposing (fetchContact)  import Commands exposing (contactsApiUrl) import Contact.Decoder as Decoder import Contact.Messages exposing (ContactMsg(FetchContact)) import Http   fetchContact : Int -&gt; Cmd ContactMsg fetchContact id =     let         apiUrl =             contactsApiUrl ++ "/" ++ toString id     in         Decoder.decoder             |&gt; Http.get apiUrl             |&gt; Http.send FetchContact   assets/elm/src/Update.elm   module Update exposing (update, urlUpdate)  -- ...  urlUpdate : Model -&gt; ( Model, Cmd Msg ) urlUpdate model =     case model.route of         -- ...          ShowContactRoute id -&gt;             ( { model | contact = Requesting }             , id                 |&gt; Contact.Commands.fetchContact                 |&gt; Cmd.map ContactMsg  -- ...   Phew! We\u2019ve made quite a lot of changes across multiple files, so let\u2019s see if it paid off!      Having compilation problems? Compare what you\u2019ve written with code in the rest-refactor branch of the Address App and see if they match up.    Re-generate the module-graph.json file (./elm-module-graph.py src/Main.elm), and re-upload it to https://justinmimbs.github.io/elm-module-graph/ and let\u2019s see what the graph says:      Awesome! Modules in the Contact concern now have no direct dependencies with the top level Messages module!   I have attempted to take this even further by removing ContactList dependencies in the Messages module, and you can see the results of that in the rest-refactor branch of the Address App if you are interested.  Suffice to say, the graph now looks like:      Not bad! With further refactoring and re-architecting, maybe I could remove ContactList.View from this list, but I\u2019m done fighting with types for now :sweat_smile:   Conclusion   I found that using elm-module-graph was helpful in getting a high level overview of my Elm application, determining where potential compilation bottlenecks could appear, and deciding how to structure modules.   Is the way I architected and then refactored the application presented here a \u201cgood\u201d way to do it? At this stage, I do not know. I am very happy to be shown to be wrong about this, but for now, this way of doing things (less massive files; more smaller functions in smaller modules under concern directories) feels right to me, especially since I do not know of any \u201cofficial\u201d guidance on this.   Regardless, on your next Elm project, give generating a graph for it a try for some easy-to-digest information about its dependencies!   ',categories:[],tags:["elm","refactoring","architecture","graphs"],url:"/blog/graph-driven-refactoring-elm/",teaser:"/assets/images/2018-03-17/REST-branch-Messages-pre-refactor.png"},{title:"Runtime Language Switching in Elm",
excerpt:'When it comes to creating multilingual web pages, internationali[s|z]ation (I18n) would seem to be a deceptively complex problem using Elm.   I have never had to consider the choice of generating application translations as a pre-build phase of an app (eg elm-i18n), or have them be dynamically loaded (eg elm-i18next) when working with i18n in Rails or Phoenix. To be honest, I still do not know which way of doing things is \u201cbest\u201d in an Elm context. But, I do know that I want to have runtime-switchable languages via a dropdown menu, so the creation of an example page with dynamically loaded translations will be the main focus of this blog post.   I have been using Tachyons a lot lately for styling, and like how it plays with Elm, so we will set about doing the following:      Re-create Tachyons\u2019 Full Screen Centered Title component documentation page in Elm   Add a custom language-switcher dropdown menu to the page   Provide some translations for the page in JSON format, and allow the dropdown menu to switch the language   Store the selected language in localStorage so that any selected language persists through page refreshes and different sessions.   Explore generating Elm modules from the JSON translation files in order to give the translations some type safety   (If you want to skip ahead and see the final result, feel free to clone my elm-i18n-example repo)   Let\u2019s get started!      Update (21 December 2018)     The version of Elm used in this post is 0.18. I still stand by the overall points of the post, but some of the code is now outdated. The master branch of the elm-i18n-example repo has been updated to Elm 0.19, so if you are following along, and you get issues, try reconciling them there with the updated codebase.     The full original 0.18 codebase used in this post can be found on the 0.18 branch of the repo.    Bootstrap a New Elm Application   Create Elm App will help us bootstrap our app, so install it with:   npm install -g create-elm-app   Then, generate a new app, initialise npm (using the default fields provided for the generated package.json file is fine), and install Tachyons:   create-elm-app elm-i18n-example cd elm-i18n-example npm init npm install tachyons   Next, to import Tachyons into the project, change the generated index.js file to look like the following:   src/index.js   import "tachyons" import "./main.css" import { Main } from "./Main.elm"  const appContainer = document.getElementById("root")  if (appContainer) {   Main.embed(appContainer) }   Now, if you run elm-app start, http://localhost:3000/ should open automatically and you should see a familiar splash screen letting you know that your Elm app is working.   Before we get started properly, let\u2019s do a bit of clean-up of some of the generated code Create Elm App gave us:      We do not need src/main.css since Tachyons will take care of styling   This app will not use service workers, so src/registerServiceWorker.js can be removed   We will not be using the Elm logo from the splash screen, so that can be removed, as well as references to it in src/Main.elm   So, run the command below and make the following changes:   rm src/main.css src/registerServiceWorker.js public/logo.svg   src/index.js   import "tachyons" import { Main } from "./Main.elm"  // ...   src/Main.elm   -- ...  view : Model -&gt; Html Msg view model =     div []         [ h1 [] [ text "Your Elm App is working!" ]         ]   You should now be left with a very plain looking (but compilable) page, so let\u2019s brighten it up a bit!   Re-create the Tachyons Documentation Page   Using the sample code on the Full Screen Centered Title page as a guide (but with a few minor edits), change the Main.elm module definitions, import declarations, and view function to re-create the page:   src/Main.elm   module Main exposing (main)  import Html exposing (Html, article, div, h1, main_, text) import Html.Attributes exposing (class)  -- ...  view : Model -&gt; Html Msg view model =     let         classes =             [ "bg-dark-pink"             , "overflow-container"             , "sans-serif"             , "white"             ]                 |&gt; String.join " "                 |&gt; class     in         main_ [ classes ]             [ content ]   content : Html Msg content =     let         articleClasses =             [ "dt"             , "vh-100"             , "w-100"             ]                 |&gt; String.join " "                 |&gt; class          divClasses =             [ "dtc"             , "ph3 ph4-l"             , "tc"             , "v-mid"             ]                 |&gt; String.join " "                 |&gt; class     in         article [ articleClasses ]             [ div [ divClasses ]                 [ heading ]             ]   heading : Html Msg heading =     let         classes =             [ "f6 f2m"             , "f-subheadline-l"             , "fw6"             , "tc"             ]                 |&gt; String.join " "                 |&gt; class     in         h1 [ classes ]             [ text "Vertically centering things in css is easy!" ]   I think that putting Tachyons classes in lists like this makes them easier to scan and maintain, but it also has the side effect of making function definitions really long, so here we have split out the content across three different smaller functions.   Using utility-based CSS frameworks like Tachyons and Tailwind can seem daunting at first, what with all the mnemonics that you seem to have to commit to memory, so I always keep Tachyons\u2019 Table of Styles open in a browser tab for quick reference, and if this is your first look at Tachyons, I would recommend you do the same.   Anyway, your page should now look like the following screen shot:      If it does not, check your code against the 1-recreate-tachyons-doc-page branch of my codebase to see if anything is missing.   Add Language Dropdown Menu   For now, the language dropdown menu will be populated with placeholder values, and will not actually be able to change languages, but what we want from the menu in the end is:      The current language should be shown on the menu by default   When you click the menu, it should open, revealing any other available languages aside from the current language   When you mouse over a menu item, it should be highlighted in some way   When you click on a menu item, it should change the current language of the application (we\u2019ll do that later)   If, while the menu is open, you click anywhere else on the page, the menu should close   Most of these requirements sound like they would be best served in their own module, so let\u2019s create one called LanguageDropdown.elm, and start with rendering just the current language selection so we can get the menu positioning right.   Current Selection   src/LanguageDropdown.elm   module LanguageDropdown exposing (view)  import Html exposing (Html, div, li, p, span, text, ul) import Html.Attributes exposing (class)   view : Html msg view =     let         classes =             [ "center"             , "f3"             , "flex"             , "h3"             , "items-center"             , "justify-end"             , "w-90"             ]                 |&gt; String.join " "                 |&gt; class     in         div [ classes ]             [ currentSelection ]   currentSelection : Html msg currentSelection =     let         classes =             [ "b--white"             , "ba"             , "br2"             , "pa2"             , "pointer"             , "tc"             , "w4"             ]                 |&gt; String.join " "                 |&gt; class          caretClasses =             [ "absolute"             , "ml2"             ]                 |&gt; String.join " "                 |&gt; class     in         p [ classes ]             [ span []                 [ text "English" ]             , span [ caretClasses ]                 [ text "\u25be" ]             ]   Next, we have to import the language dropdown code in the Main module, as well as slightly adjust the styles in the view function, since there is now more on the page than just the message:   src/Main.elm   -- ... import LanguageDropdown  -- ...  view : Model -&gt; Html Msg view model =     let         classes =             [ "bg-dark-pink"             , "overflow-container"             , "pt3"             , "sans-serif"             , "vh-100"             , "white"             ]                 |&gt; String.join " "                 |&gt; class     in         main_ [ classes ]             [ LanguageDropdown.view             , content             ]  content : Html Msg content =     let         articleClasses =             [ "dt"             , "vh-75"             , "w-100"             ]                 |&gt; String.join " "                 |&gt; class          -- ...     in         -- ...   Now, your page should look like this:      The \u201cmenu\u201d here (yes, it is currently just a p tag), currently does nothing, but we can at least confirm that it looks like it is in a good spot on the page. Now, let\u2019s actually give it a dropdownList under the currentSelection!   Language Dropdown List   src/LanguageDropdown.elm   view : Html msg view =     let         -- ...     in         div [ classes ]             [ currentSelection             , dropdownList             ]  -- ...  dropdownList : Html msg dropdownList =     let         classes =             [ "absolute"             , "b--white"             , "bb"             , "bl"             , "br"             , "br--bottom"             , "br2"             , "items-center"             , "list"             , "mt5"             , "pl0"             , "pointer"             , "pr0"             , "pt1"             , "tc"             , "top-0"             , "w4"             ]                 |&gt; String.join " "                 |&gt; class          selectableLanguages =             [ "Italiano", "\u65e5\u672c\u8a9e" ]      in         ul [ classes ]             (List.map dropdownListItem selectableLanguages)   dropdownListItem : String -&gt; Html msg dropdownListItem language =     let         classes =             [ "hover-bg-white"             , "hover-dark-pink"             , "ph1"             , "pv2"             , "pt0"             , "w-100"             ]                 |&gt; String.join " "                 |&gt; class     in         li [ classes ]             [ span [] [ text language ] ]   This results in:         For the dropdown list, we are shoving a HTML unordered list (ul) right underneath the p tag, simulating a menu opening.   When we hover over a menu item, we can tell which item is currently being selected.   Selectable languages currently have strings as their placeholders, but we will change that later on as we introduce the concept of a language to the application.   So, we now know what the menu looks like when it is open, but we need it to respond to mouse clicks to open and close the dropdown list (read: show and hide the list), so let\u2019s do that now.   Show and Hide Available Languages   The application needs to be able to keep track of whether to show or hide the dropdown list, and needs to be able to track clicks on the menu and page, so it sounds like we need the following:      A Boolean flag to tell the app whether to showAvailableLanguages or not   An update Msg that will toggle the visibility of the dropdown list; let\u2019s call it ShowAvailableLanguages   An update Msg that will hide the dropdown list, for when the dropdown is open but a click is registered anywhere else on the page; let\u2019s call it CloseAvailableLanguages   We will start with updating the Msg union type. Both Main.elm and LanguageDropdown.elm are going to need access to Msg, so let\u2019s extract it into its own module:   src/Msg.elm   module Msg exposing (Msg(..))   type Msg     = CloseAvailableLanguages     | ShowAvailableLanguages   Next, extract Model and the init function from Main into a new Model.elm module, making sure that the dropdown is set to be hidden by default:   src/Model.elm   module Model exposing (Model, init)  import Msg exposing (Msg)   type alias Model =     { showAvailableLanguages : Bool }   init : ( Model, Cmd Msg ) init =     ( { showAvailableLanguages = False }, Cmd.none )   Now, we need to update Main.elm and LanguageDropdown.elm to import these modules, and then write some handling code for these Msgs in the update function:   src/Main.elm   -- ... import Model exposing (Model) import Msg exposing (Msg(CloseAvailableLanguages, ShowAvailableLanguages))   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         CloseAvailableLanguages -&gt;             ( { model | showAvailableLanguages = False }, Cmd.none )          ShowAvailableLanguages -&gt;             ( { model                 | showAvailableLanguages = not model.showAvailableLanguages               }             , Cmd.none             )  -- ...  main : Program Never Model Msg main =     Html.program         { view = view         , init = Model.init         , update = update         , subscriptions = always Sub.none         }   In the LanguageDropdown, since we will be now be sending messages of type Msg, all function annotations with Html msg will need to be updated to be Html Msg. We will also be making use of the view function\u2019s model parameter throughout the dropdown in order to determine what to show, as well as how to style the dropdown menu when it is open and closed:   src/LanguageDropdown.elm   -- ... import Html.Events exposing (onClick) import Model exposing (Model) import Msg exposing (Msg(ShowAvailableLanguages))   view : Model -&gt; Html Msg view model =     let         -- ...     in         div [ classes ]             [ currentSelection model             , dropdownList model             ]   currentSelection : Model -&gt; Html Msg currentSelection model =     let         displayClasses =             if model.showAvailableLanguages then                 [ "br--top" ]             else                 []          classes =             [ -- ...             ]                 ++ displayClasses                 |&gt; String.join " "                 |&gt; class          -- ...     in         p [ classes, onClick ShowAvailableLanguages ]             [ -- ...             ]   dropdownList : Model -&gt; Html Msg dropdownList model =     let         displayClasses =             if model.showAvailableLanguages then                 [ "flex", "flex-column" ]             else                 [ "dn" ]          classes =             [ -- ...             ]                 ++ displayClasses                 |&gt; String.join " "                 |&gt; class          -- ...     in        -- ...   dropdownListItem : String -&gt; Html Msg -- ...   Once the above changes are made, you should be able to click on the dropdown menu to open and close it, showing and hiding the available languages. However, if you open the menu and then click anywhere else, the menu stays open.   In order to get it to close (and actually use that CloseAvailableLanguages message), we are going to have to make use of the Elm Mouse package, and a subscription to mouse clicks.   Subscribe to Mouse Clicks   Install the Elm Mouse package:   elm-package install -y elm-lang/mouse   Then, create a subscriptions function in Elm that listens out for mouse clicks only when the dropdown menu is open, and if a click is detected, sends a CloseAvailableLanguages message:   src/Main.elm   -- ... import Mouse  -- ...  subscriptions : Model -&gt; Sub Msg subscriptions model =     if model.showAvailableLanguages then         Mouse.clicks (\\_ -&gt; CloseAvailableLanguages)     else         Sub.none   main : Program Never Model Msg main =     Html.programWithFlags         { view = view         , init = Model.init         , update = update         , subscriptions = subscriptions         }   Now, whenever you click open the dropdown menu, and then click anywhere else, the menu will close, as expected.   If the app so far is not behaving as you would expect, compare your code to the 2-add-language-dropdown branch of my codebase to see if anything is missing.   Now, it\u2019s time to give the application the concept of a language to switch, and replace those placeholder values with actual data!   Language Switching   Time to get some translations into the application, and for that, we will use elm-i18next, along with the HTTP in Elm package, so let\u2019s get installing:   elm-package install -y ChristophP/elm-i18next elm-package install -y elm-lang/http   First, let\u2019s provide some translation JSON files for the message on screen in English, Italian, and Japanese. Create a public/locale/ directory and add the following files under it:   public/locale/translations.en.json   {   "verticallyCenteringInCssIsEasy": "Vertically centering things in css is easy!" }   public/locale/translations.it.json   {   "verticallyCenteringInCssIsEasy": "Centrare verticalmente con css \xe8 facile!" }   public/locale/translations.ja.json   {   "verticallyCenteringInCssIsEasy": "CSS\u3067\u5782\u76f4\u30bb\u30f3\u30bf\u30ea\u30f3\u30b0\u306f\u7c21\u5358\u3060\u3088\uff01" }   Next, let\u2019s create a Translations module where we will define the type for a language, and provide a helper function to convert a string language code into a language:   src/Translations.elm   module Translations exposing (Lang(..), getLnFromCode)   type Lang     = En     | It     | Ja   getLnFromCode : String -&gt; Lang getLnFromCode code =     case code of         "en" -&gt;             En          "it" -&gt;             It          "ja" -&gt;             Ja          _ -&gt;             En   Great! Now we need to add some new Msg types for:      Fetching the translations from the JSON files   Changing the language   src/Msg.elm   module Msg exposing (Msg(..))  import Http exposing (Error) import I18Next exposing (Translations) import Translations exposing (Lang)   type Msg     = ChangeLanguage Lang     | CloseAvailableLanguages     | FetchTranslations (Result Error Translations)     | ShowAvailableLanguages   We now need a way to be able to go and fetch the translations from the JSON files, and return the result back via the FetchTranslations message, so let\u2019s create that in a new module called Cmd:   src/Cmd.elm   module Cmd exposing (fetchTranslations)  import I18Next import Msg exposing (Msg(FetchTranslations)) import Translations exposing (Lang)   fetchTranslations : Lang -&gt; Cmd Msg fetchTranslations language =     language         |&gt; toTranslationsUrl         |&gt; I18Next.fetchTranslations FetchTranslations   toTranslationsUrl : Lang -&gt; String toTranslationsUrl language =     let         translationLanguage =             language                 |&gt; toString                 |&gt; String.toLower     in         "/locale/translations." ++ translationLanguage ++ ".json"   Now, the Model needs to know about what the currentLanguage of the application is in order to determine what translations should be loaded, so let\u2019s add that information, and call the Cmd.fetchTranslations En command to immediately go and fetch the appropriate English translations, which we will also set as the default language:   src/Model.elm   module Model exposing (Model, init)  import Cmd import I18Next exposing (Translations) import Msg exposing (Msg) import Translations exposing (Lang(En))   type alias Model =     { currentLanguage : Lang     , showAvailableLanguages : Bool     , translations : Translations     }   init : ( Model, Cmd Msg ) init =     ( { currentLanguage = En       , showAvailableLanguages = False       , translations = I18Next.initialTranslations       }     , Cmd.fetchTranslations En     )   Next, we need to handle the new ChangeLanguage and FetchTranslations messages in the update function:      When the language is changed, as well as change the currentLanguage, we need to go and fetch the translations for that language in the same way we did in the init function   If fetching the translations succeeds, we will display the new translations, otherwise, for now we will just ignore any errors since we would not expect to fetch translations for a language that we did not create ourselves.   src/Main.elm   -- ... import Cmd import Msg     exposing         ( Msg             ( ChangeLanguage             , CloseAvailableLanguages             , FetchTranslations             , ShowAvailableLanguages             )         )  --- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         -- ...         ChangeLanguage language -&gt;             ( { model | currentLanguage = language }             , Cmd.fetchTranslations language             )          FetchTranslations (Ok translations) -&gt;             ( { model | translations = translations }, Cmd.none )          FetchTranslations (Err msg) -&gt;             ( model, Cmd.none )   At this stage, the application should be back to a point where everything is compiling again, but on the surface there are no changes since the language display still consists of static values, so let\u2019s change that.   First, we will create a Language module that will have some helper functions around generating the string value for a language (eg \u201cEnglish\u201d should always be displayed as \u201cEnglish\u201d, regardless of what the current language is), and keeping a static list of available languages so we can display them in the dropdown menu. Unfortunately, there is no way to generate a list of type values from a type (eg [En, It, Ja] from the Lang type), so it will have to be a separate definition:   src/Language.elm   module Language exposing (availableLanguages, langToString)  import Translations exposing (Lang(En, It, Ja))   availableLanguages : List Lang availableLanguages =     [ En, It, Ja ]   langToString : Lang -&gt; String langToString language =     case language of         En -&gt;             "English"          It -&gt;             "Italiano"          Ja -&gt;             "\u65e5\u672c\u8a9e"   Now that we have our language data setup, let\u2019s go back to the view code and get the page to start displaying it. First, let\u2019s get the correct information displayed on the dropdown menu for both the current language, and for the other available languages in the dropdown:   src/LanguageDropdown.elm   -- ... import Language import Msg exposing (Msg(ChangeLanguage, ShowAvailableLanguages)) import Translations exposing (Lang)  -- ...  currentSelection : Model -&gt; Html Msg currentSelection model =     let         -- ...     in         p [ classes, onClick ShowAvailableLanguages ]             [ span []                 [ text (Language.langToString model.currentLanguage) ]             , span [ caretClasses ]                 [ text "\u25be" ]             ]   dropdownList : Model -&gt; Html Msg dropdownList model =     let         -- ...          selectableLanguages =             List.filter                 (\\language -&gt; language /= model.currentLanguage)                 Language.availableLanguages     in         ul [ classes ]             (List.map dropdownListItem selectableLanguages)   dropdownListItem : Lang -&gt; Html Msg dropdownListItem language =     let         -- ...     in         li [ classes, onClick (ChangeLanguage language) ]             [ span []                 [ text (Language.langToString language) ]             ]   At this point, if you select a new language from the dropdown menu, you will see the current language display change on the menu, and if you open the Elm debugger, you will see that the language of the application is actually changing, and the translations for the language are being loaded into the application:      Great! Now let\u2019s get that translated message showing on the page by letting the content know what translations it is supposed to be displaying:   src/Main.elm   -- ... import Translations exposing (Lang)  -- ...  view : Model -&gt; Html Msg view model =     let         -- ...     in         main_ [ classes ]             [ LanguageDropdown.view model             , content model.translations             ]   content : Translations -&gt; Html Msg content translations =     let        -- ...     in         article [ articleClasses ]             [ div [ divClasses ]                 [ heading translations ]             ]   heading : Translations -&gt; Html Msg heading translations =     let         -- ...     in         h1 [ classes ]             [ text (I18Next.t translations "verticallyCenteringInCssIsEasy") ]   And now, when you change language, you should see the displayed message in that language:      Fantastic! That covers the main functionality of language switching, but there is still more we can do. Before we move on though, if you cannot switch languages, be sure to double-check your code against the 3-add-language-switching branch of my codebase.   Detect User Language   Currently, the application language is set to English by default when it starts, but it would be nice if we at least tried to set the application to initially display in the user\u2019s preferred language. To simplify the idea of a \u201cpreferred language\u201d (because this is not universal amongst browers), we will consider it to be the language of the browser being used. How do we get that? In Javascript, we can use:      navigator.language   navigator.userLanguage (for Internet Explorer)   So, let\u2019s grab this information from Javascript, and pass it into Elm as a flag:   src/index.js   import "tachyons" import { Main } from "./Main.elm"  const appContainer = document.getElementById("root")  if (appContainer) {   Main.embed(appContainer, { language: getLanguage() }) }  function getLanguage() {   return navigator.language || navigator.userLanguage }   Our application cannot currently accept flags from Javascript, so let\u2019s change our program type to programWithFlags to allow that to happen:   src/Main.elm   -- ... import Model exposing (Flags, Model)  -- ...  main : Program Flags Model Msg main =     Html.programWithFlags         { view = view         , init = Model.init         , update = update         , subscriptions = subscriptions         }   Next, we will define what type of flags we will accept in the Model module, and because we do not trust any information passed in from Javascript, we will decode the flag to ensure that we are getting a string.   src/Model.elm   module Model exposing (Flags, Model, init)  -- ... import Json.Decode as Decode exposing (Value) import Language   type alias Flags =     { language : Value }  -- ...  init : Flags -&gt; ( Model, Cmd Msg ) init flags =     let         language =             flags.language                 |&gt; Decode.decodeValue Decode.string                 |&gt; Language.langFromFlag     in         ( { currentLanguage = language           , showAvailableLanguages = False           , translations = I18Next.initialTranslations           }         , Cmd.fetchTranslations language         )   Finally, we will create the Language.langFromFlag function that will return a language if decoding goes well, and return a default language if not:   src/Language.elm   module Language exposing (availableLanguages, langFromFlag, langToString)  -- ...  langFromFlag : Result String String -&gt; Lang langFromFlag language =     case language of         Ok language -&gt;             Translations.getLnFromCode language          Err _ -&gt;             En   If your browser language is English, you will not notice any change as a result of these additions, but if you change your browser language to Italian or Japanese and then refresh the page, you will see that the application will start in that language.   For Chrome, you can change the language setting by opening the browser preferences, opening the Advanced preferences\u2026      \u2026finding the Languages preferences, and then choosing a language to Move to the top of the list:      Default language not changing? Check your code against the 4-detect-user-language branch of my codebase.   Now, having a default language is nice, but if you switch languages and then refresh the page, the application will revert back to the language set in the browser. Plenty of people want to read content in a different language than their system settings, and it would be nice to be able to save their language preference for this application. So, let\u2019s then use the browser\u2019s localStorage to help us do exactly that.   Store Language Preference   Sending Elm data to Javscript requires us to use Elm Ports. All port functions return a Cmd msg, so let\u2019s put the function to remember a language preference in the Cmd module, changing it over to a port module:   src/Cmd.elm   port module Cmd exposing (fetchTranslations, storeLanguage)  -- ...  port storeLanguageInLocalStorage : String -&gt; Cmd msg  -- ...  storeLanguage : Lang -&gt; Cmd msg storeLanguage language =     language         |&gt; toString         |&gt; String.toLower         |&gt; storeLanguageInLocalStorage   Here we have created a storeLanguage command function that takes in a Lang type, stringifies it, and sends it off to Javascript via the storeLanguageInLocalStorage port. On the Javascript side, there is currently no code that is subscribing to messages coming from that port, so we\u2019ll make that next:   src/index.js   // ... if (appContainer) {   const app = Main.embed(appContainer, { language: getLanguage() })    app.ports.storeLanguageInLocalStorage.subscribe((language) =&gt; {     localStorage.setItem("elm-i18n-example-language", language)   }) } // ...   There is no particular reason behind the \u201celm-i18n-example-language\u201d named key; it could have been named anything, but it is best to have it as unique as possible, since many different applications will likely be making use of localStorage.   Okay, we\u2019ve got the pathway to Javascript set up, now we need to make sure that the command is run every time the language is changed (ie the ChangeLanguage message is sent), so let\u2019s make that addition to the update function:   src/Main.elm   -- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         ChangeLanguage language -&gt;             ( { model | currentLanguage = language }             , Cmd.batch                 [ Cmd.fetchTranslations language                 , Cmd.storeLanguage language                 ]             )     -- ...   The ChangeLanguage branch of the update function has gotten a bit busier, needing to use Cmd.batch to send commands to both fetch new language translations, and store the user language preference.   Now, you should be able to switch languages, and have it stored in localStorage. Open up the Javascript console in your browser\u2019s developer tools to confirm this with the following command: localStorage.getItem("elm-i18n-example-language")      Success! But there is one small lingering issue though: if you refresh the browser, the application is still reverting back to the default language of English. We need to have our Javascript code get the language from localStorage (if it\u2019s there), and pass that in as the Elm language flag, so let\u2019s do that:   src/index.js   // ... function getLanguage() {   return localStorage.getItem("elm-i18n-example-language") ||     navigator.language ||     navigator.userLanguage }   Now, if you change languages and refresh the page, the application should still show you the language that you originally selected! If it doesn\u2019t, check your code against the 5-store-language-preference branch of my codebase.   At this stage, our page is pretty much feature complete. However, there are still a few potential issues that would be worthy of a bit more investigation:      If you refresh the page, you may see the translation key \u201cverticallyCenteringInCssIsEasy\u201d briefly flash before the translation is shown. This is particularly noticeable on the Japanese translation. Perhaps the translations are being loaded too slowly\u2026?   If you accidentally make a typo when requesting a translation by key in a view (eg I18Next.t translations "thisKeyDoesNotExist"), then no error is raised: the key is simply displayed on the page, which may not be what you want.   If you accidentally do not provide a translation for a particular key for a known available language, or make a typo in the translation file (eg delete the translations.ja.json file or change its key name), then, again, no error is raised, and the requested key is displayed on the page as-is.   Elm programmers are spoiled by the Elm compiler always looking over our shoulder and helping us avoid these kinds of mistakes. If you are confident about manually handling the issues outlined or they are not important to you, then all is good and you need not go any further. But, if want Elm to cast more of an eye over your i18n development, what options are available to you?   Type-Safe Translations   Since we have our translation files as JSON, we can use Elm i18n Gen to generate a Translations module containing one function for every translation in the JSON files. So, let\u2019s give it a try.   Install it with the following command:   npm install -g elm-i18n-gen   Generate a new Translations module for the app with the following command:   elm-i18n-gen public/locale src/Translations.elm   And if you open up the Translations module you should see the following:   src/Translations.elm   module Translations exposing (..)   type Lang     = En     | It     | Ja   getLnFromCode : String -&gt; Lang getLnFromCode code =     case code of         "en" -&gt;             En          "it" -&gt;             It          "ja" -&gt;             Ja          _ -&gt;             En   verticallyCenteringInCssIsEasy : Lang -&gt; String verticallyCenteringInCssIsEasy lang =     case lang of         En -&gt;             "Vertically centering things in css is easy!"          It -&gt;             "Centrare verticalmente con css \xe8 facile!"          Ja -&gt;             "CSS\u3067\u5782\u76f4\u30bb\u30f3\u30bf\u30ea\u30f3\u30b0\u306f\u7c21\u5358\u3060\u3088\uff01"   We only have one translation key in our JSON files, so elm-i18n-gen created just one function for us that covers translations for all our languages. You can also see here that I adopted elm-i18n-gen\u2019s specific naming conventions for Lang, and getLnFromCode in advance, and deliberately put that information in the Translations module knowing it would be overwritten when the new Translations file was generated (\u2026I think my Chekhov\u2019s Gun is jammed\u2026).   Anyway, now that we have our function, let\u2019s use it in the view:   src/Main.elm   -- ... import Translations exposing (Lang)  -- ...  view : Model -&gt; Html Msg view model =     let         -- ...     in         main_ [ classes ]             [ LanguageDropdown.view model             , content model.currentLanguage             ]   content : Lang -&gt; Html Msg content language =     let         -- ...     in         article [ articleClasses ]             [ div [ divClasses ]                 [ heading language ]             ]   heading : Lang -&gt; Html Msg heading language =     let         -- ...     in         h1 [ classes ]             [ text (Translations.verticallyCenteringInCssIsEasy language) ]   The effects of this one change are the following:      There is now no need to fetch any translations, and consequently the FetchTranslations Msg, the fetchTranslations function in the Cmd module, the translations entry in the Model, and any trace of the I18Next and Http packages, can now be safely removed.   The issue of a translation key displaying before the translation is loaded has consequently gone away since we are now just calling a function.   Elm will raise a compiler error if a translation is not provided for all languages.   Those are some pretty good benefits! I\u2019m not sure about any downsides to this, aside from maybe having a single module with potentially hundreds of functions in it for any given large JSON translation file. But, I would guess the overhead for maintainability of that module would be the same for the JSON file. Please let me know if I\u2019m wrong about this!   See the 6-type-safe-translations branch of my codebase to see the final form of the application, with all extraneous code removed.   Conclusion   Even after all this, I\u2019m still not really sure what to think when it comes to an ideal solution for I18n in Elm. I am planning on using the methods outlined in this blog post for the time being, but if you have any better ways of doing things (I\u2019d love to see an actual example of an app using the elm-i18n package), please let me know!   ',
categories:[],tags:["elm","i18n","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"/blog/runtime-language-switching-elm/",teaser:"/assets/images/2018-05-11/ameet-dhanda-476959-unsplash.jpg"},{title:"Connecting Elm to Phoenix 1.4 with webpack",excerpt:'As of version 1.4, Phoenix has changed its front end configuration framework from Brunch to webpack version 4 (reasons given in this pull request). This means that the way to get Elm connected to Phoenix has also changed since I last wrote about it, so this blog post will re-tread those main steps (read: copy-paste them from the previous blog entry where possible), updating information where relevant.      NOTE: Phoenix 1.4 is in beta at the time of this writing, so if it still is at the time of your reading this, and you would like to follow along, you can install Phoenix 1.4 Beta by doing the following:    mix archive.uninstall phx_new mix archive.install https://github.com/phoenixframework/archives/raw/master/1.4-dev/phx_new.ez      Don\u2019t forget to re-install the latest stable version of Phoenix when you are done experimenting!    mix archive.uninstall phx_new mix archive.install https://github.com/phoenixframework/archives/raw/master/phx_new.ez   Generate Phoenix app   mix phx.new phx_elm_webpack cd phx_elm_webpack mix ecto.create mix phx.server   Navigate to http://localhost:4000/ and you should see the familiar Phoenix welcome screen.      No surprises here. Close down the server, and let\u2019s move on.   Generate Elm app   First, install Elm if you haven\u2019t already:   npm install elm --global   Next, in order to help us generate an Elm app with a default structure and sensible configuration, we\u2019ll use Create Elm App (inspired by Create React App):   npm install create-elm-app --global   Generate the new Elm app inside the \u201cfront end\u201d of the Phoenix application, which in this case means the assets/ directory:   cd assets create-elm-app elm   You should now have an elm folder alongside your js and css folders. Let\u2019s make sure it works as we expect:   cd elm elm-app start   Starting the Elm app should then automatically open a browser window for you at http://localhost:3000/, and you should see a message saying that\u2026      Note that the Elm app is running independently here: it knows nothing about the Phoenix environment that it\u2019s located in, and is happily using assets, like the image that you see, from its own assets/elm/public/ directory.   Now that we\u2019ve confirmed that both the Phoenix app and the Elm app work of their own accord, it\u2019s time to connect them together. Close down the Elm server and let\u2019s write some config.   Connect Elm to Phoenix   In order to get webpack to track our new Elm dependencies, we will need the Elm loader plugin. So, navigate to the assets/ folder and install it:   npm install elm-webpack-loader   Now, open up webpack.config.js in a text editor and add the configuration rule for Elm files underneath the css rule:   assets/webpack.config.js   // ... module.exports = (env, options) =&gt; ({   // ...   module: {     rules: [       {         test: /\\.js$/,         exclude: /node_modules/,         use: {           loader: \'babel-loader\'         }       },       {         test: /\\.css$/,         use: [MiniCssExtractPlugin.loader, \'css-loader\']       },       {         test: /\\.elm$/,         exclude: ["/elm-stuff/", "/node_modules"],         loader: "elm-webpack-loader",         options: {           debug: true,           // NOTE: `warn` option was removed in Elm 0.19.           // Re-enable if desired for use in Elm 0.18.           // warn: true,           cwd: path.resolve(__dirname, "elm")         }       }     ]   },   //... });   Display Elm app in Phoenix template   So that we show both Phoenix and Elm working together, let\u2019s keep the default generated Phoenix layout template as-is, and replace the content of the page index template with a &lt;div&gt; tag for the Elm app:   lib/phx_elm_webpack/templates/page/index.html.eex   &lt;div id="elm-main"&gt;&lt;/div&gt;   Next, we\u2019ll target that &lt;div&gt; tag and replace it with the content of the Elm app:   assets/js/app.js   Elm 0.18   // ... import Elm from "../elm/src/Main.elm"  const elmDiv = document.getElementById("elm-main") Elm.Main.embed(elmDiv)   Elm 0.19   // ... import { Elm } from "../elm/src/Main.elm"  const elmDiv = document.getElementById("elm-main") Elm.Main.init({ node: elmDiv })   Now, run mix phx.server again and navigate to http://localhost:4000 to see if we\u2019re in business:      Well, we\u2019re pretty much there: we can see that the Elm app is being rendered in the template, but we\u2019ve got a broken image. This is because that image currently lives inside the Elm app at assets/elm/public/logo.svg, and Phoenix doesn\u2019t know anything about compilation of static image assets within Elm applications: it\u2019s looking for assets under its own assets/static/ directory.   The path of least resistance here is, I think, to move all assets to where Phoenix is expecting to find them, and change the Elm code to point to them.   So, first, move the logo image into Phoenix\u2019s image assets directory:   mv assets/elm/public/logo.svg assets/static/images/logo.svg   Then, change the Elm code to look for the image in Phoenix (/images/logo.svg), rather than in Elm (/logo.svg):   assets/elm/src/Main.elm   module Main exposing (..)  -- ...  view : Model -&gt; Html Msg view model =     div []         [ img [ src "/images/logo.svg" ] []         , h1 [] [ text "Your Elm App is working!" ]         ]   Now, at http://localhost:4000/, you should see the following:      At this point, everything is technically working, so you can happily continue your application bootstrapping, but if you need to have the styling on this screen pixel perfect before finishing, read on.   Tell webpack about Elm app styling   Currently, the Elm app has some styling in assets/elm/src/main.css, and Phoenix has its styling in assets/css/app.css. However, if we have a look at the top of assets/js/app.js, we can see that only the Phoenix CSS is being imported, and hence loaded, by webpack. So, let\u2019s see what happens when we get webpack to load the Elm application\u2019s CSS file as well:   assets/js/app.js   import css from "../css/app.css" import "../elm/src/main.css"   Re-start the app and let\u2019s see what happened\u2026      Well, the Elm app styling looks like we would expect, but some of the Elm styles would seem to be overriding the Phoenix styles, so let\u2019s see if we can take the path of least resistance in fixing this (since this is all only temporary anyway\u2026).   First, give the Elm logo a HTML id so we can target styling on it directly:   assets/elm/src/Main.elm   module Main exposing (..)  import Html exposing (Html, text, div, h1, img) import Html.Attributes exposing (id, src)  -- ...  view : Model -&gt; Html Msg view model =     div []         [ img [ src "/images/logo.svg", id "elm-logo" ] []         , h1 [] [ text "Your Elm App is working!" ]         ]   Then, give the Elm styles some minor tweaks from their defaults\u2026   assets/elm/src/main.css   /* ... */  body {   text-align: center; }  h1 {   color: #293c4b;   font-family: \'Source Sans Pro\', \'Trebuchet MS\', \'Lucida Grande\', \'Bitstream Vera Sans\', \'Helvetica Neue\', sans-serif;   font-size: 30px; }  img#elm-logo {   margin: 20px 0;   max-width: 200px; }   Re-start the app, and\u2026      That looks about right. Now, you can get down to the business of ripping it all out again, and start building out your own Phoenix-and-Elm powered app!   ',categories:[],tags:["elixir","phoenix","elm"],url:"/blog/elm-phoenix-14-webpack/",teaser:"/assets/images/2018-07-26/functional_web_wallpaper.jpg"},{title:"Escape the defaults and Control your keyboard with QMK",excerpt:'I love mechanical keyboards, and have been using an Ergodox as my daily driver since 2014.      If you are someone who spends a lot of time using a keyboard, and are likely to continue to do so in the future, then I would:      encourage you to learn touch typing if you haven\u2019t already   consider ergonomic keyboard options to increase comfort, as well as reduce strain on your shoulders and wrists (the keyboard you choose does not necessarily have to be mechanical, or a split-hand option like the Ergodox)   If you are programmer or tinkerer, then getting a keyboard with programmable firmware can enable you to personalise how you use your keyboard, allowing your brain (or hand muscle memory) a say in assigning functionality to keys, rather than you having to train yourself to adapt to some product\u2019s specification.      When I got my first Ergodox, I used Massdrop\u2019s Ergodox Configurator to generate firmware for the keyboard. As I got to know my Ergodox better, and my brain started to tell me that it was expecting certain keys to be in different places from the default setup, I was able to use the Configurator\u2019s nice user interface to make basic changes, and then re-generate the firmware in a matter of minutes.   It was only when I started wanting to have a keystroke represent a combination of keys, rather than a single key, that I hit the limitations of what the web-based Configurator enabled me to do. So, I decided to bypass it and go straight to the source code that the Configurator itself was using to generate its firmware: Ben Blazak\u2019s Ergodox Firmware.   I am not a C language programmer, but after a period of tinkering, I was able to cobble together a custom keymap layout, and successfully flash it on to my keyboard firmware. It worked great, and I happily used it for years.   Then, one day, I wanted to make some updates, and realised that some code libraries that the firmware used were now so old and outdated that I was unable to compile a new version of the firmware on my computer.   As of this writing, it looks like development on the firmware has stalled, and so if I really wanted to update my keyboard layout, I would need re-write it for a new platform.   Enter QMK   After some investigation, I came to the conclusion that the Quantum Mechanical Keyboard (QMK) Firmware would likely be my best choice, given its popularity with Ergodox users, and because it supports many other keyboard types. So, I can continue to use it if, somehow, I accidentally end up buying other different types of mechanical keyboards (if you are into mechs, you know how it is\u2026 :money_with_wings:)   So, let\u2019s grab the firmware from Github:   git clone git@github.com:qmk/qmk_firmware.git cd qmk_firmware   Now, open up the QMK Ergodox EZ default layout (so called, I believe, because Ergodox EZ is now the pre-eminent retailer of original version Ergodoxes) to use as a base, and see about getting a feel for how to use it.   Keyboard Layout      Below is an abbreviated part of the default layout, focusing on one layer for the left side of an Ergodox keyboard:   qmk_firmware/keyboards/ergodox_ez/keymaps/default/keymap.c   // ... /* Keymap 0: Basic layer  *  * ,--------------------------------------------------.  * |   =    |   1  |   2  |   3  |   4  |   5  | LEFT |  * |--------+------+------+------+------+-------------|  * | Del    |   Q  |   W  |   E  |   R  |   T  |  L1  |  * |--------+------+------+------+------+------|      |  * | BkSp   |   A  |   S  |   D  |   F  |   G  |------|  * |--------+------+------+------+------+------| Hyper|  * | LShift |Z/Ctrl|   X  |   C  |   V  |   B  |      |  * `--------+------+------+------+------+-------------\'  *   |Grv/L1|  \'"  |AltShf| Left | Right|  *   `----------------------------------\'  *                                        ,-------------.  *                                        | App  | LGui |  *                                 ,------|------|------|  *                                 |      |      | Home |  *                                 | Space|Backsp|------|  *                                 |      |ace   | End  |  *                                 `--------------------\'  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL,          KC_1,        KC_2,          KC_3,    KC_4,    KC_5, KC_LEFT,   KC_DELT,         KC_Q,        KC_W,          KC_E,    KC_R,    KC_T, TG(SYMB),   KC_BSPC,         KC_A,        KC_S,          KC_D,    KC_F,    KC_G,   KC_LSFT,         CTL_T(KC_Z), KC_X,          KC_C,    KC_V,    KC_B, ALL_T(KC_NO),   LT(SYMB,KC_GRV), KC_QUOT,     LALT(KC_LSFT), KC_LEFT, KC_RGHT,                                                         ALT_T(KC_APP), KC_LGUI,                                                                        KC_HOME,                                                KC_SPC,  KC_BSPC,       KC_END,   // .. )   Here, we can see:      Constant variables that begin with KC_. These represent a single basic key code, like the \u201cA\u201d or \u201c1\u201d keys.   Other mappings that do not begin with KC_. These are functions that take arguments, and can represent actions like holding down one key while pressing another.   All these constants and functions (and more representing every key on a keyboard, as well as various key combinations) are enumerated in the QMK Keycodes Documentation, and are available to use in the layout without any further configuration.   That\u2019s all well and good, but what if there is no built-in mapping for a key combination you want to perform?   Custom Key Mappings   Let\u2019s say that on the layout above, instead of having the top left corner key be the \u201c=\u201d character (ie KC_EQL) when tapped, you would like it to perform some custom combination of key presses, which we\u2019ll name MY_KEY_COMBO.   Where does MY_KEY_COMBO get declared, and where do we define what it is supposed to actually do? Well, there are three main steps for this, but before we do them, let\u2019s create a copy of the default keymap folder, put it into a custom directory, and make our edits on that:   cp -r qmk_firmware/keyboards/ergodox_ez/keymaps/default qmk_firmware/keyboards/ergodox_ez/keymaps/custom   First, we need to add a new MY_KEY_COMBO type to the existing custom_keycodes enumerated types list, which is declared towards the top of the keymap file:   qmk_firmware/keyboards/ergodox_ez/keymaps/custom/keymap.c   enum custom_keycodes {   // ...   MY_KEY_COMBO };   Now, we can replace KC_EQL with MY_KEY_COMBO in the keyboard layout:   // ... [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   MY_KEY_COMBO, KC_1, KC_2, KC_3, KC_4, KC_5, KC_LEFT,   // ...   To give this new type some behaviour, we need to register it inside a function called process_record_user(), which can be found towards the bottom of the keymap file:   bool process_record_user(uint16_t keycode, keyrecord_t *record) {   switch (keycode) {     case MY_KEY_COMBO:       if (record-&gt;event.pressed) {         // Do whatever it is that MY_KEY_COMBO is supposed to do when pressed       }       return false;       break;     // other case statements ...   }   return true; }   process_record_user() will get called automatically whenever a key on your keyboard is pressed or released, so there is no need to add any code that specifically calls it. More information about this function, as well as how to define a new key code, can be found on the QMK Custom Quantum Functions documentation page.      You will, of course, see more code and functions in the keymap file, but for what we want to accomplish, we just need to concern ourselves with a limited section of code. If there is anything you see that we do not cover, and that you do not understand, and you want more information about, then definitely give the QMK documentation a search.    So, now that we know where we need to put code for custom key actions, what kind of implementation code can we actually put in there? We will answer this with a few examples of the actions I have in my personal keymap.   Key Requirements   My main use cases for custom key actions pretty much fall into the following categories:      Output a string of characters on screen, which enables single-key mappings to programming-related operators like the pipe operator (|&gt;) from Elixir, ERB tags (&lt;%=, %&gt;) from Ruby, and emoji codes like :+1: (:+1:)   Key Hold/Key Press combinations of varying complexity, which enable single key mappings for application start up or manipulation. For example, Option-Space for Alfred, Shift-Command-Space for Divvy, and Alt-Command-Left/Right for moving web browser tabs to the left or right.   Modifying a key based on its state. For example, re-mapping the Caps Lock key to be Control when held, and Escape when tapped: a popular mod for Vim users.   QMK does have built-in functionality for some of these use-cases:      The Mod Tap function LCTL_T(kc) is Left Control when held, and kc when tapped. So, LCTL_T(KC_ESC) will provide the desired \u201cLeft Control when held, Escape when tapped\u201d functionality. All that needs to be done is assign that function to a key, and you will be a happy Vimmer.   Modifier Key functions like LALT(kc) (apply Left Alt to kc), and SGUI(kc) (Hold Left Shift and GUI \u2014 read: \u2318Command \u2014 and press kc), cover Alfred and Divvy commands (LALT(KC_SPACE) and SGUI(KC_SPACE) respectively).   For the rest though, we will need to write some custom implementation code.   Sending Strings   Let\u2019s get started with the programming-related operators and emoji codes. Like before, first add the new types:   qmk_firmware/keyboards/ergodox_ez/keymaps/custom/keymap.c   enum custom_keycodes {   // ...   FORWARD_PIPE   LEFT_ERB   PLUS_ONE   RIGHT_ERB };   Assign the types to some keys (these key locations are illustrative only, you probably don\u2019t actually want these keys at the top left of the board):   // ... [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   FORWARD_PIPE, LEFT_ERB, PLUS_ONE, RIGHT_ERB, KC_4, KC_5, KC_LEFT,   // ...   And now, let\u2019s use the SEND_STRING Feature Macro to type out the strings:   bool process_record_user(uint16_t keycode, keyrecord_t *record) {   if (record-&gt;event.pressed) {     switch (keycode) {       case FORWARD_PIPE:         SEND_STRING("|&gt;");         return false;       case LEFT_ERB:         SEND_STRING("&lt;%=");         return false;       case PLUS_ONE:         SEND_STRING(":+1:");         return false;       case RIGHT_ERB:         SEND_STRING("%&gt;");         return false;     }   }   return true; }   That wasn\u2019t too bad! All we have left now is getting Alt-Command-Left/Right working for navigating browser tabs. Unfortunately, the list of Modifier Keys, although comprehensive, does not have a function available for holding down Alt, Command, and pressing a key. So, we will have to manually re-create it.   Create two new types, LEFT_PANE and RIGHT_PANE, add them to the custom_keycodes enumerated types list, and assign them to keys, just like with the previous types. Then, their implementation will look something like this:   qmk_firmware/keyboards/ergodox_ez/keymaps/custom/keymap.c   bool process_record_user(uint16_t keycode, keyrecord_t *record) {   if (record-&gt;event.pressed) {     switch (keycode) {       // ...       case LEFT_PANE:         SEND_STRING(SS_DOWN(X_LALT)SS_DOWN(X_LGUI));         SEND_STRING(SS_TAP(X_LEFT));         SEND_STRING(SS_UP(X_LGUI)SS_UP(X_LALT));         return false;       case RIGHT_PANE:         SEND_STRING(SS_DOWN(X_LALT)SS_DOWN(X_LGUI));         SEND_STRING(SS_TAP(X_RIGHT));         SEND_STRING(SS_UP(X_LGUI)SS_UP(X_LALT));         return false;     }   }   return true; }   Let\u2019s take a look at what\u2019s going on here:      SS_DOWN, SS_UP, and SS_TAP are specific Feature Macros that cover pressing (but not releasing) a key, releasing a key, and pressing-and-releasing a key respectively. So, we are issuing three commands in our case statements: press (and hold) Left Alt and Left GUI, then tap the Left (or Right) Arrow key, then release the Left GUI and Left Alt keys.   Keycodes, when used with the SEND_STRING function, apparently need to have an X_ prefix, rather than KC_, \u201cbecause of some pre-processor magic\u201d\u2026 \xaf\\_(\u30c4)_/\xaf   Compile Time   At this point, we should have a compilable program, so if you wanted to generate the firmware, return to the root qmk_firmware directory, and after installing the build tools for your system, run the following command:   make ergodox_ez:custom   This should result in an ergodox_ez_custom.hex file being generated in the qmk_firmware root directory, which can then be used to flash the Ergodox keyboard firmware, instructions for which are in the video on the ErgoDox EZ Graphical Configurator page (consult your keyboard\u2019s documentation for its specific firmware-flashing instructions).   Rather than actually compiling and using the layout we have created here, though, use what we have done as a base for thinking about what custom keys you would like to have, and then creating your own personal keymap layout.   There is plenty of inspiration in the QMK Ergodox EZ keymaps directory (or in the keymaps directory of whatever type of keyboard you may be using), and please feel free to take anything of use from my own keymap layout.   Other Resources      If you like emoji, but would prefer to have your mappings send Unicode characters, rather than emoji codes (eg SEND_STRING(SS_LALT("D83D+DC4D")) rather than SEND_STRING(":+1:")), then check out the One-keystroke Unicode characters in QMK on macOS blog post by Rebecca Le.   Bonus: Software-based Key Mapping for Mac   Sometimes, you just cannot get to an external keyboard and need to use the keyboard built-in to your laptop computer. If you need key mappings in that situation, then I can definitely recommend Karabiner Elements. My mappings look like the following from the user interface:      Some notes on these rules:      In order to get a mirroring \u201cCaps Lock to Control/Escape\u201d key on the right side of the keyboard for Vim, using a combination of rules, I mapped Enter/Return to be \u201cControl when held, Return/Enter when tapped\u201d. Works great for touch typing Vimmers that want to stay close to the home row!   The final rule represents the following mappings: when Left-\u2318 is tapped (not held), send the \u201c\u82f1\u6570\u201d (eis\u016b, alphanumeric) key, and when Right-\u2318  is tapped (not held), send the \u201c\u304b\u306a\u201d (kana, Japanese) key. These two keys are often found on Japanese Mac OS keyboards and make it easy to switch between the inputting English and Japanese. More info here if you are interested.   You can also get the config details in karabiner.json from my Dotfiles.   Happy Clacking!   ',categories:[],tags:["ergodox","keyboards","mechanical-keyboards","qmk","clang","japanese","\u65e5\u672c\u8a9e"],url:"/blog/escape-defaults-control-keyboard-qmk/",teaser:"/assets/images/2018-07-31/ergodox-ez.jpg"},{title:"The Curious Incident of the Shadow in the Run-Time",
excerpt:'Coding in Ruby is full of sweetness and light, but where there is light, shadows are cast. So, let\u2019s get out our torches and see if we can illuminate our way through these darker corners of the language.   Variable Shadowing   The use of shadowing in a codebase usually refers to variable shadowing. A basic example of this in Ruby would be:   variable_shadowing.rb   x = 42 3.times { |x| puts "x is #{x}" }   Notice that there are two variables named \u201cx\u201d: the outer variable, and the block variable. Is this an actual problem, though? Let\u2019s try running it:   $ ruby variable_shadowing.rb x is 0 x is 1 x is 2   The output looks reasonable. The call to puts is inside a block, so it outputs the x value that is local to that block: it would definitely be surprising if puts prioritised values that are outside of its local scope, and output \u201cx is 42\u201d three times.   So, does Ruby really care that we are writing our code like this as long as we are getting the output we expect? To answer that, let\u2019s try running the program again, but this time with warnings enabled:   $ ruby -w variable_shadowing.rb variable_shadowing.rb:2: warning: shadowing outer local variable - x variable_shadowing.rb:1: warning: assigned but unused variable - x x is 0 x is 1 x is 2   It looks like Ruby does care: about both the shadowing, as well as declaring an unused variable (not enough to raise an error, but enough to make you feel that perhaps Matz is very mildly frowning at you). But why, though? Well, one reason could be that what if we wanted to change our program to have puts output both the block variable and the outer variable?   variable_shadowing.rb   x = 42 3.times { |x| puts "Local x is #{x} and outer x is #{\'What goes here??\'}" }   Since we already have a local variable named x, there is no way to access some other variable, also called x, that is outside the local scope. In order to get this to work, we would have to change the name of one of the variables:   variable_shadowing.rb   y = 42 3.times { |x| puts "x is #{x} and y is #{y}" }   $ ruby -w variable_shadowing.rb x is 0 and y is 42 x is 1 and y is 42 x is 2 and y is 42   This is why variable shadowing in Ruby is generally considered \u201ca bad habit and should be discouraged\u201d. Aside from Ruby warnings, Rubocop has a ShadowingOuterLocalVariable cop (which mimics Ruby\u2019s warning), so there are ways to enable your tools to help you keep the shadows at bay.   However, there is another kind of shadowy figure lurking at the peripheries of the Ruby language, aside from the variable-on-variable kind, that Ruby tooling does not warn you about. You are probably unlikely to come across it in the wilds of production code, but it is worth knowing about since it can make for some interesting/confusing behaviour.   Instance Method Shadowing                    Photo by Samuel Zeller on Unsplash        The Local Variables and Methods Assignment section of Ruby\u2019s syntax documentation says that:      In Ruby, local variable names and method names are nearly identical. If you have not assigned to one of these ambiguous names, Ruby will assume you wish to call a method. Once you have assigned to the name, Ruby will assume you wish to reference a local variable.     The local variable is created when the parser encounters the assignment, not when the assignment occurs.    Ruby parses code line by line from top to bottom during run time. So, the understood meaning of one of the \u201cnames\u201d mentioned above can change as the parser moves down the file: what was originally considered a method call, can become a reference to a local variable.   Let\u2019s illustrate this using a completely contrived example:   person.rb   class Person   attr_accessor :name    def initialize(name = nil)     @name = name   end    def say_name     if name.nil?       name = "Unknown"     end      puts "My name is #{name.inspect}"   end end   Given what we now know of local variable and method assignment, I would expect the following to happen when we attempt to get a Person to say its name:      In the #say_name instance method, the first occurrence of name, seen in the if name.nil? statement, would refer to the #name instance method provided by attr_accessor   When the Ruby parser sees the name = "Unknown" assignment line, it will, from that point on, consider any reference to name after the assignment to refer to a local variable called name, and not the instance method #name   Therefore, even if an object of Person had a @name assigned to it on initialisation (eg Person.new("Paul")), the name referenced in the final line of the #say_name method (name.inspect) would have a value of nil. This is because at the point of name.inspect, even though name.nil? would have failed, and therefore the name = "Unknown" local variable assignment would not actually be made, the parser still sees that name should now refer to a local variable, which has not been assigned to, and so is nil.   Let\u2019s open up an IRB console and test these assumptions.   $ irb irb(main):001:0&gt; require "./person.rb" true irb(main):002:0&gt; Person.new("Paul").say_name My name is nil nil   Looks like the first assumption is confirmed:      the instance method check of name.nil? fails   a name local variable is not assigned   name.inspect is checking the value of a local variable and not an instance method   name is therefore nil   Now, what happens when we initialise a Person object without a name:   irb(main):003:0&gt; Person.new.say_name My name is "Unknown" nil      name.nil? succeeds   name local variable is assigned to "Unknown"   "Unknown" is that value that gets output.   Great! I mean, kind of weird, but okay! Now, how about we dive a bit deeper and see if we can observe how the referencing of name changes as the Ruby parser reads through the code.   Schrodinger\u2019s Variable                    Photo by Jo\xe3o Silas on Unsplash        We will use the Pry debugger to see if we can follow name\u2019s journey from instance method to local variable. After you      run gem install pry   add require "pry" at the top of person.rb   add a binding.pry breakpoint at the beginning of the #say_name method   open up another IRB console and let\u2019s take a peek at what is going on.   $ irb irb(main):001:0&gt; require "./person.rb" true irb(main):002:0&gt; Person.new("Paul").say_name  From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   if name.nil?     14:     name = "Unknown"     15:   end     16:     17:   puts "My name is #{name.inspect}"     18: end  [1] pry(#&lt;Person&gt;)&gt;   Right, we now have a breakpoint at the point where name.nil? gets checked. At this point, we have not reached the name variable assignment, so name should refer to the instance method, and have a value of "Paul". Let\u2019s check:   irb(main):002:0&gt; Person.new("Paul").say_name  From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   if name.nil?     14:     name = "Unknown"     15:   end     16:     17:   puts "My name is #{name.inspect}"     18: end  [1] pry(#&lt;Person&gt;)&gt; name nil [2] pry(#&lt;Person&gt;)&gt;   Err, what? How does name have a value of nil if we have not reached the variable assignment statement yet? What is name referring to? Is this some weird Pry thing? So many questions\u2026   Well, regardless of having our expectations flipped, let\u2019s follow this through to the end. Since we now have nil, I would expect that our next stop will be at line 14, where "Unknown" does get assigned to name. Let\u2019s get Pry go to the next execution statement:   [1] pry(#&lt;Person&gt;)&gt; name nil [2] pry(#&lt;Person&gt;)&gt; next  From: /person.rb @ line 17 Person#say_name:      10: def say_name     11:   binding.pry     12:     13:   if name.nil?     14:     name = "Unknown"     15:   end     16:  =&gt; 17:   puts "My name is #{name.inspect}"     18: end  [2] pry(#&lt;Person&gt;)&gt;   It\u2026skipped directly to the bottom, and it would seem that the assignment did not happen. Let\u2019s see if that is the case, and what gets output:   From: /person.rb @ line 17 Person#say_name:      10: def say_name     11:   binding.pry     12:     13:   if name.nil?     14:     name = "Unknown"     15:   end     16:  =&gt; 17:   puts "My name is #{name.inspect}"     18: end  [2] pry(#&lt;Person&gt;)&gt; name nil [3] pry(#&lt;Person&gt;)&gt; exit My name is nil nil irb(main):003:0&gt;   This is all quite confusing. We got the expected result from running Person.new("Paul").say_name, but, on the way, did we encounter some kind of spooky quantum Ruby that ended up changing the value of name just because we observed it? Well, before we start handing ourselves honorary doctorates in quantum computing, let\u2019s call on the old traditional Ruby debugger, puts, to see if we can get an impartial view of what the value of name is before the name.nil? check:   $ irb irb(main):001:0&gt; require "./person" true irb(main):002:0&gt; Person.new("Paul").say_name  From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   puts name.inspect     14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end   Now, let\u2019s compare what value we get for name when using Pry, versus the value we get inside the code with puts:   [1] pry(#&lt;Person&gt;)&gt; name nil [2] pry(#&lt;Person&gt;)&gt; next "Paul"  From: /person.rb @ line 14 Person#say_name:      10: def say_name     11:   binding.pry     12:     13:   puts name.inspect  =&gt; 14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end  [2] pry(#&lt;Person&gt;)&gt;   Running next executes the puts name.inspect code, which gives us "Paul", the value we expect, but Pry still says that name is nil. How can the same variable have two values? It can\u2019t, so there must be something else at play here. What version of name exactly are Pry and puts seeing when the code is being stepped through? Well, there is one more Ruby tool that can help us find that out: the defined? keyword, which returns a string describing its argument.   $ irb irb(main):001:0&gt; require "./person" true irb(main):002:0&gt; Person.new("Paul").say_name  From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   puts defined?(name).inspect     14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end   Okay, first, let\u2019s see what what the Ruby code considers name to be:   From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   puts defined?(name).inspect     14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end  [1] pry(#&lt;Person&gt;)&gt; next "method"   Ruby says name is a method! That gels with what we would expect. So what about Pry\u2026?   From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   puts defined?(name).inspect     14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end  [1] pry(#&lt;Person&gt;)&gt; defined?(name) "local-variable"   Pry sees name as a local variable! How can this be if we have not reached the assignment statement yet? Can Pry see into the future? Well, Pry itself can\u2019t, and what is happening is not really seeing into the future.   Not even slightly elementary, my dear Ruby   The key to this mystery is the binding part of the binding.pry statement. Ruby\u2019s Binding \u201cencapsulates the execution context at some particular place in the code\u201d, which, in our case, is the entirety of the #say_name method.   When we step through the code with binding.pry, at the point of the name.nil? statement, the Ruby parser sees name as referring to a method, since it knows nothing about any assignment statements yet. Pry, on the other hand, thanks to the binding effectively \u201crushing ahead to read the rest of the method\u201d so it can create its execution context, knows all about the local variable assignments that could happen. Hence, we can now see the discrepancies in the results between running puts inline and using Pry in this case.   How can you avoid falling into these kinds of pits of potential confusion? Well, just don\u2019t shadow, really. Leaving aside the quality issues of the example code (it is meant to illustrative of the problem and not exemplary Ruby code after all), to get expected results, there are enough ways it could be changed to fulfil different objectives like:           Specifically assign to the person\u2019s name attribute if they were not given one:       def say_name   if name.nil?     self.name = "Unknown"   end   puts "My name is #{name.inspect}" end                Output a display name without assigning a name attribute if one was not originally given.                       Using self to refer to the name property:           def say_name   name = self.name || "Unknown"   puts "My name is #{name.inspect}" end                                Using parentheses:           def say_name   name = name() || "Unknown"   puts "My name is #{name.inspect}" end                           So, be kind to your future self and your team mates, and re-consider shadowing in your code. If you ever do find yourself needing to, though, be sure to leave a comment explaining why.   Other Resources      Behaviours of a Ruby local variable shadowing an instance method - A Stack Overflow question I asked regarding this kind of shadowing and that eventually led to the creation of this blog post.   What does \u201cshadowing\u201d mean in Ruby? - A good Stack Overflow question outlining variable shadowing in Ruby.   A Ruby shadowing bug in the wild - The blog post that originally got me scratching the surface of Ruby shadowing.   ',categories:[],tags:["ruby","shadowing"],url:"/blog/curious-incident-shadow-run-time/",teaser:"/assets/images/2018-08-20/matthew-ansley-254316-unsplash.jpg"},{title:"Starting Stenography with an Ergodox",
excerpt:"After years of touch typing using everyone\u2019s favourite 19th century keyboard layout (QWERTY), I seem to have capped out my typing speed abilities at about 80-85 words-per-minute (WPM).   This isn\u2019t too bad for my needs as a programmer, but I was curious about whether there were any other ways that could help me improve. So, I did a bit of research on other potential layout options like Dvorak, Colemak, and Workman, all of which purport to increase the speed and efficiency of your typing, as well as cut down the travel distance of your fingers, hence reducing the strain on your hands and wrists.   I cannot vouch personally for any of their claims: I did not find the time-and-effort investment in learning one of those layouts, versus the potential benefits, particularly appealing. So, I gave up and just carried on my merry 80 WPM-way.   That is, until a visit to the Open Steno Project put stenography on my radar as an actual viable choice to potentially supercharge my WPM rate. As of this writing, I have just started learning, so I have no idea if I actually will improve, or whether I will continue down the steno path in the future.   However, just getting my Ergodox set up for stenography was quite an exercise in configuration, so that will be the focus for the remainder of this blog post, in hopes that it will help get the Ergodox-toting steno-curious up and running as quickly as possible.      What You Need      An Ergodox \u2014 if you do not have one already, buy one or wait for the next kit to drop if you want to build one   Quantum Mechanical Keyboard (QMK) Firmware \u2014 see my blog post Escape the defaults and Control your keyboard with QMK for a guide to set up an Ergodox with QMK from scratch.   Plover \u2014 open source software that lets you use your keyboard as a steno machine (installation instructions)      A small note about Plover: if you open it, and it immediately crashes without any kind of error message, you may need to check your operating system-level keyboard input source. If you use Google IME or a symbolic language like Japanese or Korean, you will probably \u201chave to change to a QWERTY/US layout to use Plover for now\u201d.    UPDATE 05 May 2021: Oryx now supports steno!   The Oryx online keyboard layout configuration tool by ZSA Technology Labs, makers of the Ergodox EZ, now supports configuring stenography keys!   This means that rather than get your hands dirty with code, you can use the nice web-based user interface to create your steno firmware.   Here is a layout I created using Oryx based on the one described in this blog post:      My Oryx Steno Layout   Feel free to take whatever you would like from it, or use it as a base to build out your own configuration!   If you are interested in coding up your own layout or getting in to some technical details, then definitely read on. Otherwise, you can probably skim the rest of this post, and only focus on the sections that involve configuring the Plover application itself.   Initial Setup   For this post, we will use the QMK default Ergodox EZ keymap as a base, and make changes to it to add functionality for stenography. Feel free to follow along as-is, or make appropriate changes to your own custom keymaps. You can also see the finished layouts in this post\u2019s companion keymaps on my QMK example keymaps Github repository:      QWERTY Steno   Default Steno High   Default Steno   (These keymap names will make more sense as you read through the post).   After installing the build tools for your operating system, make a clone of the QMK Firmware repository from Github if you do not have one already. Then, create a copy of the default Ergodox EZ keymaps directory into a new directory that we will call default_steno:   git clone git@github.com:qmk/qmk_firmware.git cd qmk_firmware cp -r keyboards/ergodox_ez/keymaps/default keyboards/ergodox_ez/keymaps/default_steno      If you have had a look through the list of provided QMK Ergodox keymaps, you may have seen that there is already a steno configuration provided, so why not just use that? Why go to the trouble of creating another layout? Well\u2026          The provided layout does not take advantage of QMK\u2019s built-in support for stenography (which we will go over later), and instead re-implements steno functionality from scratch using custom binary key codes and custom functions     The codes would seem to only work with the TX Bolt steno protocol (which, at least for me, resulted in incorrect key press processing, but more about that later as well\u2026)       UPDATE 28-04-2019: The issue with TX Bolt is now fixed, and the current QMK Ergodox EZ steno configuration does now use QMK\u2019s built-in support for stenography. I may be biased, but I think the rest of this post still has value, with the added benefit of now having less configuration to do if you decide to adapt QMK\u2019s current Ergodox steno configuration for your own needs.    N-Key Rollover   Before adding a new keyboard layout to our keymap, the first thing we will need to do is ensure that we have N-Key Rollover (NKRO) enabled.   Stenography involves hitting multiple keys at once in a \u201cchord\u201d-like fashion. Therefore, we need to make sure that all of these key presses are detected by the Ergodox so they can be sent to the computer; keyboards typically detect up to 6 simultaneous key presses (aka \u201c6KRO\u201d), so the \u201cn\u201d in NKRO essentially stands for \u201cas many keys as you like\u201d.   The easiest way to confirm whether you have NKRO enabled is to perform Plover\u2019s Keyboard Ghosting Test. In the Plover in-browser steno demo, if you find that only 6 keys light up on screen when you press the ASDFJKL; keys all at once, then you currently do not have NKRO enabled.   Luckily, the QMK Ergodox firmware has a built-in shortcut that can turn this on for you: hold down Left-Shift + Right-Shift + N. Now, try the steno demo again and you should see 8 keys light up on screen.   Having to turn NKRO on again manually every time you re-flash Ergodox firmware is going to get tiresome and potentially confusing, so let\u2019s create some files to tell the firmware to enable it by default.   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/rules.mk   FORCE_NKRO = yes   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/config.h   #include \"../../config.h\"  #define FORCE_NKRO   You may be wondering why we need a config.h file since rules.mk already has a rule that says to force NKRO to be on.  The best explanation I could find is that NKRO is, apparently, \u201cdisabled by default because some bioses aren\u2019t compatible with NKRO\u201d. So, I would just say to accept it, smile and nod, and just know that if you make these changes and then re-flash your firmware (see the video on the Ergodox EZ Graphical Configurator Page for how to do that), you should see that NKRO is now on without having to manually enable it.   New Steno QWERTY layer   The QMK default Ergodox EZ keymap has three layers: a base layer, a layer for symbols, and a layer for media keys (for our purposes, we can safely ignore the symbol and media keys layers). We cannot use the base QWERTY layer as-is for stenography: we need to move some keys around, and some keys we will not use. So, let\u2019s add a new stripped-down QWERTY-like layer based on the QWERTY-to-steno mapping that Plover is expecting, which we will call STEN.   We will then (arbitrarily) assign the top right-most key on the left hand of the BASE layer to be the toggle to turn the STEN layer on and off, using QMK\u2019s TG(layer) function:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/keymap.c   // ... #define BASE 0 // default layer #define SYMB 1 // symbols #define MDIA 2 // media keys #define STEN 3 // Stenography  // Helper to make keymaps a bit easier to read at a glance #define _x_ KC_NO #define ___ KC_TRNS  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Keymap 0: Basic layer  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  | STEN | ...  * |--------+------+------+------+------+-------------| ...  * ...  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL, KC_1, KC_2, KC_3, KC_4, KC_5, TG(STEN),   // ... ), // ... [SYMB] = LAYOUT_ergodox(   // ... ), // ... [MDIA] = LAYOUT_ergodox(   // ... ), /* Keymap 3: Modified QWERTY for Stenography  *  * ,--------------------------------------------------.  ,--------------------------------------------------.  * |   [x]  |   1  |   2  |   3  |   4  |   5  |      |  |  [x] |   6  |   7  |   8  |   9  |   0  |  [x]   |  * |--------+------+------+------+------+------+------|  |------+------+------+------+------+------+--------|  * |   [x]  |   Q  |   W  |   E  |   R  |   T  |      |  |      |   Y  |   U  |   I  |   O  |   P  |   [    |  * |--------+------+------+------+------+------|  [x] |  |  [x] |------+------+------+------+------+--------|  * |   [x]  |   A  |   S  |   D  |   F  |   G  |------|  |------|   H  |   J  |   K  |   L  |   ;  |   '    |  * |--------+------+------+------+------+------|      |  |      |------+------+------+------+------+--------|  * |   [x]  |  [x] |  [x] |  [x] |  [x] |      |  [x] |  |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |  [x]   |  * `--------+------+------+------+------+-------------'  `-------------+------+------+------+------+--------'  *   | [x]  |  [x] |  [x] |  [x] |  [x] |                              |  [x] |  [x] |  [x] |  [x] |  [x] |  *   `----------------------------------'                              `----------------------------------'  *                                      ,-------------.  ,-------------.  *                                      |  [x] |  [x] |  |  [x] |  [x] |  *                               ,------|------|------|  |------+------+------.  *                               |      |      |  [x] |  |  [x] |      |      |  *                               |  C   |   V  |------|  |------|   N  |   M  |  *                               |      |      |  [x] |  |  [x] |      |      |  *                               `--------------------'  `--------------------'  */ [STEN] = LAYOUT_ergodox(  // layer 3 : Modified QWERTY for Stenography   // left hand   _x_, KC_1, KC_2, KC_3, KC_4, KC_5, ___,   _x_, KC_Q, KC_W, KC_E, KC_R, KC_T, _x_,   _x_, KC_A, KC_S, KC_D, KC_F, KC_G,   _x_, _x_,  _x_,  _x_,  _x_,  _x_,  _x_,   _x_, _x_,  _x_,  _x_,  _x_,                                _x_,  _x_,                                      _x_,                          KC_C, KC_V, _x_,   // right hand   _x_, KC_6, KC_7, KC_8, KC_9, KC_0,    _x_,   _x_, KC_Y, KC_U, KC_I, KC_O, KC_P,    KC_LBRC,        KC_H, KC_J, KC_K, KC_L, KC_SCLN, KC_QUOT,   _x_, _x_,  _x_,  _x_,  _x_,  _x_,     _x_,              _x_,  _x_,  _x_,  _x_,     _x_,   _x_, _x_,   _x_,   _x_, KC_N, KC_M ) }; // ...      Note the uses of _x_and ___ here:          _x_ specifically indicates that pressing the key results in a NOOP: the keystroke is ignored     ___ is a \u201ctransparent\u201d mapping, which in this case for the toggle key, will \u201cfall back\u201d to the TG(STEN) function on the BASE layer. This is really just a convenience so that we don\u2019t need to specify TG(STEN) again on the STEN layer       More information about these two mappings in the QMK Special Keys documentation.    Next, generate the firmware from the qmk_firmware directory root path:   make ergodox_ez:default_steno   This should generate an ergodox_ez_default_steno.hex file, which you can then use to flash your Ergodox firmware. If you get any build issues, check what you have against my example code for this layer.   Once you\u2019ve flashed your keyboard firmware, open up your favourite text editor, press the top right-most key on the left hand to toggle the steno layer, and type some text to confirm that all is working as expected (the thumb clusters using the CVNM keys are a good litmus test).   Now, there is no steno magic happening quite yet, since our keystrokes are being interpreted and output as-is by the computer. What we need now is something to receive our keystrokes, and then translate them what a steno machine would output.   Enter Plover   Open up the Plover application, select the \u201cEnable\u201d radio button, and try typing again.      The output should be completely different than before, which would indicate that everything is working: we are typing in steno! So, what I would recommend doing now is opening up Lesson 1 of the Learn Plover! free text book, try typing some of the one-syllable steno words, and generally have a play around.   Awesome! Are we done now\u2026?   From a keyboard configuration and typing standpoint, we have pretty much achieved our objectives. In order to get back to our base QWERTY layout, we will need to:      Click the \u201cDisable\u201d radio button on the Plover window so that our keystrokes do not get translated into steno output any more   Press the key to toggle the STEN layer off and get back to our BASE layer   If you feel comfortable with this setup, then you are all done!   First-world Steno Problems   For me though, even after a few minutes of using this setup, I ended up being annoyed about having to turn steno functionality \u201coff\u201d at both the hardware and software level. When I toggle my STEN layer off, I want the computer/Plover to consider me out of steno-mode and back into vanilla-keyboard-mode: I do not want to have to remember to manually disable Plover.   So, what can be done about this? You could do something similar to what Waleed Khan did, and create a macro in your keyboard layout that toggles Plover when the steno layer is toggled, bringing hardware and software in sync with each other. This is a very valid option, though I wondered if I could somehow have Plover enabled all the time, but just have it ignore any non-steno input.   As it turns out, we can do exactly this by doing the following:      Have QMK speak to Plover using a steno machine protocol that Plover understands   Have Plover listen only for input in that protocol, ignoring non-steno keyboard chatter   Since our STEN layer currently sends standard key presses to Plover, we will have to completely change the layout to use QMK steno keycodes instead of character key presses. So, back to the text editor!   Steno Layer: Take 2   Open up the keymap file and change the code so that it looks like this:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/keymap.c   // ... #include \"keymap_steno.h\"  #define BASE 0 // default layer #define SYMB 1 // symbols #define MDIA 2 // media keys #define STEN 3 // Stenography  // Helper to make keymaps a bit easier to read at a glance #define _x_ KC_NO #define ___ KC_TRNS  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Keymap 0: Basic layer  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  | STEN | ...  * |--------+------+------+------+------+-------------| ...  * ...  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL, KC_1, KC_2, KC_3, KC_4, KC_5, TG(STEN),   // ... ), // ... [SYMB] = LAYOUT_ergodox(   // ... ), // ... [MDIA] = LAYOUT_ergodox(   // ... ), /* Keymap 3: Stenography  *  * ,--------------------------------------------------.           ,--------------------------------------------------.  * |   [x]  |   #  |   #  |   #  |   #  |   #  |      |           |  [x] |   #  |   #  |   #  |   #  |  #   |   #    |  * |--------+------+------+------+------+------+------|           |------+------+------+------+------+------+--------|  * |   [x]  |   S  |   T  |   P  |   H  |   *  |      |           |      |   *  |   F  |   P  |   L  |   T  |   D    |  * |--------+------+------+------+------+------|  [x] |           |  [x] |------+------+------+------+------+--------|  * |   [x]  |   S  |   K  |   W  |   R  |   *  |------|           |------|   *  |   R  |   B  |   G  |   S  |   Z    |  * |--------+------+------+------+------+------|      |           |      |------+------+------+------+------+--------|  * |   [x]  |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |           |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |  [x]   |  * `--------+------+------+------+------+-------------'           `-------------+------+------+------+------+--------'  *   | [x]  |  [x] |  [x] |  [x] |  [x] |                                       |  [x] |  [x] |  [x] |  [x] |  [x] |  *   `----------------------------------'                                       `----------------------------------'  *                                        ,-------------.       ,-------------.  *                                        |  [x] |  [x] |       |  [x] |  [x] |  *                                 ,------|------|------|       |------+------+------.  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 |  A   |   O  |------|       |------|   E  |   U  |  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 `--------------------'       `--------------------'  */ [STEN] = LAYOUT_ergodox(  // layer 3 : Stenography     // left hand     _x_, STN_N1, STN_N2, STN_N3, STN_N4, STN_N5,  ___,     _x_, STN_S1, STN_TL, STN_PL, STN_HL, STN_ST1, _x_,     _x_, STN_S2, STN_KL, STN_WL, STN_RL, STN_ST2,     _x_, _x_,    _x_,    _x_,    _x_,    _x_,     _x_,     _x_, _x_,    _x_,    _x_,    _x_,                                          _x_,     _x_,                                                   _x_,                                  STN_A,  STN_O,   _x_,   // right hand   _x_, STN_N6,  STN_N7, STN_N8, STN_N9, STN_NA, STN_NB,   _x_, STN_ST3, STN_FR, STN_PR, STN_LR, STN_TR, STN_DR,        STN_ST4, STN_RR, STN_BR, STN_GR, STN_SR, STN_ZR,   _x_, _x_,     _x_,    _x_,    _x_,    _x_,    _x_,                 _x_,    _x_,    _x_,    _x_,    _x_,   _x_, _x_,   _x_,   _x_, STN_E,   STN_U ) };  // ...  // Runs just one time when the keyboard initializes. void matrix_init_user(void) {   // ...   steno_set_mode(STENO_MODE_GEMINI); };   Some notes about these changes:      #include \"keymap_steno.h\" at the top of the file enables us to use QMK steno-specific functionality like keycodes and protocols   The keymap now looks more like a steno machine keymap   The steno_set_mode(STENO_MODE_GEMINI) function sets the steno protocol to be GeminiPR when the keyboard initialises. I initially tried to use TX Bolt (STENO_MODE_BOLT) for the parameter, as QMK apparently speaks that protocol by default, but I found that key presses did not come in (or were not processed) properly, while GeminiPR worked as expected (Update 28-04-2019: This issue has been fixed)   We will also need to update the rules file due to a few quirks of using steno-specific functionality in QMK:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/rules.mk   STENO_ENABLE = yes VIRTSER_ENABLE = yes FORCE_NKRO = yes MOUSEKEY_ENABLE = no   Some notes about these changes:      As you can see, steno mode needs to be specifically enabled in our rules (STENO_ENABLE = yes), and if steno is enabled, then the USB serial driver for the firmware needs to be enabled as well (VIRTSER_ENABLE = yes) or the keymap will not compile   The cost of enabling steno is that it takes up 3 virtual serial ports that would normally be used by mouse-related functionality in our MDIA layer, so we have to explicitly disable mouse keys (MOUSEKEY_ENABLE = no). If you make a lot of use of mouse movements and clicks via your keyboard, you may want to consider going back and using the modified QWERTY steno keymap. For me personally, I can live without using my keyboard as a mouse.   Now, let\u2019s re-generate the ergodox_ez_default_steno.hex and flash our firmware:   make ergodox_ez:default_steno   If you get any build issues, check what you have against my example code for this layer.   Configure Plover for GeminiPR   Now that we have got QMK speaking in GeminiPR protocol, we need to get Plover configured to listen for it.         Click the \u201cConfigure\u2026\u201d button in the Plover window         Select \u201cGemini PR\u201d from the \u201cStenotype Machine\u201d dropdown list   Click the \u201cConfigure\u2026\u201d button next to the dropdown list         Select a port from the \u201cPort\u201d dropdown. The device name may not exactly match what you see in this screen shot. If you see an empty \u201cPort\u201d dropdown list, click the \u201cScan\u201d button to populate it   Change the \u201cBaudrate\u201d dropdown value to 115200 (since QMK can handle that speed)   Click \u201cOK\u201d   Click \u201cSave\u201d on the \u201cPlover Configuration\u201d window         Click \u201cEnable\u201d on the Plover window and you should get a message saying \u201cGemini PR: connected\u201d   You should now be able to just leave Plover enabled: any keystrokes you make when you switch your Ergodox layer over to STEN will be translated to steno, and Plover will ignore keystrokes made when using any other layer.   One Final Hardware Tweak   The key caps on my Ergodox are DCS profile, which means that they are sculptured differently per row on the keyboard, leading to ergonomically-sized gaps between each key row.   Steno keys are meant to be close together since chording will require a single finger to press multiple keys. In order to get the keys closer together, I turned the QWERT and YUIOP[ keys upside down, so they would lean closer to the keys in the layer below, and changed the direction of the large thumb cluster keys so they would face each other.   At this stage, I am not sure how much of an effect this will have, but I think this is the best I can do without buying a potentially more appropriate key cap set.   The Journey Begins   All this effort put towards getting a perfect QMK steno set up has taken time away from actually getting better at steno, so I\u2019d better get back to that. (Just for completeness\u2019 sake, though, here are my current keymaps that I will be using moving forward)   As of this writing, I am currently only at 12 WPM after completing Lesson 1 of Learn Plover!, so when it comes to stenography, I am very much a beginner student with a long road ahead. So, if there are any glaring mistakes or omissions in this post, please let me know in the comments.   Update (8 Nov 2018)   After working my way through Learn Plover!, I have come to the conclusion that I set the steno keys to be one row too high, and that changing keycaps made a big difference.   Move steno keys down a row   Complex key chords for words that, say, require a right thumb press for EU, as well as a stretched right little finger press for DZ, caused a bit of discomfort in my fingers and wrists as I had to awkwardly contort my hand to press all the keys.   So, I moved all the steno keys down a single row on the keyboard, and now all is well again, even with more complex chords. So, in the context of the default_steno keymap, the keymap will now look like this:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/keymap.c   // ... #include \"keymap_steno.h\"  #define BASE 0 // default layer #define SYMB 1 // symbols #define MDIA 2 // media keys #define STEN 3 // Stenography  // Helper to make keymaps a bit easier to read at a glance #define _x_ KC_NO #define ___ KC_TRNS  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Keymap 0: Basic layer  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  | STEN | ...  * |--------+------+------+------+------+-------------| ...  * ...  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL, KC_1, KC_2, KC_3, KC_4, KC_5, TG(STEN),   // ... ), // ... [SYMB] = LAYOUT_ergodox(   // ... ), // ... [MDIA] = LAYOUT_ergodox(   // ... ), /* Keymap 3: Stenography  *  * ,--------------------------------------------------.           ,--------------------------------------------------.  * |   [x]  |  [x] |  [x] |  [x] |  [x] |  [x] |      |           |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |  [x]   |  * |--------+------+------+------+------+------+------|           |------+------+------+------+------+------+--------|  * |   [x]  |   #  |   #  |   #  |   #  |   #  |      |           |      |   #  |   #  |   #  |   #  |   #  |   #    |  * |--------+------+------+------+------+------|  [x] |           |  [x] |------+------+------+------+------+--------|  * |   [x]  |   S  |   T  |   P  |   H  |   *  |------|           |------|   *  |   F  |   P  |   L  |   T  |   D    |  * |--------+------+------+------+------+------|      |           |      |------+------+------+------+------+--------|  * |   [x]  |   S  |   K  |   W  |   R  |   *  |  [x] |           |  [x] |   *  |   R  |   B  |   G  |   S  |   Z    |  * `--------+------+------+------+------+-------------'           `-------------+------+------+------+------+--------'  *   | [x]  |  [x] |  [x] |  [x] |  [x] |                                       |  [x] |  [x] |  [x] |  [x] |  [x] |  *   `----------------------------------'                                       `----------------------------------'  *                                        ,-------------.       ,-------------.  *                                        |  [x] |  [x] |       |  [x] |  [x] |  *                                 ,------|------|------|       |------+------+------.  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 |  A   |   O  |------|       |------|   E  |   U  |  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 `--------------------'       `--------------------'  */ [STEN] = LAYOUT_ergodox(  // layer 3 : Stenography     // left hand     _x_, _x_,    _x_,    _x_,    _x_,    _x_,     ___,     _x_, STN_N1, STN_N2, STN_N3, STN_N4, STN_N5,  _x_,     _x_, STN_S1, STN_TL, STN_PL, STN_HL, STN_ST1,     _x_, STN_S2, STN_KL, STN_WL, STN_RL, STN_ST2, _x_,     _x_, _x_,    _x_,    _x_,    _x_,                                          _x_,     _x_,                                                   _x_,                                  STN_A,  STN_O,   _x_,   // right hand   _x_, _x_,     _x_,    _x_,    _x_,    _x_,    _x_,   _x_, STN_N6,  STN_N7, STN_N8, STN_N9, STN_NA, STN_NB,   _x_, STN_ST3, STN_FR, STN_PR, STN_LR, STN_TR, STN_DR,        STN_ST4, STN_RR, STN_BR, STN_GR, STN_SR, STN_ZR,                 _x_,    _x_,    _x_,    _x_,    _x_,   _x_, _x_,   _x_,   _x_, STN_E,   STN_U ) };  // ...  // Runs just one time when the keyboard initializes. void matrix_init_user(void) {   // ...   steno_set_mode(STENO_MODE_GEMINI); };   I have updated the code on this post\u2019s companion Github repo to reflect these changes, but kept the original \u201chigh\u201d configuration in another directory for your reference. You can also see how I\u2019ve incorporated this change in my current personal keymaps.   Use Steno-Appropriate Keycaps   Based on the Plover Keycap Recommendations, I picked up a set of G20 Blank Keysets and this has made chording much easier.   Switching the direction of my original DCS profile keys helped a little bit, but the flat and wide profile of the G20s makes pressing two keys with the same finger significantly less awkward. So, I can definitely recommend picking up a set if you are going to make a serious attempt at learning steno on an Ergodox, or really any mechanical keyboard.   For Ergodox users, I would recommend picking up both the G20 Ergodox Base and Ergodox Modifier sets that PMK offers. I initially only ordered a modifier set, thinking that I would be fine with having a mix of profiles on the board, but the issues with that I found were:      Having a board with multiple types of keycap profiles is kind of awkward when switching back to QWERTY typing   The Ergodox Modifier set only contains enough keys to cover a base steno layout, and not the steno number key # row (this may not necessarily be a deal breaker for you if you plan on just using the QWERTY number row)   The Ergodox Modifier set does not come with any homing keys (keys with a bar or dot on them to signify to your index finger that you are on home row). My index fingers naturally seek out homing keys, and I could not get over not having them, which is partly what prompted me to pick up the Ergodox Base set (if you want the homing bars/dots but don\u2019t want the base set, you have the option of just buying a set of those keys separately)   Update (8 Jun 2020)   Use Steno-Appropriate Switches (if possible)   A few months ago from this writing, I had occasion to pick up a new Ergodox EZ. While I have played with a variety of keyboard switches on other people\u2019s keyboards, I have only ever used Cherry MX Browns and Gateron Browns on a regular basis.  So, I decided to look into more steno-friendly keyswitch types for the new board.   Based on advice in the Plover keyswitch guide, I looked at the Ergodox EZ keyswitches page to see which ones provide a \u201clight actuation force on a linear switch\u201d. Judging by the page comparison charts, Kailh Speed Silver switches seemed the most appropriate, so that\u2019s what I got.   After practising with Kailh Silvers, I can definitely recommend them over Cherry/Gateron Browns for stenography. Chording is noticeably easier due to the lighter touch, and I have found that my hands are a bit less fatigued after a practice session.   However, I would probably not recommend buying a brand new Ergodox specifically to get new keyswitches, especially if you are still a learner and your current board works fine.  If you have a newer Ergodox that has changeable switches, then you have the option to just buy some Kailh Speed Silvers (or any of the other switches the Plover guide mentions).   If you are like me, though, and your older board needs replacing, or you are considering buying/building your first Ergodox, then the path I took is open to you.   Number \u201cBar\u201d versus Button   I have found chording numbers quite challenging, and have wondered if there was perhaps an easier way to stroke them.   The QMK Ergodox EZ steno configuration, as of this writing, re-creates a stenography machine number bar over 11 separate keys. However, looking at the layout of a modern keyboard made specifically for stenography, the Georgi (QMK layout), it uses a single number key on each of its thumb clusters, presumably to be used in the same vein as the asterisk key.   It makes a lot of sense to me to palm off number duty to your thumbs in order to keep your other fingers from ever moving away from steno home row, so I have modified my own layout to have number keys in two extra places on the Ergodox:      under the R keys on both halves   above the O and E keys   Applied to the layout used above, it would look like the following, using the STN_NC keycode for all the keys since it has not been used yet:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/keymap.c   // ... /* Keymap 3: Stenography  *  * ,--------------------------------------------------.           ,--------------------------------------------------.  * |   [x]  |  [x] |  [x] |  [x] |  [x] |  [x] |      |           |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |  [x]   |  * |--------+------+------+------+------+------+------|           |------+------+------+------+------+------+--------|  * |   [x]  |   #  |   #  |   #  |   #  |   #  |      |           |      |   #  |   #  |   #  |   #  |   #  |   #    |  * |--------+------+------+------+------+------|  [x] |           |  [x] |------+------+------+------+------+--------|  * |   [x]  |   S  |   T  |   P  |   H  |   *  |------|           |------|   *  |   F  |   P  |   L  |   T  |   D    |  * |--------+------+------+------+------+------|      |           |      |------+------+------+------+------+--------|  * |   [x]  |   S  |   K  |   W  |   R  |   *  |  [x] |           |  [x] |   *  |   R  |   B  |   G  |   S  |   Z    |  * `--------+------+------+------+------+-------------'           `-------------+------+------+------+------+--------'  *   | [x]  |  [x] |  [x] |  [x] |   #  |                                       |   #  |  [x] |  [x] |  [x] |  [x] |  *   `----------------------------------'                                       `----------------------------------'  *                                        ,-------------.       ,-------------.  *                                        |   #  |  [x] |       |  [x] |   #  |  *                                 ,------|------|------|       |------+------+------.  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 |  A   |   O  |------|       |------|   E  |   U  |  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 `--------------------'       `--------------------'  */ [STEN] = LAYOUT_ergodox(  // layer 3 : Stenography     // left hand     _x_, _x_,    _x_,    _x_,    _x_,    _x_,     ___,     _x_, STN_N1, STN_N2, STN_N3, STN_N4, STN_N5,  _x_,     _x_, STN_S1, STN_TL, STN_PL, STN_HL, STN_ST1,     _x_, STN_S2, STN_KL, STN_WL, STN_RL, STN_ST2, _x_,     _x_, _x_,    _x_,    _x_,    STN_NC,                                          STN_NC,  _x_,                                                   _x_,                                  STN_A,  STN_O,   _x_,   // right hand   _x_, _x_,     _x_,    _x_,    _x_,    _x_,    _x_,   _x_, STN_N6,  STN_N7, STN_N8, STN_N9, STN_NA, STN_NB,   _x_, STN_ST3, STN_FR, STN_PR, STN_LR, STN_TR, STN_DR,        STN_ST4, STN_RR, STN_BR, STN_GR, STN_SR, STN_ZR,                 STN_NC, _x_,    _x_,    _x_,    _x_,   _x_, STN_NC,   _x_,   _x_, STN_E,   STN_U ) // ...   I am not sure which of these thumb-based number keys I will end up using yet (if any), so I am planning on letting my hands decide what feels right. See my personal QMK keymap for more details and code to copy if you want to try this layout as well.   ",
categories:[],tags:["ergodox","keyboards","mechanical-keyboards","qmk","clang","stenography","plover"],url:"/blog/starting-stenography-ergodox/",teaser:"/assets/images/2018-10-18/phil-botha-469097-unsplash.jpg"},{title:"Build a CI/CD pipeline for your Jekyll site",excerpt:'Since setting up my Jekyll site, I thought that being disciplined enough to continue writing content regularly would be the main blog-related problem I would be dealing with.   That is, until I ran HTMLProofer over the site, and it spat out a bunch of validation issues that showed me I had a significant amount of problems including:      Some of the links I had in older posts were returning 404 messages, even though the links had worked when I first wrote the posts\u2026   The sitemap generated by jekyll-sitemap apparently contained invalid jekyll-archives-generated archive page links (eg https://www.paulfioravanti.com/tags/jekyll/), which I thought was strange as they all worked in my development environment\u2026   It turns out that:      I had references to code on Github that referred directly to the master branch of a codebase, rather than use a permalink, which would refer to a file at the time I accessed it (always use permalinks when linking to code on Github to avoid this headache)   The list of supported Jekyll plugins on Github Pages does not include jekyll-archives (I forgot/didn\u2019t check), so although the archive links worked in my local development environment, when they were added to the locally-generated sitemap, and then an attempt made to check their production-side links, they all 404-ed.   The issues that HTMLProofer brought up raised some questions around the quality of the site code and post content:      Links in posts could become stale, and I would never know about it, since I do not ever go and manually re-check all the links in every post   I had no process that could stop me from inadvertently deploying bad code, or deploying plugin code that would just be ignored by Github Pages, leading to production environments not matching what I was seeing in development   Limitations on Github Pages plugin availability mean I could also not take advantage of some plugins that could help with search engine optimisation (SEO), like those that minify your HTML/CSS/JS files   I still want to keep Github Pages as the deployment platform for my blog (at least, for now), but it just seems really limiting, so what options do I have?  Well, thanks to Derek Smart and his post Supercharge GitHub Pages with Jekyll and Travis CI, I learned that I should:      Break free of the constricting GitHub Pages Ruby Gem   Replace it with the Jekyll gem, and a list of any Jekyll plugin gems I please   Create a build pipeline using Travis CI.   Have Travis test my code, build the site with all the plugins I want, and then deploy the built site directly to the master branch of my Jekyll Github repository   Let\u2019s see about getting this done!                    Photo originally by Fancycrave on Unsplash        Switch to Jekyll gem   My Gemfile initially looked similar to the Github specification for Jekyll sites that get published to Github Pages:   Gemfile   source "https://rubygems.org" ruby "2.5.3"  group :jekyll_plugins do   gem "github-pages", "192"   gem "jekyll-archives", "~&gt; 2.1"   gem "jekyll-include-cache", "~&gt; 0.1"   gem "jekyll-remote-theme", "~&gt; 0.3" end   After migrating over to the Jekyll gem, it changed over to be something like:   Gemfile   source "https://rubygems.org" ruby "2.5.3"  gem "jekyll", "~&gt; 3.8"  group :jekyll_plugins do   gem "jekyll-archives", "~&gt; 2.1"   gem "jekyll-include-cache", "~&gt; 0.1"   gem "jekyll-remote-theme", "~&gt; 0.3"   gem "jekyll-feed", "~&gt; 0.11"   gem "jekyll-gist", "~&gt; 1.5"   # and a bunch of other jekyll plugin gems... end   In order to determine what other gem plugins I should include under the :jekyll_plugins group, now that the github-pages gem was not bringing them in for me, I referenced the Github Pages gem dependencies, as well as the plugins key in my site\u2019s _config.yml file, and then manually added any that I knew I was using.      For reference, here is my blog\u2019s Gemfile at the time of this writing.    Set up Travis to test and deploy site   The Supercharge GitHub Pages with Jekyll and Travis CI article perfectly describes, with appropriate detail, how to set up Github and Travis to build and deploy a Jekyll site, so I will only repeat a summary here with links to Github and Travis documentation:      Since Github Pages publishes code pushed into the master branch, create a new release branch on your repository and set it to be the default branch. This effectively makes release the new master branch for development purposes, and master will, moving forward, only ever hold the contents of the built Jekyll site   Activate your Jekyll site on Travis   Create a personal access token for use with the Jekyll site   Copy your new personal access token into an environment variable in the Travis repository settings for your Jekyll site (suggested name: GITHUB_TOKEN)   Create a .travis.yml configuration file in the root of your Jekyll site to tell Travis what to do   Build Stages   What Travis should do specifically is run all the lints and tests for the Jekyll site. Then, if everything passes, Travis should build the site, and deploy it to the master branch of the site Github repository, at which point it gets automatically published to Github Pages.   Travis Build Stages enable us to do exactly that, so let\u2019s see how to do that in configuration:   .travis.yml   sudo: false dist: trusty language: ruby cache: bundler rvm:   - 2.5.3 bundler_args: --without development env:   global:     - NOKOGIRI_USE_SYSTEM_LIBRARIES=true addons:   apt:     packages:       - libcurl4-openssl-dev branches:   only:     - release jobs:   include:     - stage: Test       before_script:         - npm install -g sass-lint htmllint-cli markdownlint-cli       script:         - JEKYLL_ENV=production bundle exec jekyll build         - htmllint _includes/stripped_markdown.html         - markdownlint _posts _drafts _pages README.md         - sass-lint --verbose --no-exit         - bundle exec htmlproofer _site --allow-hash-href --assume-extension --url-ignore "/localhost/" --http-status-ignore "999"     - stage: Github Release       script:         - JEKYLL_ENV=production bundle exec jekyll build       deploy:         provider: pages         local-dir: ./_site         target-branch: master         name: Travis Deployment Bot         skip-cleanup: true         github-token: $GITHUB_TOKEN         keep-history: true         on:           branch: release   If you have used Travis to build a Ruby project before, you will no doubt recognise some of the configuration entries listed here, so I will outline some notes only about the potentially unfamiliar parts of this file, and why they\u2019re there:      The NOKOGIRI_USE_SYSTEM_LIBRARIES=true statement and use of the libcurl4-openssl-dev library are for using HTMLProofer on Travis: the former speeds up installation of HTMLProofer, and the latter is so checks on external links referenced in posts can actually be performed   We only ever want to test and deploy the release branch, so make sure we ignore pushes to any other branch   Build stages are defined under the jobs key, and here we have two: Test and Github Release   All the lint checks are described in my previous blog post Setting up a Jekyll Blog. Check it out for more information on what they are linting, so you can get a better idea of whether you should be changing any parameters to suit your own site\u2019s needs   The htmlproofer command line interface (CLI) application has lots of options, but the reasons I use certain options are the following:            --allow-hash-href - The build will fail on the first and last post entries if this isn\u2019t allowed because I have pagination \u201cprevious\u201d and \u201cnext\u201d buttons that have href="#", and hence considered \u2018links to nowhere\u2019       --assume-extension - Jekyll 3 supports extension-less permalinks, and my blog uses them, so this flag needs to be here to prevent errors       --url-ignore "/localhost/" - I have tutorial posts that have explicit link references to localhost, so I don\u2019t want them considered \u201cproper\u201d external links that need to be validated       --http-status-ignore "999" - LinkedIn doesn\u2019t seem to like crawlers, and hence sends back 999 errors, even if a link to them is valid           The configuration under the deploy key is adapted from a Travis example configuration of deploying to Github Pages, and Derek Smart\u2019s example configuration      For reference, here is the .travis.yml file for my own Jekyll site at the time of this writing.    With Travis and Github all set up, you now have a continuous integration and deployment pipeline that can publish a Jekyll site, free of Github\u2019s restrictions, to Github Pages! :tada:   ',categories:[],tags:["jekyll","ruby"],url:"/blog/build-ci-cd-pipeline-jekyll/",teaser:"/assets/images/2018-10-29/samuel-sianipar-1082943-unsplash.jpg"},{title:"Elm 0.18 to 0.19 upgrade notes",excerpt:'I upgraded a few toy Elm 0.18 applications I had to 0.19, and along the way, I encountered some things that I felt I needed to jot down for future me (and hopefully current/future you as well) to reference.   They are mostly the results of trawling the Elm Slack, Elm Discourse, Github issues, documentation for upgraded-to-Elm-0.19 libraries, other blog posts, and trial and error.   So, here they are in no particular order. If you are currently going through an Elm 0.18 to 0.19 upgrade, I hope these points save you some time!   Preface   The very first thing you should do before attempting to update any code manually is install elm-upgrade, and run it over your Elm 0.18 app.   There is not much else to add here that is not covered in elm-upgrade\u2019s README file. Follow its instructions until you have implemented its recommendations, and you will be ready to venture out on your own.   RIP partially exposing custom types   In Elm 0.18, if I had a union type (re-named \u201ccustom type\u201d in 0.19) that looked like:   module Language exposing (Lang(..))  type Lang     = En     | It     | Ja   I was able to partially expose values in the type when imported into another module. For example, if I wanted to use Lang in another module, but did not require the It value, I could write:   import Language exposing (Lang(En, Ja))  availableLanguages : List Lang availableLanguages =     [ En, Ja ]   In Elm 0.19, this is no longer permitted, nor is explicitly exposing all values from a custom type i.e. import Language exposing (Lang(En, It, Ja)).   The only options for accessing the types directly are exposing everything from a module (import Language exposing (..)), which I do not like due to its non-explicit nature, or the remaining option, accessing the custom type values through the module name itself:   import Language exposing (Lang)  availableLanguages : List Lang availableLanguages =     [ Language.En, Language.Ja ]   I do miss not being able to explicitly expose imported custom type values, and it feels strange in this case to write Language.En instead of Lang.En (because are we not accessing a value of the type and not of the module?), but this is how I will be using them moving forward. More information about the rationale behind this change can be found at this Elm Discourse thread.   RIP Basics.toString   In Elm 0.18, I used the convenience of toString to stringify custom type values. I had a list of typed languages in an app that looked like this:   Language.elm   type Language     = En     | It     | Ja   In order to keep track of what language a user switched the app to, I wanted to stringify the face values of the type before sending them off via ports to be put in browser local storage. This happened in an update function that looked something like:   Locale/Update.elm   update : Msg -&gt; Locale -&gt; ( Locale, Cmd Msg ) update msg locale =     case msg of         ChangeLanguage language -&gt;             ( { locale | language = language }             , language                 |&gt; toString                 |&gt; String.toLower                 |&gt; Ports.storeLanguage             )          -- ...   When a ChangeLanguage message is received, before sending the Language outside of Elm-land, it would get transformed from En to "En" to "en". I thought this was pretty convenient, but Elm 0.19 put a stop to that, and I needed to change the code to something like this:   Language.elm   type Language     = En     | It     | Ja  toString : Language -&gt; String toString language =     case language of         En -&gt;             "en"          It -&gt;             "it"          Ja -&gt;             "ja"   Update.elm   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         Msg.ChangeLanguage language -&gt;             ( Model.changeLanguage language model             , language                 |&gt; Language.toString                 |&gt; Ports.storeLanguage             )   This change initially felt like Elm was forcing me to write more boilerplate code. But, I now like the extra explicitness, as well as the very hard line approach that conveys to me that types are in no way related to strings.   There is still an escape hatch to stringify a type during development using Elm 0.19\u2019s Debug.toString function, but as its documentation says, \u201c[i]t is not available for use in packages or production\u201d.   &lt;body&gt; tag attributes must still be set via ports   One major change with views in Elm 0.19 is that if you are creating an HTML document that is entirely managed by Elm (using either Browser.document or Browser.application), then your view function now returns Document msg, rather than Html msg.   A Document is a record that looks like this:   type alias Document msg =     { title : String     , body : List (Html msg)     }   What is strange to me, is that unlike the function signatures of all the tags in the Html module, which look like List (Attribute msg) -&gt; List (Html msg) -&gt; Html msg, the body attribute of a Document only takes a List (Html msg) for the children of the &lt;body&gt; tag, and not a List (Attribute msg) for attributes of the &lt;body&gt; tag itself.   So, if I want to, say, set some classes on the &lt;body&gt; tag to get &lt;body class="bg-white sans-serif w-100", I would have to do this using ports, just like in Elm 0.18.  For a Browser.application Elm app, this could look like:   Main.elm   port initBodyClasses : String -&gt; Cmd msg  main : Program Flags Model Msg main =     Browser.application         { init = init         , -- ...         }   init : Flags -&gt; Url -&gt; Key -&gt; ( Model, Cmd Msg ) init flags url key =     ( Model.init flags url key     , Cmd.batch         [ Navigation.pushUrl key (Url.toString url)         , initBodyClasses "bg-white sans-serif w-100"         ]     )   index.js   // ... app.ports.initBodyClasses.subscribe(classes =&gt; {   document.body.className = classes })   Ultimately, this is a minor inconvenience, but I only note it because it is something that I would expect to be able to do in Elm-land. Perhaps in a future version\u2026?   Conditional subscriptions dependent on model attributes   I had a locale dropdown menu in an application which, when clicked, would open a list of languages that could be switched to (i.e. a msg would be sent to update a showAvailableLanguages attribute on a locale record in the model to True).  Whenever you clicked anywhere on the page aside from the menu, it would close (i.e. a msg would be sent to update showAvailableLanguages to False).   This was implemented in the application subscriptions using the elm-lang/mouse package, looking something like this in Elm 0.18 code:   Main.elm   main : Program Flags Model Msg main =     Navigation.programWithFlags         UpdatePage         { -- ...         , subscriptions = subscriptions         }  subscriptions : Model -&gt; Sub Msg subscriptions { locale } =     if locale.showAvailableLanguages then         Mouse.clicks (\\_ -&gt; CloseAvailableLanguages)     else         Sub.none   In Elm 0.18, the model that is passed into the subscriptions function is the post-update new model, and therefore we can make subscriptions conditional based on values in it.   However, as of this writing, in Elm 0.19 it would seem that is no longer the case. Even after updating Mouse.clicks in the above code to use Browser.Events.onClick from elm/browser, the dropdown menu would not close, and showAvailableLanguages would seem to get updated \u201cout-of-sync\u201d to the application state I was seeing in the Elm debugger.   After finding this Github issue, I realised that the problem may be with the Elm compiler itself. So, I ended up completely removing the conditional subscription from the Elm 0.19 version of the app, and replacing it with an Html.Events.onMouseLeave event directly on the dropdown menu div element that would send the CloseAvailableLanguages message, which I now actually prefer. Something like:   LanguageSelector/View.elm   view : Language -&gt; LanguageSelector -&gt; Html msg view language languageSelector =     let         availableLanguagesToggle =             if languageSelector.showAvailableLanguages then                 [ onMouseLeave Msg.CloseAvailableLanguages ]              else                 []     in     div         ([ attribute "data-name" "language-selector"          , -- ..          ]             ++ availableLanguagesToggle         )         [ -- ..         ]   It\u2019s a shame that there is no Html.Events.none to prevent the list concatenation. Regardless, the takeaway is to, at least for now, refrain from having conditional subscriptions that depend on any attributes in your model until the issue mentioned above is fixed.   URL fragment navigation has issues   If you use hashes (#) in your application, either in the form of hash-based routing (e.g. in a URL like http://example.com/store/#/products/1, you parse information in the fragment to determine that you need to display the page for a product with ID of 1), or you use fragments in HTML anchors to link to different parts of the same page (e.g. &lt;a href="#top"&gt;Top&lt;/a&gt;), you will have some decisions to make to get them working as you would expect in Elm 0.19.   Hash-based routing in path-based clothes   evancz/url-parser, often used in Elm 0.18 applications that have navigation, has a UrlParser.parseHash function to help with parsing URL fragments against defined routes. Elm 0.19\u2019s Url.Parser from elm/url no longer supports this. So, your current routing options for Elm 0.19 are:      Change your application to route on URL paths, rather than fragments        Keep your fragment routing, but before you pass your Url, to Url.Parser.parse to run it against your route matchers, send it through a function that will overwrite the path property of the Url with the content of the fragment. Something like:       migrateUrlFragmentToPath : Url -&gt; Url migrateUrlFragmentToPath url =     { url | path = Maybe.withDefault "" url.fragment, fragment = Nothing }           The Github issues to follow with regards to this are here and here. Both provide further explanation and helpful examples of the problem, so be sure to subscribe to them if this is an issue that affects you.   Anchor navigation requires a page load   Even if your application has path-based routing, and you think you are not affected by the issue above, if you use fragments to navigate to different parts of a page, and have used code from the Elm navigation example for handling Internal types of Browser.UrlRequests (since a fragment is certainly not an External type of link), you may be surprised that when your UrlRequest is passed into the Browser.Navigation.pushUrl function\u2026nothing happens.   More information around this problem is contained in this Github issue, but the way I am currently working around this, in an application that is both path-routed and contains fragments in anchor tags for same-page navigation, is through the following clause in my update function:   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         Msg.LinkClicked urlRequest -&gt;             case urlRequest of                 Browser.Internal url -&gt;                     let                         href =                             Url.toString url                          navigation =                             case url.fragment of                                 Nothing -&gt;                                     Navigation.pushUrl model.key href                                  Just _ -&gt;                                     Navigation.load href                     in                     ( model, navigation)                  Browser.External href -&gt;                     ( model, Navigation.load href )   This does result in a page load for anchor fragment links, but in my case this does not seem to have been a noticeable issue, and as of this writing I do not see another way around it.   Testing applications without a Browser.Navigation.Key   When the init function is called in a Browser.application program, one of the parameters that it receives is a Browser.Navigation.Key, which is needed to \u201ccreate navigation commands that change the URL\u201d. For example:   main : Program () Model Msg main =     Browser.application         { init = init         , -- ...         }   type alias Model =     { key : Key     , url : Url     }   init : () -&gt; Url -&gt; Key -&gt; ( Model, Cmd Msg ) init () url key =     ( Model key url, Cmd.none )   You receive this key whether you like it or not; it is passed into the Elm application from Javascript-land, and as of this writing there is no way to generate one yourself on-the-fly in Elm-land. What this means is that the init function, as well as parts of any function that use a key, cannot be tested with elm test.   This is not so great for tests that simulate a click somewhere on a page and check that the right msg is being sent (example). If you have an update function that looks similar to what is in the Elm navigation example, you will see that you need to pass a key into the Browser.Navigation.pushUrl function:   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         LinkClicked urlRequest -&gt;             case urlRequest of                  Browser.Internal url -&gt;                      ( model, Navigation.pushUrl model.key (Url.toString url) )                   Browser.External href -&gt;                      ( model, Navigation.load href )   Assuming that, like in the example above, you keep your key somewhere in your model, what can you do without a key during testing that will allow your application to compile?   The path of least resistance for me was to change what is stored in the model to a Maybe Key, and ensure that functions like Browser.Navigation.pushUrl are never run when the key is Nothing:   type alias Model =     { key : Maybe Key     , url : Url     }  init : () -&gt; Url -&gt; Key -&gt; ( Model, Cmd Msg ) init () url key =     ( Model (Just key) url, Cmd.none )   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         LinkClicked urlRequest -&gt;             case urlRequest of                 Browser.Internal url -&gt;                     case model.key of                         Just key -&gt;                             ( model, Navigation.pushUrl key (Url.toString url) )                          Nothing -&gt;                             ( model, Cmd.none )                  Browser.External href -&gt;                     ( model, Navigation.load href )   The clause for Nothing will never be matched while you are running your application in development or production: it is there simply so you can test your update function with a key-less model.   There is a Github issue tracking this problem, and the Elm team are \u201cworking on designs for a possible API to address this\u201d, so consider the above solution strictly a temporary workaround until an API is developed. For now, you will just have to deal with a maximum test coverage of 99%.   Upgrading dependencies   Once you have upgraded your Elm application to 0.19, you will probably need a way to determine whether any of its packages are out of date.   As far as I know, Elm itself does not currently have a way to determine this. However, thanks to elm-dependencies-analyzer, you can simply cut and paste the content of your application\u2019s elm.json file into the live version of the program, and it will tell you which packages you are able to version up.   What you should actually do once you know what package(s) you have to upgrade was initially a source of confusion for me, but after reading this Discourse thread, and a bit of trial and error, I now work on this rule of thumb:      If the dependency to be upgraded is a \u201cdirect\u201d dependency, remove the entry from elm.json and then run elm install author/package to re-introduce it back into the elm.json file using the newest version   If the dependency to be upgraded is an \u201cindirect\u201d dependency, then directly edit the entry in elm.json to the target version number, and then run elm make, which will download the new dependency (yes, you are not supposed to directly edit elm.json, but as of this writing I do not see another way around this)   Perhaps an elm install author/package --indirect command will find its way into a future version of Elm\u2026?   Other miscellaneous thoughts      I quite liked the change in the Html.Attributes.style API from its List ( String, String ) -&gt; Attribute msg implementation in elm-lang/html versus the current String -&gt; String -&gt; Attribute msg implementation in elm/html. More readable in my opinion.        I think the Elm Javascript interface is much nicer in 0.19: being able to explicitly specify node and flags elements in a single object to pass in to the Elm application is less cognitive overhead:       index.js       // Elm 0.18 import { Main } from "./Main.elm";  const appContainer = document.querySelector("#root"); Main.embed(appContainer, {   apiUrl: "https://www.example.com/api/endpoint" })  // Elm 0.19 import { Elm } from "./Main.elm";  Elm.Main.init({   node: document.querySelector("#root"),   flags: {     apiUrl: "https://www.example.com/api/endpoint"   } })           For an application that does not accept flags, I like to now be able to write the type signature for its flags with the unit type: main : Program () Model Msg, rather than main : Program Never Model Msg   Being able to update the title of a page in Elm-land, rather than through ports, thanks to the Browser.Document API, is a great addition   The change in API from Html.Events.onWithOptions to Html.Events.custom makes it more readable in my opinion. I found out about the change itself here   A good reference for a bare minimum implementation of each of the 4 different ways to boot an Elm app can be found at this gist   ',categories:[],tags:["elm","upgrade","elm-0.18","elm-0.19"],url:"/blog/elm-018-019-upgrade-notes/",teaser:"/assets/images/2019-04-01/david-travis-547046-unsplash.jpg"},{title:"Chording QWERTY with QMK Combos",
excerpt:"As a current learner of stenography and mechanical keyboard enthusiast, I was pretty excited to learn about the Georgi keyboard.      Aside from its cool form factor, one of the things that caught my eye was that although the hardware is dedicated to replicating a steno machine keymap, the Georgi firmware also manages to squeeze a QWERTY layout keymap into its two rows using stenographic-style chording.      Here, in order to output an \u201cA\u201d, you need to press the \u201cQ\u201d and \u201cZ\u201d keys together. As you can see, there are also similar rules for the rest of the standard QWERTY middle row keys.   I do not think I have ever seen QWERTY used this way until now, so I would absolutely like to give it a go. But, I do not feel I can justify a Georgi purchase as of this writing because I would not consider my stenography skills to even be at novice level yet.   What I do have, though, is an Ergodox set up for stenography that uses Quantum Mechanical Keyboard (QMK) firmware, which is coincidentally what the Georgi uses for its firmware as well.   Looking through the Georgi firmware for inspiration (or code to steal) to achieve a chorded QWERTY layout on an Ergodox left me a bit perplexed. I felt a little bit better when I found that authors acknowledge that it \u201cis the most nonQMK layout you will come across\u201d, but that only left me wondering whether there was an \u201cofficial\u201d QMK way to chord keys.   As you may have guessed, there most certainly is.   QMK Combos are \u201ca chording type solution for adding custom actions\u201d that let you \u201chit multiple keys at once and produce a different effect\u201d. This looks like the configuration we are looking for, so let\u2019s try adding them to a layout!   What You Need      A keyboard that at least supports N-Key Rollover (NKRO). The easiest way to confirm whether you have NKRO enabled is to perform Plover\u2019s Keyboard Ghosting Test. In the Plover in-browser steno demo, if you find that only 6 keys light up on screen when you press the ASDFJKL; keys all at once, then you either currently do not have NKRO enabled, or your keyboard does not support it. The default Ergodox QMK firmware does not enable it by default, but we will fix this soon.   For easier chording, the keyboard should also preferably have a matrix layout (read: straight column layout, like the Ergodox or Planck), rather than a staggered layout like most QWERTY keyboards, and use flat keycaps like G20, but these points do not represent blockers to getting QWERTY chording to work as expected.   QMK Firmware \u2014 see my blog post Escape the defaults and Control your keyboard with QMK for a guide to set up an Ergodox with QMK from scratch, otherwise find your firmware from QMK\u2019s list of supported keyboards.   Initial Setup   For this post, we will use the QMK default Ergodox EZ keymap as a base, and make changes to it to add functionality for QWERTY chording. Feel free to follow along as-is, or make appropriate changes to your own custom keymaps. You can also see the finished layout on this post\u2019s companion QMK Ergodox Chorded QWERTY Example keymap.   After installing the build tools for your operating system, make a clone of the QMK Firmware repository from Github if you do not have one already. Then, create a copy of the default Ergodox EZ keymaps directory into a new directory that we will call chorded_qwerty:   git clone git@github.com:qmk/qmk_firmware.git cd qmk_firmware cp -r keyboards/ergodox_ez/keymaps/default keyboards/ergodox_ez/keymaps/chorded_qwerty   Enable NKRO and Combos   Before adding a new keyboard layout to our keymap, the first thing we will need to do is ensure that we have NKRO and combos enabled. We will do this by adding two new files:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/rules.mk   FORCE_NKRO = yes COMBO_ENABLE = yes   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   #include \"../../config.h\"  #define FORCE_NKRO #define COMBO_COUNT 1      The FORCE_NKRO config makes sure that we have NKRO enabled by default   The COMBO_COUNT 1 specifies the number of combos used in the layout. For now, we will keep this at 1 to focus on just getting a \u201cQ and Z to A\u201d combo working, and then add more later.   New Chorded QWERTY layer   The QMK default Ergodox EZ keymap has three layers: a base layer, a layer for symbols, and a layer for media keys (for our purposes, we can safely ignore the symbol and media keys layers). Rather than change the base layer directly, let\u2019s copy it into a new layer we will call CHORD.   We will then (arbitrarily) assign the top right-most key on the left hand of the BASE layer to be the toggle to turn the CHORD layer on and off, using QMK\u2019s TG(layer) function:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... #define BASE 0  // default layer #define SYMB 1  // symbols #define MDIA 2  // media keys #define CHORD 3 // chorded QWERTY layer  // Helpers to make keymaps a bit easier to read at a glance #define ___ KC_TRNS #define _x_ KC_NO  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Keymap 0: Basic layer  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  |CHORD | ...  * |--------+------+------+------+------+-------------| ...  * | Del    |   Q  |   W  |   E  |   R  |   T  |  L1  | ...  * |--------+------+------+------+------+------|      | ...  * | BkSp   |   A  |   S  |   D  |   F  |   G  |------| ...  * |--------+------+------+------+------+------| Hyper| ...  * | LShift |Z/Ctrl|   X  |   C  |   V  |   B  |      | ...  * `--------+------+------+------+------+-------------' ...  * ...  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL,  KC_1,        KC_2, KC_3, KC_4, KC_5, TG(CHORD),   KC_DELT, KC_Q,        KC_W, KC_E, KC_R, KC_T, TG(SYMB),   KC_BSPC, KC_A,        KC_S, KC_D, KC_F, KC_G,   KC_LSFT, CTL_T(KC_Z), KC_X, KC_C, KC_V, KC_B, ALL_T(KC_NO),   // ... ), // ... [SYMB] = LAYOUT_ergodox(   // ... ), // ... [MDIA] = LAYOUT_ergodox(   // ... ), /* Keymap 3: Chorded QWERTY  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  |      | ...  * |--------+------+------+------+------+-------------| ...  * | Del    |  [x] |   W  |   E  |   R  |   T  |  L1  | ...  * |--------+------+------+------+------+------|      | ...  * | BkSp   |   Q  |   S  |   D  |   F  |   G  |------| ...  * |--------+------+------+------+------+------| Hyper| ...  * | LShift |   Z  |   X  |   C  |   V  |   B  |      | ...  * `--------+------+------+------+------+-------------' ...  * ...  */ [CHORD] = LAYOUT_ergodox( // Layer 3: Chorded QWERTY   // left hand   KC_EQL,  KC_1, KC_2, KC_3, KC_4, KC_5, ___,   KC_DELT, _x_,  KC_W, KC_E, KC_R, KC_T, TG(SYMB),   KC_BSPC, KC_Q, KC_S, KC_D, KC_F, KC_G,   KC_LSFT, KC_Z, KC_X, KC_C, KC_V, KC_B, ALL_T(KC_NO),   // ... ) }; // ...   Let\u2019s briefly compare the (abbreviated) CHORD layer to the BASE layer:      The right-most key of the first row uses ___ (KC_TRNS) as a \u201ctransparent\u201d mapping.  In this case, it means that the key will \u201cfall back\u201d to the TG(CHORD) function on the BASE layer. This is really just a convenience so that we don\u2019t need to specify TG(CHORD) again on the CHORD layer.   The \u201cQ\u201d key\u2019s original position has been replaced with _x_ (KC_NO) for the time being, specifically indicating that pressing the key results in a NOOP: the keystroke is ignored. We will do something else with this key later.   The \u201cA\u201d key has been removed, and replaced with the \u201cQ\u201d key.   The default base layer of the Ergodox EZ keymap uses the Mod-Tap advanced keycode shortcut CTL_T(KC_Z) to make the \u201cZ\u201d key Left Control when held, and \u201cZ\u201d when pressed. Combos only support QMK basic keycodes, so we\u2019ve changed the \u201cZ\u201d key to be just the \u201cZ\u201d key (KC_Z).   So, now that we are without a way to print \u201cA\u201d to the screen, let\u2019s actually add in configuration for a combo to enable pressing both \u201cQ\u201d and \u201cZ\u201d to do just that.   Opening Combo   The first thing we need to do is give our combo a name. You may have previously created your own custom keycodes, so if you would like, you may add any named combos to your custom_keycodes list.   However, for this example, let\u2019s keep the focus on combos and put them in their own enumerated type list called combos, and place it underneath the custom_keycodes list. Let\u2019s also use a naming convention of &lt;key 1&gt;&lt;key 2&gt;_&lt;output key&gt; for the entries. So, we\u2019ll name a \u201cQ and Z to A\u201d combo as QZ_A:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum custom_keycodes {   // ... };  enum combos {   QZ_A }; // ...   Next, we need to define a sequence of keys for our combo in a list, terminated by COMBO_END. Our sequence will consist of the \u201cQ\u201d and \u201cZ\u201d keys, and let\u2019s use a similar naming convention as combos and call it qz_combo:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum combos {   QZ_A };  const uint16_t PROGMEM qz_combo[] = {KC_Q, KC_Z, COMBO_END}; // ...   The final piece of the combo puzzle is to now create a list of length COMBO_COUNT called key_combos that will map our combo sequences to their resulting actions:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum combos {   QZ_A };  const uint16_t PROGMEM qz_combo[] = {KC_Q, KC_Z, COMBO_END};  combo_t key_combos[COMBO_COUNT] = {   [QZ_A] = COMBO(qz_combo, KC_A) }; // ...      Currently, key_combos only has one element, but when we eventually add more to it, we will need to change the COMBO_COUNT value in config.h accordingly.    Great, we have now configured our first combo! Let\u2019s now generate the firmware from the qmk_firmware directory root path:   make ergodox_ez:chorded_qwerty   This should generate an ergodox_ez_chorded_qwerty.hex file, which you can then use to flash your Ergodox firmware.   Once you have flashed your firmware, switch over to the CHORD layer, press the \u201cQ\u201d and \u201cZ\u201d keys together, and it should output \u201ca\u201d. As expected, if you hold down Shift and press \u201cQ\u201d and \u201cZ\u201d together, it should output uppercase \u201cA\u201d.   Finishing Combos   Now that we have one combo working, the same principles apply in combos for the remaining QWERTY middle row keys. We will end up with 10 combos total, so first, let\u2019s update COMBO_COUNT:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   // ... #define COMBO_COUNT 10   Now, let\u2019s add in configuration for the rest of the combos:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum combos {   QZ_A,   WX_S,   EC_D,   RV_F,   TB_G,   YN_H,   UM_J,   ICOMMA_K,   ODOT_L,   PSLASH_SCOLON };  const uint16_t PROGMEM qz_combo[] = {KC_Q, KC_Z, COMBO_END}; const uint16_t PROGMEM wx_combo[] = {KC_W, KC_X, COMBO_END}; const uint16_t PROGMEM ec_combo[] = {KC_E, KC_C, COMBO_END}; const uint16_t PROGMEM rv_combo[] = {KC_R, KC_V, COMBO_END}; const uint16_t PROGMEM tb_combo[] = {KC_T, KC_B, COMBO_END}; const uint16_t PROGMEM yn_combo[] = {KC_Y, KC_N, COMBO_END}; const uint16_t PROGMEM um_combo[] = {KC_U, KC_M, COMBO_END}; const uint16_t PROGMEM icomma_combo[] = {KC_I, KC_COMMA, COMBO_END}; const uint16_t PROGMEM odot_combo[] = {KC_O, KC_DOT, COMBO_END}; const uint16_t PROGMEM pslash_combo[] = {KC_P, KC_SLASH, COMBO_END};  combo_t key_combos[COMBO_COUNT] = {   [QZ_A] = COMBO(qz_combo, KC_A),   [WX_S] = COMBO(wx_combo, KC_S),   [EC_D] = COMBO(ec_combo, KC_D),   [RV_F] = COMBO(rv_combo, KC_F),   [TB_G] = COMBO(tb_combo, KC_G),   [YN_H] = COMBO(yn_combo, KC_H),   [UM_J] = COMBO(um_combo, KC_J),   [ICOMMA_K] = COMBO(icomma_combo, KC_K),   [ODOT_L] = COMBO(odot_combo, KC_L),   [PSLASH_SCOLON] = COMBO(pslash_combo, KC_SCOLON) };  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { // ... /* Keymap 3: Chorded QWERTY  *  * ,--------------------------------------------------.  ,--------------------------------------------------.  * |   =    |   1  |   2  |   3  |   4  |   5  |CHORD |  | RIGHT|   6  |   7  |   8  |   9  |   0  |   -    |  * |--------+------+------+------+------+-------------|  |------+------+------+------+------+------+--------|  * | Del    |  [x] |  [x] |  [x] |  [x] |  [x] |  L1  |  |  L1  |  [x] |  [x] |  [x] |  [x] |  [x] |   \\    |  * |--------+------+------+------+------+------|      |  |      |------+------+------+------+------+--------|  * | BkSp   |   Q  |   W  |   E  |   R  |   T  |------|  |------|   Y  |   U  |   I  |   O  |   P  |' / Cmd |  * |--------+------+------+------+------+------| Hyper|  | Meh  |------+------+------+------+------+--------|  * | LShift |   Z  |   X  |   C  |   V  |   B  |      |  |      |   N  |   M  |   ,  |   .  |   /  | RShift |  * `--------+------+------+------+------+-------------'  `-------------+------+------+------+------+--------'  * ...  */ [CHORD] = LAYOUT_ergodox( // Layer 3: Chorded QWERTY   // left hand   KC_EQL,  KC_1, KC_2, KC_3, KC_4, KC_5, ___,   KC_DELT, _x_,  _x_,  _x_,  _x_,  _x_,  TG(SYMB),   KC_BSPC, KC_Q, KC_W, KC_E, KC_R, KC_T,   KC_LSFT, KC_Z, KC_X, KC_C, KC_V, KC_B, ALL_T(KC_NO),   // ...    // right hand   KC_RGHT,      KC_6, KC_7, KC_8,    KC_9,   KC_0,    KC_MINS,   TG(SYMB),     _x_,  _x_,  _x_,     _x_,    _x_,     KC_BSLS,                 KC_Y, KC_U, KC_I,    KC_O,   KC_P,    GUI_T(KC_QUOT),   MEH_T(KC_NO), KC_N, KC_M, KC_COMM, KC_DOT, KC_SLSH, KC_RSFT,   // ... ) }; // ...   Now, re-generate your firmware:   make ergodox_ez:chorded_qwerty   Flash your firmware and you should now have a chorded middle QWERTY row!   You now have a full row of keys to re-assign values as you please. You could bring the number keys down a row, or perhaps create some more custom_keycodes to assign to them. Just for fun, let\u2019s get those keys to mimic a stenotype number bar.   Steno Number Combos   To successfully imitate a stenotype number bar and the chords for stenotype numbers, we will need to do the following:      create a new custom keycode that represents a number bar press - let\u2019s call it NUM   assign NUM to all of the keys we are currently not using   create the following combos:            Pressing NUM and each of the QWER keys will output numbers 1-4       Pressing NUM and each of the UIOP keys will output numbers 6-9       Pressing NUM and the Space key will output 5       Pressing NUM and the Backspace key will output 0              The Space and Backspace keys here represent where I would place the stenotype keyboard \u201cA\u201d and \u201cO\u201d keys respectively on an Ergodox using the default QMK layout we have been modifying.    Here is what those changes will entail:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   // ... #define COMBO_COUNT 20   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum custom_keycodes {   // ...   NUM }  enum combos {   // ...   NUMQ_1,   NUMW_2,   NUME_3,   NUMR_4,   NUMSPACE_5,   NUMU_6,   NUMI_7,   NUMO_8,   NUMP_9,   NUMBSPACE_0 };  // ... const uint16_t PROGMEM numq_combo[] = {NUM, KC_Q, COMBO_END}; const uint16_t PROGMEM numw_combo[] = {NUM, KC_W, COMBO_END}; const uint16_t PROGMEM nume_combo[] = {NUM, KC_E, COMBO_END}; const uint16_t PROGMEM numr_combo[] = {NUM, KC_R, COMBO_END}; const uint16_t PROGMEM numspace_combo[] = {NUM, KC_SPACE, COMBO_END}; const uint16_t PROGMEM numu_combo[] = {NUM, KC_U, COMBO_END}; const uint16_t PROGMEM numi_combo[] = {NUM, KC_I, COMBO_END}; const uint16_t PROGMEM numo_combo[] = {NUM, KC_O, COMBO_END}; const uint16_t PROGMEM nump_combo[] = {NUM, KC_P, COMBO_END}; const uint16_t PROGMEM numbspace_combo[] = {NUM, KC_BSPACE, COMBO_END};  combo_t key_combos[COMBO_COUNT] = {   // ...   [NUMQ_1] = COMBO(numq_combo, KC_1),   [NUMW_2] = COMBO(numw_combo, KC_2),   [NUME_3] = COMBO(nume_combo, KC_3),   [NUMR_4] = COMBO(numr_combo, KC_4),   [NUMSPACE_5] = COMBO(numspace_combo, KC_5),   [NUMU_6] = COMBO(numu_combo, KC_6),   [NUMI_7] = COMBO(numi_combo, KC_7),   [NUMO_8] = COMBO(numo_combo, KC_8),   [NUMP_9] = COMBO(nump_combo, KC_9),   [NUMBSPACE_0] = COMBO(numbspace_combo, KC_0) };  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { // ... /* Keymap 3: Chorded QWERTY  *  * ,--------------------------------------------------.           ,--------------------------------------------------.  * |   =    |   1  |   2  |   3  |   4  |   5  |CHORD |           | RIGHT|   6  |   7  |   8  |   9  |   0  |   -    |  * |--------+------+------+------+------+-------------|           |------+------+------+------+------+------+--------|  * | Del    |  NUM |  NUM |  NUM |  NUM |  NUM |  L1  |           |  L1  |  NUM |  NUM |  NUM |  NUM |  NUM |   \\    |  * |--------+------+------+------+------+------|      |           |      |------+------+------+------+------+--------|  * | BkSp   |   Q  |   W  |   E  |   R  |   T  |------|           |------|   Y  |   U  |   I  |   O  |   P  |' / Cmd |  * |--------+------+------+------+------+------| Hyper|           | Meh  |------+------+------+------+------+--------|  * | LShift |   Z  |   X  |   C  |   V  |   B  |      |           |      |   N  |   M  |   ,  |   .  |   /  | RShift |  * `--------+------+------+------+------+-------------'           `-------------+------+------+------+------+--------'  *   |Grv/L1|  '\"  |AltShf| Left | Right|                                       |  Up  | Down |   [  |   ]  | ~L1  |  *   `----------------------------------'                                       `----------------------------------'  *                                        ,-------------.       ,-------------.  *                                        | App  | LGui |       | Alt  |Ctrl/Esc|  *                                 ,------|------|------|       |------+--------+------.  *                                 |      |      | Home |       | PgUp |        |      |  *                                 | Space|Backsp|------|       |------|  Tab   |Enter |  *                                 |      |ace   | End  |       | PgDn |        |      |  *                                 `--------------------'       `----------------------'  */ [CHORD] = LAYOUT_ergodox( // Layer 3: Chorded QWERTY   // left hand   KC_EQL,          KC_1,        KC_2,          KC_3,    KC_4,    KC_5,    ___,   KC_DELT,         NUM,         NUM,           NUM,     NUM,     NUM,     TG(SYMB),   KC_BSPC,         KC_Q,        KC_W,          KC_E,    KC_R,    KC_T,   KC_LSFT,         KC_Z,        KC_X,          KC_C,    KC_V,    KC_B,    ALL_T(KC_NO),   LT(SYMB,KC_GRV), KC_QUOT,     LALT(KC_LSFT), KC_LEFT, KC_RGHT,                                                            ALT_T(KC_APP), KC_LGUI,                                                                           KC_HOME,                                                          KC_SPC, KC_BSPC, KC_END,   // right hand   KC_RGHT,      KC_6,          KC_7,    KC_8,    KC_9,    KC_0,    KC_MINS,   TG(SYMB),     NUM,           NUM,     NUM,     NUM,     NUM,     KC_BSLS,                 KC_Y,          KC_U,    KC_I,    KC_O,    KC_P,    GUI_T(KC_QUOT),   MEH_T(KC_NO), KC_N,          KC_M,    KC_COMM, KC_DOT,  KC_SLSH, KC_RSFT,                                KC_UP,   KC_DOWN, KC_LBRC, KC_RBRC, TT(SYMB),   KC_LALT,      CTL_T(KC_ESC),   KC_PGUP,   KC_PGDN,      KC_TAB,        KC_ENT ) }; // ...   Re-generate and re-flash the firmware, and you will now have combos approximating number input on a stenotype keyboard!   Multi-key Combos   Although all of the combos we have created so far have been two-key combos, you are certainly not limited to just two keys. To demonstrate this, let\u2019s create a combo that mimics the chord needed to output a full stop (.) on a stenotype keyboard (yes, I know this is not particularly practical on this layout, but play along just for this example).   The chord for a full stop in steno is TP-LT, meaning that the \u201cT\u201d and \u201cP\u201d keys on the left half of the keyboard, and the \u201cL\u201d and \u201cT\u201d keys on the right half of the keyboard are pressed together. This corresponds to pressing the WEIO keys together in the chorded QWERTY layout, so let\u2019s configure that in:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   // ... #define COMBO_COUNT 21   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum combos {   // ...   WEIO_DOT };  // ... const uint16_t PROGMEM weio_combo[] = {KC_W, KC_E, KC_I, KC_O, COMBO_END};  combo_t key_combos[COMBO_COUNT] = {   // ...   [WEIO_DOT] = COMBO(weio_combo, KC_DOT) };   No need to change any of the keymaps for this combo. If you now re-generate and re-flash your firmware, you will have a chorded full stop.   Conclusion   Learning about QMK combos was pretty useful, but should anyone actually consider chording their QWERTY layout if they are on a keyboard with enough keys to support each letter, or will doing this hinder more than help?   After putting in the effort to write this blog post, it pains me to say that, at least for me, at the time of this writing, it hinders more than helps for probably the following reasons:      I have too many years worth of touch typing muscle memory invested into the standard QWERTY layout: fighting back against inertia is hard.   I am learning stenography, and my brain seems to have siloed chorded key presses to the stenotype layout. There would seem to now be a trigger in my brain that fires when I move my fingers from QWERTY home row to steno home row, and I got very confused when I attempted to try and type QWERTY when my brain was in \u201csteno mode\u201d. I would wager that perhaps this might be worth re-visiting if I become more competent/confident in steno and/or end up using a keyboard like the Georgi, where there is no physical full-size QWERTY keyboard available, and I am forced to adapt.   So, ultimately, your mileage may vary for chorded QWERTY, but I really like QMK combos themselves, and look forward to experimenting with them: perhaps by replacing some keyboard shortcuts with chords instead.   If you do use QMK combos for anything interesting, please do reach out and let me know!   Update (19 February 2021)   Twitter user @azulee asked about whether NKRO was actually needed in order to perform combos.   I think I must have just assumed it was without confirming, so I changed and commented out some of my configuration to explicitly disable NKRO, and ran a check:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/rules.mk   # FORCE_NKRO = yes NKRO_ENABLE = no COMBO_ENABLE = yes   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   #include \"../../config.h\"  // #define FORCE_NKRO // ...   After re-compiling and re-flashing the firmware, all the combos in this blog post still worked! So, NKRO is not specifically needed in order to use QMK Combos.   I did wonder, though, whether combos that used more than 6 keys could still be performed without NKRO enabled. So, as a test, I added a new combo to my layout, in which the 8 ASDFJKL; keys would output a hash (#) when pressed together:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   enum combos {   // ...   ASDFJKLSCOLON };  // ... const uint16_t PROGMEM eightkey_combo[] = {   KC_A, KC_S, KC_D, KC_F, KC_J, KC_K, KC_L, KC_SCOLON, COMBO_END };  combo_t key_combos[COMBO_COUNT] = {   // ...   [ASDFJKLSCOLON] = COMBO(eightkey_combo, KC_HASH) };   \u2026and this combo also worked without NKRO enabled on the Ergodox EZ!   So, it would seem that even if you do not want to enable NKRO in your keyboard firmware, you are not prevented from using combos, even if their length may make it seem like it would be required.   ",categories:[],tags:["ergodox","keyboards","mechanical-keyboards","qmk","clang","stenography"],url:"/blog/chording-qwerty-qmk-combos/",teaser:"/assets/images/2019-04-28/samuel-ramos-1319769-unsplash.jpg"},{title:"Resume as Code",
excerpt:'I recently got back on the job market after a lengthy hiatus, and so had to re-visit the content of my humble resume.   As a developer, if the first recipient of your resume in a new organisation is a non-technical person, then you will probably need to be bound by convention and send along a PDF file of some sort. However, if that person is technical, it could be worth playing around with those conventions using the skills you know best because\u2026   Resumes are Boring   No one really likes to read or write resumes: you may have a duty to read them as part of your job if you are an interviewer, and you likely begrudgingly write them if you are an interviewee. Regardless, they are still the most widely accepted (and expected) artefact used to sell a person at the point of first contact.   They serve a single-use purpose: to convince someone that you are worth the time, effort, and money to begin an interview process with. An interviewer may use your resume as a reference to quiz you in more detail about your past work experience, but at that point you are already through the door, so its job is done.   But, it\u2019s that first step that\u2019s the hardest: having your resume, in a sea of similar resumes, get the attention and curiosity of someone in a position of authority, and convincing them that they should interview you.   In an attempt to achieve that goal, I chose Ruby to be in my corner to add some :sparkles:sparkles:sparkles: to a bland resume submission process.   Resume as Script                    Photo by Alice Pasqual on Unsplash        My actual resume is still ultimately a PDF document (I don\u2019t have the skills to do something extremely cool), but the method used to make that document come into existence is where I hope to get potential new colleagues on side.   That method is a Ruby application, using the Prawn gem under the hood for PDF generation. I send the generated PDF result to human resource contacts, but send only the application to technical contacts, and let them run it. The application ended up being a lot of fun for me to write and continue tweaking, and I hope that it ends up being at least a little bit fun for those I send it to. The intention is that it will lead to follow-on effects like:      The resume actually getting read since some minor effort was needed to generate it: pretty much an attempt to harness the IKEA effect, which would lead to\u2026   A positive response, which will then hopefully lead to an interview in a shorter time frame and\u2026   Potentially skip any coding tests, as the resume itself would also be a showcase code sample   You can get the resume application from Github and try it out yourself.   Design   I am not a designer, but there were a few things I did want to have in the resume document so that it looked familiar, yet not too pedestrian:      2 pages maximum because of low attention spans; no one needs to know my life story, and the details of any position can be discussed in an interview.   A line of image links at the top of the first page to various contact information, social media, professional, technical, and hobby accounts that I think are worth sharing on a resume but don\u2019t want taking up too much space    Buzzword bingo below the image links to make it easier to matchmake my abilities at a glance with any position requirements   LinkedIn-style position and education listings with links and images (regardless of what I may think of LinkedIn, most people know of it and are familiar with the way they lay out information, so I figured it was worth mimicking)   My hope is that most people will get all the re-reference-able information they really want to know out of the image links and Buzzword bingo (ie the first half of the first page of the resume), with all the rest of the information for the most part being read-once supplementary.   Technical Overview   The codebase of the resume has changed greatly as I\u2019ve tinkered with it, but as it stands now, it consists of two major parts:      The command line interface (CLI) program, which handles user input, and what needs to happen before and after the resume gets created   The resume itself: a series of modules that use Prawn to define individual parts of the resume document   Content   There is no content in the resume app at all, so you can\u2019t just open up the code to read the resume in plain text. Rather, the content comes from JSON files hosted in the project Github repo. All text there is encoded in Base64, so you really do need to generate the resume to read any of its content, and this is deliberate.   resources/resume.en.json   {   // ...   "social_media_logo_set": {     "logos": {       "email": {         "image": "aHR0cHM6Ly93d3cuZHJvcGJveC5jb20vcy8yYnQwOGw5MDg0YzR3NnkvcmVzdW1lX2VtYWlsLnBuZz9kbD0x",         "link": "bWFpbHRvOnBhdWwuZmlvcmF2YW50aUBnbWFpbC5jb20/c3ViamVjdD1Zb3VyJTIwcmVzdW1lJTIwaXMlMjBhd2Vzb21lISZib2R5PUklMjB3YW50JTIwdG8lMjBnaXZlJTIweW91JTIwYSUyMGpvYiUyMHJpZ2h0JTIwbm93IQ=="       },       "linked_in": {         "image": "aHR0cHM6Ly93d3cuZHJvcGJveC5jb20vcy9sdDY3NGNycnF3Y293bHcvcmVzdW1lX2xpbmtlZGluLnBuZz9kbD0x",         "link": "aHR0cHM6Ly9saW5rZWRpbi5jb20vaW4vcGF1bGZpb3JhdmFudGk="       },       "twitter": {         "image": "aHR0cHM6Ly93d3cuZHJvcGJveC5jb20vcy80cWo5YnVsem4wd200MWgvcmVzdW1lX3R3aXR0ZXIucG5nP2RsPTE=",         "link": "aHR0cHM6Ly90d2l0dGVyLmNvbS9wYXVsZmlvcmF2YW50aQ=="       },     // ...   },   // ... }   I love internationalisation, so aside from English, the content is available in Italian and Japanese. Japanese was a tough language to get working with Prawn initially since none of Prawn\u2019s bundled fonts support it, but I got there eventually, and will provide further details below.   Assets   Image assets are hosted on my Dropbox account, and when you run the resume application for the first time, it downloads all those files and stores them in your tmp directory. So, when you have generated the resume once, it will generate quicker subsequent times (or until your system clears out your tmp directory). Want to know exactly where those files are being stored? You can find out in IRB with Dir.tmpdir:   $ irb irb(main):001:0&gt; require "tmpdir" true irb(main):002:0&gt; Dir.tmpdir "/var/folders/g0/2s3h_j8n0rqcjjcmyr3v8cwh0000gn/T" irb(main):003:0&gt; exit $ ls /var/folders/g0/2s3h_j8n0rqcjjcmyr3v8cwh0000gn/T | grep resume resume_10fastfingers.png resume_background.jpg resume_duolingo.png resume_email.png resume_exercism.png # ...   Structure   The directory structure of the resume is pretty much standard for any Ruby project, which is fine for development, but I didn\u2019t want to package up multiple files when sending the resume to someone. So, there is a rake task that reads in all the files, and writes them to a single file (which I call the \u201cone-sheet\u201d resume), making it much more straightforward to, say, attach it to an email.   Testing and Code Quality   The application is fully tested using RSpec, and since it\u2019s showcase code, I have tried to add developer niceties like:      100% Simplecov test coverage   Rubocop is generally happy with it   Fully documented with Yard   The tests are also bundled into the one-sheet resume, so you can run both the application itself and the tests from the same file. When you generate the one-sheet resume, it also makes sure to test itself and check its own quality:   $ rake resume Generating one-sheet resume... Successfully generated one-sheet resume Running specs... Run options: include {:focus=&gt;true}  All examples were filtered out; ignoring {:focus=&gt;true}  115/115 |======================== 100 ========================&gt;| Time: 00:00:00  Finished in 0.72365 seconds (files took 0.24667 seconds to load) 115 examples, 0 failures Running code quality check...  1/1 file |======================= 100 ========================&gt;| Time: 00:00:00  1 file inspected, no offenses detected   Technical Challenges   During development, I came across a quite a few challenges, but simulating image links and getting internationalisation to work were ones that I needed to actively get community assistance for, so I will expand upon them below.   Prawn and Image Links   Prawn\u2019s README states:      One thing Prawn is not, and will never be, is an HTML to PDF generator. [\u2026] We do have basic support for inline styling but it is limited to a very small subset of functionality and is not suitable for rendering rich HTML documents.    I wanted to add a set of clickable image links to the resume; Prawn supports text links in PDFs, as you would expect, but it would seem that image links are considered \u201crich HTML\u201d, and outside the scope of Prawn\u2019s API. So, I wondered if there was a way to potentially simulate the effect that I wanted, and it turns out that there is. The high level explanation is to:      insert an image into the PDF   Move the document cursor up to the top of the image   draw some text over the image   make that text a link to somewhere   make that text transparent   And voil\xe0, it kind of looks like you are clicking the image.      An abbreviated code sample would look something like this:   # bounding_box provide bounds for flowing text, starting at a given point bounding_box([0, cursor], width: 35) do   image(     open("path/to/image.jpg"),     fit: [35, 35],     align: :center   )   # moves page "cursor" up   move_up(35)   # 0 is transparent, 1 is opaque   transparent(0) do     formatted_text(       [         {           text: "|||", # placeholder text           size: 40,           link: "http://example.com/"         }       ],       align: :center     )   end   # ... end   More details about this can be found in this StackOverflow question, and you can see how it is used in the resume codebase here.   Displaying Japanese Text   Japanese text cannot be rendered with Prawn\u2019s built-in fonts, and you will need to rely on external TrueType font files (extension .ttf) to display text.   When you attempt to generate my resume in Japanese, Ruby goes and fetches font files from my Dropbox account, and downloads them into your tmp directory. These files were originally provided by the Information-Technology Promotion Agency (IPA), but are now the concern of the Character Information Technology &amp; Promotion Council (CITPC). The specific set of font files are the \u201c4 fonts package\u201d (4\u66f8\u4f53\u30d1\u30c3\u30af) listed on this page, which contains the IPA Mincho and IPA Gothic fonts. The latest versions of these fonts can be found on the IPAex Font Downloads page.   I used the IPAPMincho font (ipamp.ttf) for \u201cnormal\u201d font, and IPAPGothic (ipagp.ttf) for \u201cbold\u201d; they are different fonts, but one worked for me as the \u201cbold version\u201d of the other. These fonts are configured in Prawn on-the-fly using code that looks something like this:   Prawn::Document.generate("MyJapaneseDocument.pdf") do |pdf|   # assume `font_name` here is something like "IPA",   # ie not a font that is shipped with the Prawn gem   unless Prawn::Font::AFM::BUILT_INS.include?(font_name)     pdf.font_families.update(       font_name =&gt; {         normal: "path/to/ipamp.ttf",         bold: "path/to/ipagp.ttf"       }     )   end   pdf.font font_name end   Japanese font then displays quite nicely, including half-width kana.      More details about this can be found in this StackOverflow question, and you can see how it is used in the resume codebase here.   Final Thoughts   Coding my resume ended up becoming one of my longest, most consistently maintained and developed projects (still going since 2013), small as it is. I certainly did not expect this to be the case when I started, but I would end up using it as a sandbox for ideas I wanted to test out in Ruby, and they ended up becoming features.   Sometimes, those features would result in \u201cbugs in production\u201d, and technical people would end up requesting the generated PDF from me when they would get errors trying to run the one-sheet Ruby script (though I\u2019m pretty sure it\u2019s okay now\u2026). But, at least they would usually laugh them off and acknowledge the effort to try something different (and then usually push me forward for an interview, anyway).   Creating your resume doesn\u2019t have to be a chore: it can be as fun and rewarding as any other software that you write, and that\u2019s all the better if doing something a bit different can help you in your job hunting as well.   Feel free to use any or all of my resume if you want to generate PDFs, and happy interviewing!   ',categories:[],tags:["pdf","prawn","resume","ruby","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"/blog/resume-code/",teaser:"/assets/images/2019-06-22/drew-beamer-692664-unsplash.jpg"},{title:"Internationalisation with Phoenix LiveView",
excerpt:'This blog post is the first in a series on the creation of a small I18n application using Phoenix LiveView, which updates page content based on the language chosen from a dropdown menu:      Internationalisation with Phoenix LiveView   Internationalisation with Phoenix LiveComponents   Internationalisation with Phoenix Live Layouts      In a previous blog post, Runtime Language Switching in Elm, I re-created the Tachyons Full Screen Centered Title component documentation page in Elm, and added a language dropdown menu to change the page language.      The page is deployed here, and you can find the code here, but to save a click, the animated GIF above shows all of its use cases:      Click on the current language, and the menu opens, showing a list of selectable languages   Click the current language again, or anywhere else on the page, and the menu closes   If you select a different language, the language of the page content and title will change, and the list of selectable languages in the dropdown menu will update   Refresh the page, and you will see that your choice of language is remembered   The blog post goes through different methods I used to get internationalisation (i18n) working, but, in my opinion, the options in Elm as of this writing are not quite as nice as Elixir\u2019s gettext-based API.   However, when I have previously implemented language switching for a standard Phoenix application, compared with frontend-only Elm, needing to make a request back to the server to change the application locale means that a bit more time is needed before the update is visible on screen.   Granted, changing application locale is not something a typical user would perform very often, and so, needing a page refresh for it is probably not a pain point for anyone. But, with the advent of Phoenix LiveView, I wondered whether I would be able to exactly replicate the snappiness of the Elm example application with Phoenix, just for fun.   And so, the rest of this post will focus on porting over/re-creating the Elm application in Phoenix, evolving over four stages:      Straight client-server   Augmenting client-server with Javascript \u201csprinkles\u201d   Letting Javascript take over   Swapping out Javascript for LiveView      The software versions we will use to build out this application are:          Elixir: 1.9.2     Erlang: 22.0.7     Phoenix: 1.4.10     Gettext: 0.7.10     LiveView: 0.3.1     Node: 12.12.0     Tachyons: 4.11.1      Let\u2019s get started!   Initial Setup   No Ecto   Generate and install dependencies of a new Phoenix application. We will not be using a database, so pass in the --no-ecto flag to make sure we do not generate any unneeded Ecto configuration:   mix phx.new phx_i18n_example --no-ecto cd phx_i18n_example mix deps.get   Gettext   Next, we will need to tell Gettext about what locales we want to use in the application (in our case English, Italian, and Japanese), and what locale should be the default (English). Add the following lines to your configuration:   config/config.exs   config :phx_i18n_example, PhxI18nExampleWeb.Gettext,   default_locale: "en",   locales: ~w(en it ja)   Tachyons   Since we will use Tachyons for styling, we have to install it and make it available in Phoenix.   First, install it with npm:   npm install --save-dev tachyons@4.11.1 --prefix assets   Then, import it into Phoenix:   assets/js/app.js   // ... // import css from "../css/app.css" // ... import "phoenix_html" import "tachyons" // ...   Make sure you also comment out or remove the default Phoenix-generated import css from "../css/app.css" line since we will not be using those default styles, and we do not want anything in app.css to overwrite Tachyons styling.   Client-Server   Dealing with Params   For this first development step, the goal will be to go as far as we can in building out the main use cases of the application using just Phoenix, and no Javascript.  This means we will have to start using URL parameters to send information to the server in order to tell it about the desired state of the application.   For example, if we want the locale to be Japanese, we could send a locale URL parameter to tell the application to switch to Japanese:   http://localhost:4000/?locale=ja   Since we are not using Javascript, we will also have to use URL parameters to let the application know if we want to open or close the locale dropdown menu:   http://localhost:4000/?show_available_locales=true http://localhost:4000/?show_available_locales=false   I think the best way for dealing with these parameters as they come in to the application is to use a Plug, so let\u2019s add a LocalePlug to our :browser pipeline:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   use PhxI18nExampleWeb, :router   alias PhxI18nExampleWeb.LocalePlug    pipeline :browser do     # ...     plug LocalePlug   end   # ... end   We need this LocalePlug to do the following:      Fetch and set the locale:            First, check the parameters for the locale       If it cannot be found in the parameters, check the browser cookies       If it cannot be found in the browser cookies, return the default locale       Update the global application locale to the retrieved locale value, but only if that locale value is actually different to the global application locale           Determine the dropdown menu state:            If the parameters have a show_available_locales=true value, indicate that the dropdown should be open       If there is any other value for show_available_locales, including false, or if show_available_locales is not present in the params, the dropdown should display as closed           Persist the locale in the cookies            If the locale value is already stored in the cookie, do nothing       Otherwise, if the cookie value is different from the locale value, or the cookie value is not present, store the locale value in the cookie           Let\u2019s see what this looks like in code:   lib/phx_i18n_example_web/plugs/locale_plug.ex   defmodule PhxI18nExampleWeb.LocalePlug do   alias Plug.Conn   @behaviour Plug    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @cookie "phxi18nexamplelanguage"   @ten_days 10 * 24 * 60 * 60    defguard known_locale?(locale) when locale in @locales    @impl Plug   def init(_opts), do: nil    @impl Plug   def call(conn, _opts) do     locale = fetch_and_set_locale(conn)      conn     |&gt; determine_language_dropdown_state()     |&gt; persist_locale(locale)   end    defp fetch_and_set_locale(conn) do     case locale_from_params(conn) || locale_from_cookies(conn) do       nil -&gt;         # This will fallback to the default locale set in `config.exs`         Gettext.get_locale()        locale -&gt;         # Update the global locale only if the `locale` value         # is different to it         if locale != Gettext.get_locale() do           Gettext.put_locale(locale)         end          locale     end   end    defp locale_from_params(%Conn{params: %{"locale" =&gt; locale}})        when known_locale?(locale) do     locale   end    defp locale_from_params(_conn), do: nil    defp locale_from_cookies(%Conn{cookies: %{@cookie =&gt; locale}})        when known_locale?(locale) do     locale   end    defp locale_from_cookies(_conn), do: nil    defp determine_language_dropdown_state(conn) do     show_available_languages =       case conn.params["show_available_locales"] do         "true" -&gt;           true          _ -&gt;           # `false`, `nil`, `blah` etc           false       end      Conn.assign(conn, :show_available_locales, show_available_languages)   end    defp persist_locale(%Conn{cookies: %{@cookie =&gt; locale}} = conn, locale) do     # Cookie locale is the same as the current locale, so do nothing and just     # return the original `conn`     conn   end    defp persist_locale(conn, locale) do     Conn.put_resp_cookie(conn, @cookie, locale, max_age: @ten_days)   end end   A few notes on this Plug file:      We are using Gettext.get_locale/0 as the source of truth for the application locale. It \u201cgets the global Gettext locale for the current process\u201d, and since we\u2019re doing a single process client-server implementation, it suits our purposes. There is no need to assign a separate locale value in the conn: whenever we want the application locale, we will ask Gettext to provide it to us   We are following Elixir\u2019s rule of thumb and deliberately using ||, and not or, in fetch_and_set_locale/1, since the values returned on either side are non-boolean   Having the cookie be valid for ten days is completely arbitrary. Feel free to change as you see fit   From Route to Template   Now that we have our application state set up, our flow from here towards the view layer is exactly as Phoenix provides out-of-the-box:   The root path gets routed to the PageController:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   use PhxI18nExampleWeb, :router   alias PhxI18nExampleWeb.LocalePlug    pipeline :browser do     # ...     plug LocalePlug   end    # ...    scope "/", PhxI18nExampleWeb do     pipe_through :browser     get "/", PageController, :index   end end   Then, the PageController renders the index.html template:   lib/phx_i18n_example_web/controllers/page_controller.ex   defmodule PhxI18nExampleWeb.PageController do   use PhxI18nExampleWeb, :controller    def index(conn, _params) do     render(conn, "index.html")   end end   \u2026which we need to change to the following code:   lib/phx_i18n_example_web/templates/page/index.html.eex   &lt;article class="&lt;%= article() %&gt;"&gt;   &lt;div class="&lt;%= heading_container() %&gt;"&gt;     &lt;h1 class="&lt;%= heading() %&gt;"&gt;       &lt;%= gettext("Vertically centering things in css is easy!") %&gt;     &lt;/h1&gt;   &lt;/div&gt; &lt;/article&gt;      The Phoenix-generated lib/phx_i18n_example_web/gettext.ex file enables us to use a gettext macro to search for translated strings depending on the Gettext locale setting. We do not have any translations at the moment, so this call will just return the \u201cVertically centering things in css is easy!\u201d string itself (we will get to generating translations later)   All the functions that you see interpolated in the various tag class attribute values exist to make it easier for us to manage sets of Tachyons utility classes   Modules Specifically for Styling   Functions declared without qualified module names in templates will be attempted to be resolved in the view that renders them, which, in index.html.eex\u2019s case, as per Phoenix convention, is the PageView.   Since the functions that are being referenced here will all thematically relate to styling, and be quite verbose, I think we should put them inside their own specific \u201cstyle\u201d modules, and have PageView delegate to them. This, to me at least, makes the PageView explicitly say:      \u201cI know I am meant to respond to these functions, but their details are not my responsibility, so please go and look in this other module\u201d    lib/phx_i18n_example_web/views/page_view.ex   defmodule PhxI18nExampleWeb.PageView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.PageStyle    defdelegate article, to: PageStyle   defdelegate heading, to: PageStyle   defdelegate heading_container, to: PageStyle end   lib/phx_i18n_example_web/views/styles/page_style.ex   defmodule PhxI18nExampleWeb.PageStyle do   @article_classes ~w[     dt     vh-75     w-100   ] |&gt; Enum.join(" ")    @heading_container_classes ~w[     dtc     ph-3 ph4-l     tc     v-mid   ] |&gt; Enum.join(" ")    @heading_classes ~w[     f6 f2-m f-subheadline-l     fw6     tc   ] |&gt; Enum.join(" ")    def article, do: @article_classes   def heading_container, do: @heading_container_classes   def heading, do: @heading_classes end      In order to make the Tachyons mnemonics easier to manage, they are in lists contained in module attributes, which get joined into a single string at compile time   The attributes are then wrapped in functions so they become a part of the module\u2019s public interface   I think this is a nicer way to deal with CSS utility classes, rather than modify them directly in a template. But, as with any subjective opinion, your mileage may vary.   Page Layout   Now, every template gets rendered inside of a layout, so let\u2019s look at the main application layout next, and mark where we will make changes from the Phoenix-generated defaults:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html&gt;   &lt;head&gt;     &lt;!-- ... --&gt;     &lt;title&gt;&lt;%= gettext("Multilingualisation in Phoenix") %&gt;&lt;/title&gt;     &lt;!-- ... --&gt;   &lt;/head&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= render LanguageDropdownView,                "language_dropdown.html",                show_available_locales: @show_available_locales %&gt;     &lt;main role="main"&gt;       &lt;%= render @view_module, @view_template, assigns %&gt;     &lt;/main&gt;     &lt;!-- ... --&gt;   &lt;/body&gt; &lt;/html&gt;   Like the index.html.eex template, the &lt;title&gt; uses the gettext macro to get its translation, and the &lt;body&gt; calls out to a body/0 view function in LayoutView to fetch its Tachyons style classes:   lib/phx_i18n_example_web/views/layout_view.ex   defmodule PhxI18nExampleWeb.LayoutView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.{LanguageDropdownView, LayoutStyle}    defdelegate body, to: LayoutStyle end   lib/phx_i18n_example_web/views/styles/layout_style.ex   defmodule PhxI18nExampleWeb.LayoutStyle do   @body_classes ~w[     bg-dark-pink     overflow-container     pt3     sans-serif     vh-100     white   ] |&gt; Enum.join(" ")    def body, do: @body_classes end   Language Dropdown Menu   Above the main section of app.html.eex, within which in this case index.html.eex is rendered, we render a separate view and template for the locale dropdown, passing in a @show_available_locales value, available here as a module attribute due to show_available_locales being assigned in the Plug.Conn in LocalePlug:   lib/phx_i18n_example_web/templates/language_dropdown/language_dropdown.html.eex   &lt;div class="&lt;%= dropdown_container() %&gt;"&gt;   &lt;%= render LanguageDropdownView,              "_current_locale_link.html",              show_available_locales: @show_available_locales %&gt;   &lt;ul class="&lt;%= dropdown_list(@show_available_locales) %&gt;"&gt;     &lt;%= render_many selectable_locales(),                     LanguageDropdownView,                     "_locale_link.html",                     as: :locale %&gt;   &lt;/ul&gt; &lt;/div&gt;   Using the same LanguageDropdownView, we render two partial templates:      _current_locale_link.html, passing in the @show_available_locales value we received from app.html.eex   _locale_link.html, which we are rendering for each of the non-current selectable locales, which we get from the selectable_locales/0 function, using Phoenix.View.render_many/4   Let\u2019s have a look at each of the partial templates:   lib/phx_i18n_example_web/templates/language_dropdown/_current_locale_link.html.eex   &lt;a href="?show_available_locales=&lt;%= !@show_available_locales %&gt;"    class="&lt;%= current_selection_link() %&gt;"&gt;   &lt;p class="&lt;%= current_selection(@show_available_locales) %&gt;"&gt;     &lt;span&gt;&lt;%= current_locale_string() %&gt;&lt;/span&gt;     &lt;span class="&lt;%= caret() %&gt;"&gt;\u25be&lt;/span&gt;   &lt;/p&gt; &lt;/a&gt;      The &lt;a&gt; tag here links to the opposite value of whatever the passed-in @show_available_locales value is, so that we can implement a toggle-like action   The styling of the dropdown is dependant on the value in @show_available_locales, which gets passed into the current_selection/1 function   lib/phx_i18n_example_web/templates/language_dropdown/_locale_link.html.eex   &lt;a href="?locale=&lt;%= @locale %&gt;" class="&lt;%= dropdown_list_item_link() %&gt;"&gt;   &lt;li class="&lt;%= dropdown_list_item() %&gt;"&gt;     &lt;%= locale_string(@locale) %&gt;   &lt;/li&gt; &lt;/a&gt;      The @locale attribute comes from the as: :locale option used in the render_many/4 function in language_dropdown.html.eex: each locale from the selectable_locales/0 function (see below) that is passed in to the partial is referenced as @locale   The &lt;a&gt; tag here links to its own locale as the target locale   Displays the humanised version of the locale (eg locale "en" displays as \u201cEnglish\u201d)   All the functions in the previous two partial templates are contained in the LanguageDropdownView:   lib/phx_i18n_example_web/views/language_dropdown_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.LanguageDropdownStyle   alias __MODULE__, as: LanguageDropdownView    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_strings %{     "en" =&gt; "English",     "it" =&gt; "Italiano",     "ja" =&gt; "\u65e5\u672c\u8a9e"   }    defdelegate caret, to: LanguageDropdownStyle   defdelegate current_selection(show_available_locales), to: LanguageDropdownStyle   defdelegate current_selection_link, to: LanguageDropdownStyle   defdelegate dropdown_container, to: LanguageDropdownStyle   defdelegate dropdown_list(show_available_locales), to: LanguageDropdownStyle   defdelegate dropdown_list_item, to: LanguageDropdownStyle   defdelegate dropdown_list_item_link, to: LanguageDropdownStyle    def locale_string(locale), do: @locale_strings[locale]   def current_locale_string, do: locale_string(Gettext.get_locale())   def selectable_locales, do: List.delete(@locales, Gettext.get_locale()) end      The Tachyons style-related functions are all delegated off to this view\u2019s style module, LanguageDropdownStyle   The locale_string/1 and current_locale_string/0 functions simply perform a lookup of the @locale_strings map to get the value to show in the menu: note that these strings are static, and the menu itself is not internationalised at all   Notice that the current_locale_string/0 function immediately calls the locale_string/1 function, passing in the result of the Gettext.get_locale/0 function as a parameter: we are always using Gettext as the source of truth for the application locale   In the same way, to get the list of selectable locales to populate the locale menu, we are subtracting the current locale from the list of known locales that we configured in config.exs   The LanguageDropdownStyle module contains the following:   lib/phx_i18n_example_web/views/styles/language_dropdown_style.ex   defmodule PhxI18nExampleWeb.LanguageDropdownStyle do   @caret_classes ~w[     absolute     ml2   ] |&gt; Enum.join(" ")    @current_selection_classes ~w[     b--white     ba     br2     pa2     pointer     tc     w4   ]    @current_selection_border_radius_classes "br--top"    @current_selection_link_classes ~w[     no-underline     white   ] |&gt; Enum.join(" ")    @dropdown_container_classes ~w[     center     f3     flex     h3     items-center     justify-end     w-90   ] |&gt; Enum.join(" ")    @dropdown_list_classes ~w[     absolute     b--white     bb     bl     br     br--bottom     br2     items-center     list     mt5     pl0     pointer     pr0     pt1     tc     top-0     w4   ]    @dropdown_show_classes ~w[     flex     flex-column   ] |&gt; Enum.join(" ")    @dropdown_hide_classes "dn"    @dropdown_list_item_classes ~w[     hover-bg-white     hover-dark-pink     ph1     pv2     pt0     w-100   ] |&gt; Enum.join(" ")    @dropdown_list_item_link_classes ~w[     no-underline     w-100     white   ] |&gt; Enum.join(" ")    def caret, do: @caret_classes    def current_selection(show_available_locales) do     display_classes =       if show_available_locales do         [@current_selection_border_radius_classes | @current_selection_classes]       else         @current_selection_classes       end      Enum.join(display_classes, " ")   end    def current_selection_link, do: @current_selection_link_classes    def dropdown_container, do: @dropdown_container_classes    def dropdown_list(show_available_locales) do     display_classes =       if show_available_locales do         [@dropdown_show_classes | @dropdown_list_classes]       else         [@dropdown_hide_classes | @dropdown_list_classes]       end      Enum.join(display_classes, " ")   end    def dropdown_list_item, do: @dropdown_list_item_classes   def dropdown_list_item_link, do: @dropdown_list_item_link_classes end   You can see that things here are quite verbose, and hence extracting these functions out into their own module creates a hard concern barrier between style-related functions, and other utility-like functions that are typically needed in view modules.   Generate Translations   Now that we know all of the two places where we need the gettext macro, we can generate translation placeholders for all of our known locales using the following commands:   mix gettext.extract mix gettext.merge priv/gettext --locale en mix gettext.merge priv/gettext --locale it mix gettext.merge priv/gettext --locale ja   Now that we have our locale placeholders, let\u2019s put some translations in them! The English locale file can be left as-is:   priv/gettext/en/LC_MESSAGES/default.po   # ...  #, elixir-format #: lib/phx_i18n_example_web/templates/layout/app.html.eex:7 msgid "Multilingualisation in Phoenix" msgstr ""  #, elixir-format #: lib/phx_i18n_example_web/templates/page/index.html.eex:4 msgid "Vertically centering things in css is easy!" msgstr ""   priv/gettext/it/LC_MESSAGES/default.po   # ...  #, elixir-format #: lib/phx_i18n_example_web/templates/layout/app.html.eex:7 msgid "Multilingualisation in Phoenix" msgstr "Multilingualizzazione in Phoenix"  #, elixir-format #: lib/phx_i18n_example_web/templates/page/index.html.eex:4 msgid "Vertically centering things in css is easy!" msgstr "Centrare verticalmente con css \xe8 facile!"   priv/gettext/ja/LC_MESSAGES/default.po   # ...  #, elixir-format #: lib/phx_i18n_example_web/templates/layout/app.html.eex:7 msgid "Multilingualisation in Phoenix" msgstr "Phoenix\u306b\u304a\u3051\u308b\u591a\u8a00\u8a9e\u5316"  #, elixir-format #: lib/phx_i18n_example_web/templates/page/index.html.eex:4 msgid "Vertically centering things in css is easy!" msgstr "CSS\u3067\u5782\u76f4\u30bb\u30f3\u30bf\u30ea\u30f3\u30b0\u306f\u7c21\u5358\u3060\u3088\uff01"   And now, when you change your locale, you should see the language change on the page content, as well as the page title!      You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 01-client-server branch. The branch is also deployed here in its own environment.   Client-Server Issues   So, we have language switching working, but what is wrong here?      It takes time to open and close the menu, and to change locale, since we are doing a round trip to the server   We cannot make the menu close if we click elsewhere on the page, since we cannot use Javascript onclick handlers. We also cannot make the entire &lt;body&gt; content a link, since we would have the dropdown links inside that body content link, and HTML does not do nested links.   Since we are missing a use case from the Elm implementation, let\u2019s compromise and allow some Javascript \u201csprinkles\u201d into the application.   Javascript Sprinkles   For this next step, aside from introducing some Javascript code, the main functionality of the application will not change very much.   Add Tag Metadata   We will need to allow Javascript to target certain page elements in order to manipulate them or perform some other actions, and that will take the form of adding some ids and roles to tags. So, let\u2019s open up the following files and make those small changes:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!-- ... --&gt;   &lt;body class="&lt;%= body() %&gt;" id="body"&gt;     &lt;!-- ... --&gt;   &lt;/body&gt; &lt;!-- ... --&gt;   lib/phx_i18n_example_web/templates/language_dropdown/language_dropdown.html.eex   &lt;!-- ... --&gt; &lt;ul class="&lt;%= dropdown_list(@show_available_locales) %&gt;" id="locale_dropdown"&gt;   &lt;!-- ... --&gt; &lt;/ul&gt; &lt;!-- ... --&gt;   lib/phx_i18n_example_web/templates/language_dropdown/_current_locale_link.eex   &lt;a href="?show_available_locales=&lt;%= !@show_available_locales %&gt;"    class="&lt;%= current_selection_link() %&gt;"    id="current_locale_link"&gt;   &lt;p class="&lt;%= current_selection(@show_available_locales) %&gt;" id="current_locale"&gt;     &lt;!-- ... --&gt;   &lt;/p&gt; &lt;/a&gt;   lib/phx_i18n_example_web/templates/language_dropdown/_locale_link.eex   &lt;a href="?locale=&lt;%= @locale %&gt;"    class="&lt;%= dropdown_list_item_link() %&gt;"    role="locale_link"&gt;   &lt;!-- ... --&gt; &lt;/a&gt;   Add Javascript   Now, in the main Javascript entry point for a Phoenix application, we are going to add a click-handler to the &lt;body&gt; that tells the dropdown to hide itself:   assets/js/app.js   // ... // Import local files // // Local files can be imported directly using relative paths, for example: // import socket from "./socket" import { LocaleDropdown } from "./locale_dropdown"  document.getElementById("body").onclick = () =&gt; {   LocaleDropdown.hide() }   I prefer Javascript with an interface that looks like it follows an Elixir-like Module.function() convention. This was able to be done using an Immediately Invoked Function Expression (IIFE; pronounced \u201ciffy\u201d) that returns an object containing functions in its values:   assets/js/locale_dropdown.js   export { LocaleDropdown }  const LocaleDropdown = ((document, window) =&gt; {   const LOCALE_DROPDOWN_CLASSES = document.getElementById("locale_dropdown").classList   const CURRENT_LOCALE_CLASSES = document.getElementById("current_locale").classList   const CURRENT_LOCALE_LINK = document.getElementById("current_locale_link")   const LOCALE_DROPDOWN_LINKS =     document.querySelectorAll(\'[role="locale_link"], #current_locale_link\')    // REF: https://tachyons.io/docs/table-of-styles/   const TOP_BORDER_RADIUS_ONLY = "br--top"   const DROPDOWN_VISIBLE_CLASSES = ["flex", "flex-column"]   const DROPDOWN_HIDDEN_CLASS = "dn"    initLocaleDropdownLinks()    return Object.freeze({     hide: hide   })    function initLocaleDropdownLinks() {     LOCALE_DROPDOWN_LINKS.forEach(link =&gt; {       // NOTE: Prevent propagation to the onclick handler for the `body` tag.       link.onclick = event =&gt; { event.stopPropagation() }     })   }    function hide() {     if (isVisible()) {       hideLocaleDropdown()       setCurrentLocaleLinkToOpenDropdownMenu()       resetCurrentLocaleBottomBorderRadius()       updateShowAvailableLocalesToHidden()     }   }    function isVisible() {     return (       DROPDOWN_VISIBLE_CLASSES.some(value =&gt; {         return LOCALE_DROPDOWN_CLASSES.contains(value)       })     )   }    function hideLocaleDropdown() {     LOCALE_DROPDOWN_CLASSES.remove(...DROPDOWN_VISIBLE_CLASSES)     LOCALE_DROPDOWN_CLASSES.add(DROPDOWN_HIDDEN_CLASS)   }    function setCurrentLocaleLinkToOpenDropdownMenu() {     CURRENT_LOCALE_LINK.setAttribute("href", "/?show_available_locales=true")   }    function resetCurrentLocaleBottomBorderRadius() {     CURRENT_LOCALE_CLASSES.remove(TOP_BORDER_RADIUS_ONLY)   }    function updateShowAvailableLocalesToHidden() {     // NOTE: This is done purely from a UX standpoint: If the locale dropdown is     // closed, do not have the search parameter say that it\'s open.     if (window.location.search === "?show_available_locales=true") {       window.history.pushState(         {}, document.title, "/?show_available_locales=false"       )     }   } })(document, window)   Yes, this is a pretty liberal helping of Javascript \u201csprinkles\u201d, but, we needed it. We won\u2019t go through all the details of this code, but there a few peculiarities worth bringing up briefly:      As the IIFE executes, it \u201cinitialises\u201d itself by calling initLocaleDropdownLinks(). This sets up event handlers to make sure all links in the dropdown menu, including the current locale link, do not have events generated by their clicks inadvertently propagate down to &lt;body&gt; tag, causing LocaleDropdown.hide() to also be called   The returned frozen object contains what is essentially the \u201cpublic interface\u201d for the IIFE: the hide function, which, as you can see, is called in app.js   The document and window do not technically need to be passed into the IIFE as arguments since they are globally available, but I think encapsulation is always a goal worth striving for. It is probably also better to have as many variables as possible resolve locally within the IIFE, rather than have to go out and get global variables every time you want to use them   Now, when you open the dropdown menu, and click anywhere else on the page, the menu closes.      You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 02-js-sprinkles branch. The branch is also deployed here in its own environment.   Javascript Sprinkles Issues   We are now technically on-par feature-wise with the Elm implementation, but there are still some lingering issues:      It still takes time to open and close the menu and change the locale   Closing the menu via clicking somewhere else on the page is snappier than clicking the current locale, even though their function is the same, which is a bit awkward   You can really feel now that we are perhaps unnecessarily forcing the back end to do things that the front end really wants us to do, so let\u2019s acquiesce to Javascript and let it take over more functionality. Further, let\u2019s get rid of any mandatory state management via URL parameters: like the Elm app, I don\u2019t want to see parameters that I don\u2019t have to.   Javascript Takeover   Remove Language Dropdown State Parameter   Dropdown state is currently managed via the @show_available_locales attribute, which is initially set in the LocalePlug, and then used throughout the templates and views. So, let\u2019s first purge our plug of this param: open up locale_plug.ex, and delete the determine_language_dropdown_state/1 function entirely, since we are not determining the language dropdown state in the plug anymore. Then, remove that function call from the call/2 function as follows:   lib/phx_i18n_example_web/plugs/locale_plug.ex   defmodule PhxI18nExampleWeb.LocalePlug do   # ...    @impl Plug   def call(conn, _opts) do     locale = fetch_and_set_locale(conn)     persist_locale(conn, locale)   end    # ... end   Great! Now, let\u2019s go and remove any trace of the @show_available_locales in our templates and views. First, in the layout:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!-- ... --&gt; &lt;%= render LanguageDropdownView, "language_dropdown.html" %&gt; &lt;!-- ... --&gt;   Then, in the dropdown menu template:   lib/phx_i18n_example_web/templates/language_dropdown/language_dropdown.html.eex   &lt;div class="&lt;%= dropdown_container() %&gt;"&gt;   &lt;%= render LanguageDropdownView, "_current_locale.html" %&gt;   &lt;ul class="&lt;%= dropdown_list() %&gt;" id="locale_dropdown"&gt;     &lt;%= render_many selectable_locales(),                     LanguageDropdownView,                     "_locale_list_item.html",                     as: :locale %&gt;   &lt;/ul&gt; &lt;/div&gt;   Here, you can see that we have renamed the _current_locale_link.html and _locale_link.html partials to _current_locale.html and _locale_list_item.html respectively, as we will use handlers for click events in them, rather than &lt;a&gt; links   The partials themselves look like the following:   lib/phx_i18n_example_web/templates/language_dropdown/_current_locale.html.eex   &lt;p class="&lt;%= current_selection() %&gt;" id="current_locale"&gt;   &lt;span&gt;&lt;%= current_locale_string() %&gt;&lt;/span&gt;   &lt;span class="&lt;%= caret() %&gt;"&gt;\u25be&lt;/span&gt; &lt;/p&gt;   lib/phx_i18n_example_web/templates/language_dropdown/_locale_list_item.html.eex   &lt;li class="&lt;%= dropdown_list_item() %&gt;" id="&lt;%= @locale %&gt;" role="selectable_locale"&gt;   &lt;%= locale_string(@locale) %&gt; &lt;/li&gt;   The number of styling-related functions has also decreased as a result of these changes, so we change the view and styling module code accordingly:   lib/phx_i18n_example_web/views/language_dropdown_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownView do   # ...    defdelegate caret, to: LanguageDropdownStyle   defdelegate current_selection, to: LanguageDropdownStyle   defdelegate dropdown_container, to: LanguageDropdownStyle   defdelegate dropdown_list, to: LanguageDropdownStyle   defdelegate dropdown_list_item, to: LanguageDropdownStyle    # ... end   lib/phx_i18n_example_web/views/styles/language_dropdown_style.ex   defmodule PhxI18nExampleWeb.LanguageDropdownStyle do   @caret_classes ~w[     absolute     ml2   ] |&gt; Enum.join(" ")    @current_selection_classes ~w[     b--white     ba     br2     pa2     pointer     tc     w4   ] |&gt; Enum.join(" ")    @dropdown_container_classes ~w[     center     f3     flex     h3     items-center     justify-end     w-90   ] |&gt; Enum.join(" ")    # NOTE: Default visibility is `display: none` (`dn`).   @dropdown_list_classes ~w[     absolute     b--white     bb     bl     br     br--bottom     br2     dn     items-center     list     mt5     pl0     pointer     pr0     pt1     tc     top-0     w4   ] |&gt; Enum.join(" ")    @dropdown_list_item_classes ~w[     hover-bg-white     hover-dark-pink     ph1     pv2     pt0     w-100   ] |&gt; Enum.join(" ")    def caret, do: @caret_classes   def current_selection, do: @current_selection_classes   def dropdown_container, do: @dropdown_container_classes   def dropdown_list, do: @dropdown_list_classes   def dropdown_list_item, do: @dropdown_list_item_classes end   Increase Javascript Responsibility   Finally, we update the locale dropdown Javascript so that it can:      Open the dropdown, as well as close it   Handle click events for each locale in the dropdown list, including the current locale   Prompt a locale change by sending an AJAX request, and then update the page with the server response   assets/js/locale_dropdown.js   export { LocaleDropdown }  const LocaleDropdown = ((document, window) =&gt; {   const LOCALE_DROPDOWN_CLASSES = document.getElementById("locale_dropdown").classList   const CURRENT_LOCALE = document.getElementById("current_locale")   const SELECTABLE_LOCALES = document.querySelectorAll("[role=\'selectable_locale\']")    // REF: https://tachyons.io/docs/table-of-styles/   const TOP_BORDER_RADIUS_ONLY = "br--top"   const DROPDOWN_VISIBLE_CLASSES = ["flex", "flex-column"]   const DROPDOWN_HIDDEN_CLASS = "dn"    initCurrentLocale()   initSelectableLocales()    return Object.freeze({     hide: hide   })    function initCurrentLocale() {     const currentLocaleClassList = CURRENT_LOCALE.classList     CURRENT_LOCALE.onclick = event =&gt; {       // NOTE: Prevent propagation to the onclick handler for the `body` tag.       event.stopPropagation()       if (isVisible()) {         hideLocaleDropdown()         removeCurrentLocaleBottomBorderRadius(currentLocaleClassList)       } else {         showLocaleDropdown()         addCurrentLocaleBottomBorderRadius(currentLocaleClassList)       }     }   }    function initSelectableLocales() {     SELECTABLE_LOCALES.forEach(locale =&gt; {       locale.onclick = () =&gt; {         changeLocale(locale)       }     })   }    function hide() {     const currentLocaleClassList = CURRENT_LOCALE.classList     if (isVisible()) {       hideLocaleDropdown()       removeCurrentLocaleBottomBorderRadius(currentLocaleClassList)     }   }    function changeLocale(locale) {     // Clear params in case the locale was originally set using them.     window.history.replaceState({}, document.title, "/")     const xhr = new XMLHttpRequest()     xhr.open("GET", document.location.origin + `?locale=${locale.id}`)     xhr.onreadystatechange = () =&gt; {       document.open()       document.write(xhr.responseText)       document.close()     }     xhr.send()   }    function isVisible() {     return (       DROPDOWN_VISIBLE_CLASSES.some(value =&gt; {         return LOCALE_DROPDOWN_CLASSES.contains(value)       })     )   }    function hideLocaleDropdown() {     LOCALE_DROPDOWN_CLASSES.remove(...DROPDOWN_VISIBLE_CLASSES)     LOCALE_DROPDOWN_CLASSES.add(DROPDOWN_HIDDEN_CLASS)   }    function showLocaleDropdown() {     LOCALE_DROPDOWN_CLASSES.add(...DROPDOWN_VISIBLE_CLASSES)     LOCALE_DROPDOWN_CLASSES.remove(DROPDOWN_HIDDEN_CLASS)   }    function removeCurrentLocaleBottomBorderRadius(currentLocaleClassList) {     currentLocaleClassList.remove(TOP_BORDER_RADIUS_ONLY)   }    function addCurrentLocaleBottomBorderRadius(currentLocaleClassList) {     currentLocaleClassList.add(TOP_BORDER_RADIUS_ONLY)   } })(document, window)   After applying those changes, you can see that the application is now as snappy as the Elm version.      You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 03-js-takeover branch. The branch is also deployed here in its own environment.   Javascript Takeover Issues   In order to fetch translations, the application is still making a call out to the server, so it will never be quite as fast as Elm there, but that\u2019s fine: I would rather not give up using the gettext API for a potential front-end-based solution.   But, the issue now is\u2026we have a lot of Javascript :wink:! Wouldn\u2019t it be nicer if we could handle all this \u201cfront-end\u201d functionality in Elixir-land? Well, let\u2019s see how much LiveView can help us in achieving that goal!   LiveView   It feels like it\u2019s been a long evolution for this application, but we are finally at the main event: leveraging the power of LiveView!   Before we begin changing our application logic, we have some new dependencies to add and some configuration ceremony to perform, so let\u2019s do that.   Installation and Configuration      NOTE: The method of installation/configuration below is current as of LiveView 0.3.1, but since LiveView is a rapidly evolving project as of this writing, make sure to check the Phoenix LiveView README file for the latest information if you run into any issues.    First, we need to install the LiveView hex package, so add the following entries to your mix file:   mix.exs   defmodule PhxI18nExample.MixProject do   # ...    defp deps do     [       # ...       {:phoenix_live_view, "~&gt; 0.3.0"},       {:floki, "&gt;= 0.0.0", only: :test}     ]   end   Then, run mix deps.get.   Next, we need to add configuration for a signing salt. Generate one by running mix phx.gen.secret 32, and then add it as follows:   config/config.exs   config :phx_i18n_example, PhxI18nExampleWeb.Endpoint,   # ...   live_view: [     signing_salt: "&lt;YOUR_SECRET_SALT&gt;"   ]   Add the LiveView flash to the browser pipeline:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   # ...    pipeline :browser do     # ...     plug :fetch_flash     plug Phoenix.LiveView.Flash     # ...   end    # ... end   Add some LiveView configuration to your controllers, views, and router in your web file:   lib/phx_i18n_example_web.ex   defmodule PhxI18nExampleWeb do   # ...    def controller do     quote do       # ...       import Phoenix.LiveView.Controller     end   end    def view do     quote do       # ...       import Phoenix.LiveView,         only: [           live_render: 2,           live_render: 3,           live_link: 1,           live_link: 2         ]     end   end    def router do     quote do       # ...       import Phoenix.LiveView.Router     end   end    # ... end   Expose a new websocket for LiveView updates:   lib/phx_i18n_example_web/endpoint.ex   defmodule PhxI18nExampleWeb.Endpoint do   use Phoenix.Endpoint, otp_app: :phx_i18n_example    socket "/live", Phoenix.LiveView.Socket    # ... end   Add LiveView to the Node dependencies:   assets/package.json   {   // ...   "dependencies": {     // ...     "phoenix_live_view": "file:../deps/phoenix_live_view"   },   // ... }   Install the dependencies with:   npm install --prefix assets   Finally, enable connecting to a LiveView socket from Javascript:   assets/js/app.js   // ...  import { Socket } from "phoenix" import LiveSocket from "phoenix_live_view"  let liveSocket = new LiveSocket("/live", Socket) liveSocket.connect()   Okay, configuration ceremony complete! Now, let\u2019s move over to actually changing the application.   From Conn to Session   We will start, yet again, with the locale plug, where we find that there are some significant changes from before:   lib/phx_i18n_example_web/plugs/locale_plug.ex   defmodule PhxI18nExampleWeb.LocalePlug do   alias Plug.Conn   @behaviour Plug    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @cookie "phxi18nexamplelanguage"    defguard known_locale?(locale) when locale in @locales    @impl Plug   def init(_opts), do: nil    @impl Plug   def call(conn, _opts) do     locale = fetch_locale(conn)      conn     |&gt; Conn.assign(:locale, locale)     |&gt; Conn.put_session(:locale, locale)   end    defp fetch_locale(conn) do     case locale_from_params(conn) || locale_from_cookies(conn) do       nil -&gt;         # NOTE: This will fallback to the default locale set in `config.exs`         Gettext.get_locale()        locale -&gt;         locale     end   end    defp locale_from_params(%Conn{params: %{"locale" =&gt; locale}})        when known_locale?(locale) do     locale   end    defp locale_from_params(_conn), do: nil    defp locale_from_cookies(%Conn{cookies: %{@cookie =&gt; locale}})        when known_locale?(locale) do     locale   end    defp locale_from_cookies(_conn), do: nil end   A few notes on this file:      In the fetch_locale/1 function, we are still attempting to fetch the locale from values potentially given in the params, or in the cookies. If we cannot find it, we ask gettext to give us the default locale; that part has not changed. However, if we do find the locale, we are simply returning it, without calling Gettext.put_locale/1 to set the locale globally, because LiveViews run in their own process. As opposed to before, where the application was essentially single process, the application will now be multi-process, which means that there is no global locale for a LiveView to refer to, even if we do set it: each process can only rely on its own encapsulated state, and hence will need a local reference to a locale   This relates directly to why we are using Plug.Conn.put_session/3: we provide session data to LiveViews, not conn data, to initialise their state   We are also providing the exact same locale data to the conn assigns, though. Why store the same data in two different places? Because the layout template the LiveView is rendered in, app.html.eex, needs it. A layout, or at least the main layout (I have not tested nested layouts), as far as I can gather, can have LiveViews rendered within in it, but cannot itself be a LiveView (this took me far too long to finally figure out)   All code related to persisting the locale value in the cookie has been removed since a Phoenix.LiveView.Socket does not have the ability to directly access or assign values to cookies. So how do we make sure the application can remember our locale choice? Using a Javascript escape hatch called \u201chooks\u201d to get at the cookies, which we will see more of later\u2026   Goodbye Controller, Hello LiveView   Now, let\u2019s see about getting a LiveView rendered. First, to the router:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   # ...    scope "/", PhxI18nExampleWeb do     pipe_through :browser     live "/", PageLive, session: [:locale]   end end      Rather than routing the root path to the PageController, we can route directly to a LiveView with Phoenix.LiveView.Router.live/3. LiveViews are responsible for setting up state within their own process, so they pretty much fulfil the role that a controller would. So, if you would like, you can safely delete the lib/phx_i18n_example_web/controllers/page_controller.ex file. (Note that we could have continued to use PageController, and just converted the index function\u2019s render/3 to a live_render/3, but it\u2019s purpose would have only been to manually extract the locale out of conn.assigns and assign it to the session, so I figured going straight to a live route would feel more \u201cLiveView-y\u201d, if that\u2019s even a thing\u2026)   The session: [:locale] option here indicates that we want to pass the session locale value we populated in the LocalePlug to PageLive, our named LiveView   Speaking of which, let\u2019s create a PageLive module, which, by what seems like an emerging convention, should be placed in a live/ web directory:   lib/phx_i18n_example_web/live/page_live.ex   defmodule PhxI18nExampleWeb.PageLive do   use Phoenix.LiveView   alias PhxI18nExampleWeb.PageView    def mount(%{locale: locale}, socket) do     socket = assign(socket, locale: locale)     {:ok, socket}   end    def render(assigns) do     PageView.render("index.html", assigns)   end end   A LiveView has two main callback functions that you must implement:      mount/2, where you set up your initial state from session values and assign them to the socket state   render/1, which is responsible for returning rendered content, which in this case is the index.html template, passing it the assigns information, which comes from the socket. So, in this case, assigns could contain %{locale: "en"} if that is what was set in the socket, either from mount/2, or an event handler, which we will look at later   As for the index.html template that gets rendered in the LiveView, it looks fairly similar to before, but we now need to give it a .leex extension for Live Embedded Elixir:   lib/phx_i18n_example_web/templates/page/index.html.leex   &lt;%= with_locale(@locale, fn -&gt; %&gt;   &lt;article class="&lt;%= article() %&gt;" phx-click="hide-dropdown"&gt;     &lt;div class="&lt;%= heading_container() %&gt;"&gt;       &lt;h1 class="&lt;%= heading() %&gt;"&gt;         &lt;%= gettext("Vertically centering things in css is easy!") %&gt;       &lt;/h1&gt;     &lt;/div&gt;   &lt;/article&gt; &lt;% end) %&gt;      As mentioned previously, we can no longer rely on Gettext.get_locale/0 to be our global source of truth for the application locale, since each LiveView is its own process. So, we need to specifically provide a locale to every template that needs translating. I initially thought that I could use Gettext.get_locale/0 and Gettext.put_locale/1 within a LiveView to set a global locale within the LiveView process: I tried using them in mount/2, render/1, and even within the above template, but I had no luck in getting the string-to-translate to re-evaluate until I used Gettext.with_locale/2 with the @locale that was set in the socket.assigns.  So, please be aware of that potentially time-consuming gotcha, or, if you found a way to use them in LiveView, please let me know!   The &lt;article&gt; tag now has a phx-click="hide-dropdown" binding on it, which will send PageLive a "hide-dropdown" message when it is clicked (remember that clicking outside the dropdown menu while it is open should close the menu). We haven\u2019t put the message-handling code in PageLive just yet, but we will come back to it   In order to get with_locale/2 available in the template, make sure to update the PageView:   lib/phx_i18n_example_web/views/page_view.ex   defmodule PhxI18nExampleWeb.PageView do   use PhxI18nExampleWeb, :view   import Gettext, only: [with_locale: 2]    # ... end   Every LiveView in its own Process   In the layout, the standard &lt;%= render @view_module, @view_template, assigns %&gt; statement renders the PageLive LiveView, but that is not the only place where we need dynamic functionality. The language dropdown needs to open, close, and change locale, and the page title needs to change when the locale changes.   We cannot wrap the entire page in a single LiveView (there\u2019s no equivalent for document.getElementById("body").onclick for us here), so we are going to need separate LiveViews for the dropdown menu and title, rendered from the layout:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html&gt;   &lt;head&gt;     &lt;!-- ... --&gt;     &lt;%= live_render @conn, TitleLive, session: %{locale: @locale} %&gt;   &lt;/head&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= live_render @conn, LanguageDropdownLive, session: %{locale: @locale} %&gt;     &lt;main role="main"&gt;       &lt;%= render @view_module, @view_template, assigns %&gt;     &lt;/main&gt;     &lt;!-- ... --&gt;   &lt;/body&gt; &lt;/html&gt;   The live_render/3 function \u201crenders a LiveView within an originating plug request or within a parent LiveView\u201d. If we were rendering these LiveViews from another LiveView, we would pass in the parent LiveView\u2019s @session attribute. But, since the layout is within a plug request, we do not have a session yet, and, therefore, need to create one for the new LiveViews. Hence, we use @conn as the first argument, and make sure to pass in the @locale attribute from the conn, that we set up in the LocalePlug (remember, we set the same locale value in both the conn and in the session), into both the TitleLive and LanguageDropdownLive\u2019s session.   In order to have TitleLive aliased properly in the layout template, make sure to make the following minor change to the LayoutView:   lib/phx_i18n_example_web/views/layout_view.ex   # ... alias PhxI18nExampleWeb.{LanguageDropdownLive, LayoutStyle, TitleLive}   We will get into the details of TitleLive and LanguageDropdownLive soon, but an important thing to understand is that we now have 3 LiveViews, each running in their own separate process, which conceptually looks like this:      Now, even though each of these LiveViews exist in isolated processes, they still need to be able to talk to each other when certain events occur:      When LocaleDropdownLive changes the locale, PageLive and TitleLive need to know what the locale has been changed to so they can re-render themselves with the correct string for the locale   When the current locale is clicked, it needs to look at what the state of the available locales dropdown menu is, open or closed, and toggle it   If the dropdown menu is open in LocaleDropdownLive, and a click occurs either in PageLive or in LocaleDropdownLive outside of the dropdown menu, LocaleDropdownLive needs to know so that it can re-render itself with a closed menu      In order to get these LiveViews chatting, we will call on Phoenix PubSub to help us out.   LiveView Event Handling   Since we\u2019re already most familiar with PageLive, let\u2019s code up message handling there first:   lib/phx_i18n_example_web/live/page_live.ex   defmodule PhxI18nExampleWeb.PageLive do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageView}    @locale_changes "locale-changes"   @dropdown_changes "dropdown-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@locale_changes)     socket = assign(socket, locale: locale)     {:ok, socket}   end    def render(assigns) do     PageView.render("index.html", assigns)   end    def handle_event("hide-dropdown", _value, socket) do     Endpoint.broadcast_from(self(), @dropdown_changes, "hide-dropdown", %{})     {:noreply, socket}   end    def handle_info(%{event: "change-locale", payload: %{locale: locale}}, socket) do     socket = assign(socket, :locale, locale)     {:noreply, socket}   end end         There are two different types of messages that PageView has to concern itself with: locale change messages, and dropdown change messages, which we have set up as two different Phoenix Channel names: @locale_changes and @dropdown_changes. Not all LiveViews will need to care about all kinds of messages, which is why we are not using a single channel for all message types   When the PageView mounts, it calls Phoenix.Endpoint.subscribe/2 to set up a subscription to @locale_changes messages, since it needs to be told when the locale changes so it can render the correct language string. The message we are looking out for from @locale_changes is called "change-locale", which we handle with Phoenix.LiveView.handle_info/2. When we get the "change-locale" message, we extract the locale from its payload, and assign it to the socket. render/1 will then be called automatically, and any necessary template re-rendering will occur   The PageView also needs to listen out for "hide-dropdown" messages that its own template, index.html.leex could send to it (remember we set phx-click="hide-dropdown" on the &lt;article&gt; tag). When a "hide-dropdown" message is received by Phoenix.LiveView.handle_event/3, the PageView does not need to do anything to itself, but it instead calls Phoenix.Endpoint.broadcast_from/4 to send out a broadcast to anything that\u2019s listening on the @dropdown_changes channel telling it that they should hide their dropdown; you can probably guess what would be listening out for that   Let\u2019s now create a TitleLive module:   lib/phx_i18n_example_web/live/title_live.ex   defmodule PhxI18nExampleWeb.TitleLive do   use Phoenix.LiveView   import PhxI18nExampleWeb.Gettext, only: [gettext: 1]   import Gettext, only: [with_locale: 2]   alias PhxI18nExampleWeb.Endpoint    @locale_changes "locale-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@locale_changes)     socket = assign(socket, locale: locale)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= with_locale(@locale, fn -&gt; %&gt;       &lt;title&gt;         &lt;%= gettext("Multilingualisation in Phoenix") %&gt;       &lt;/title&gt;     &lt;% end) %&gt;     """   end    def handle_info(%{event: "change-locale", payload: %{locale: locale}}, socket) do     socket = assign(socket, :locale, locale)     {:noreply, socket}   end end         As you can see, the mount/1 and handle_info/2 functions are identical to PageView: they both subscribe to the @locale_changes channel and specifically handle "change-locale" messages to change their own locales   For render/1, though, because there is not much code, we will render it inline rather than create a new template just for the &lt;title&gt; tag   When I initially wrote the inline template, I figured that I could get away with leaving the &lt;title&gt; tag in app.html.eex, and just render the gettext macro, since that\u2019s the only thing that changes. However, a LiveView must contain at least one HTML tag in order to render, so just be aware of that gotcha   Let\u2019s now create our last, and busiest, LiveView: LanguageDropdownLive.   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownView}    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_changes "locale-changes"   @dropdown_changes "dropdown-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@dropdown_changes)     socket = init_dropdown_state(socket, locale)     {:ok, socket}   end    def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end    # Event handling code will go here...    defp init_dropdown_state(socket, locale) do     selectable_locales = List.delete(@locales, locale)      assign(       socket,       %{         locale: locale,         selectable_locales: selectable_locales,         show_available_locales: false       }     )   end end   For the time-being, we will leave out any event handling code, and instead gradually add it in as we look through the templates that will fire off the events that LanguageDropdownLive needs to handle. The major points we need to know about at this stage are:      LanguageDropdownLive subscribes to the @dropdown_changes channel, since clicks could occur within itself, outside of the actual dropdown menu, as well as from PageLive, that would necessitate it to close the dropdown menu   We have also set up a @locale_changes channel, that we will broadcast on to let PageLive and TitleLive know about locale changes, and which we will use in an event handler soon   On mount, the init_dropdown_state/2 function is called to\u2026initialise the dropdown state. Note that we have brought back the show_available_locales attribute that we initially got rid of when we migrated from client-server to Javascript. It is now back to being a part of the overall language dropdown state, and so we need to deal with it here in the LiveView   A Quick Styling Detour   The re-emergence of show_available_locales affects the way we deal with the Tachyons styling, so we will make a quick detour to handle re-writing of the LanguageDropdownView and LanguageDropdownStyle files to re-incorporate the show_available_locales attribute:   lib/phx_i18n_example_web/views/language_dropdown_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.LanguageDropdownStyle   alias __MODULE__, as: LanguageDropdownView    @locale_strings %{     "en" =&gt; "English",     "it" =&gt; "Italiano",     "ja" =&gt; "\u65e5\u672c\u8a9e"   }    defdelegate caret, to: LanguageDropdownStyle   defdelegate current_selection(show_available_locales), to: LanguageDropdownStyle   defdelegate dropdown_container, to: LanguageDropdownStyle   defdelegate dropdown_list(show_available_locales), to: LanguageDropdownStyle   defdelegate dropdown_list_item, to: LanguageDropdownStyle    def locale_string(locale), do: @locale_strings[locale] end   lib/phx_i18n_example_web/views/styles/language_dropdown_style.ex   defmodule PhxI18nExampleWeb.LanguageDropdownStyle do   @caret_classes ~w[     absolute     ml2   ] |&gt; Enum.join(" ")    @current_selection_classes ~w[     b--white     ba     br2     pa2     pointer     tc     w4   ]    @current_selection_border_radius_classes "br--top"    @current_selection_link_classes ~w[     no-underline     white   ] |&gt; Enum.join(" ")    @dropdown_container_classes ~w[     center     f3     flex     h3     items-center     justify-end     w-90   ] |&gt; Enum.join(" ")    @dropdown_list_classes ~w[     absolute     b--white     bb     bl     br     br--bottom     br2     items-center     list     mt5     pl0     pointer     pr0     pt1     tc     top-0     w4   ]    @dropdown_show_classes ~w[     flex     flex-column   ] |&gt; Enum.join(" ")    @dropdown_hide_classes "dn"    @dropdown_list_item_classes ~w[     hover-bg-white     hover-dark-pink     ph1     pv2     pt0     w-100   ] |&gt; Enum.join(" ")    @dropdown_list_item_link_classes ~w[     no-underline     w-100     white   ] |&gt; Enum.join(" ")    def caret, do: @caret_classes    def current_selection(show_available_locales) do     display_classes =       if show_available_locales do         [@current_selection_border_radius_classes | @current_selection_classes]       else         @current_selection_classes       end      Enum.join(display_classes, " ")   end    def current_selection_link, do: @current_selection_link_classes    def dropdown_container, do: @dropdown_container_classes    def dropdown_list(show_available_locales) do     display_classes =       if show_available_locales do         [@dropdown_show_classes | @dropdown_list_classes]       else         [@dropdown_hide_classes | @dropdown_list_classes]       end      Enum.join(display_classes, " ")   end    def dropdown_list_item, do: @dropdown_list_item_classes   def dropdown_list_item_link, do: @dropdown_list_item_link_classes end   Language Dropdown Event Handling   Back to our scheduled event handling programming. Let\u2019s dive straight into the language dropdown template:   lib/phx_i18n_example_web/templates/language_dropdown/language_dropdown.html.leex   &lt;div class="&lt;%= dropdown_container() %&gt;" phx-click="hide"&gt;   &lt;%= render LanguageDropdownView,              "_current_locale.html",              locale: @locale,              show_available_locales: @show_available_locales %&gt;   &lt;ul class="&lt;%= dropdown_list(@show_available_locales) %&gt;"&gt;     &lt;%= render_many @selectable_locales,                     LanguageDropdownView,                     "_locale_list_item.html",                     as: :locale %&gt;   &lt;/ul&gt; &lt;/div&gt;      As expected, the language dropdown template is now a .leex file since it is being rendered by a LiveView   The full set of dropdown state that was set in the socket is on display here, with the @locale and @show_available_locales attributes now being passed into the _current_locale.html partial, and @selectable_locales now being used to determine what locales need to have _locale_list_items.html partials rendered for them, rather than a selectable_locales/0 view function that we used previously   Notice that the partials are being render-ed \u201cnormally\u201d, as in, they are not being live_rendered. This is because the partials are not meant to be run in a separate process to the parent template and they are essentially \u201ca part\u201d of the parent template itself, and hence are automatically \u201clive rendered\u201d. Nested LiveViews are possible, but that is not what is occurring in this case   We can see the first event that LanguageDropdownLive needs to handle is a "hide" event, occurring whenever somewhere in the template that is not the dropdown menu is clicked, so let\u2019s write the function to handle that:   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...    def handle_event("hide", _value, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    # ... end      Okay, first event handled! Let\u2019s now see what the _current_locale.html needs us to do:   lib/phx_i18n_example_web/templates/language_dropdown/_current_locale.html.eex   &lt;p class="&lt;%= current_selection(@show_available_locales) %&gt;"    name="current_locale"    id="&lt;%= @locale %&gt;"    phx-click="toggle"    phx-hook="currentLocale"&gt;   &lt;span&gt;&lt;%= locale_string(@locale) %&gt;&lt;/span&gt;   &lt;span class="&lt;%= caret() %&gt;"&gt;\u25be&lt;/span&gt; &lt;/p&gt;   Compared to before, the &lt;p&gt; tag now:      has an id attribute containing the @locale passed into it from its parent template   fires a "toggle" message when clicked   has a binding to a hook named "currentLocale"   Let\u2019s handle the message first, and then the hook.   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...    def handle_event("toggle", _value, socket) do     %{assigns: %{show_available_locales: show_available_locales}} = socket     socket = assign(socket, :show_available_locales, !show_available_locales)     {:noreply, socket}   end    # ... end   To handle the "toggle" message, we take the current value of the show_available_locales attribute from the socket, flip the value, and then re-assign it back to the socket.      Hooks   LiveView provides life-cycle callback functions to handle custom client-side Javascript when an element is added, updated, or removed by the server. In our case, we are going to want to use two of those callback functions, mounted and updated, for the exact same purpose:   assets/js/app.js   // ...  import { Socket } from "phoenix" import LiveSocket from "phoenix_live_view" import { Cookie } from "./cookie"  const Hooks = {   currentLocale: {     mounted() {       Cookie.set(this.el.id)       // Clear params in case the locale was originally set using them.       window.history.replaceState({}, document.title, "/")     },     updated() {       Cookie.set(this.el.id)     }   } }  let liveSocket = new LiveSocket("/live", Socket, { hooks: Hooks }) liveSocket.connect()      In the mounted() callback, executed when the current locale has been mounted into the DOM (eg when first opening the application or after a page refresh), we are able to access the &lt;p&gt; tag element from _current_locale.html.eex itself in by calling this.el.  Since we set an id attribute on the &lt;p&gt; tag containing the current locale, we can access it using this.el.id.   Since we have not explicitly disallowed setting the locale by params, but we do not want them to hang around after mounting, we clear them out using History.replaceState   Since we want to make sure that the locale is stored in cookies on every locale change, which could happen during a mount (application first starts), and an update (locale is selected from the dropdown menu), we set the cookie in the updated() callback as well   Make sure you pass a { hooks: Hooks } options object to LiveSocket in order to initialise the hooks   The Javascript to set the cookie looks like the following:   assets/js/cookie.js   export { Cookie }  const Cookie = (document =&gt; {   const NAME = "phxi18nexamplelanguage"    return { set: set }    function set(locale) {     document.cookie = `${NAME}=${locale}; expires=${expires()}`   }    function expires() {     let expiry = new Date()     // Set expiry to ten days     expiry.setDate(expiry.getDate() + 10)     return expiry.toGMTString()   } })(document)   For some reason, it took me longer than expected to get the Document.cookie code working properly. Setting the cookie did not seem to work unless its name only contained letters and numbers, and no other characters. Maybe you will have better luck if you decide to re-write any of this code.   Passing Values in Bindings   Back in Elixir-land, we now need to look at what messages should sent when a locale in the language dropdown menu gets clicked:   lib/phx_i18n_example_web/templates/language_dropdown/_locale_list_item.html.eex   &lt;li class="&lt;%= dropdown_list_item() %&gt;"     id="&lt;%= @locale %&gt;"     role="selectable_locale"     phx-click="locale-changed"     phx-value-locale="&lt;%= @locale %&gt;"&gt;   &lt;%= locale_string(@locale) %&gt; &lt;/li&gt;   When a locale is clicked, it fires a "locale-changed" message, and in order to tell the LiveView what the new locale should be, it uses a phx-value- prefixed attribute called, unsurprisingly, locale. So, let\u2019s handle this message and parameter in LanguageDropdownLive:   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(self(), @locale_changes, "change-locale", %{locale: locale})     socket = init_dropdown_state(socket, locale)     {:noreply, socket}   end    # ... end      Here, we get told that \u201cthe locale has changed\u201d (passive voice), at which point we broadcast out to anything that is listening on the @locale_changes channel that they should \u201cchange their locale\u201d (active voice) to the specified locale value   Then, we re-use the init_dropdown_state/2 function, that we also used in mount/2, to reset the language dropdown menu to its initial state, and re-render it      The final message that LanguageDropdownLive needs to deal with, is the "hide-dropdown" message that it would receive when a click is registered on PageLive. The implementation for this is the same as handling the "hide" message we did earlier, so let\u2019s just include it in for the final version of the full LanguageDropdownLive code:   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownView}    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_changes "locale-changes"   @dropdown_changes "dropdown-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@dropdown_changes)     socket = init_dropdown_state(socket, locale)     {:ok, socket}   end    def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end    def handle_event("hide", _value, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    def handle_event("toggle", _value, socket) do     %{assigns: %{show_available_locales: show_available_locales}} = socket     socket = assign(socket, :show_available_locales, !show_available_locales)     {:noreply, socket}   end    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(self(), @locale_changes, "change-locale", %{       locale: locale     })      socket = init_dropdown_state(socket, locale)     {:noreply, socket}   end    def handle_info(%{event: "hide-dropdown"}, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    defp init_dropdown_state(socket, locale) do     selectable_locales = List.delete(@locales, locale)      assign(       socket,       %{         locale: locale,         selectable_locales: selectable_locales,         show_available_locales: false       }     )   end end   We have now completed our LiveView implementation, and the application\u2019s final form :tada:! Open up a browser and give it and try, and hopefully you should see or feel no discernable difference between the Javascript takeover version of the application and the LiveView version.   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 04-liveview branch. The branch is also deployed here in its own environment.   Conclusion   So, after all this, was using LiveView to implement locale switching worth it? As a toy application to learn all about and get more of an intuitive feel for LiveView, absolutely! How about a production application? Now that I have spent so much time on this application, chances are the next time I do a LiveView project, development may not take me quite as long, so, maybe! Is it overkill for functionality like locale switching, which will likely be done very rarely? Probably!   Regardless of the actual value of this example application, I think that on my next Phoenix project, where possible, I will very likely be reaching for LiveView first before Javascript, and only resort to the Javascript when I hit the limits of what LiveView is able to do, wherever they happen to be.   Update (18 January 2020)   It was brought to my attention that the application, as it stands, has a bit of an issue. Open up the application in two separate browsers and see if you can spot it.      That\u2019s right: if you change the locale in one browser, then the locale changes for every client that is using the application. If we are using the application at the same time, I really should not be able to control what language you are viewing, and vice versa.   Furthermore, the language dropdown menu itself is not aware of what is going on because it is not listening out for locale-change events; it believes that it is the sole source of locale-change events, and not some other parallel-universe language dropdown menu that is reaching across its barrier and pulling the language rug out from underneath it.   So, what is the cause of this issue?   Static PubSub Channels   Currently, all the LiveView files are broadcasting and subscribing to exactly the same static channels. For example:   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...    @locale_changes "locale-changes"   @dropdown_changes "dropdown-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@dropdown_changes)     # ...   end    # ...    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(self(), @locale_changes, "change-locale", %{       locale: locale     })     # ..   end    # ... end   Endpoint.subscribe/1 and Endpoint.broadcast_from/4 are using only the static string channel names defined in the @locale_changes and @dropdown_changes module attributes. Consequently, all clients are subscribing and broadcasting message changes to the same channel, resulting in all the unexpected state sharing issues.   Arbitrary User IDs   This kind of behaviour might be desired in some situations, but for this application, we want PubSub actions to be siloed to specific users: channel names should look something like @locale_changes &lt;&gt; id, where id is some identifier unique to the browser client or user, so that PubSub messages and updates would only apply for that client/user.   In some Phoenix applications, this could take the form of the database ID of a User or Account, but for something as trivial as this application, we do not have a concept of \u201cusers\u201d or \u201caccounts\u201d.   So, in the absence of database-backed users with unique IDs, let\u2019s create the next best thing with the lowest barrier to entry, and arbitrarily assign a unique \u201cuser_id\u201d to each application browser connection. We will need this ID in both the conn and the session to make sure all the application LiveViews can utilise it. So, let\u2019s handle the user_id problem in a similar way to how we handled the locale: generate it in a Plug.   First, tell the router that we will use a UserIdPlug in the browser pipeline:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   use PhxI18nExampleWeb, :router   alias PhxI18nExampleWeb.{LocalePlug, UserIdPlug}    pipeline :browser do     # ...     plug UserIdPlug     plug LocalePlug   end    # ... end   Next define the plug: generate a random ID and assign it to the conn and the session:   lib/phx_i18n_example_web/plugs/user_id_plug.ex   defmodule PhxI18nExampleWeb.UserIdPlug do   alias Plug.Conn   @behaviour Plug    @num_bytes 16    @impl Plug   def init(_opts), do: nil    @impl Plug   def call(conn, _opts) do     random_id = generate_random_id()      conn     |&gt; Conn.assign(:user_id, random_id)     |&gt; Conn.put_session(:user_id, random_id)   end    defp generate_random_id do     @num_bytes     |&gt; :crypto.strong_rand_bytes()     |&gt; Base.encode64()   end end   Then, provide the user_id to the LiveView session:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   # ...    scope "/", PhxI18nExampleWeb do     pipe_through :browser     live "/", PageLive, session: [:locale, :user_id]   end end   The user_id is now available in PageLive via the session, and in the app.html.eex layout via the conn, so we can pass it off to TitleLive and LanguageDropdownLive. Let\u2019s first make sure that the LiveViews rendered from the layout get given a user_id:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt;   &lt;head&gt;     &lt;!-- ... --&gt;     &lt;%= live_render @conn,                     TitleLive,                     session: %{locale: @locale, user_id: @user_id} %&gt;     &lt;!-- ... --&gt;   &lt;/head&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= live_render @conn,                     LanguageDropdownLive,                     session: %{locale: @locale, user_id: @user_id} %&gt;     &lt;!-- ... --&gt;   &lt;/body&gt; &lt;/html&gt;   Now, for each LiveView, add the user_id to the static PubSub channel names, as well as make any other minor adjustments to make everything work:   lib/phx_i18n_example_web/live/title_live.ex   defmodule PhxI18nExampleWeb.TitleLive do   # ...    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, :locale, locale)     {:ok, socket}   end    # ... end   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...   @locale_changes "locale-changes:"   @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@dropdown_changes &lt;&gt; user_id)     state = init_state(locale, user_id)     socket = assign(socket, state)     {:ok, socket}   end    # ...    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(       self(),       @locale_changes &lt;&gt; socket.assigns.user_id,       "change-locale",       %{locale: locale}     )      state = init_dropdown_state(locale)     socket = assign(socket, state)     {:noreply, socket}   end    defp init_state(locale, user_id) do     Map.merge(       %{user_id: user_id},       init_dropdown_state(locale)     )   end    defp init_dropdown_state(locale) do     selectable_locales = List.delete(@locales, locale)      %{       locale: locale,       selectable_locales: selectable_locales,       show_available_locales: false     }   end end   lib/phx_i18n_example_web/live/page_live.ex   defmodule PhxI18nExampleWeb.PageLive do   # ...    @locale_changes "locale-changes:"   @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, locale: locale, user_id: user_id)     {:ok, socket}   end    def handle_event("hide-dropdown", _value, socket) do     Endpoint.broadcast_from(       self(),       @dropdown_changes &lt;&gt; socket.assigns.user_id,       "hide-dropdown",       %{}     )      {:noreply, socket}   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   Note that user_id is deliberately not passed into the socket in TitleLive, since it is only ever used in mount/2 when setting up its subscriptions, as opposed to the other LiveViews which need the user_id when they send out broadcasts.   Now, when you use the application with multiple browsers, you should see that it works as expected:      You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 05-liveview-fix branch. The branch is also deployed here in its own environment.   Follow the next steps of this application\u2019s journey in Internationalisation with Phoenix LiveComponents!   ',
categories:[],tags:["elixir","phoenix","liveview","i18n","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"/blog/internationalisation-phoenix-liveview/",teaser:"/assets/images/2019-11-03/nareeta-martin-vF1YCoLHMpg-unsplash.jpg"},{title:"Employee Sans Office",excerpt:"   I originally wrote this blog post for RemoteBase on December 15, 2016.   It seems that RemoteBase shut down in 2018, and since my thoughts on remote   working have not changed, I figure this post can now live on the internet   here.    I\u2019m a company employee, but I can\u2019t go to my office, even for a visit. It simply doesn\u2019t exist.   At reinteractive, a digital consultancy, \u201cremote-first\u201d is trumped by \u201cremote-only\u201d: all employees, regardless of their role in the organisation, work remotely.  Our team chat software is the virtual roof that houses us, and it is our primary method of communication, both internally and with our clients.   Before starting at reinteractive, I had worked at other technology companies where very occasional remote work was permitted, but it was generally outside of the norm, and the principal mindsets were that work was done at the workplace.  Now, all my work is done wherever I can use my laptop and get a 4G signal: my physical location is completely detached from the work output I provide.   Remote mindset   Changing to the remote-style of long term full time work did require a transition period for me in order to find a work rhythm that I was comfortable with.   The first issue that I had was how to convince myself that I was \u201cat work\u201d, when I was physically at home.  Previously, getting from a \u201chome\u201d to a \u201cwork\u201d mindset involved lots of different unconscious triggers over a period of time: putting on \u201cworkplace clothes\u201d, physically leaving my home, commuting, entering an office, and seeing and interacting with people that I associate with work.   All that was gone: what I wear is irrelevant, the commute is ten steps to a desk, and at home there\u2019s no one else around.  I had to find a new trigger, and for me this was our team chat software.  When it\u2019s open, and I say \u201cgood morning\u201d to my team, then I\u2019m at work.  When I\u2019m done with work for the day, say \u201cgood night\u201d, and close team chat, then my desk magically stops being for work, and becomes my personal desk.  Doing this every day eventually made it routine, and hence easier to switch between the mindsets as time went by.   Proving you exist   When you\u2019re working with a team or for a client on-site, then you\u2019re assumed to be doing your job by anyone that can physically see you, because otherwise why else would you be there?  When your team only knows you as text/video on a screen, and there is no constant visual feedback for them that tells them you are working, I\u2019ve found that I\u2019ve needed to kick my communication levels into overdrive.  This includes asking lots of questions, raising potential issues early, periodic one-line status updates, and insisting that someone sign-off on the work performed, usually via a project/work tracker.   This last point in particular forces acknowledgement of work being done, and brings a reality to the value it provides.  If you can get to a point where you\u2019re overloading someone with finished work to approve, it can help people overcome any anxiety or trust issues that they may have with wondering if you are actually doing any work because they can\u2019t physically see you doing it.  The worst thing that can happen is to, say, get stuck on a problem all day and not say anything about it because you\u2019re afraid of being the barer of bad news.  If you\u2019re feeling pain, your team/client should also feel it, and I\u2019ve found that concrete pain is far more manageable than uncertainty.   Keeping up appearances   Although I love the freedom to be able to work where I please, and to be able to focus on tasks without the distractions that an office environment can cause, I still really like face-to-face interactions.  After a certain period of time working from home, I can start to really crave just talking to people, anyone, face-to-face (we are social animals, after all).  Meetups have really helped me fulfil this need, both professionally and personally, and have been great catalysts to be able to just get out of the house and get a change of scenery.   Just for tech?   I\u2019m a software engineer and hence my line of work is generally very compatible with remote working, but I don\u2019t think it should be limited there. There are plenty of knowledge workers in non-technical fields who could potentially work remotely, and the barriers to giving it a try are lower than they\u2019ve ever been.  A great resource on getting further information about remote work, and arming yourself with great reasons to give it a try to your bosses, is Remote: Office not Required, by Jason Fried and David Heinemeier Hansson.   So, if remote is something that you, as an employee, want to explore further with your company, I\u2019d highly encourage you to trail blaze a path for yourself and your colleagues.  I think that any roadblocks incurred along the way will be worth the satisfaction that you will get by gaining more freedom around one of the most important activities in your life.   ",categories:[],tags:["remote-working"],url:"/blog/employee-sans-office/",teaser:"/assets/images/2020-01-08/allie-smith-vuWCq1bXZy0-unsplash.jpg"},{title:"Internationalisation with Phoenix LiveComponents",
excerpt:'This blog post is the second in a series on the creation of a small I18n application using Phoenix LiveView, which updates page content based on the language chosen from a dropdown menu:      Internationalisation with Phoenix LiveView   Internationalisation with Phoenix LiveComponents   Internationalisation with Phoenix Live Layouts      Development on LiveView is currently proceeding at a cracking pace, and one of the newer additions to it is the ability to \u201ccompartmentalize state, markup, and events in LiveView\u201d using LiveComponent. So, let\u2019s introduce LiveComponents to the application, and see what effect it has on the codebase.      The software versions used for this version of the application have changed slightly, and are now the following:          Elixir: 1.9.4     Erlang: 22.2.1     Phoenix: 1.4.11     Gettext: 0.17.4     LiveView: 0.4.1     Node: 13.6.0     Tachyons: 4.11.1      Current State of Play   We are going to pick the application up where we left off from the end of Internationalisation with Phoenix LiveView, which is its state on the 05-liveview-fix branch of the phx_i18n_example Github repository. So, if you do not have the repository already, just run these commands and the internet shall provide it to you:   git clone git@github.com:paulfioravanti/phx_i18n_example.git cd phx_i18n_example git checkout 05-liveview-fix   Housekeeping   Upgrading dependencies   Before beginning, we will need to upgrade the version of LiveView being used in the application from 0.3.1 to 0.4.1:   mix.exs   defmodule PhxI18nExample.MixProject do   # ...   defp deps do     [       # ...       {:phoenix_live_view, "~&gt; 0.4.1"},       # ...     ]   end end   Then, upgrade the Elixir dependencies with mix:   mix deps.upgrade --all   Updating Javascript asset dependencies should not be an issue for introducing LiveComponents, but if you do find you have front end issues, or you just need to have all the latest packages all the time, then by all means, check what\u2019s outdated and update to your heart\u2019s content:   npm outdated --prefix assets   Enabling LiveComponent Functions   In order to use LiveComponents from LiveViews, we are going to need access to the Phoenix.LiveView.Helpers.live_component/4 function (and its lower arity cousins), so add it to the list of LiveView-related imports:   lib/phx_i18n_example_web.ex   defmodule PhxI18nExampleWeb do   # ...   def view do     quote do       # ...       import Phoenix.LiveView,         only: [           live_render: 2,           live_render: 3,           live_link: 1,           live_link: 2,           live_component: 2,           live_component: 3,           live_component: 4         ]     end   end   # ... end   File Structure and Naming Changes   It would seem that there has been an informal(?) convention to name LiveView files with a pattern of FooLive and BarLive, and place them inside a directory called live/ directly under the Phoenix application web/ directory. The application currently follows this convention.   However, with the advent of LiveComponents, we now have more than one type of \u201cLiveThing\u201d, with the likely potential for more \u201cLiveThings\u201d in the future. So, in the absence of any set conventions, we shall:      Move all LiveView files under a new live/views/ directory   Re-name all LiveView files from FooLive to FooLiveView, and change all of their references throughout the application (specifically, do search and replaces for TitleLive -&gt; TitleLiveView, LanguageDropdownLive -&gt; LanguageDropdownLiveView, and PageLive -&gt; PageLiveView)   Create an empty live/components/ directory to store LiveComponent files   Once you have done that, check to see that the application still runs without error, and you will be ready to start the actual fun component-y stuff!   LiveComponent Flavours   There are two different officially-named types of LiveComponents: Stateless and Stateful.   Personally, I find this naming quite confusing as both types of component do hold some kind of state, and the difference would seem to lie rather in the degree of independence that the LiveComponent has from its parent LiveView in updating its state, handling messages etc:      Stateless, in diapers, is completely dependent on its parent for any changes   Stateful is moved out of home, doing most things independently, but occasionally needs help from its parent for things it cannot do   Anyway, regardless of my opinions about the current naming, use of shared language is important to convey information coherently, so Stateless and Stateful it is.   Update to Stateless Component   Let\u2019s first update the LiveViews to Stateless Components, starting with the one that has the least amount of logic in it: the TitleLiveView.   It is currently responsible for:      Setting up a subscription to locale-change messages, so it knows when it should change languages, and then handling those locale-change events   Keeping track of the locale in its socket   Rendering a LiveView template, in this case inline   At present, the code looks like this:   lib/phx_i18n_example_web/live/views/title_live_view.ex   defmodule PhxI18nExampleWeb.TitleLiveView do   use Phoenix.LiveView   import PhxI18nExampleWeb.Gettext, only: [gettext: 1]   import Gettext, only: [with_locale: 2]   alias PhxI18nExampleWeb.Endpoint    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, :locale, locale)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= with_locale(@locale, fn -&gt; %&gt;       &lt;title&gt;         &lt;%= gettext("Multilingualisation in Phoenix") %&gt;       &lt;/title&gt;     &lt;% end) %&gt;     """   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   In introducing a stateless component, we are not interested in giving the component very much agency or responsibility: we just want to offload view-related functionality to it, and have it render the inline template. So, let\u2019s extract out some code into our first new LiveComponent!   lib/phx_i18n_example_web/live/components/title_live_component.ex   defmodule PhxI18nExampleWeb.TitleLiveComponent do   use Phoenix.LiveComponent   import PhxI18nExampleWeb.Gettext, only: [gettext: 1]   import Gettext, only: [with_locale: 2]    def render(assigns) do     ~L"""     &lt;%= with_locale(@locale, fn -&gt; %&gt;       &lt;title&gt;         &lt;%= gettext("Multilingualisation in Phoenix") %&gt;       &lt;/title&gt;     &lt;% end) %&gt;     """   end end   Not much to it, is there? Every component does actually require a mount/1 and an update/2 function, but LiveComponent provides default implementations of those functions that look something like this:   def mount(socket) do   {:ok, socket} end  def update(assigns, socket) do   {:ok, assign(socket, assigns)} end   If any finer-grained control over mounting and updating is needed, these functions would need to be overridden, but for this LiveComponent, the defaults work just fine.   Back in TitleLiveView, we make a call out to live_component to spawn off the child LiveComponent:   lib/phx_i18n_example_web/live/views/title_live_view.ex   defmodule PhxI18nExampleWeb.TitleLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, TitleLiveComponent}    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, :locale, locale)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket, TitleLiveComponent, locale: @locale %&gt;     """   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   A Quick Detour   A few things initially confused me as I was implementing this.   I thought that because the locale had already been assigned to the socket belonging to TitleLiveView in mount/2, it would flow through automatically to the @socket that gets passed into the live_component function. This is because if you inspect the @socket in the render/1 function like so:   def render(assigns) do   ~L"""   &lt;% IO.inspect(@socket) %&gt;   &lt;%= live_component @socket, TitleLiveComponent, locale: @locale %&gt;   """ end   The output you get is:   #Phoenix.LiveView.Socket&lt;   assigns: %{locale: "en", user_id: "mlZvNkbr/5DxyM9hq2TS0w=="},   changed: %{locale: true, user_id: true},   endpoint: PhxI18nExampleWeb.Endpoint,   id: "phx-VwPm6nt2",   parent_pid: nil,   view: PhxI18nExampleWeb.PageLiveView,   ... &gt;   So, I would have thought that the assigns would carry through to the socket in TitleLiveComponent, but when I overrode the mount/1 function there to inspect the state of the socket like so:   def mount(socket) do   IO.inspect(socket)   {:ok, socket} end   The output was:   #Phoenix.LiveView.Socket&lt;   assigns: %{},   changed: %{locale: true, user_id: true},   endpoint: PhxI18nExampleWeb.Endpoint,   id: "phx-VwPm6nt2",   parent_pid: nil,   view: PhxI18nExampleWeb.PageLiveView,   ... &gt;   The information in the assigns disappears\u2026? But the socket id ("phx-VwPm6nt2" in this case) is the same in the LiveView and the LiveComponent! What happened here?  This is when a part of the live_component documentation finally clicked:      \u201cA LiveComponent provides similar functionality to LiveView, except   they run in the same process as the LiveView, with its own encapsulated state\u201d    So, if my understanding is correct, the id for the socket is the same since it is the same process, but the assigns states of the LiveView and LiveComponent are isolated from each other, and we essentially get a \u201cblank slate\u201d socket assigns in the LiveComponent.   The assigns values we pass in to the live_component function (in this case locale: @locale), become available to us in update/2 (which the parent LiveView will call during the initialisation process), where we can then assign them to the LiveComponent socket.   Finishing Up Stateless   Now that we have cleared up some LiveComponent socket-related gotchas, let\u2019s finish up porting over the remaining two LiveViews to use Stateless components. The way we will do this will be very similar to TitleLiveView, with the content in the render/1 functions being extracted out into LiveComponents:   LanguageDropdownLiveView   lib/phx_i18n_example_web/live/views/language_dropdown_live_view.ex   Before:   defmodule PhxI18nExampleWeb.LanguageDropdownLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownView}    # ...   def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end   # ... end   After:   defmodule PhxI18nExampleWeb.LanguageDropdownLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownLiveComponent}    # ...   def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        LanguageDropdownLiveComponent,                        locale: @locale,                        selectable_locales: @selectable_locales,                        show_available_locales: @show_available_locales %&gt;     """   end   # ... end   lib/phx_i18n_example_web/live/components/language_dropdown_live_component.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.LanguageDropdownView    def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end end   PageLiveView   lib/phx_i18n_example_web/live/views/page_live_view.ex   Before:   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageView}    # ...   def render(assigns) do     PageView.render("index.html", assigns)   end   # ... end   After:   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageLiveComponent}    # ...   def render(assigns) do     ~L"""     &lt;%= live_component @socket, PageLiveComponent, locale: @locale %&gt;     """   end   # ... end   lib/phx_i18n_example_web/live/components/page_live_component.ex   defmodule PhxI18nExampleWeb.PageLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.PageView    def render(assigns) do     PageView.render("index.html", assigns)   end end   And that\u2019s it! The application is now using Stateless LiveComponents!   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 06-live-stateless branch. The branch is also deployed here in its own environment.   Optional Refactor   Before we move on to stateful components, I would just like to bring up that if you do not like to have inline LiveView templates (aka Live Embedded Elixir (leex), ie ~L""" code) in any of your LiveViews, then it is possible to refactor them out completely into separate files. For example, in PageLiveView, our render/1 function looks like:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   # ...   def render(assigns) do     ~L"""     &lt;%= live_component @socket, PageLiveComponent, locale: @locale %&gt;     """   end   # ... end   Rather than have this inline template, we could refactor this into something like the following:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageLiveViewView}    # ...   def render(assigns) do     PageLiveViewView.render("component.html", assigns)   end   # ... end   And then create a new view and template to call the component:   lib/phx_i18n_example_web/views/page_live_view_view.ex   defmodule PhxI18nExampleWeb.PageLiveViewView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.PageLiveComponent end   lib/phx_i18n_example_web/templates/page_live_view/component.html.leex   &lt;%= live_component @socket, PageLiveComponent, locale: @locale %&gt;   This refactor works, but, to me at least, it just feels awkward to have such few lines of code spread out over multiple files, not to mention the even more awkward PageLiveViewView naming.   I do like having longer templates in their own file, with their own dedicated view file, but for a live_component one-liner like this, I think inline is fine. But, your mileage may vary, and by all means use your best judgement to determine if this kind of refactor is to your benefit or liking.   Update to Stateful Components   Now, we will move on to giving our LiveComponents more responsibility for managing their own state, by making them Stateful Components. Like before, let\u2019s start with the least complex LiveView/LiveComponent set for the page title. Here is the finished product:   lib/phx_i18n_example_web/live/views/title_live_view.ex   defmodule PhxI18nExampleWeb.TitleLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, TitleLiveComponent}    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, :locale, locale)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        TitleLiveComponent,                        id: :title,                        locale: @locale %&gt;     """   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   No, your eyes do not deceive you: literally the only change from before has been the addition of the id: title keyword argument in the live_component function call. No changes to TitleLiveComponent were necessary. And now it is stateful.   If you are thinking that this does not really represent a change in responsibilities of the TitleLiveComponent, you would be absolutely correct.   Although I would very much like to allow the TitleLiveComponent to receive and handle "change-locale" messages, \u201ccomponents do not have a handle_info/2 callback\u201d, and so this is one of the areas where a stateful LiveComponent must depend on its parent.   Technically, we could have moved the Endpoint.subscribe/1 function call into the LiveComponent, and it would have worked, but I think the demarcation lines of responsibility are clearer if we say that the parent LiveView is entirely responsible for handling external PubSub communication.   Therefore, for this particular LiveView/LiveComponent set, there is probably not much value in making it Stateful.   Moving on   So, that was rather anti-climactic. Let\u2019s move on to the PageLiveView where we will hopefully have more luck with making at least some consequential changes.  Currently, it looks like:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageLiveComponent}    @locale_changes "locale-changes:"   @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, locale: locale, user_id: user_id)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket, PageLiveComponent, locale: @locale %&gt;     """   end    def handle_event("hide-dropdown", _value, socket) do     Endpoint.broadcast_from(       self(),       @dropdown_changes &lt;&gt; socket.assigns.user_id,       "hide-dropdown",       %{}     )      {:noreply, socket}   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   Like TitleLiveView, there is some external PubSub message handling here around "change-locale" events that we need to leave in the parent LiveView, but handling "hide-dropdown" events is definitely something that a LiveComponent can perform, so let\u2019s extract the handle_event/3 code out to PageLiveComponent:   lib/phx_i18n_example_web/live/components/page_live_component.ex   defmodule PhxI18nExampleWeb.PageLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.{Endpoint, PageView}    @dropdown_changes "dropdown-changes:"    def render(assigns) do     PageView.render("index.html", assigns)   end    def handle_event("hide-dropdown", _value, socket) do     Endpoint.broadcast_from(       self(),       @dropdown_changes &lt;&gt; socket.assigns.user_id,       "hide-dropdown",       %{}     )      {:noreply, socket}   end end   Great! The LiveComponent is now broadcasting out "hide-dropdown" messages if it, itself, receives a "hide-dropdown" event. This extraction leaves the parent LiveView with slightly less code, and one less thing to worry about:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageLiveComponent}    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, locale: locale, user_id: user_id)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        PageLiveComponent,                        id: :page,                        locale: @locale,                        user_id: @user_id %&gt;     """   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     send_update(PageLiveComponent, id: :page, locale: payload.locale)     {:noreply, socket}   end end   Note that as opposed to the TitleLiveView, in which we only passed the @locale parameter into the call to live_component, in the PageLiveView, we are also passing through the @user_id, since PageLiveComponent needs it to perform the "hide-dropdown" broadcasts. Parent LiveViews can keep a tight leash on what information child LiveComponents need to know about.   Filial Piety   We have been taking baby-steps towards LiveComponent independence, but now it\u2019s time to take a bigger step: let\u2019s move on to the busiest LiveView in the application, LanguageDropdownLiveView, and see how much we can lighten its load. Currently, it does quite a lot:   lib/phx_i18n_example_web/live/views/language_dropdown_live_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownLiveComponent}    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_changes "locale-changes:"   @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@dropdown_changes &lt;&gt; user_id)     state = init_state(locale, user_id)     socket = assign(socket, state)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        LanguageDropdownLiveComponent,                        locale: @locale,                        selectable_locales: @selectable_locales,                        show_available_locales: @show_available_locales %&gt;     """   end    def handle_event("hide", _value, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    def handle_event("toggle", _value, socket) do     socket =       assign(         socket,         :show_available_locales,         !socket.assigns.show_available_locales       )      {:noreply, socket}   end    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(       self(),       @locale_changes &lt;&gt; socket.assigns.user_id,       "change-locale",       %{locale: locale}     )      state = init_dropdown_state(locale)     socket = assign(socket, state)     {:noreply, socket}   end    def handle_info(%{event: "hide-dropdown"}, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    defp init_state(locale, user_id) do     Map.merge(       %{user_id: user_id},       init_dropdown_state(locale)     )   end    defp init_dropdown_state(locale) do     selectable_locales = List.delete(@locales, locale)      %{       locale: locale,       selectable_locales: selectable_locales,       show_available_locales: false     }   end end   Like the other LiveViews, there is external PubSub communication that we must keep as-is, but I would say every other function can be shipped out wholesale to LanguageDropdownLiveComponent, lightening LanguageDropdownLiveView\u2019s load considerably:   lib/phx_i18n_example_web/live/views/language_dropdown_live_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownLiveComponent}    @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@dropdown_changes &lt;&gt; user_id)     socket = assign(socket, locale: locale, user_id: user_id)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        LanguageDropdownLiveComponent,                        id: :language_dropdown,                        locale: @locale,                        user_id: @user_id %&gt;     """   end    def handle_info(%{event: "hide-dropdown"}, socket) do     send_update(       LanguageDropdownLiveComponent,       id: :language_dropdown,       show_available_locales: false     )      {:noreply, socket}   end end   It now does not need to worry about setting up internal state for the dropdown menu, nor handle any of its events. It does still continue to handle external PubSub messages, but it completely delegates responsibility of what action should be performed to LanguageDropdownLiveComponent via the send_update/2 function.   So, let\u2019s see where all that logic has gone:   lib/phx_i18n_example_web/live/components/language_dropdown_live_component.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownView}    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_changes "locale-changes:"    def update(%{locale: locale} = assigns, socket) do     state = Map.merge(assigns, init_dropdown_state(locale))     socket = assign(socket, state)     {:ok, socket}   end    def update(%{show_available_locales: false}, socket) do     socket = assign(socket, :show_available_locales, false)     {:ok, socket}   end    def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end    def handle_event("hide", _value, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    def handle_event("toggle", _value, socket) do     socket =       assign(         socket,         :show_available_locales,         !socket.assigns.show_available_locales       )      {:noreply, socket}   end    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(       self(),       @locale_changes &lt;&gt; socket.assigns.user_id,       "change-locale",       %{locale: locale}     )      state = update_locale_changed_state(socket.assigns, locale)     socket = assign(socket, state)     {:noreply, socket}   end    defp update_locale_changed_state(assigns, locale) do     assigns     |&gt; Map.merge(%{locale: locale})     |&gt; Map.merge(init_dropdown_state(locale))   end    defp init_dropdown_state(locale) do     selectable_locales = List.delete(@locales, locale)      %{       selectable_locales: selectable_locales,       show_available_locales: false     }   end end   The LiveComponent now has responsibilities over:      Manually handling updating its state by overriding the update/2 function, since the LiveComponent default implementation does not cut it any more   Handling the two different flavours of update that the component needs to know about (via the update function heads), which are:            when the locale is updated, upon which it needs to re-initialise its state (which, by the by, the parent LiveView does not need to know anything about)       when show_available_locales is explicitly set to false (ie from when LanguageDropdownLiveView calls send_update/2), at which point the menu needs to be hidden           Handling all its local events   Broadcasting "change-locale" messages when it gets a "locale-changed" message   Easily the most independent of the three LiveComponents in the application.   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 07-live-stateful branch. The branch is also deployed here in its own environment.   Stateless or Stateful?   In this application, I think the benefits of using Stateless versus Stateful LiveComponents are largely subjective, and really depend on personal preferences about how to divide up logic between LiveViews and LiveComponents.   If you have an application that has more moving parts and complexity, like fetching from a database to populate multiple LiveComponents on a page, in which you may need to consider preloading using preload/1 (not covered in this blog post), then the decision to specifically use Stateful components may become clearer.   Regardless of your preferred flavour of LiveComponent, I think they are a welcome addition to the Phoenix\u2019s Live Toolbox, and I\u2019m sure I will be making more use of them in the future.   Update (29-01-2020)   Well, the cracking pace of development on new libraries like LiveView can mean that even minor version changes can result in having the rug pulled out from under you, and this application is no exception.   On updating the application to LiveView version 0.6.0, everything stopped working, and my LiveComponents mysteriously stopped handling events.   If you are following along, here is the diff between the 07-live-stateful branch you have already seen, and a new 08-live-stateful-0-6 branch, all updated and working with LiveView 0.6.0 (with a couple of small refactors).   It is not worth going into the deep details of how to upgrade, since I think the diff, as well as the LiveView 0.6 Installation instructions and the Changelog, provide enough information, but I will outline a few points:      The socket session now accepts only string keys. This affected code in Plugs as well as LiveViews. It does seem a bit strange now to have Conn.assign(:locale, locale) with an atom key, and Conn.put_session("locale", locale) with a string key   I think it\u2019s great that any session variables set in plugs are available automatically in LiveViews now, without having to explicitly indicate a set of session keys in the route. (eg live "/", PageLiveView, session: [:locale, :user_id]). You could explicitly override values here using a map, though, if you wanted to (eg live "/", PageLiveView, session: %{"locale" =&gt; "en"})   Targeting Component Events is where the Stateful LiveComponent trip ups occurred. With 0.6.0, if template code managed by a LiveComponent does not have a phx-target attribute, then the LiveComponent\u2019s handle_event/3 function that previously may have worked will now not pick up the event, and instead event handling will go straight to the parent LiveView. In this case, I got an error complaining that I did not have handle_event/3 implementations in the LiveView to handle the events that it was receiving. See the Targeting Component Events documentation and the .eex/.leex template files in the diff for details on getting your Stateful LiveComponents back on the job of handling events   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 08-live-stateful-0-6 branch. The branch is also deployed here in its own environment.   Follow the next steps of this application\u2019s journey in Internationalisation with Phoenix Live Layouts!   ',categories:[],tags:["elixir","phoenix","liveview","live-components","i18n","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"/blog/internationalisation-phoenix-live-components/",teaser:"/assets/images/2020-01-27/jason-leung-jCBzW_Q_UGI-unsplash.jpg"},{title:"Internationalisation with Phoenix Live Layouts",
excerpt:'This blog post is the third in a series on the creation of a small I18n application using Phoenix LiveView, which updates page content based on the language chosen from a dropdown menu:      Internationalisation with Phoenix LiveView   Internationalisation with Phoenix LiveComponents   Internationalisation with Phoenix Live Layouts      LiveView version 0.5.0 introduced Live Layouts, a mechanism that allows LiveViews to move view-specific layout code into separate sub-layout files. This enables an individual LiveView\u2019s template to nest itself within content that can dynamically update.   We will continue developing the application where we left off from the end of Internationalisation with Phoenix LiveComponents, which is its state on the 08-live-stateful-0-6 branch of the phx_i18n_example Github repository. That branch does not use Live Layouts, so we will see what the issues are with not using them, and then proceed to implement them.   If you do not have the repository already, just run these commands and it shall find its way to you:   git clone git@github.com:paulfioravanti/phx_i18n_example.git cd phx_i18n_example git checkout 08-live-stateful-0-6      The software versions used for this version of the application are the following:          Elixir: 1.10.0     Erlang: 22.2.1     Phoenix: 1.4.12     Gettext: 0.17.4     LiveView: 0.6.0     Node: 13.6.0     Tachyons: 4.11.1      Current State of Play   There are three LiveViews in the application, each operating independently, containing their own LiveComponent, and communicating with each other by PubSub where needed:      LanguageDropdownLiveView and TitleLiveView are live rendered from the (static) layout:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt;   &lt;head&gt;     &lt;!-- ... --&gt;     &lt;%= live_render @conn,                     TitleLiveView,                     session: %{"locale" =&gt; @locale, "user_id" =&gt; @user_id} %&gt;     &lt;!-- ... --&gt;   &lt;/head&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= live_render @conn,                     LanguageDropdownLiveView,                     session: %{"locale" =&gt; @locale, "user_id" =&gt; @user_id} %&gt;     &lt;main role="main"&gt;       &lt;%= render @view_module, @view_template, assigns %&gt;     &lt;/main&gt;   &lt;/body&gt; &lt;/html&gt;   The Problem   For the application in its current form, this presents no issue. However, what if we wanted to add another routed LiveView (a LiveView used from router.ex) to the application to complement PageLiveView? What if we wanted to have this new LiveView set its own page title, or what if its content did not need to be internationalised, and hence we would not need the language dropdown menu to display?   The app.html.eex file is the main layout template within which all other template content is embedded, which means that any new LiveView would not have any control over the content that surrounds its template code:      its title would be set according to whatever TitleLiveView renders, rather than being able to provide its own page title logic   LanguageDropdownLiveView will always be rendered (meaning also that the new LiveView would have to unnecessarily implement handlers for the "change-locale" events that the dropdown menu emits)   So, let\u2019s set about giving our routed LiveView, in this case PageLiveView, more control over its surrounding content, starting with the page title.   LiveView-Controlled Page Title Updates   With LiveView 0.5.0, updating the HTML document title of a page becomes possible through specific use of an assigns variable called @page_title. Normally, the content of app.html.eex, or any non-.leex template, cannot be dynamically changed. But, Phoenix LiveView special-cases the page title, enabling a LiveView module to set the page title in Phoenix.LiveView.mount/3, and update it in any event handling callback functions.   So, in the layout, let\u2019s switch out TitleLiveView for @page_title:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt;   &lt;head&gt;     &lt;!-- ... --&gt;      &lt;title&gt;&lt;%= @page_title %&gt;&lt;/title&gt;     &lt;!-- ... --&gt;   &lt;/head&gt;   &lt;!-- ... --&gt; &lt;/html&gt; &lt;!DOCTYPE html&gt;   Now, in PageLiveView, let\u2019s initialise the page_title assigns in mount/3, and update its value when the locale changes (ie we receive an external "change-locale" PubSub message):   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   # ...   require Gettext   require PhxI18nExampleWeb.Gettext    @title "Multilingualisation in Phoenix"   @locale_changes "locale-changes:"    def mount(         %{} = _params,         %{"locale" =&gt; locale, "user_id" =&gt; user_id},         socket       ) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)      socket =       assign(         socket,         locale: locale,         user_id: user_id,         page_title: page_title(locale)       )      {:ok, socket}   end    # ...    def handle_info(         %{event: "change-locale", payload: %{locale: locale}},         socket       ) do     send_update(PageLiveComponent, id: :page, locale: locale)     socket = assign(socket, locale: locale, page_title: page_title(locale))     {:noreply, socket}   end    defp page_title(locale), do: Gettext.with_locale(locale, &amp;title/0)   defp title, do: PhxI18nExampleWeb.Gettext.gettext(@title) end   You should now see that the application continues to work as expected.   Just by virtue of setting and updating the page_title assigns value, Phoenix does all the heavy lifting of dynamically updating the @page_title module attribute. PageLiveView now has complete control over the page title when its template is rendered, which means the TitleLiveView and TitleLiveComponent modules have become completely obsolete. So, we can reduce our maintenance burden by removing them entirely. Hurray!   Live Layouts   Let\u2019s now move our focus over to enabling LiveViews to choose whether they want to display a language selection dropdown menu or not, by extracting code for it into a separate layout.   We will start by removing the call to live render the LanguageDropdownLiveView from the main layout\u2019s &lt;body&gt; tag:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt;   &lt;!-- ... --&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= render @view_module, @view_template, assigns %&gt;   &lt;/body&gt; &lt;/html&gt;   That code will now go directly inside a new page Live Layout file (note the .leex filename):   lib/phx_i18n_example_web/templates/layout/page.html.leex   &lt;%= live_render @socket,                 LanguageDropdownLiveView,                 id: :language_dropdown,                 session: %{"locale" =&gt; @locale, "user_id" =&gt; @user_id} %&gt; &lt;main role="main"&gt;   &lt;%= @live_view_module.render(assigns) %&gt; &lt;/main&gt;   In this case, the @live_view_module attribute refers to the PageLiveView module.   Now, we need to specify that PageLiveView will be using this layout to wrap its template content:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   alias PhxI18nExampleWeb.{Endpoint, LayoutView, PageLiveComponent}   use Phoenix.LiveView, layout: {LayoutView, "page.html"}   # ... end   Note that the LayoutView is doing double-duty here as the view file for both app.html.eex and page.html.leex. If we were to extract the template code inline with the view code, it would look like this (also note the differences in sigils used; ~E for standard embedded Elixir templates vs ~L for LiveView templates):   lib/phx_i18n_example_web/views/layout_view.ex   defmodule PhxI18nExampleWeb.LayoutView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.{LanguageDropdownLiveView, LayoutStyle}    defdelegate body, to: LayoutStyle    def render("app.html", assigns) do     ~E"""     &lt;!DOCTYPE html&gt;     &lt;html lang="en"&gt;       &lt;head&gt;         &lt;meta charset="utf-8"/&gt;         &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"/&gt;         &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"/&gt;         &lt;%= csrf_meta_tag() %&gt;         &lt;title&gt;&lt;%= @page_title %&gt;&lt;/title&gt;         &lt;link rel="stylesheet"               href="&lt;%= Routes.static_path(@conn, "/css/app.css") %&gt;"/&gt;         &lt;script type="text/javascript"                 src="&lt;%= Routes.static_path(@conn, "/js/app.js") %&gt;"&gt;         &lt;/script&gt;       &lt;/head&gt;       &lt;body class="&lt;%= body() %&gt;"&gt;         &lt;%= render @view_module, @view_template, assigns %&gt;       &lt;/body&gt;     &lt;/html&gt;     """   end    def render("page.html", assigns) do     ~L"""     &lt;%= live_render @socket,                     LanguageDropdownLiveView,                     id: :language_dropdown,                     session: %{"locale" =&gt; @locale, "user_id" =&gt; @user_id} %&gt;     &lt;main role="main"&gt;       &lt;%= @live_view_module.render(assigns) %&gt;     &lt;/main&gt;     """   end end   The layout code extraction is now complete, and the application works as expected! Or, at least I thought it did, until I tried out the specific use case of opening the language dropdown menu, and then clicking the text on the page, which closes it:      Looks like there is a glitch in the LiveView Matrix\u2026 Why is the open language dropdown menu disappearing momentarily before re-appearing closed? Ultimately, all we did was cut code from one file, and paste it in another\u2026right?   Although I\u2019m not entirely sure of the specifics, it looks like perhaps the communication processes via PubSub between PageLiveView and DropdownLanguageLiveView are clobbering each other, and thus a re-think of how these two LiveViews and their LiveComponents talk to each other is in order, as well as deciding whether all these LiveView modules are even needed at all.   Too Many LiveViews?   Each of the LiveViews we had in the application at the beginning of this blog post, PageLiveView, LanguageDropdownLiveView, and TitleLiveView, were like isolated islands, functionality-wise.      There was no coupling between any of them; naturally, there was coupling between parent LiveViews and their child LiveComponents, but not between the LiveViews themselves.   With the introduction of Live Layouts, this has changed: now, PageLiveView, as well as being the parent of its own PageLiveComponent, is also, via the Live Layout, the parent of LanguageDropdownLiveView, which renders LanguageDropdownLiveComponent.      With TitleLiveView gone, the only place that LanguageDropdownLiveComponent needs to notify about locale changes is the PageLiveView, its \u201cgrandparent\u201d. Similarly, LanguageDropdownLiveView would only seem to exist to let its child, LanguageDropdownLiveComponent, know about any "hide-dropdown" messages that it receives.   Given that the "hide-dropdown" messages come from PageLiveComponent, wouldn\u2019t it be easier, and maybe less message-clobbery, to:      get rid of the LanguageDropdownLiveView middleman   let LanguageDropdownLiveComponent be PageLiveView\u2019s child, rather than grandchild   have PageLiveComponent and LanguageDropdownLiveComponent talk to each other as siblings through PageLiveView?   Let\u2019s find out!   Family Tree Engineering   Okay, first thing\u2019s first, LanguageDropdownLiveView is now gone. What do we need to do to get this working again? Let\u2019s start with PageLiveView\u2019s Live Layout, which now needs to directly render LanguageDropdownLiveComponent:   lib/phx_i18n_example_web/views/layout_view.ex   defmodule PhxI18nExampleWeb.LayoutView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.{LanguageDropdownLiveComponent, LayoutStyle}   # ... end   lib/phx_i18n_example_web/templates/layout/page.html.leex   &lt;%= live_component @socket,                    LanguageDropdownLiveComponent,                    id: :language_dropdown,                    locale: @locale,                    user_id: @user_id %&gt; &lt;main role="main"&gt;   &lt;%= @live_view_module.render(assigns) %&gt; &lt;/main&gt;   Now, in the LanguageDropdownLiveComponent, whenever we get a local "locale-changed" event, rather than blast out a PubSub message, we instead want to send that message to the now-direct parent, PageLiveView:   lib/phx_i18n_example_web/live/components/language_dropdown_live_component.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.LanguageDropdownView    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)    # ...   def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     send(self(), {:change_locale, locale})      state = update_locale_changed_state(socket.assigns, locale)     socket = assign(socket, state)     {:noreply, socket}   end   # ... end   Note here that because the LiveComponent and the LiveView run in the same process, sending a message to self() sends the message from the component to the parent LiveView.   While we are purging PubSub message passing, let\u2019s go next to PageLiveView\u2019s other child, PageLiveComponent, and perform a similar refactor for when it receives "hide-dropdown" messages:   lib/phx_i18n_example_web/live/components/page_live_component.ex   defmodule PhxI18nExampleWeb.PageLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.PageView    # ...   def handle_event("hide-dropdown", _value, socket) do     send(self(), :hide_dropdown)      {:noreply, socket}   end end   All message-passing from child LiveComponents to parent LiveViews is now being done without PubSub. Finally, we need to make changes in the parent PageLiveView to swap any PubSub-related subscription and message-handling code for taking messages directly from children:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   alias PhxI18nExampleWeb.{     LanguageDropdownLiveComponent,     LayoutView,     PageLiveComponent   }    # ...   def mount(         %{} = _params,         %{"locale" =&gt; locale, "user_id" =&gt; user_id},         socket       ) do     socket =       assign(         socket,         locale: locale,         user_id: user_id,         page_title: page_title(locale)       )      {:ok, socket}   end    # ...    def handle_info(:hide_dropdown, socket) do     send_update(       LanguageDropdownLiveComponent,       id: :language_dropdown,       show_available_locales: false     )      {:noreply, socket}   end    def handle_info({:change_locale, locale}, socket) do     send_update(PageLiveComponent, id: :page, locale: locale)     socket = assign(socket, locale: locale, page_title: page_title(locale))     {:noreply, socket}   end   # ... end   Notice that in the handle_info/2 functions, the parameters are now atoms or tuples, and not the maps (eg %{event: "change-locale", payload: %{locale: locale}}) that we had before.   The application should now be flicker-less when hiding an open dropdown by clicking the page.   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 09-live-layout branch. The branch is also deployed here in its own environment.   Wrapping Up   The use of Live Layouts, even in this small application, has affected its architecture greatly. It has been interesting, at least for myself as the author, to have seen the codebase expand initially with lots of LiveViews and LiveComponents, and now contract back as we purge half of them away.   Deleted code is the easiest kind to maintain, though, so I do not mourn for it. Rather, I think it\u2019s great that Live Layouts have enabled more flexibility in architecting LiveView functionality, and I look forward to using them more moving forward!   ',categories:[],tags:["elixir","phoenix","liveview","live-components","live-layout","i18n","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"/blog/internationalisation-phoenix-live-layouts/",teaser:"/assets/images/2020-02-03/kyle-glenn-nXt5HtLmlgE-unsplash.jpg"},{title:"I Completed Typey Type",excerpt:"I first got into stenography in late 2018, and wrote up a blog post about Starting Stenography with an Ergodox, which outlines how I started my steno journey using an Ergodox EZ mechanical keyboard.   One of the learning resources I used was Typey Type, an awesome web-based typing application by Diana MacDonald. I would use it occasionally over the course of a few months until, unfortunately, my steno learning fell by the wayside some time in early 2019. I then completely neglected it for the rest of the year.   Come 2020, one of my New Year\u2019s resolutions was to get my steno learning back on track, and Typey Type was going to be key. Typey Type keeps track of your progress through its lessons, and provides you with a percentage score based on how many words you have typed without mis-strokes. It was this number that I latched on to: I wanted it to be 100%.   But, what was to stop yet another lapse in practice, resulting in writing off yet another year of potential progress? Accountability! I was able to find another person who wanted to kick-start their steno-related activities, and we became accountability buddies!   Define Success and Establish Cadence   First of all, we each defined and declared what success in our steno endeavours would look like. Here is what I wrote back in January:      30 minutes minimum steno practice a day, preferably an hour   I want to hit 100% progress on Typey Type this year (maybe this can take 6 months on this schedule\u2026?)   It would be nice to have my steno speeds match, or at least approach, my QWERTY typing speeds by the end of the year, so I can justify integrating it with my everyday workflows   Every week, without fail, I would need to send my accountability buddy an email outlining what I had done in the last week to move forward towards completing those goals.   I do not think I can possibly stress enough how beneficial it was to have this system in place:      I had a deadline, every week, where someone was expecting to hear from me   I did not want to have to report a lack of or no progress, which helped force me to keep up my routines   Being able to report percentage gains towards the completion goal to an interested party felt great, and helped propel me forward   I took an \u201ceat that frog\u201d approach to the timing of the 30 minutes practice being first thing in the morning before breakfast, so I would not worry about it for the rest of the day, or while at work   For the first three months, I kept a schedule of 30 minutes steno practice a day, every day, even if I did not want to do it, which, initially, was often. Then, from the fourth month, I made a small increase to doing an hour a day on weekends. Finally, seeing this r/plover post spurred me to go up to an hour steno practice every day, which I have been able to keep as of this writing.   And so, after five months of practice, I finally reached 100% completion, meaning I have been able to type 10,000 words without mis-strokes.   I was initially worried that I was not hitting goals fast enough since I read of people who were, say, getting up to 50 words-per-minute (WPM) after just a month or two of steno practice. Maybe they had the luxury to dedicate their entire full-time schedule to stenography, or maybe they were super-geniuses, or maybe a bit of both\u2026.   Regardless, I needed to consciously ignore all this, not compare myself to anyone else (real or imagined), and just keep up the routine. It may have taken a while, but I do not mind; the journey has been beneficial and being able to hit a goal feels great!   Contributing Back   Aside from learning stenography through Typey Type, one of the other goals I had was that if I find dictionary issues in Typey Type (incorrect or missing words etc), I would make notes of them, and set aside time to file issues and pull requests (PRs) to Typey Type\u2019s dictionary Github repository as close to finishing steno practice as possible.   This is particularly important to me. Typey Type is a massively valuable piece of open source software that is being provided for free.  Given the value I personally get from it, the least I can do is to help improve it where I can.   As a software engineer, I use Git and Github daily, so contributing back does not require any extra effort to learn new tools; just the time to make notes and craft them into issues/PRs (there are other ways to get your proposals in, so do not let not knowing Git or caring about Github stop you from proposing a dictionary entry improvement!).   The process of contributing back also had the great knock-on effects of gaining a deeper understanding about Plover theory through researching discrepancies between Typey Type and Plover dictionary entries, and receiving expert knowledge from Diana in the interesting discussion threads on Github.   Now What?   I may have \u201ccompleted\u201d Typey Type, but, there is still a long, long road ahead of me. I now know viscerally that steno is not something that I can casually pick up: success is going to require continuous pushing until I can use steno in daily typing in the way I currently use QWERTY. Steno feels more like learning a new language than just a keyboard layout.   Since Typey Type has lots of activities outside of those scored 10,000 words, I\u2019m planning to continue doing them to learn ever more and hopefully build up more muscle memory.   Just as important, though, is that I did not focus on gaining speed at all during my practice, so I am still currently a very slow steno typist (read: less than 20 WPM slow). I think the lack of gains I made in speed were made up for with an increase in stroke intuition, but getting higher speeds remains a major goal.   So, the grind may not be over, but I am still energised. I\u2019m looking forward to keeping up my current steno pace, and then taking stock again in another six months to hopefully realise what could be my first successful completion of a New Year\u2019s resolution.     Postscript: Typey Type Tips   This section did not really fit within the body of the blog post, so it gets tacked on at the end\u2026   If you are currently using Typey Type or about to start, and maybe even thinking of contributing back, here are some things I have learned along the way, in no particular order.      After downloading Plover, if you find that you are not getting the expected output when stroking words in Typey Type, chances are that this is because you are using Plover version 3.1.1 (the current stable release), while Typey Type dictionary entries are more optimised to favour Plover version 4 pre-release (the latest as of this writing being weekly-v4.0.0.dev8+66.g685bd33) entries. So, I would currently recommend downloading pre-release versions to have a smoother steno experience. The latest information about installing Plover can always be found in its Installation Guide   Your Typey Type progress file is stored in your browser, which means there is a non-zero chance you may accidentally delete it if you are ever too eager with clearing your browser data. Having lost my progress file once, I can recommend having backups. I back mine up to Dropbox after every practice session.   Plover\u2019s Lookup functionality has been my constant companion when using Typey Type. Whenever a word came up in Typey Type whose outline did not \u201cfeel quite right\u201d to me, I would look the word up in Plover to see if there were any other outlines for that word that fit my brain better. If there were, I would sometimes submit these to the Typey Type dictionary Github repo as a potential change for consideration. Sometimes, an outline I thought better suited for a word would turn out to be a mis-stroke. So, it\u2019s also worth checking Typey Type\u2019s mis-stroke dictionary to test your suspicions   Many entries from Typey Type\u2019s Top 1000 Project Gutenberg Words dictionary, which appear in Typey Type practice exercises, use British English spelling. This means that there is a high chance that American-English-based Plover dictionaries will not have corresponding entries for those words. Typey Type does not necessarily need you to load up any other dictionaries aside from those that come bundled with Plover, but I would recommend that you download Di\u2019s dict-en-AU-with-extra-stroke.json dictionary and add it to your list of default Plover dictionaries (user.json, commands.json, main.json etc) so you can stroke these words with ease   If you cannot seem to get past a particular entry no matter what word you attempt to stroke, fingerspelling the word will get you past it, and it will be logged as a successfully typed word in your progress   Good luck in your steno adventures!   ",categories:[],tags:["stenography","keyboards","ergodox","mechanical-keyboards","plover"],url:"/blog/completed-typey-type/",teaser:"/assets/images/2020-06-10/stenotype.jpg"},{title:"All I want is a Timestamp",
excerpt:'Inserting the current date and time into a Google Sheets cell can be done with the following keyboard shortcut:                  Platform       Shortcut                       PC       Ctrl + Alt + Shift + ;                 Mac       \u2318 + Option + Shift + ;           If you have found this page via searching specifically for this information, then please consider your objective fulfilled. You\u2019re welcome!   There is a story around me getting to this point, though, since behind the simple table above is a small journey involving Google Sheets\u2019 functions and macros, Javascript, and eventually QMK Firmware for mechanical keyboards. Still with me? Read on\u2026   To-Do List      Using Google Sheets, I wanted to have a task list, similar to this screenshot, where I could log the start and end times of my tasks.   I made the assumption that there was a built-in function that could generate a timestamp for me, and when I went looking, I found NOW.      Using it in the spreadsheet would seem to have given me what I wanted, formatted in the way that I expect. Great!   When a task is finished, all I should have to do is make another call to NOW, and I would get a new generated date and time, right? Well, that happened, but also\u2026      \u2026the start time also got re-generated, ending up the same value as the finish time!   I thought that surely this could not be correct behaviour, but deleting the finish time caused the start time to be re-generated yet again!   So, it would seem that cells that use the NOW function get re-calculated whenever any change occurs in the spreadsheet. Perhaps there is a way to adjust this behaviour\u2026?      In the Spreadsheet Settings, located under the File &gt; Spreadsheet Settings &gt; Calculation menu options, there are three re-calculation options for the spreadsheet, but none of them turn off re-calculation.   Looking back at the documentation for NOW, which I really should have viewed in more detail earlier, brings into focus that I\u2019m using the wrong tool for the job:           Note that NOW is a volatile function, updating on every edit made to the spreadsheet, and can hurt spreadsheet performance.     NOW will always represent the current date and time the last time the spreadsheet was recalculated, rather than remaining at the date and time when it was first entered.      Now that I know I have a dynamic values problem, I wonder if there is any way to get a static datetime value, rather than what seems like a reference to a function that gets executed periodically?   At first glance, it looks like there are potentially two other functions that could fit the bill, since they return \u201cvalues\u201d:      DATEVALUE   TIMEVALUE   However, both of these functions require a static string parameter, and \u201creturn integers that can be used in formulas\u201d, those integers being a serial number representation of the date or time.   I definitely know that this is not what I want, so no need to go further down this rabbit hole.   Custom Behaviour with Macros   At this stage, it looks like I will need to create my own custom function/behaviour to get what I want. In Google Sheets, you do this with Macros.   Since what I wanted was a NOW value, I will call the macro the next best thing: _now, and get it to do the following:      When I type _now into a cell, and the cell loses \u201cfocus\u201d (ie I move the cursor to another cell), the value of that cell changes from the string _now, to the current date and time.    In Google Sheets, custom functions are created using Javascript, and are written in the Script Editor (Tools &gt; Script Editor).   To get the desired behaviour, the _now function will need to hook into Sheets\u2019 Simple Triggers, specifically the onEdit(e) trigger function, which \u201cruns when a user changes a value in a spreadsheet.\u201d   Opening up the Script Editor provides a default file called macros.gs, so that\u2019s where the function will go:   macros.gs   /** @OnlyCurrentDoc */ function onEdit(e) {   if (e.range.getValue() == "_now") {     let date = new Date();     let formattedDate =       date         .toLocaleString("en-AU", { timeZone: "Australia/Sydney", hour12: false })         .replace(",", "");     e.range.setValue(formattedDate);   } }   This function does the following:      Whenever an edit occurs in the spreadsheet, the content of the cell is checked to see if it contains the string "_now" (technically, the value of the range of the event object e is checked)   If it does contain "_now", then it uses Javascript to create a new date   From that date object, a new date string is created and formatted according to my current locale (Sydney, Australia), and in 24-hour time   The content of the cell is then set to the formatted date string   Let\u2019s see how this works back in the spreadsheet:      Looks good to me! We\u2019re done here now, right?   Well, something about this still did not sit right with me: surely the desire for a current date and time could not be so uncommon that all this ceremony and customisation was needed\u2026?   The punch line is that, as you already know, if I had just looked into Google Sheets\u2019 keyboard shortcuts, I could have saved myself all this time (though I would probably not have learned about all the things I\u2019ve covered here, nor written this blog post at all, so I guess that is a good thing\u2026?).   Opening up the shortcut search modal (\u2318 + /) and searching for \u201ctime\u201d displays the following:      The solution was unfortunately hidden away from me, but it was simpler than what I had created. So, rather than keep the custom function, I removed it in favour of using the \u201cInsert current date and time\u201d shortcut.   The only issue I can see now, though, is that a 4-key \u201cshortcut\u201d is a bit unwieldy, and since I will be using this a lot moving forward, I want it to be shorter. And, just for fun, I want to actually map it to a key on my keyboard.   So, it\u2019s time to crack open QMK and make this happen!   (I know I could potentially make the shortcut a bit shorter using an operating-system level custom keyboard shortcut, rather than go down to the metal of my keyboard firmware, but where\u2019s the fun in that?)   Configuring a Google Sheets Datetime Key   I have gone into the details on how to create new keyboard keycodes that map to custom actions in a couple of other blog posts:      Escape the defaults and Control your keyboard with QMK   Chording QWERTY with QMK Combos   So, I will just summarise the changes I needed to make to get a datetime appearing on a key press of my Ergodox EZ, and the blog posts above should be able to fill in any areas you may be uncertain about. You can also view the final result in my QMK Keymaps.   Custom Keycode   Add a custom keycode for a Google Sheets timestamp, which I will call GS_TIMESTAMP, to the custom_keycodes list:   enum custom_keycodes {   // ....   GS_TIMESTAMP,   // ... };   My custom_keycodes.   Custom Action   Add a custom action for when the key corresponding to the GS_TIMESTAMP is pressed. In this case, I want to map it to the Google Sheets shortcut: \u2318 + Option + Shift + ;.   This gets coded up in the process_record_user() function as one of the case options in the switch statement:   bool process_record_user(uint16_t keycode, keyrecord_t *record) {   if (record-&gt;event.pressed) {     switch (keycode) {       // ...       case GS_TIMESTAMP:         SEND_STRING(SS_DOWN(X_LGUI)SS_DOWN(X_LALT)SS_DOWN(X_LSHIFT));         SEND_STRING(SS_TAP(X_SCOLON));         SEND_STRING(SS_UP(X_LGUI)SS_UP(X_LALT)SS_UP(X_LSHIFT));         return false;       // ...     }   }   return true; }   My process_record_user function.   Assign Keycode to Key   Now that GS_TIMESTAMP has a definition and an action that it performs, it needs to be assigned to a key on the keyboard:   // ... [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   GS_TIMESTAMP, KC_1, KC_2, KC_3, KC_4, KC_5, KC_LEFT,   // ... ), // ...   Note that the positioning of the GS_TIMESTAMP keycode on the top left key of the keyboard, before the \u201c1\u201d key, is just meant to be illustrative of the kind of code change required. I ended up defining it somewhere else on my keymap.   If you followed along with your own QMK keyboard mapping, you can now re-compile your keymap, and enjoy one-key timestamp-ing in any of your Google Sheets!   And remember, if you come across a problem in Google Sheets that surely should have a solution, make sure to read every bit of documentation you can find before reaching for that text editor!   ',categories:[],tags:["google-sheets","javascript","keyboards","ergodox","mechanical-keyboards"],url:"/blog/google-sheets-timestamp/",teaser:"/assets/images/2020-07-25/all-i-want-is-a-timestamp.png"},{title:"My JLPT N1 Study Guide",excerpt:"In my life, I have failed the highest level of the Japanese Language Proficiency Test (JLPT) 7 times.   Five of my attempts on the old Level 1 exam (before it became N1) were when I was living and working in Japan, using Japanese full-time. I felt like my abilities were improving, so every \u4e0d\u5408\u683c\u3075\u3054\u3046\u304b\u304f (Failure) notification stung a little harder than the last, but, well\u2026maybe I would pass it the following year.   As the time came for me to move out of Japan, I wanted to pass the JLPT just once to get a certificate. So, I cut my losses, attempted the old Level 2 exam, passed it, and appeased myself with the relief that I would finally be free of these infernal tests.   Fast forward 8 years.   For whatever reason, I started to get antsy about leaving my JLPT attempt in a failed state for so long: it beat me, and that sucked, and I sucked, and I was obviously not over it.   But before making another attempt, though, I had to figure out what went wrong, why I had continued to fail all those other times, re-strategise my study plans, and actually execute them: properly, this time.   Here is what got me over the line.      The following contains to my personal opinions and experiences with the N1 exam specifically: nothing is meant to be prescriptive (since everyone learns differently), and the approaches may not be relevant for all levels of the JLPT. My hope is that you will find at least something of reference as you formulate your own study plan.    Mindset Change   There were years where I attempted to study for the JLPT, and others where I would promptly forget I applied to take it, turn up on the day, and test my luck.   Neither scenario resulted in significantly different scores, though, so it would seem that the net value of any dedicated study I did, and any general improvements in the language gained during the year, was zero.   Therein lies the need for the mindset change: JLPT N1 does not test your Japanese abilities so much as it tests your ability to pass JLPT N1.   The exam demands that:      you remember a lot of grammar patterns, kanji, and vocabulary that are used infrequently in everyday Japanese   you speed-read excerpts from novels and articles and be able to interpret and answer nuanced questions about them   you keep a mental track of the results of multiple weaving threads of conversations (which feel like they are deliberately engineered to trick you) before finding out which one is related to the question   It is a high-stress artificial environment requiring deep focus, where there is no time to waste when considering questions: you have to instinctively know answers immediately, or take your best guess and move on. This is not Japanese in a real life context.   Naturally-assimilated Japanese abilities will not cut it here: your brain needs to go to the gym to build muscle memory through memorisation drilling exercises. The weights (content) that you train on are determined by the barbells (books) that you use, and N1 barbells are not lightweight.   Buy Textbooks   A cursory search on any internet book seller\u2019s site for \u201c\u65e5\u672c\u8a9e\u306b\u307b\u3093\u3054\u80fd\u529b\u306e\u3046\u308a\u3087\u304f\u8a66\u9a13\u3057\u3051\u3093\u201d yields more options than you could possibly read through, and a further search querying which set of books are \u201cthe best\u201d will likely net you enough opinions to cause analysis paralysis.   I cannot help decide which textbooks would be right for you, but what I can say is that I used the following books in order to get a passing grade for N1 (and can personally recommend them):      The \u65b0\u5b8c\u5168\u3057\u3093\u304b\u3093\u305c\u3093\u30de\u30b9\u30bf\u30fc (Shin Kanzen Master) series of books. There is five in the set: one each for grammar (\u6587\u6cd5\u3076\u3093\u307d\u3046), reading comprehension (\u8aad\u89e3\u3069\u3063\u304b\u3044), kanji (\u6f22\u5b57\u304b\u3093\u3058), vocabulary (\u8a9e\u5f59\u3054\u3044), and listening comprehension (\u8074\u89e3\u3061\u3087\u3046\u304b\u3044). Get them all.   The \u65e5\u672c\u8a9e\u306b\u307b\u3093\u3054\u80fd\u529b\u306e\u3046\u308a\u3087\u304f\u8a66\u9a13\u3057\u3051\u3093\u516c\u5f0f\u3053\u3046\u3057\u304d\u554f\u984c\u96c6\u3082\u3093\u3060\u3044\u3057\u3085\u3046 (JLPT Official Practice Workbook). This book contains practice exams that you will absolutely want to attempt, under exam conditions, about 1-2 weeks before the actual exam. It\u2019s all well and good to study in a vacuum, but you will not want exam day to be the first time you realise you have budgeted your efforts incorrectly and need to cover too much ground in too little time. Do all of the practice exams.   The links above lead to Japan-based book stores which may or may not ship overseas. If you have issues ordering the books, or you do not want to wait for shipping, then definitely check out your local international book store.   If you are in Australia, I recommend checking out Kinokuniya\u2019s range of JLPT books, and visiting them if you are in range of a store.   Strict Study Cadence   Are you serious about getting N1? Great, because you are going to need to deliberately and consciously set aside time to study every day for at least a few months. There will inevitably be times where you are tired or you may just not want to study.   Too bad. Do it. Even if you slightly reduce your study time on off-days, you must keep up your cadence because it is so easy to break, and stay broken.   You are going to run a marathon that is currently only held twice a year, and the price of failure is the time, effort, and cost of having to ramp up for the exam again, not to mention the opportunity cost of not being able to direct those efforts to some other activity/hobby/venture you may have.   For me, I took an Eat That Frog approach and front-loaded my Japanese study early in the morning, every morning, during my study marathon period.   So, what is the optimal amount of study time per day? I actually do not know, so I outsourced figuring that out to a software program specifically designed to help you remember things efficiently.   Textbooks -&gt; Flash Cards   Anki was the secret weapon to my success at passing JLPT N1.      Those textbooks you bought? The content in them is great, but in the confines of those dead trees, none of it is:      searchable   portable   customisable   extensible   Therefore, the very first activity in your study plan should be to manually port all the content in those books into a different format: Anki flash cards.   Yes, AnkiWeb has a huge set of community-submitted JLPT-related flash card decks that you can download and use for free. But, I strongly recommend not using any of them, and instead roll your own decks as this is a great form of study. It will markedly assist in:      your initial learning and internalising of the content   your revision of the content as Anki works its spaced-revision-ing algorithms over it, surfacing your weaknesses and making sure they improve   For me, the most logical candidates for books to port over to Anki flash cards ended up being grammar (103 cards), kanji (394 cards), and vocabulary (239 cards).   After creating the three decks, I would revise each of them every day at the pace that Anki dictated, and slot in listening and reading comprehension study once Anki preventing me from revising the decks further.   During commutes to work, I would continue to revise the cards using AnkiMobile.  You may think that AnkiMobile is pricey for \u201cjust an app\u201d, but, in my opinion, it is absolutely worth it given the objective you are trying to achieve, and the price of failure. I highly recommended using it if you can, and you can feel good about helping to support keeping Anki itself free.   Creating the actual flash card decks can be a bit confusing, especially if you do not have a coding background, so I have shared my JLPT Anki templates, which you are free to use to create your own cards and/or customise to your liking. Each deck has an example card to get your started.   I have deliberately not shared my own decks on AnkiWeb, or anywhere else, as they are a straight port of copyrighted content. It would not be fair to the book authors, and I am sure their publishers would not be so happy with me if I did. So, definitely roll your own decks.   Results   I rinsed and repeated the Anki revision process for a few months, kicked off practice exams a couple of weeks before the day of the JLPT, and eventually entered the exam with a feeling of contentedness knowing that I did all I could possibly have done.   The exam was still really tough, and I left it giving myself a 50-50 chance of passing, since the brutal time limitations still left me having to rush through some sections and guess at some problems.   But on that attempt, on attempt number eight, I finally got it. So, with apologies to Vitas Gerulaitis:      And let that be a lesson to you all. No JLPT exam beats Paul Fioravanti 8 times in a row.    Worth it?   In order to relieve my poor shoulder of the giant JLPT-shaped chip that had obviously been laying dormant there for years, the effort put in to finally getting that passing mark was absolutely worth it.   From a career perspective, not having Level 1 (or any level) ever stopped me from getting a job while I was living in Japan. I found that most employment-based language \u201ctesting\u201d ended up being litmus tests during face-to-face interviews to see if you had any degree of conversational and kanji-reading fluency.   I guess that if you are planning on doing an activity where passing JLPT N1 is a pre-requisite, then passing it represents a hard barrier that you must cross. But, back in Australia, my work requires no Japanese at all, so the JLPT qualification is simply a nice feather in my hat, and something I can write a blog post about.   From a language perspective, I absolutely did learn a lot of interesting new words, grammar, and kanji. There may be a lot of content examined in the JLPT that is not used much in everyday Japanese, but learning it was valuable. From that point of view, you could say that studying for the JLPT forced my hand in learning Japanese I would not have picked up of my own volition, for which I am thankful.   Postscript: After N1   I do not study Japanese formally any more, but I do keep up my language practice every day, so here is a random list of the forms that that takes.      I have a Japanese spouse, and my spoken language at home is Japanese. I\u2019m not saying you should marry a Japanese to keep up your language skills, of course, but the fact is, it does help a lot.   Yahoo Japan News, regardless of its design being stuck in Web 1.0, is still the most trafficked news site in Japan, and so is worth checking regularly on that merit alone. If you use Google Chrome, I highly recommend installing the rikaikun extension to help make reading kanji a breeze.   I do not watch much Japanese TV, but one show that I will actively watch every week is \u30ef\u30a4\u30c9\u30ca\u30b7\u30e7\u30fc (The Wide Show), a news and entertainment show. I like Hitoshi Matsumoto, a comedian and one of the co-hosts, and I find that the programme is good to help get a view on what stories and issues are being talked about in Japan currently. There is no official way to view the show outside of Japan, but you can always find a channel on YouTube that streams it live at 10:00am JST Sundays.   There are a lot of great YouTube and online video channels originating from Japan. Here is a selection of a few in my subscriptions:            \u65e5\u672c\u8a9e\u306b\u307b\u3093\u3054\u306e\u68ee\u3082\u308a: Nihongo no Mori, the Japanese Forest, is a fantastic resource for JLPT videos. If you are actively studying, or you just want the occasional refresher, you want to subscribe to this channel.       \u3042\u304b\u306d\u7684\u3066\u304d\u65e5\u672c\u8a9e\u306b\u307b\u3093\u3054\u6559\u5ba4\u304d\u3087\u3046\u3057\u3064 (Akane\u2019s Japanese classroom): Akane\u2019s lessons are great for learning contextual Japanese. She roleplays through various situations like job interviewing, talking on the phone, going out to eat, and checking in at a hotel, so there is plenty of practical Japanese to learn from her videos.       Easy Japanese for Work \u3057\u3054\u3068\u306e\u306b\u307b\u3093\u3054: If you are planning to work in Japan, or you would just like to learn about use of Japanese in a working environment context, this series of videos by NHK World, is an excellent supplement to any formal Japanese studies, with plenty of phrases and cultural nuances you may not find in your textbooks. NHK World\u2019s YouTube channel does not have the full set of these videos, so be sure to view them directly on their website.       \u3084\u3063\u3059\u3093\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u5927\u5b66\u3060\u3044\u304c\u304f: If, like me, you are a computer programmer, or you are involved in technological fields involving software, you will definitely appreciate Yasun\u2019s channel as he goes on deep dives with a variety of different technologies. Your Japanese technical vocabulary will doubtlessly improve as a result of watching his videos.       \u30a8\u30ac\u3061\u3083\u3093\u306d\u308b EGA-CHANNEL: The official channel of Egashira 2:50, probably the nicest completely bonkers comedian in Japan.       \u30de\u30ad\u30b7\u30de\u30e0 \u30b6 \u30db\u30eb\u30e2\u30f3\u516c\u5f0f\u3053\u3046\u3057\u304d: The official channel of band Maximum the Hormone. Their music is awesome, but in particular, their \u30ac\u30c1\u30f3\u30b3 \u30b6 \u30db\u30eb\u30e2\u30f3 series where they held auditions to create a second \u201coutlet\u201d of their band (\uff12\u53f7\u5e97\u3054\u3046\u3066\u3093) is novel and excellent viewing.       \u7981\u65ad\u304d\u3093\u3060\u3093\u30dc\u30fc\u30a4\u30ba: The channel for Kindan (Prohibited) Boys. The interviews this team of 4 comedians do in places like Shibuya provide a great insight into the minds of young Japanese. The \u201cCinderella\u201d dating show they did for one of their members, \u201cMessiah\u201d (\u3081\u3055\u3044\u3042\u30b7\u30f3\u30c7\u30ec\u30e9), is one of the channel highlights.       Popular YouTubers \u30d2\u30ab\u30eb\uff08Hikaru\uff09 and \u30e9\u30d5\u30a1\u30a8\u30eb Raphael have some interesting content in their channels, and I would recommend sorting by \u201cMost popular\u201d to see if what they offer is of interest to you.           If you have any recommendations for Japanese language study guides, or Japanese language media that you like reading/watching, please let me know in a comment!   ",categories:[],tags:["japanese","jlpt","anki","html","css","javascript","\u65e5\u672c\u8a9e"],url:"/blog/jlpt-study-guide/",teaser:"/assets/images/2020-11-22/abi-schreider-yb16pT5F_jE-unsplash.jpg"},{title:"Playing in Plaid's Sandbox",excerpt:'I had a software client who required an integration to Plaid, a financial technology company specializing in bank login verification.   If you are in a similar position, and are attempting to get started with Plaid\u2019s Application Programming Interface (API), then this post may be of assistance to you in setting up and using their Plaid Postman Collection with Postman (if not, then this post will probably not make that much sense, and I will not be offended if you bail out now).   I found that even with the Plaid documentation, it still took me quite a bit of time to figure out how to get valid responses from the Plaid Sandbox. I originally submitted the content of this post as a documentation pull request, but it seems that Plaid was not interested, and so I figure it can live here on my blog.   The following is meant to be read after you have completed the steps in the Getting Started section of the Plaid Postman README.   Making Plaid API calls   Most Plaid API calls require a Plaid Token in the form of an access_token (or an asset_report_token when dealing with a Plaid Asset).   After you have imported and configured the request collection in Postman, if you open up the Retrieve Auth request and click the Send button, you will receive something like the following error:      Opening up the Body tab of the request will reveal the issue:      You can see that the access_token contains an invalid place holder ("ENTER_ACCESS_TOKEN_HERE"), leading to the request failing. So, how can you use the Postman Collection to generate a valid access_token?   You will need to emulate the Exchange Token Flow process by using the following included API requests:      Create Item [Sandbox Only]   Exchange Token   Only then can you begin using the generated access_token to make other requests. So, let\u2019s set about doing just that.   Create a Public Token   First, you need to create a public_token using the Create Item [Sandbox Only] request. Simply open it up, click the Send button, and you should see a response similar to the following:      If you are going to need to use the Assets API, then make sure you open up the Body tab of the request and add "assets" to the initial_products array, and then generate your token. Otherwise, your public_token will not have the correct permissions set to use Assets:      Create an Access Token   Next, use the public_token you generated in the previous step to generate an access_token with the Exchange Token request.   Paste your public_token into the "public_token" field into the Body section of the request. Click the Send button, and you should see a response similar to the following:      An access_token associated to an Item does not expire, so you can use it in all of your requests. The Postman Collection has an access_token environment variable field available where you can store your generated access token, so I would suggest putting your newly generated token in there.      Use Access Token in API Calls   Now, go back to the Retrieve Auth request that failed earlier, open up the Body of the request, and set the access_token field to be a reference to the access token set in your environment variables. Do this by changing the value to be "{{access_token}}". Then, click the Send button, and you should see a successful response.      You can now repeat this step for any other Plaid API that requires an access_token.   Create an Asset Report Token   As well as using access_tokens, Plaid Asset Reports have their own asset_report_token that need to be used when using the Retrieve an Asset Report request.   You generate an asset_report_token using the Create Asset Report request.   Open up the request Body tab, and add a reference to your access token ("{{access_token}}") to the array in the access_tokens field. Then, click the Send button, and you should see a response similar to the following:      (The options object that is included by default in the Body was removed here for brevity).   Similar to an access_token, an asset_report_token also does not expire, so you can use it in all of your asset report-related requests.   The Postman Collection has an asset_report_token environment variable field available where you can store your generated token, so I would suggest putting it here with your access_token.      Use Asset Report Token in API Calls   Now, you can try an API request like the Retrieve an Asset Report (JSON) request, which requires an asset_report_token.   Open up the Body of the request, and set the asset_report_token field to be a reference to the asset report token set in your environment variables ("{{asset_report_token}}"). Then, click the Send button, and you should see a successful response.      You should now be all set up and ready to begin playing in Plaid\u2019s Sandbox with any API that requires an access_token or asset_report_token.   ',categories:[],tags:["plaid","postman","api"],url:"/blog/plaid-sandbox-api/",teaser:"/assets/images/2020-11-29/plaid.jpg"},{title:"Speak at a Meetup",
excerpt:"Meetups are great! The best ones provide a sense of community where the curious and the enthusiastic can engage together to create a great experience that draws people in and keeps them coming back.   Since my primary experience with meetups are those related to programming and technology (as of this writing I organise the Elixir Sydney, GraphQL Sydney, and Elm Sydney meetups, and have previously organised the Ruby on Rails Oceania Sydney meetup), this post will focus on meetups where there is typically a roster of talks on software/technical topics, and a good deal of socialising.   Why Give a Talk?   If you are a developer, at any stage of your career or training, you should strongly consider finding a local meetup group (on Meetup most likely), and do a talk on something you have worked on, or have learned.   Develop a New Skill   Presenting at a meetup is a win/win situation.      You, the speaker, get to practise public speaking, a skill that may not be exercised much in your day to day activities, and your audience gets to leverage your knowledge to learn new things that can potentially help them in their own activities.   You may be apprehensive toward public speaking, particularly if you have previously had negative experiences with it.   However, I posit that since technical meetups are typically attended by people who lean more towards identifying as introverts than extroverts, and hence viscerally understand the courage that it takes to deliver a talk in front of your peers, you will find them to be a sympathetic audience who want you to succeed. Pre-talk nerves will never go away, but they can feel less debilitating when you feel that your audience has your back.   Also, if you have ever thought that you would like to present at a big conference, then a meetup audience is a great start point to get practice and hone your skills.   Add to your Portfolio   Doing a meetup talk provides takeaway artefacts of \u201csoft skills\u201d, which are becoming ever more important in development teams (which makes me feel they should be re-branded as \u201cessential skills\u201d).   You can take your talk/slide deck and essentially open source it on a wide variety of platforms, much like you would with your open source code (eg Speaker Deck, SlideShare, or even Github if your presentation is written in Markdown).      COVID-19 has pushed many meetups out of meatspace and into online platforms like Zoom (hopefully only temporarily\u2026), allowing your talk to be recorded easily. Check and see if your target meetup records talks, and hopefully they have a space to publish content, like a YouTube channel.   These artefacts, in their various forms, can provide a great addition to your resume, or maybe even ammunition you can take in to your next pay-rise negotiations.   Show Something Off   Meetups provide you with a captive audience to directly promote and show off something awesome you have built lately, or maybe pose a question or problems that you\u2019d like input and/or discussion around.   Discussion about any thought-provoking issues have often continued after the meetup ends, and you get to take the credit for being the catalyst!   Practise Demoing   If you are up to the challenge, doing a talk can be a catalyst to practise demoing something in front of an audience, which is significantly different to just showing someone else what is currently on your screen.      Being able to effectively demo, and recover from any issues that occur during them (and unless you have adequately appeased the demo gods, they will happen), is a highly sought after developer (and presales) superpower.   Become an Expert   Doing a talk can have the pleasant side effect of making you known in your community as an expert on something, even if don\u2019t consider yourself one!   If you teach someone something that they did not know before, then, to them, you are an expert.   Furthermore, the questions that you get from others about what you know can lead down extra knowledge-gathering paths to further refine your abilities, to the point where even you must acknowledge your own expertise. Not a bad self-fulfilling prophecy!   Your Perspective is Unique   Even if you think the content of your talk must have been covered in a previous meetup, or is just too obvious to talk about, your perspective on it (and the way you present it) is unique to you, so never let that stop you from giving a talk.   People love to hear presentations about things they already know because it makes them feel smart about understanding something worth presenting.      If you are the one presenting it, you unconsciously join the league of experts about that subject in your audience\u2019s mind, and I will bet anything that even those experienced in the topic you present will learn something from your take.   Land a Job   I have friends who have received offers to go and interview at organisations, and consequently get jobs there, based solely on having done a talk at a meetup, and impressing their future peers in the audience.   This scenario obviously does not play out at every meetup, but it goes to show you that you never know who could be in your audience, and what opportunities sharing your knowledge could provide you.   This \u201cmaking your own luck\u201d scenario is one of the primary reasons I like to specifically appeal to junior developers to do meetup talks. A successful talk delivered to your peers (and they are your peers), can help your job application shine a bit brighter from the pack :sparkles:   Leverage Organisers   Speaking from experience, meetup organisers are always hungry for new content. Finding talks is easily the most difficult and time-consuming part of technical meetup organisation.   If you are willing to freely spend time and effort creating content for a meetup, then meetup organisers will very likely be happy to act as a sounding board for your talk content and provide feedback before you present (I certainly do, with pleasure!).   They will have seen a lot of talks, have likely delivered some themselves, and will be invested in making your talk come out great. Good talks make for good meetups, which then attracts more good talks in a virtuous circle, so your success is their success!   Leap of Faith   Deciding to take on delivering a technical talk is a hard first step to take, but remember, it is good to throw yourself out of your comfort zone and try something different.   Who knows, you might even end up liking it and wanting to do more, which could lead to all manner of new doors opening for you. Take that first step and find out!      ",categories:[],tags:["meetups","public-speaking"],url:"/blog/speak-at-meetups/",teaser:"/assets/images/2020-12-06/roro-paul.jpg"},{title:"Oi! Kochi: Japanese Feature Phone-Driven Development",excerpt:"     Back in the early 2000s, when I was on the JET Programme in Kochi Prefecture, I was in charge of an English/Japanese bilingual community newsletter called Oi! Kochi (\u30aa\u30fc\u30a4\uff01\u9ad8\u77e5\u3053\u3046\u3061).                       I made sure to use only the       latest technology       when recording interviews.           Since my position was Coordinator of International Relations, my mere involvement with the newsletter automatically fulfilled its \u201cinternational relations\u201d objective, giving me pretty much free reign over what content appeared in it.   I did not fancy myself as a journalist at all, and had no idea what I was doing (my lack of logo design skills may have clued you in on that, not that current me would be able to do any better\u2026; for those curious, yes, that is Sakamoto Ry\u014dma on the left), but it was great fun being able to act as a reporter, editor, and translator to produce this thing that was being read by others.   After the third issue I had been involved with was released, I was informed that due to departmental budget cuts, Oi! Kochi no longer had a print budget, and hence it would be the final issue.   Not wanting my run to end so soon, I thought that this might be a good opportunity to attempt to put Oi! Kochi not just on the web, but attempt to give it a space within the walled garden that was Japan\u2019s fledgling mobile internet.                       Photo from Wikimedia.           So, without knowing anything about code whatsoever, I attempted to make some HTML web pages. Japan was predominantly using clamshell-style feature phones, and sites developed for them used C-HTML, so that is what I used for the mobile pages.   I recall having eventually put the pages somewhere on the internet, but I do not think the Kochi Prefectural Government gave me any space on their servers (not that I understood what a server was back then\u2026), but probably used some kind of free service and shared the link with whomever would humour me. Those pages are, unsurprisingly, long gone.   However, I did still have the codebases lying around, and figured it would be nice to see if they could be deployed back out on the internet, so the content does not stay lost. So, here they are!      Oi! Kochi Web Pages   Oi! Kochi Mobile Pages   Revel in their Web 1.0-ness!   I have also made the codebases, and scans of the print versions of the newsletter, available in the Oi! Kochi GitHub repository. If you have the courage to actually look at the code, remember, it was written a long time ago\u2026   Viewing Pages                       A younger me on a feature phone, with mandatory extra-long straps, which       was the style at the       time.           For the most period-accurate browsing experience (simulating how the pages would have looked on my AU by KDDI phone), I would have recommended using an emulator that replicates the old Japanese feature phones, the closest of which I\u2019ve ever found is viewing the pages using the Firefox browser, along with the FireMobileSimulator add-on.   Unfortunately, FireMobileSimulator is now dead and buried, with no future releases planned, and it does not work on current versions of Firefox. There are also no alternatives that I could find.   The only consolation is that you are able to trigger accesskey attributes for links (ie for a link with text \u201c1. English\u201d, you could press the :one: number key on the feature phone to directly \u201cclick\u201d on that link) in Firefox and Chrome.  See Mozilla\u2019s accesskey page for the key shortcuts for your platform and browser.   ",categories:[],tags:["jet-programme","html","kochi","japan","mobile-phones","feature-phones","chtml","i-mode","\u65e5\u672c","\u9ad8\u77e5\u770c","\u30ac\u30e9\u30b1\u30fc"],url:"/blog/oi-kochi/",teaser:"/assets/images/2021-01-03/infobar.jpg"},{title:"Organise a Meetup",
excerpt:"In a previous post, Speak at a Meetup, I attempted to convince you that actively participating and delivering talks at your local technical meetup is A Good Thing that you definitely Want To Try.   I will assume the pitch was a :sparkles: great success :sparkles:, and you have been attending, participating, and even speaking at meetups; receiving accolades, and the admiration of your peers.   Would you consider stretching your meetup wings a bit further, give back to your community, or even just get some event management experience?   Well, becoming a meetup organiser ticks all of those boxes! So, this post aims to:      Pitch the benefits of becoming a meetup organiser   Share some anecdotes and experiences of my time as an organiser   Share my ideas and opinions around preparing for and holding meetups, for your consideration   Basically just brain dump everything I know about organising meetups   There is a lot to go over, so strap yourself in.      A Word about the Plague     With the advent of COVID-19, meetup dynamics changed completely from in-person to online-only.     As of this writing, I would certainly not feel comfortable hosting in-person events, for the sake of all participants, even if any of the venues who have graciously allowed us to use their facilities in the past would permit them.     The logistics of hosting an online meetup are comparatively simpler than in-person, but new challenges arise around keeping your community engaged and coming back to events.     My hope is that in-person meetups have not become obsolete, and will return in the near future (and hence the following information about them will become relevant again), but even when they do, there are definitely elements from online meetups that I intend to bring into meatspace, which I will further elaborate on later.    Why become an organiser?      At a distant past Ruby on Rails Oceania Sydney (RORO) meetup, the organisers starting asking some participants if they would consider becoming organisers themselves, and effectively take over running the meetup (I seem to recall the reasons being due to the demands of raising a young family, and competing time commitments for work, which is fair enough).   Before being asked, organising was not something I had thought about doing at all. It was great being a participant and a member of a community, and I did not feel actively compelled to seek out what seemed like more work. However, by the end of the meetup, I had signed up for the following reasons:      It would be a new experience. I had never done any kind of event organising before, so I decided to silence all internal dissenting voices, throw myself out of my comfort zone, see what would happen, and hopefully learn something along the way.   Giving back would be a good thing. The very evening I moved permanently to Sydney, Australia, a place where I had no family and few friends, I made a beeline directly for the Ruby community, and was welcomed. Over time, I gave talks, mentored new developers, made new friends, and had lots of fun. I felt that this was a community worth maintaining and contributing to.   More public speaking. I figured that becoming an organiser would essentially force me to have a regular speaking gig, and help keep those vocal skills sharp.   After nearly two years of being a RORO organiser, I took on further organiser roles at the Elixir Sydney, GraphQL Sydney, and Elm Sydney meetups, of which I am still an organiser of at the time of this writing. This required me to pass on my RORO torch on to a new team of amazing people, as four meetups became a bit too much for me to handle (it is good to be cognizant of your personal limits!).   I have no regrets on having travelled down the organiser path, and still find that I enjoy doing it. I get tremendous personal satisfaction from being able to provide a platform for others to speak about all the awesome stuff they have been doing, and help them construct their talks.   Meetups are all about community, and their management teams benefit greatly from a wide range of ideas and experiences, including yours. So, if you ever have the opportunity to be the enabler of those sparks of enthusiasm, I would encourage you to give it a try!   Okay, I\u2019m interested! Now what?   If you want to know what kind of things you could help out with, or you want some ideas around what to include when starting your own meetup, read on, and hopefully the following will be of some reference as you take the reins and start leading your community.   Content is King   No half measures, let\u2019s start with what I consider the hardest part of organising a technical meetup, regardless of whether it is in-person or online: sourcing talks.              Photo by            Tomasso Armstrong           The dream for an organiser is to have a full pipeline of talks by willing and able speakers on a wide variety of topics that will cover multiple months worth of meetups. You then have the luxury of being able to group talks by content or technology, and establish an underlying theme for a meetup.   I remember I once had a pipeline of talks that covered a present and a subsequent month\u2019s meetups, and it felt amazing! Good times\u2026   So, yes, few organisers probably get to live that dream, but I am certainly not discouraged by that. Regardless of how much I may regurgitate the benefits I pitch in Speak at a Meetup, I know I am making a Big Ask when I canvass the community for presentations. I am essentially asking you to:      take time out of your schedule to work for free by creating a talk   take more time out of your schedule to refine and practice your talk   maybe take even more time out of your schedule to have companion technical materials like demo environments and code repositories available   do something that you may not have experience doing, and initially may be uncomfortable, or just not like, doing   feel gratified that content creation is its own reward, and believe that the audience response will justify all your time and effort spent   Would you do that for me\u2026? Community Glory awaits! \u2026Maybe next month, then\u2026? Well, have a think about it and let\u2019s talk again later!   \u2026   Rinse and repeat, every month, with all the humility and thankfulness that you, as an organiser, can muster. Take the mindset that nobody owes you anything, and it is the community doing you a favour by providing the content needed to make the meetup a success. Proactively ask, but do not pressure.   Begging is fine, though; I get to practice that a lot :pray:   How do I find new content?      Finding talk content for meetups is a treasure hunt, and the \u201cX\u201d that marks the spot on your map is a moving target, but I have been able to strike gold at the following places:      Your own meetups. After talks are finished at every meetup, make sure to take some time to let participants know that you are always looking for talks, especially from first-time speakers. After proceedings, I have had many people ask whether a topic they want to talk about has been done before, or whether it would be interesting or not. Harness that interest and curiosity and guide it towards becoming a talk submission.   Other meetups. See a talk you liked at another meetup that your community might also like or benefit from? Reach out to that speaker and see if they want to get more mileage out of their talk with another audience. Write once, run anywhere can work for talks, too!   Social Media. Assuming your community is subscribed to your social media, call outs are definitely the easiest way to do a beg blast for talks. Their regularity can become more frequent as the date of the meetup draws closer and you realise you still need speakers, but it is always better to secure talks as early as possible.   Direct Messaging. If indirect social media requests yield nothing, sometimes people respond to being nudged directly. You should have a list of your community members, so do not be shy in reaching out and getting personal with requests.   Chat channels. Your local tech community will likely have multiple Slack workspaces or Discord servers they frequent. I have had success in reaching out to developers who promote their projects there to give talks about them (also works when those promotions happen over social media).   Blog posts. Did a member of your community write a blog post about something interesting? Ask if they can adapt it into a talk since they have already gone most of the distance with regards to content creation. It\u2019s not plagiarism if it\u2019s your own work!   Coding Bootcamps. In order to get more junior developers to attend my meetups, I have gone and done talks at various coding bootcamps, which are very fertile ground for new speakers. Ask a developer-in-training to take a presentation/demo they have already likely delivered to their class, and also give it to their future peers!   Group Exercises. Providing some kind of well-defined problem to solve can result in great content. I use Exercism problems to encourage junior developers and first-time speakers to deliver a lightning talk on their solution, which then often produces great community discussion about the different ways to figure out that particular problem.   Post-Meetup Pub :beers: There is almost always a group that heads to a nearby pub after an in-person meetup has finished (regardless of whether you had alcohol available at the meetup itself). As well as affording you the opportunity to talk with attendees you were unable to catch up with because you were too busy organising, the pub environment can also be the catalyst for conversations that lead into getting more talk submissions (promises after a few drinks are still promises!). For non-drinkers, those conversations take place over post-meetup gelato :icecream:   Once you do get someone interested in doing a talk for the meetup, depending on their level of experience or confidence with preparing talks, you may need, or be asked, to assist them with their content preparation, dry runs, timing, or generally be a sounding board. Relish these requests as your speaker\u2019s success also becomes your own (and the meetup\u2019s), and doing this often leads to a virtuous circle that leads even more new content.   What if I get no content?   If, despite your best efforts, you were not able to get talks lined up for your technical meetup, or you have had last minute talk cancellations (it happens), and you, yourself, do not have your own content to prop up the speaker line-up, then there are a few options that can tide you over until the next meetup (note, though, that these ideas will probably mostly work best for in-person meetups):      Hack Night. Change the meetup format to be a \u201chack night\u201d, where people can work together on solving a problem, get mentored, or assist on each others projects etc.   Mob Programming. Pick a problem to solve, like an Exercism exercise, and have one person \u201cdrive\u201d a machine, while everyone else chimes in with their solution proposals. Change the driver periodically. The rowdy discussions are part of the fun, and with tools like Repl.it, this can also succeed in a remote setting.     Quiz Night. At some Elixir Sydney meetups, we have used Elixir Flashcards to form the basis of pub quiz-style activities, where the winning team takes all\u2026of the kudos and admiration of the community :clap:   Social Night. Just do what you were planning on doing, but without the talks, focusing instead on just catching up, socialising, and debating the important issues.   Cancel It. Sometimes, especially for online-only meetups, if the content is not there, then you may feel the need to cut your losses and focus on the following meetup. No shame.   There are, of course, plenty of meetups out there whose sole purpose revolves around what I have outlined as an \u201calternative\u201d activity, like hack/social nights. You may even want to have designated events for these kinds of activities in your meetup cadence to break up the flow, which is absolutely fine! The most important thing is holding events that people want to keep on coming back to, and that can be different for every community.   Venues   If you are going to hold an in-person meetup, you need a location where people can gather to see all the wonderful content on offer. Depending on factors like how established your meetup is, and how many RSVPs you receive, your meetup\u2019s venue requirements will be different.   Regardless or which kind of venue you intend to host your meetup at, I would implore you to have a think about, and explicitly make a note of, the minimum conditions that a venue must meet in order for you to be able to run your meetup successfully: the must-haves and the nice-to-haves.   When I attempted this exercise, this is what I came up with, and still use it as a baseline reference (bear in mind that some of the nice-to-haves only apply to an office venue context):      Must-Haves      Room for 80 people to at least stand   Projector/Big Screen that a laptop computer can connect to   Ability for food options to be available or delivered (street parking/elevators/docking area/trollies etc)   Tables/trestles where food can be placed   Ability for finished food/utensils to be cleared/disposed of   Access to male/female toilets   Ability for people to get in to the venue if they come late   Nice-To-Haves      Ability to sponsor food   Ability to provide disposable cutlery/crockery for catered food   Ability to sponsor drinks/open up their drinks fridge   Room for 80 people to sit on chairs   Lectern   Microphone/Sound systems   Cables for projector/screen to laptops   Provide remote controls for presentations   Ability to record presentations   Ability to have a table to put name tags on to place near the entrance   Close to the Central Business District (CBD)   Close to public transport   The technical meetups I organise are community-driven non-profit events, where attendance is free for participants, and so there is no monetary budget to hire out some fancy venue. Within the context of Sydney, Australia, this has meant a choice of two types of potential venue that meet the must-have conditions: pubs and offices.   Pubs   Many pubs have event rooms that they rent out, but if your meetup is held at a time when those rooms are not typically used, you can often get room fees waived if you ensure some minimum threshold of attendees. The assumption will be that a high percentage of those attendees will buy food and drinks, and you, as the organiser, can help nudge those sales along when you kick off the meetup.   I have heard that pubs are considered \u201cneutral ground\u201d for technical meetups, meaning free from the \u201cinterference\u201d of any third-party that could potentially attempt to impose editorial control over content delivered at the meetup.   I guess that is true in theory, but I have personally never experienced a situation where the venue is a company office and the host insists on something like \u201csince you\u2019re using our office we want all the speakers to be our employees promoting our stuff\u201d.   The RORO meetup had a long tradition of being held at pubs in Sydney, but eventually moved to being held in offices, for various reasons including issues with pub audio visual equipment and ambient noise. See this GitHub issue for a stellar problem write-up and solution proposal by Andrew Harvey, a previous RORO organiser.   Regardless of any shortcomings, though, a pub may be an appropriate option for your meetup, and can provide a great casual atmosphere, without you needing to worry about food or drink budgets since everyone takes care of themselves.   Offices   Software developers are in the privileged position of currently being in very high demand in the job market, which has the knock-on effect of companies being interested in hosting gatherings of developers, particularly if that company uses the technology that your meetup focuses on.      In many cases, companies will also have event-related budgets enabling them to cover food and/or drinks, and have facilities that cover a good chunk of the nice-to-have requirements above, resulting in a great experience for your attendees.   In return for this support, I have typically provided a spot for someone from the company to address the audience before the meetup talks start, usually to promote the company itself and any jobs they may have available, as well as sponsor shout-outs at the meetup and on social media. In rare circumstances, the host company has an employee that wants to give a community talk on home ground, so I have been happy to add them to the speaker line-up.   The ambient noise issues that occur in pubs are generally non-existent in offices, particularly if your meetup is in the evening, allowing everyone\u2019s focus to stay firmly on the content you have worked so hard to procure.   Also, as opposed to pubs, who typically have a team of wait staff to clean up after you, this is typically not the case for offices. So, make sure you actively ask your venue contact about any post-meetup cleaning up, including disposing of any excess food and/or putting away chairs and tables. Do not be shy about delegating tasks like chair-stacking and cleaning-up to your audience, either.   Food and Drink      If you can find a company who can provide you with a venue, food, and drinks on a constant monthly (or whatever your cadence is) basis, this can take a big load off your organiser shoulders, and enable you to focus exclusively on procuring content. Build a strong relationship with these organisations and don\u2019t let them go easily!   In the event where you need to organise some or all of the catering yourself, though, I can recommend the following:      Try to find another company to cover the bill. This may mean needing to pay the bill upfront yourself and getting reimbursed later by the sponsor. Don\u2019t forget to also add that company to the list of sponsors to thank at the meetup. If you cannot foist the bill on to another organisation, and it is not something you are prepared to cover yourself, I\u2019m pretty sure it is okay to not provide free food and/or drinks to your attendees (online meetups don\u2019t send food deliveries to every attendee\u2019s residence after all\u2026).   Where your budget permits, try and aim for non-pizza options. Nearly every technical meetup with a food budget provides pizza as it\u2019s the easiest option (to the point where, at least in Sydney, you could probably have your dinner covered by tech meetups most days of the week, as long as your diet can bear that much pizza). However, with that same budget, you may be surprised at what it could get you at a corporate caterer (COVID caveat: who knows what the state of shared food like pizzas and buffet-style catering is going to be when in-person meetups resume, though\u2026).     I have had mixed results from beverage delivery services. I have found they have not been as timely as food delivery; as in, drinks have arrived many hours before times I have specified, as opposed to food, which has typically arrived at expected times. So, if you are getting beverages delivered, you probably want to make sure your venue has a fridge with spare room in it (as your beers will probably not arrive cold), and someone to receive the delivery if you cannot be there yourself. If there is a bottle shop nearby to your venue, you are probably better off taking a team with you to buy direct and help bring the order back.   Keep inclusivity in mind when ordering food and drink: include vegetarian and vegan options for food, and if you do have alcohol at your meetup, ensure that you also have non-alcoholic options (including water!).   Watch out for food hogs that pile their plates insanely high, leaving less for other participants. As an organiser, sometimes you have to be an enforcer of decorum.   Encourage people to bring empty food containers to your events to take home any leftover food, preventing wastage (COVID caveat: no idea if this will be considered a responsible idea moving forward\u2026we will have to wait and see)   Venue-less   If you find yourself in the middle of a plague, or you just want to free your meetup from the constraints of geography, then you may want to consider hosting it on that internet thing we all know and love.      As of this writing, Zoom is the tool du jour for remote meetings and video conferences, and I have been utilising it to keep meetups active while in-person meetups remain infeasible. However, it is not just meetup continuance that has been achieved in the move to online-only. Significant value has been added to meetups that I fully intend on keeping around, even after we get back to meeting in-person again.   Videos   Video recording talks at in-person meetups where we could access video feeds of the speaker, slides from their computer, and, most importantly, clear audio of the speaker\u2019s voice, seemed like an insurmountable (and expensive) task. Capturing all of those feeds now is as trivial as pressing a button and recording to the cloud.   There have been plenty of times in the past where I have been asked by people who were unable to attend a meetup in-person whether the talks had been recorded. Every time I would have to apologise and say that we were \u201cworking on\u201d a way to do recordings; now I just share a link to the relevant meetup YouTube channel, where I upload talks after doing some rudimentary editing with QuickTime.   Being able to provide your speakers with a link to a video artefact of their talk, and having it promoted all over social media is, no doubt, a killer feature for someone doing a talk at your meetup. It is too good to be lost in the move back to in-person, so it will stay.   All-Access   Regardless of how much they would like to attend your meetup in-person, there are people who are simply unable to do so for all manner of reasons, from family obligations to residing too far away from your venue. When your meetup has online access, these limitations fade into irrelevance.      It gives me great joy now when we say hello to new attendees, and find fellow tech enthusiasts from all over the world have joined our \u201clocal meetup\u201d. These days, though, \u201clocal\u201d seems to only really apply to that nice community \u201cfeel\u201d of a meetup, since any open online meetup is global by default. As long as you are awake during AEST/AEDT time zone evenings, you are welcome at any online meetup that I host, no matter where you are reading this! :smiley:   So, as a meetup organiser, you have the opportunity to choose how high you would like the fences around your meetup to be: as low as live streaming, or as high as in-person venue-only. Gauge your audience, and the objectives of your meetup, and select a strategy that works best for your community.   Information Source of Truth      With the important high-level issues of content, venues, and nourishment taken care of, we can now dive into the minutiae of detailed meetup topics, starting with information management.   Each technical meetup can generate a lot of information:      A list of talk submissions and proposals, and the back and forth communications that occur as they are guided towards getting slotted in to a meetup\u2019s talk lineup   A final list of speakers, their talk summaries, and the materials they used for their talks   Promotional and attendance sign-up pages containing information about the meetup, its date, time, place (real or virtual), and purpose   Promotional social media posts   Communication amongst organisers, and between organisers and speakers/venues   A meetup host slide deck   Post-meetup artefacts like videos   Unfortunately, there is no one system that takes care of handling all of this information (that I know of). I use a variety of third party services to handle particular types of information; you may not need them all for your meetup, but hopefully this list will serve as some reference:      Email. Create a new meetup-specific email account with a service like Gmail, store its credentials somewhere safe (like a password manager), and share them with any co-organisers you have via services like Keybase. Use this email address to create accounts for all of the other third party services you need for the meetup, and correspond with speakers and venues with it (where email is needed to do that).  The benefits of doing this, rather than using your personal email, are the transparency and burden-sharing with your co-organisers for any external communications that may need to occur. Also, should the time come when you want to step back as an organiser and relinquish the meetup to someone else, having this account separate from you personally will make handover significantly easier. I would recommend taking the viewpoint that the meetup should exist as its own entity, and not being tied tightly to you, personally.   Meetup.com. Regardless of your opinions of this site (and some technical people have pretty strong opinions about it), I would say that as of this writing, if your audience is in the English-speaking world, and you want your meetup to be found on the internet, you are going to need a paid account here (try and get a sponsor to pay for it, if possible).  You do not need to revolve your meetup around Meetup.com. I know of some organisers that use it just to springboard their audience to other systems, like Eventbrite. I only use its very basic features: discoverability via search, scheduling, RSVP management, and very occasionally member emails. I want the key information about the meetup to be separate from, and accessible out of, Meetup.com (in case it ever disappears or I want to change platforms), and so I use other services for this.   Github. As a developer you probably use GitHub (or one of its source-control competitors) every day and are intimately familiar with its workflows. I use it as the source of truth for meetup information (so it doesn\u2019t have to be Meetup.com), and for handling the life-cycle of talk submissions (using Issues).  A meetup has its own dedicated organisation and repository, and each individual meetup is represented by a folder in the repository. It contains a README file with meetup information (which gets copied over to Meetup.com), as well as the host presentation materials for that meetup.  Issue templates are used to guide people through the creation of full-length talk, lightning talk, and talk request submissions, and outline the general definitions and expectations of them (eg for this meetup, a \u201cfull-length\u201d talk means no more than 40 minutes long and a \u201clightning talk\u201d is typically about 5 minutes etc). Every meetup has its own milestone that issues are marked against to symbolically \u201clock in\u201d a talk for that meetup.  Once a meetup has concluded, I encourage speakers to share their presentation materials publicly somewhere, then close the meetup issues, and their corresponding milestone. You can see examples of all this in the repositories for RORO Sydney, Elixir Sydney, GraphQL Sydney, or Elm Sydney.   Twitter. The most widely used social media platform for technical people would seem to currently be Twitter. So, each of the meetups I organise has its own Twitter account, used for meetup and speaker promotions, announcements, and requests for talks. I try and aim for a promotional tweet with speaker and talk names at the beginning of the week the meetup is scheduled to occur.   Dropbox. Used essentially as an asset host for media contained in the meetup host presentation slide deck (so, not like an asset host would be used if images were being serving on a web page that gets lots of hits).   Slack. There are official Slack workspaces for the programming languages the meetups I organise cover, and so I promote meetups in the #australia channels there, as well as in other programming community workspace channels where I am relatively sure it will not be seen as spam.   Zoom. Covered in detail above, but definitely get a paid Pro account if you are able to.   YouTube. As you may expect, a meetup\u2019s YouTube channel is the place to upload videos to share with and promote to the world (given the large size of video files, I also consider the meetup YouTube channel to be the source of truth for meetup videos). Make sure that your speakers know in advance that there is the intention of putting videos of their talk up on the meetup YouTube channel.  Also, be understanding of times when you may be asked to either not upload a video, or take one down. Speakers may have let information slip out that they didn\u2019t mean to (or regret in hindsight), or maybe they think the talk just did not go well enough to want it on their permanent record. Regardless of the reason, remove the video from the meetup channel. Meetup organisers are meant to spread community cheer and knowledge, not role-play as investigative journalists busting suspects on tape.   Meetup Host Slide Deck   Assuming that your meetup will have at least one talk, now that you have procured your most important content, let\u2019s examine the creation and maintenance of content that can bookend it.      Although certainly not needed to run a successful meetup, I like to have a meetup host slide deck to be point of reference for the event itself.   I typically include slides covering the following areas:      Welcome participants to the meetup   Housekeeping   Summarise the meetup content   Inform participants if any particular behaviour is expected of them (eg your meetup may have a Code of Conduct)   Thank sponsors (if any)   Introduce and hype-up the presenters and their talks (I like to have the presentation name, speaker name and social media handle, and a photo of the speaker \u2013 all as large as possible; these slides can then double as video thumbnails).   Prompt for people to submit talks for the next meetup, and provide details of where they should submit proposals (basically, a summarised version of the Speak at a Meetup post)   Promote the social media accounts of the presenters and the meetup itself   Prompt discussion of community news and events (see if you can trade meetup shout-outs with others in your ecosystem)   Prompt those who have jobs to promote, and those who wish to promote themselves for jobs, to give their pitches   Promote any other relevant community communication media (eg chat channels where post-meetup conversations can continue etc)   Inform the date and location of the next meetup   This might seem like a long list, but within the context of running the meetup, some of these slides might only be up on screen for a matter of seconds. The order that these slides are displayed is also up to you: for example, you may want to have your jobs slide before the talks, so that any recruiters present can say their piece, and then feel free to leave if they do not want to sit through any technical content.   Ultimately, though, no one comes to a meetup for the host deck, so I have found it best to attempt to deliver all necessary information as briskly as possible, so that we can make way for speakers.   Slideware   When it comes to slideware used to create the host deck, I tend to optimise for:      Markdown-based slide creation   Ease (and correctness) of export to PDF functionality   We are not creating the slide deck for An Inconvenient Truth here, so software like Keynote or PowerPoint does not feel like the right tool for this particular job (though if you have a particular affinity to either of these, by all means please use them; I still use them for other types of presentations, so there is no slideware elitism here).   Being a developer, I do like plain text that I can edit in a plain text editor. If the deck is a simple text file, it can easily be put under version control with Git to enable collaboration with others, and then readily shared online.   I have previously used GitPitch and MDX Deck to do this (and they are both good!), but my current slideware of choice is Deckset. It is not free (and currently only for Mac OS), but I have found the value I get out of it justifies the license cost (though I do hope more themes are added in the future\u2026).      Deckset\u2019s export to PDF functionality is great, and I find that the PDF slides actually reflect how the slides look when viewed in the application. In my experience, this is not always the case with other applications, which is why I always export a PDF copy of the deck and commit it along with the original Markdown file.   The PDF will always be smaller than its equivalent Keynote or Powerpoint file, and does not really bloat the repository size. Hosting image assets used in the slide deck outside of the repository also helps in keeping the repository size down.   Exception Handling   Regardless of whether you have a fantastic community with wonderful people, as an organiser, consider giving at least give some thought to potential worst-case scenarios that could occur at your meetup, for your community\u2019s sake.   If desired, enact some kind of formal authoritative framework, like a code of conduct, that explicitly outlines expectations of what actions should be taken when things go wrong, so it takes the guesswork out of what to do in undesirable situations, enabling you to focus on just taking action.   Audience Issues   You want speakers to not just have a great speaking experience at your meetup, but they should feel happy to come back and deliver more content to your community. If there are people in the audience who are disrupting a speaker, then you are well within your rights as an organiser to caution them, or ask them to leave.   Some speakers are very confident in their personality and speaking skills, and sometimes even actively invite audience heckling for their own amusement. Regardless of a speaker\u2019s ability to handle this, I personally discourage it because of the negative message it sends to people in the audience who might be considering giving a talk, but are not experienced or confident speakers: you might be heckled and no one will stop it (leading to your embarrassment in front of everyone).   I think that everyone should be able to feel undaunted about giving a talk to their peers, knowing that they have the support of the room. The benefits of a no-heckling policy far outweigh any charges of being a killjoy.   Speaker Issues   It is extremely difficult, if not impossible, to determine the quality of someone\u2019s content in advance of a meetup unless it is actually shared with you ahead of time (sometimes, speaker preparation can even last until the minute they get up on stage).   In principle, I am fine with this for any new speaker, or speakers who have successfully delivered talks before. Anyone who has willingly taken on the Big Ask to provide content is already a hero in my eyes, and has my assumption of good faith; I am not prepared to enforce conditions like vetting all talks, even if I had a mythical pipeline of eager speakers. Finding content is hard enough, and the less obstacles to getting that content delivered at a meetup, the better.   So, unless you get a request for assistance, the first time you will hear a speaker\u2019s talk is likely to be at the meetup itself. For the meetups I organise, this has not been an issue, aside from the very rare cases when it is.   Specifics are not relevant, and \u201cbad\u201d is subjective. But, ultimately, if you think that content delivered by a speaker at a meetup you organise (or by anyone who has been given the floor to address the audience, including those pitching jobs) has had a negative effect on your audience, could reflect badly on you as the organiser, or your ability to get an audience to a future meetup, then I think you are within your rights to either reject further submissions from them, or at least insist on a dry run of any talk prior to being accepted, where you can give feedback in the same way you would if they had actively requested it of you. If the content delivered is just patently offensive or inappropriate, you have no obligation to let a speaker finish their talk.   For the record, I have never had to outright reject someone\u2019s future submissions nor eject a speaker before they finished their talk (Sydney tech communities are really great!), but I would if the situation necessitated it.   Edge Cases   There are some problems I have yet to encounter while organising a meetup, that I hope I will never have to, but still occupy a slot in my list of worries.   Specifically, what if someone chokes on food provided at the meetup, or slips on something and falls, and an ambulance has to be called? Or, what if someone drinks too much and decides to get violent with people or property, and police have to be called? Is anyone liable in this situation? If so, who? The venue? Me, personally? Does the meetup itself have coverage under the venue\u2019s insurance policy? I am sure that the answer to this can vary drastically by jurisdiction and country, but I am wondering if there are any general rules of thumb to follow here, or maybe if I am worrying too much.   If you are knowledgeable about these kinds of issues, please reach out to me privately or share your experience or expertise in a comment. It would be great to learn more about this while in-person meetups are on hiatus.   Succession Planning      Engagement with any kind of work, like any good story, will have a beginning, middle, and end. Organising a meetup is no different: there will come a time where you will need to step back and divest yourself of organisational involvement in your meetup.   Assuming that your meetup has been created as its own entity, and is more than a cult of personality of your own making, you will likely want the meetup to outlast your involvement in it, if for no other reason than to continue your involvement as just another attendee.   I think that the best ways to ensure a smooth transition of responsibility is to have:      Co-organisers. The higher your bus factor, the easier handover will be (and the ability to take holidays!). There is probably an upper limit that, if exceeded, results in a too many chefs-style situation, but I have not hit that yet. Having said that, the biggest meetup organisational team I have worked on has been three people, which has been a fine number.   Long Goodbyes. If you manage to recruit another organiser because you plan to step down, try not hand them the keys to the meetup, wish them the best for the next one, and then disappear. I would recommend having them shadow you for a meetup or two, then take an organiser back seat for the next one or two as your successor takes the lead, and then fade away into the night.   Conclusion   I think you now know everything that I do about organising meetups, save for perhaps some intuitive on-the-fly problem solving skills you naturally develop after having actually organised and run a few meetups (and are impossible for me to enumerate coherently in this post).   I hope you are able to contribute to creating the kinds of communities you would like to see exist and thrive.   My thanks go out to you for reading this all the way to the end, and also to all the previous and current organisers of meetups I am currently involved with, or have been previously involved with, whose shoulders I stand on:      Ruby on Rails Oceania Sydney (RORO)   Elixir Sydney   GraphQL Sydney   Elm Sydney   Thanks also go to the organisers of other particular meetups I attend, and have been inspired by, or flagrantly stolen ideas from (no surprises that they are also web development-focused groups):      SydCSS   SydJS   React Sydney   There are so many differing opinions about the ways to run meetups, that I have no doubt that there are ways I can improve the way I run mine. So, if you have any feedback, suggestions, or ideas, by all means please leave a comment or reach out to me directly.      ",
categories:[],tags:["meetups","public-speaking"],url:"/blog/organise-meetups/",teaser:"/assets/images/2021-01-04/roro.jpg"},{title:"Your Code: Episode I - The Phantom Repository",excerpt:"Where is your beginner\u2019s code? You know, the code you wrote when you were first learning how to program.   If you started your developer journey after the advent of social coding sites like GitHub, chances are probably good that you learned to push early and often to your public repositories (that I would wager you use as part of your programming portfolio), and so you likely have a complete history of all the coding you have ever attempted.   But what about if you are a bit older, and you either taught yourself, or learned software engineering at one of those highfalutin tertiary education facilities like a university (think coding bootcamp but it takes years to graduate)? Is your beginner\u2019s code resting in stasis on some hard drive in your junk drawer? Or, maybe just lost to the sands of time\u2026?   If you do not know, go look for it. If you find it, see if it still runs. If it works, make it public.   You Will Be A Jedi. I Promise.   Looking through your beginner\u2019s code may make current-you cringe, but much like the old photo albums containing pictures of you with that goofy smile and crazy hairstyle that will surely never come back into fashion again, that code is a part of the story that made you the developer you are today. Be proud of it!   Releasing it publicly can contribute to our shared history of how coding was taught and learned: what languages were in vogue for teaching programming, and what kinds of exercises were used to help students grasp programming concepts.   Furthermore, junior developers who are just starting out on their journey, doing it tough, and probably battling impostor syndrome, can look at your tire fires and feel a bit better by being shown they should not expect to write great code immediately.   There\u2019s Always A Bigger Fish   In a previous post, Oi! Kochi: Japanese Feature Phone-driven Development, I made my first web site, what I would call my pre-beginner\u2019s code, public. So, to complement that, here is my beginner\u2019s code from when I was studying at the University of South Australia:      LMIF (LMIF was the course program code)   Now, This Is Podracing!   I enjoyed doing the minor repairs and documentation required to get this codebase in a releasable state.   Re-visiting the assignments brought back fond memories I have from my time doing this course: I had excellent professors and lecturers, some interesting assignments, and great classmate team members on my group assignments, some of whom are still friends to this day.   Stepping back and re-looking at it again without the nostalgic elements, though, there are a couple of observations I can make about the course and myself:      The course went all-in on Java (J2SE 1.4). Nearly all programming done for any subject that required it was in Java. The single non-Java programming course I had was named \u201cC++ for Java Developers\u201d, in case it needed to be made any clearer where the course\u2019s priorities were. In hindsight, it would have been nice to have been exposed to a dynamic language like Ruby or Python as well, but I understand why they just decided to focus on one primary language, that at the time look poised to take over the world (and it kind of did, at least for enterprise software, but when was the last time you used a Java applet on the web?).   It is clear to me that even by the end of the course, I had still not really gained an intuitive grasp of Object-orientated programming, functions, or code reuse (1000 line functions in a single class with lots of repetitive code is not something I would do or encourage today). But, hey, I passed the subjects, so\u2026   Are You An Angel?   If you have been diligently documenting your developer story as you have been creating code, you definitely have more foresight than I did. But, for those like me who were missing chapters from their story, it is never too late to retrieve those pages!   Breath some life into your old code and get it out into the world!   ",categories:[],tags:["beginner","learning","java","c-plus-plus","cpp"],url:"/blog/your-code-episode-one/",teaser:"/assets/images/2021-01-06/anakin-naboo-battle.png"},{title:"Stenography Numbers on a Georgi",excerpt:"As a present to myself for \u201ccompleting\u201d Typey Type, I picked up a Georgi keyboard, and since mid-July 2020, I have been using it as my daily driver for practising Plover stenography.   The Georgi\u2019s Kailh Choc Linear key switches with 12g ultra light springs make chording a breeze. However, its compact form factor means it has a set of number (#) keys in the thumb clusters of both halves of the keyboard, rather than a number bar (or row of keys that effectively substitute for a number bar if you are using a traditional keyboard, rather than a stenotype machine).       This change does not interfere with the majority of how anyone would use a stenographic keyboard, since, in general, we tend to type numbers significantly less frequently than letters and words. However, if you do use numbers often, then some muscle memory re-wiring will be in order to adapt to the number keys.   In order to help with memorisation, specifically around which # key to press for a given outline, I created a set of images indicating the chords pressed for each number from 0-99, and the set of hundreds numbers from 100-900, with the # key that felt right for me.      You can download a PDF containing all the images in the animated GIF above at the following link:      georgi-numbers.pdf   Also, here are some compare and contrast videos of stroking Plover steno numbers on both a Georgi and an Ergodox EZ (which I originally started learning stenography on):                                                                         I am still learning, so I am definitely not fast. Also, these videos are not   representative of my current accuracy: it took me tens of takes to record each   video until I was able to not make any major mistakes (and even then, they are   not perfect runs).    Rules   After discovering which number chords \u201cfelt right\u201d, I tried to see if I could summarise (read: reverse-engineer) my choices into a set of subjective rules. So, here is what I came up with:   General Rules      Always use two hands to stroke the outline, even if it is possible to use only one hand. I do not want to have to remember whether a chord can be stroked with one hand or not, so just use two hands by default.        When the number outline is in steno order (ie for a two-digit number, the first digit value is less than the last digit value: 13, 48 etc), the # key used should be on the opposite side of the keyboard from the key of the last digit stroked.       So, for 13, the P key for \u201c3\u201d is on the left half of the keyboard, so the right # key should be used. Likewise, for 48, the -L key for \u201c8\u201d is on the right half of the keyboard, so the left # key should be used.                    When the number outline is not in steno order (ie for a two-digit number, the first digit value is greater than the last digit value: 31, 84 etc), then the # key used is always on the left since the EU inversion chord must be stroked, and a thumb cannot comfortably stroke all three keys in the thumb cluster at once.               The thumb cluster rule: where a number outline requires non-# keys in the thumb clusters (ie A, O, E, U), wherever possible, aim to only use your thumbs to stroke those keys. This generally limits you to stroking the following adjacent keys for number outlines: #A, AO, and EU.   Exceptions      When the number outline is in steno order, the # key used should be on the opposite side of the keyboard from the first digit stroked if that digit is:                     composed of two repeated instances of the same digit (22, 66 etc), requiring the -D key                                    a multiple of 100 under 1000 (100, 700 etc), requiring the -Z key                                    For the thumb cluster rule above, there are unavoidable exceptions for numbers 60, 70, 80, and 90, where the left ring finger needs to be brought down into the left thumb cluster for stroking the # key in the #O chord.                     Since stroking the number 900 requires the -T and -Z keys, and they are diagonal from each other, it is impossible to stroke naturally using standard steno hand positions. Therefore, stroking the outline for 900 requires a \u201cPhilly shift\u201d, where your right ring finger strokes the -T key, rather than your right little finger.              Plover does offer the #EUT outline to avoid needing to perform a Philly shift, but I do not find the Philly shift that awkward to stroke given that the # keys are already moving my hands out of standard steno positions anyway, and I want keep building muscle memory on the -Z pattern and not have to remember this one potential exception to the 100s rule.       All that just for numbers?   You may be reeling in horror at the need to remember so much just to chord two-digit numbers, and vow to just stroke digits individually, or temporarily switch to QWERTY mode to type numbers. I certainly could not argue with you!   But, I personally find this set of number outlines comfortable enough to stroke, and plan to continue giving them a go moving forward. If you are also a student, or a practitioner, of Plover stenography, then I hope that the materials in this blog post serve as some reference, or at least as some amusement.   If you do end up using the chords, or have any opinions on rule variations that you think would work better, please reach out to me or leave a comment!   ",categories:[],tags:["stenography","georgi","mechanical-keyboards"],url:"/blog/steno-numbers-georgi/",teaser:"/assets/images/2021-01-17/georgi.jpg"},{title:"Test-Driven Fairy Tale",excerpt:"   This story takes place when pigs spoke rhyme  And monkeys chewed tobacco,  And hens took snuff to make them tough,  And ducks went quack, quack, quack, O!     Have you ever told a story with your code?   No, I don\u2019t mean boring user stories, I mean real, make-believe stories!   The story of The Three Little Pigs is a real story. A fable, even!                       Illustration by Lee Sheppard.           It uses the rule of three to tell a simple story of pigs versus a wolf: each encounter sets up a scenario, which gets executed, results in a pay-off that affects the state of the story, and moves the plot forward.   But, can it be coded? Can we then use its test suite to actually tell the story? I decided to try and find out!   Nice stories deserve to be told using nice programming languages. So, I chose Ruby, since Matz, Ruby\u2019s creator, seems like a nice person. For testing, I chose RSpec, a Ruby tool that uses expressive language to write tests: just what I needed to describe the progression of the story.   You can find the Ruby code for my interpretation of the story at The Three Little Pigs Github repository, but nothing beats having someone read you a story.   So, gather round your monitors and devices, and let\u2019s re-visit this classic fairy tale together, which begins Once Upon A Time\u2026      ",categories:[],tags:["ruby","rspec","minitest","testing"],url:"/blog/test-driven-fairy-tale/",teaser:"/assets/images/2021-02-20/wolf.png"},{title:"\u2591\u2592\u2593\uff25\uff2c\uff2d\uff33\uff34\uff28\uff25\uff34\uff29\uff23\uff33\u2593\u2592\u2591",
excerpt:'80sfy.com, by Art Sangurai, is a pretty cool site if you love synthwave music or the 1980s in general.   It uses a SoundCloud and Giphy combination for maximum \uff21\uff25\uff33\uff34\uff28\uff25\uff34\uff29\uff23 effect to make you \uff26\uff25\uff25\uff2c  all the nostalgias, which got it a lot of love on Reddit.                 It is programmed primarily in Javascript with the React library. So, I decided to re-create it using Elm because why not, but also just because\u2026                       Retro Wave at PhotoFunia           You can see the results of those efforts here:      Elm 80sfy Website   Elm 80sfy Codebase   If the technical details of coding with Elm aren\u2019t your thing, you can stop reading here and just go and enjoy some \uff2f\uff35\uff34\uff32\uff35\uff2e beats.   Still here? Okay, man, let\u2019s talk some Elm learnings. Open up the codebase and follow along.   First, you gotta do the Random Shuffle                 There are two scenarios in the 80sfy application where an element of randomness is required:      Shuffling the order of tracks to be played in the SoundCloud playlist   Getting a random animated GIF URL from Giphy: the application supplies a random descriptive tag, and Giphy sends back a URL that is relevant to that tag   Unlike many other programming languages, there is no Math.random() or equivalent function in Elm that allows you to summon random numbers and use them on the spot.   Generating random numbers, or doing anything involving randomness like randomly shuffling or picking an item from a list, is the responsibility of the Elm Runtime. In order get a random number, you need to:      code up a description of the kind of random number you want to generate   send that description off to the Elm Runtime as a Cmd to have the number generated for you   handle the resulting message you get returned from Elm Runtime containing the random number   Creating a Random List of Numbers   Let\u2019s have a look at a simplified-down example of the first scenario for randomising the order of tracks in a playlist. First though, a bit of context around how the SoundCloud IFrame widget interacts with the Elm application.   The SoundCloud Widget API has a getSounds(callback) method that returns the list of sound objects in its playlist. In the Elm application, though, we do not need all of that information: as long as we can get the length of the widget\u2019s playlist, we can build up our own list of integer track indexes to determine the order that tracks should play.   When the Elm application wants to tell the SoundCloud player to play a track, it sends over an index number  n, and the SoundCloud player \u201cskips\u201d over to track n  in its playlist.                 So, let\u2019s pick up our story at the point when an Elm Subscription has:      received the playlistLength via an incoming Port message from Javascript (much more to say about ports later\u2026)   wrapped it in a PlaylistLengthFetched message   sent the message off to the Elm Runtime\u2026   \u2026which is then handled in the update function for the AudioPlayer   update : Msg -&gt; AudioPlayer -&gt; ( AudioPlayer, Cmd Msg ) update msg audioPlayer =     case msg of         -- ...         PlaylistLengthFetched playlistLength -&gt;             let                 generatePlaylist : Cmd Msg                 generatePlaylist =                     Playlist.generate playlistLength             in             ( { audioPlayer | playlistLength = playlistLength }             , generatePlaylist             )   Here, the playlistLength value is passed off to a Playlist.generate function, which defines the generation of a shuffled list of track indexes, and returns a Cmd to get the Elm Runtime to do the work of actually generating the playlist.  Let\u2019s have a look at how that randomness is created:   module Playlist exposing     ( generate     , -- ...     )  import Random exposing (Generator) import Random.List  -- ...  generate : Int -&gt; Cmd Msg generate playlistLength =     let         trackList : List Int         trackList =             List.range 0 (playlistLength - 1)          generator : Generator (List Int)          generator =             Random.List.shuffle trackList     in     Random.generate PlaylistGenerated generator   Here, we specify that:      List.range should build a simple list of integers   the Random.List.shuffle function from the Random.Extra package, which returns a Generator from the Random package, should shuffle the list   We now have our recipe defined for the generator (how we want a random number generated), so we:      specify that we want to have the generated playlist sent back to us from the Elm Runtime wrapped in a PlaylistGenerated message (defined as PlaylistGenerated (List Int) so the message has a place to hold the playlist)   send it off to the Elm Runtime with the Random.generate function   handle the PlaylistGenerated message from the Elm Runtime in the update function   update : Msg -&gt; AudioPlayer -&gt; ( AudioPlayer, Cmd Msg ) update msg audioPlayer =     case msg of         -- ...         PlaylistGenerated generatedPlaylist -&gt;             let                 ( playlist, cmd ) =                     Playlist.handleNextTrackNumberRequest                         generatedPlaylist                         audioPlayer.playlistLength             in             ( { audioPlayer | playlist = playlist }, cmd )   The details of the Playlist.handleNextTrackNumberRequest function are not needed for this example, but it essentially pops off the first number in the randomised generatedPlaylist, tells the SoundCloud widget to play the track in its playlist located at that index, and stores the remaining playlist in the audioPlayer model.   But, the main point here is that we have requested the Elm Runtime to generate a random list of integers for us, it has done so, and we have been able to store it in our model! If you want to dig deeper, check out the real Playlist code.   We have covered audio playlist generation, but in this application, you cannot have random tracks without random GIFs as well! This time though, rather than generate a list, we want to be able to randomly pick a tag from a static list and send it off to Giphy, so let\u2019s see how to do that.   Randomly Picking from a List   When the 80sfy application first starts, it goes and fetches a list of descriptive string tags from a local tags.json file, emitting a TagsFetched message once that has been attempted, which is then handled in the update function for the application\u2019s SecretConfig model (have you found the application\u2019s secret config yet\u2026? :wink:) in a similar way to the following:   update : Msg -&gt; SecretConfig -&gt; ( Config, Cmd Msg ) update msg secretConfig =     case msg of         -- ...         TagsFetched (Ok tags) -&gt;             let                 generateRandomTagForVideoPlayer : String -&gt; Cmd Msg                 generateRandomTagForVideoPlayer videoPlayerId =                     Tag.generateRandomTag videoPlayerId tags                  -- ...             in             ( { secretConfig | tags = tags }             , Cmd.batch                 [ generateRandomTagForVideoPlayer "1"                 , generateRandomTagForVideoPlayer "2"                 , -- ...                 ]             )          TagsFetched (Err error) -&gt;             -- ...   Once the tags have been read in, we store them in the secretConfig model, and then send out two Cmds to generate random tags, one for each videoPlayer in the application (yes, there are two, which crossfade between each other).   Let\u2019s take a closer look at the Tag.generateRandomTag function, that, like the Playlist.generate function earlier, is responsible for creating a random generator:   module Tag exposing     ( generateRandomTag     , -- ...     )  import Random -- ...   generateRandomTag : String -&gt; List String -&gt; Cmd Msg generateRandomTag videoPlayerId tags =     let         tagsLength : Int         tagsLength =             List.length tags - 1          randomTagIndex : Generator Int         randomTagIndex =             Random.int 0 tagsLength          generator : Generator String         generator =             Random.map (atIndex tags) randomTagIndex          randomTagGeneratedMsg : String -&gt; Msg         randomTagGeneratedMsg =             (RandomTagGenerated videoPlayerId)     in     Random.generate randomTagGeneratedMsg generator   atIndex : List String -&gt; Int -&gt; String atIndex tags index =     let         defaultTag : String         defaultTag =             "80s"     in     tags         |&gt; List.drop index         |&gt; List.head         |&gt; Maybe.withDefault defaultTag   It looks like randomly picking from a static list is a little bit more involved than generating a new random list. So, what\u2019s going on?      We specify that Random.int should generate a random index number between zero and the length of the tags list   We then use Random.map to create the generator that transforms that random index into the tag at the randomTagIndex of the tags list. (All lists in Elm are linked lists, with the potential to contain Nothing when we interrogate their contents, which explains the ceremony contained in the atIndex function, and why we cannot just write something like tags[index])   We then specify that we want to have the tag sent back to us wrapped in a RandomTagGenerated message (defined as RandomTagGenerated String String so the message has a place to hold both the videoPlayerId the tag is for, as well as the generated tag itself)   Finally, like in the previous example, we call Random.generate with the message to be handled in the update function, and the generator itself   The RandomTagGenerated message is then handled in the update function as follows:   update : Msg -&gt; Config -&gt; ( Config, Cmd Msg ) update msg config =     case msg of         -- ...         RandomTagGenerated videoPlayerId tag -&gt;             let                 randomGifUrlFetchedMsg : Result Error String -&gt; Msg                 randomGifUrlFetchedMsg =                     RandomGifUrlFetched videoPlayerId                  fetchRandomGifUrl : Cmd Msg                 fetchRandomGifUrl =                     Gif.fetchRandomGifUrl                         randomGifUrlFetchedMsg                         config.giphyApiKey                         tag             in             ( config, fetchRandomGifUrl )   Once the Elm Runtime returns the randomly generated tag in the RandomTagGenerated message, along with the videoPlayerId we specified ourselves in the generateRandomTag function, we use a Gif.fetchRandomGifUrl function to make a HTTP call out to Giphy to request a GIF URL (details of which are available in the codebase, but check out the the real Tag code for the details on picking random tags).                 For more information on random generators, see the The Elm Guide\u2019s Random section. If these two examples were too scoff-inducing-ly simple and you want some Hard Mode in your randomness, go check out Charlie Koster\u2019s article Randomness in Elm, and let him bend your mind a bit.   I am a Msg, like my Father before me                 The Elm guide is quite opinionated about Elm application structuring. While it advocates less structure and longer files, I find that as an application grows, I definitely prefer more structure and smaller files.   I like to have thematically-related functions grouped together, just to aid in my own understanding of the code at a glance, which seems to push me towards what would seem to be considered a React-style(?) \u201ccomponents\u201d way of thinking, so I will often use that word when referring to what are essentially the different \u201cparts\u201d of the application.   In my mind, the 80sfy application has a few \u201cmain\u201d components in it:      AudioPlayer   VideoPlayer   ControlPanel   SecretConfig   When you press the \u201cPlay\u201d button on the control panel, you start playing the audio and start playing the GIF videos, so these different parts of the application need to be able to communicate with each other.   Of course all of these messages can live at the \u201ctop level\u201d of the application, and the handling for every one of those messages can live inside one big update function. However, there are times where I would rather have a separate AudioPlayer.Update \u201cchild\u201d file, with its own update function, to handle thematically-similar messages specifically targeted at the AudioPlayer from the \u201cparent\u201d update function, and a similar structure for the other components.   The main update function can be the \u201ctrunk\u201d of the application tree, which can handle its own top level messages, and each named component can have its own separate update function that \u201cbranches off\u201d that trunk. Each component branch can emit messages that communicate back up to the parent trunk itself, or to other sibling branch components via the parent trunk.   This kind of concept is explained in a way that resonated with me in The Translator Pattern: a model for Child-to-Parent Communication in Elm by Alex Lew. The \u201ctranslator\u201d, in this context, refers to a function that uses a dictionary of parent-level message types to \u201ctranslate\u201d child-level messages into parent-level messages. The burden of performing a message \u201ctranslation\u201d lies with the parent update function, before it is able to send any Cmds off to the Elm Runtime.   I really liked the idea of some sort of parent-level message dictionary that child components could leverage when they generate Cmds, but I found I needed to slightly tweak the way that parent-child Msg/Cmd communication occurred, compared to Alex\u2019s blog post, to get it all making sense in my own head.                 So, let\u2019s see how this way of thinking works in practice in the 80sfy application.  I have adopted a naming convention of Msgs for the type alias that defines a record containing a list of all the top-level Msgs in the application, and dictionary for the function that returns the Msgs dictionary itself:   src/Msg.elm   module Msg exposing (Msg(..), Msgs, dictionary)  import AudioPlayer import ControlPanel import Key exposing (Key) import Ports import SecretConfig import Time exposing (Posix) import VideoPlayer   type Msg     = AudioPlayer AudioPlayer.Msg     | ControlPanel ControlPanel.Msg     | CrossFadePlayers Posix     | KeyPressed Key     | NoOp     | Pause     | Ports Ports.Msg     | SecretConfig SecretConfig.Msg     | ShowApplicationState     | VideoPlayer VideoPlayer.Msg   type alias Msgs =     { audioPlayerMsg : AudioPlayer.Msg -&gt; Msg     , controlPanelMsg : ControlPanel.Msg -&gt; Msg     , crossFadePlayersMsg : Posix -&gt; Msg     , keyPressedMsg : Key -&gt; Msg     , noOpMsg : Msg     , pauseMsg : Msg     , portsMsg : Ports.Msg -&gt; Msg     , secretConfigMsg : SecretConfig.Msg -&gt; Msg     , showApplicationStateMsg : Msg     , videoPlayerMsg : VideoPlayer.Msg -&gt; Msg     }   dictionary : Msgs dictionary =     { audioPlayerMsg = AudioPlayer     , controlPanelMsg = ControlPanel     , crossFadePlayersMsg = CrossFadePlayers     , keyPressedMsg = KeyPressed     , noOpMsg = NoOp     , pauseMsg = Pause     , portsMsg = Ports     , secretConfigMsg = SecretConfig     , showApplicationStateMsg = ShowApplicationState     , videoPlayerMsg = VideoPlayer     }   The Msgs in the dictionary are a mix of \u201ctop-level\u201d-only messages, like CrossFadePlayers Posix or NoOp, and messages like AudioPlayer AudioPlayer.Msg, where the \u201ctop-level\u201d or \u201cparent\u201d part of the message is meant to indicate which component\u2019s update function the message should be sent to (AudioPlayer), and the constructor parameter (AudioPlayer.Msg) is the specific message to be handled by the child component\u2019s update function.   The dictionary is initialised as soon as the application starts, in the main function, and is passed into every function that needs to send top-level messages (ie all of them):   src/Main.elm   module Main exposing (main)  import Browser import Flags exposing (Flags) import Model exposing (Model) import Msg exposing (Msg, Msgs) import Subscriptions import Update import View -- ...   main : Program Flags Model Msg main =     let         msgs : Msgs         msgs =             Msg.dictionary     in     Browser.document         { init = init         , update = Update.update msgs         , view = View.view msgs         , subscriptions = Subscriptions.subscriptions msgs         }  -- ...   At this point, your spidey-sense may be tingling regarding passing in a record of global context this large (I do not consider it \u201cglobal state\u201d as-such since the dictionary content will never be transformed or \u201cchanged\u201d) to the three main sections of the application.   Surely all ten Msg types in the dictionary are not needed in every section of the application, right\u2026? Correct, and that\u2019s why we are going to lean on Elm\u2019s Extensible Records types to help \u201cfilter\u201d this dictionary down to the bare minimum of top-level messages that each part of the application needs to use.   Let\u2019s see what this looks like in the top-level Update function:   src/Update.elm   module Update exposing (update)  -- ...  type alias Msgs msgs =     { msgs         | audioPlayerMsg : AudioPlayer.Msg -&gt; Msg         , pauseMsg : Msg         , portsMsg : Ports.Msg -&gt; Msg         , secretConfigMsg : SecretConfig.Msg -&gt; Msg         , videoPlayerMsg : VideoPlayer.Msg -&gt; Msg     }   update : Msgs msgs -&gt; Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update parentMsgs msg model =     -- ...   The Update module essentially re-defines the type of the Msgs record that is passed to it, restricting its entries down to only those top-level messages that it needs to care about. This helps to keep the record content more focused, and feel a bit less heavy than the record with ten entries that was originally passed in.   We got a 50% reduction in entries from the original record in the Update module, so let\u2019s see how much of one we get in the View and Subscriptions:   src/View.elm   module View exposing (view)  -- ...  type alias Msgs msgs =     { msgs         | audioPlayerMsg : AudioPlayer.Msg -&gt; Msg         , controlPanelMsg : ControlPanel.Msg -&gt; Msg         , noOpMsg : Msg         , pauseMsg : Msg         , portsMsg : Ports.Msg -&gt; Msg         , secretConfigMsg : SecretConfig.Msg -&gt; Msg         , showApplicationStateMsg : Msg         , videoPlayerMsg : VideoPlayer.Msg -&gt; Msg     }   view : Msgs msgs -&gt; Model -&gt; Document Msg view msgs model =     -- ...   src/Subscriptions.elm   module Subscriptions exposing (subscriptions)  -- ...  type alias Msgs msgs =     { msgs         | audioPlayerMsg : AudioPlayer.Msg -&gt; Msg         , controlPanelMsg : ControlPanel.Msg -&gt; Msg         , crossFadePlayersMsg : Posix -&gt; Msg         , keyPressedMsg : Key -&gt; Msg         , noOpMsg : Msg         , portsMsg : Ports.Msg -&gt; Msg         , videoPlayerMsg : VideoPlayer.Msg -&gt; Msg     }   subscriptions : Msgs msgs -&gt; Model -&gt; Sub Msg subscriptions msgs model =     -- ...   The reduction in entries is not quite as great for these two modules, but at least there is a reduction, and the record can only get smaller as it gets passed down further into child components.                 As an example, let\u2019s follow the journey of the Msgs record as it gets passed down into the AudioPlayer child component from the Update module:   src/Update.elm   module Update exposing (update)  import AudioPlayer -- ...  type alias Msgs msgs =     -- ...  update : Msgs msgs -&gt; Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update parentMsgs msg model =     case msg of         Msg.AudioPlayer msgForAudioPlayer -&gt;             let                 ( audioPlayer, cmd ) =                     AudioPlayer.update                         parentMsgs                         msgForAudioPlayer                         model.audioPlayer             in             ( { model | audioPlayer = audioPlayer }, cmd )         -- ...   The parentMsgs are passed into the AudioPlayer.update function, along with whatever msgForAudioPlayer needs to be handled there, as well as the model.audioPlayer, which for all intents and purposes becomes the \u201cmodel\u201d for the AudioPlayer component.   Let\u2019s see how the type definition has changed for the Msgs in the AudioPlayer component. The AudioPlayer.elm file acts as the gateway to all audio player-related functionality, with implementation details all hidden away in sub-modules (which we will talk about in more detail later on):   src/AudioPlayer.elm   module AudioPlayer exposing     ( AudioPlayer     , Msg     , update     -- ...     )  import AudioPlayer.Model as Model import AudioPlayer.Msg as Msg import AudioPlayer.Update as Update -- ...  type alias AudioPlayer =     Model.AudioPlayer  type alias Msg =     Msg.Msg  -- ...  update : Update.ParentMsgs msgs msg -&gt; Msg -&gt; AudioPlayer -&gt; ( AudioPlayer, Cmd msg ) update parentMsgs msg audioPlayer =     Update.update parentMsgs msg audioPlayer   The update function simply calls the AudioPlayer\u2019s own internal Update.update function, but the thing to notice here, is that parentMsgs is now defined in terms of a Update.ParentMsgs msgs msg type: a further-filtered, child-component-defined record type that only contains the parentMsgs that the AudioPlayer\u2019s update function needs to use.   Notice also that the AudioPlayer.update is returning a lower-cased Cmd msg, as apposed to the Cmd Msg in Update.update. The msg here is a type variable that can technically match any type, but in this case it must match one of the types contained in parentMsgs, hence the msg in the Update.ParentMsgs msgs msg declaration. The child component does not know the specifics about the parent messages: it just knows that it needs to return the type of message that the parent is expecting to get back.   Let\u2019s see what the Update.ParentMsgs msgs msg look like now:   src/AudioPlayer/Update.elm   module AudioPlayer.Update exposing (ParentMsgs, update)  import AudioPlayer.Model as Model exposing (AudioPlayer) import AudioPlayer.Msg as Msg exposing (Msg) -- ...   type alias ParentMsgs msgs msg =     { msgs         | audioPlayerMsg : Msg -&gt; msg     }   update : ParentMsgs msgs msg -&gt; Msg -&gt; AudioPlayer -&gt; ( AudioPlayer, Cmd msg ) update { audioPlayerMsg } msg audioPlayer =     -- ...   The record has been reduced down to a single entry, the audioPlayerMsg, which is defined from the child component\u2019s perspective as being as a function that takes one of the AudioPlayer\u2019s own Msg types, and returns some kind of msg type from its parent that it does not know the details of.   This declaration mirrors the same function from the parent Update module\u2019s perspective, AudioPlayer.Msg -&gt; Msg, a function that takes in some message internal-to-AudioPlayer, returning a concrete Msg type.                 The existence of the Update.ParentMsgs alias belies the existence of similar aliases for a child component\u2019s View and Subscriptions functions. For example, staying with the AudioPlayer, we find this definition for the subscriptions function:   src/AudioPlayer.elm   module AudioPlayer exposing     ( AudioPlayer     , Msg     , subscriptions     -- ...     )  import AudioPlayer.Model as Model import AudioPlayer.Subscriptions as Subscriptions -- ...  type alias AudioPlayer =     Model.AudioPlayer  -- ...  subscriptions : Subscriptions.ParentMsgs msgs msg -&gt; AudioPlayer -&gt; Sub msg subscriptions parentMsgs audioPlayer =     Subscriptions.subscriptions parentMsgs audioPlayer   And the Subscriptions.ParentMsgs msgs msg is defined as:   src/AudioPlayer/Subscriptions.elm   module AudioPlayer.Subscriptions exposing (ParentMsgs, subscriptions)  import AudioPlayer.Model exposing (AudioPlayer) import AudioPlayer.Msg as Msg exposing (Msg) -- ...   type alias ParentMsgs msgs msg =     { msgs         | audioPlayerMsg : Msg -&gt; msg         , noOpMsg : msg     }   subscriptions : ParentMsgs msgs msg -&gt; AudioPlayer -&gt; Sub msg subscriptions parentMsgs audioPlayer =     -- ...   Similar to Update.ParentMsgs, Subscriptions.ParentMsgs restricts the passed in parentMsgs record to only a small subset of entries, including the noOpMsg, which it only knows as some msg type variable, without knowing its specific details.   All of the other child components in the 80sfy application handle the Msgs record in a similar way, concerning themselves only with the parent messages that they themselves use.   With regards to how these parent messages are used inside of views, and how they wrap their child messages, let\u2019s have a look at an example in the user interface code for the play/pause button in the ControlPanel:   src/ControlPanel/View/Controls.elm   module ControlPanel.View.Controls exposing (view)  import AudioPlayer exposing (AudioPlayer) import ControlPanel.View.Styles as Styles import Html.Styled exposing (Html, div, i) import Html.Styled.Attributes exposing (attribute, class, css) import Html.Styled.Events exposing (onClick) import Ports   type alias ParentMsgs msgs msg =     { msgs         | audioPlayerMsg : AudioPlayer.Msg -&gt; msg         , pauseMsg : msg         , portsMsg : Ports.Msg -&gt; msg     }   type alias Context a =     { a | audioPlayer : AudioPlayer }   view : ParentMsgs msgs msg -&gt; Context a -&gt; Html msg view parentMsgs { audioPlayer } =     let         -- ...          playing : Bool         playing =             AudioPlayer.isPlaying audioPlayer     in     div         [ css [ Styles.controls ]         , attribute "data-name" "controls"         ]         [ playPauseButton parentMsgs playing         -- ...         ]  -- ...  playPauseButton : ParentMsgs msgs msg -&gt; Bool -&gt; Html msg playPauseButton { pauseMsg, portsMsg } playing =     let         ( iconClass, playPauseMsg ) =             if playing then                 ( "fas fa-pause", pauseMsg )              else                 ( "fas fa-play", portsMsg Ports.playMsg )     in     div         [ css [ Styles.button ]         , attribute "data-name" "play-pause"         , onClick playPauseMsg         ]         [ div [ css [ Styles.iconBackground ] ] []         , i [ css [ Styles.icon ], class iconClass ] []         ]   Looking specifically at the playPauseButton function, and the value that is supplied to the onClick function, we can see that:      if the player is currently playing, the parameter-less parent message pauseMsg (read: Pause) gets sent as-is to be handled in the top-level Update.update function   otherwise, if the player is stopped, we fetch the Play Msg from the Ports module (Ports.playMsg), give that as a parameter to the portsMsg message (read: Ports Play), and send that off to be handled in Update.update as a message to be forwarded off to the Ports \u201cchild component\u201d for further handling (much more will be written about the Ports component later on\u2026)                 As you can see, if you want to split your Elm application out into discrete parts/components, there is a potential complexity/maintenance cost associated with doing so.   I am prepared to pay this cost since this way of doing things makes sense to me as an application grows. Given this subjective viewpoint, and the fact that the Elm Guide would seem to consider this way of doing things to be off the \u201cgolden path\u201d, definitely consider whether this approach is right for you, your team, and your application.   Say \u201chello\u201d to my little fa\xe7ade                 The fa\xe7ade pattern is probably my favourite software-design pattern, and I try and use it wherever it makes sense to make interfaces to different parts of a system more straightforward.   One of my software pet peeves is seeing one part of a system be able to break boundaries and reach down with impunity into the internals of another part of a system it has no business knowing about.      There are no natural barriers to handing out this kind of impunity in Elm, but   at least the elm-review-indirect-internal rule, for use with the fantastic   elm-review tool, can slap you on the wrist if you attempt to try.    In the previous section, you saw part of how I tried to put a \u201chard\u201d interface in the AudioPlayer module. Let\u2019s go back and re-open up that file, but instead have a scan of its entire content. For our purposes here, what the functions do is not important.   The main points are that there is no implementation code, all functions are simply one-line delegations out to sub-modules, and any other module in the application only needs to import the AudioPlayer module to interface with its functionality:   src/AudioPlayer.elm   module AudioPlayer exposing     ( AudioPlayer     , AudioPlayerId     , AudioPlayerVolume     , Msg     , -- ...     )  import AudioPlayer.Model as Model import AudioPlayer.Msg as Msg import AudioPlayer.Playlist as Playlist import AudioPlayer.Status as Status exposing (Status) import AudioPlayer.Subscriptions as Subscriptions import AudioPlayer.Task as Task import AudioPlayer.Update as Update import AudioPlayer.Volume as Volume import Ports exposing (SoundCloudWidgetPayload) import SoundCloud exposing (SoundCloudPlaylistUrl)   type alias AudioPlayer =     Model.AudioPlayer   type alias AudioPlayerId =     Model.AudioPlayerId   type alias AudioPlayerVolume =     Volume.AudioPlayerVolume   type alias Msg =     Msg.Msg   type alias TrackIndex =     Playlist.TrackIndex   init : SoundCloudPlaylistUrl -&gt; AudioPlayer init soundCloudPlaylistUrl =     Model.init soundCloudPlaylistUrl   adjustVolumeMsg : (Msg -&gt; msg) -&gt; String -&gt; msg adjustVolumeMsg audioPlayerMsg sliderVolume =     Msg.adjustVolume audioPlayerMsg sliderVolume   isMuted : AudioPlayer -&gt; Bool isMuted audioPlayer =     Status.isMuted audioPlayer.status   isPlaying : AudioPlayer -&gt; Bool isPlaying audioPlayer =     Status.isPlaying audioPlayer.status   nextTrackMsg : Msg nextTrackMsg =     Msg.NextTrack   performAudioPlayerReset : (Msg -&gt; msg) -&gt; SoundCloudPlaylistUrl -&gt; Cmd msg performAudioPlayerReset audioPlayerMsg soundCloudPlaylistUrl =     Task.performAudioPlayerReset audioPlayerMsg soundCloudPlaylistUrl   performNextTrackSelection : (Msg -&gt; msg) -&gt; Cmd msg performNextTrackSelection audioPlayerMsg =     Task.performNextTrackSelection audioPlayerMsg   performVolumeAdjustment : (Msg -&gt; msg) -&gt; String -&gt; Cmd msg performVolumeAdjustment audioPlayerMsg sliderVolume =     Task.performVolumeAdjustment audioPlayerMsg sliderVolume   rawId : AudioPlayerId -&gt; String rawId audioPlayerId =     Model.rawId audioPlayerId   rawTrackIndex : TrackIndex -&gt; Int rawTrackIndex trackIndex =     Playlist.rawTrackIndex trackIndex   rawVolume : AudioPlayerVolume -&gt; Int rawVolume audioPlayerVolume =     Volume.rawVolume audioPlayerVolume   soundCloudWidgetPayload : AudioPlayer -&gt; SoundCloudWidgetPayload soundCloudWidgetPayload audioPlayer =     Model.soundCloudWidgetPayload audioPlayer   statusToString : Status -&gt; String statusToString status =     Status.toString status   subscriptions : Subscriptions.ParentMsgs msgs msg -&gt; AudioPlayer -&gt; Sub msg subscriptions parentMsgs audioPlayer =     Subscriptions.subscriptions parentMsgs audioPlayer   toggleMuteMsg : Msg toggleMuteMsg =     Msg.ToggleMute   update : Update.ParentMsgs msgs msg -&gt; Msg -&gt; AudioPlayer -&gt; ( AudioPlayer, Cmd msg ) update parentMsgs msg audioPlayer =     Update.update parentMsgs msg audioPlayer   It would be nice if Elm had built-in syntactic sugar similar to, say, Elixir\u2019s defdelegate(funs, opts) function, in order to prevent the need to write function delegations \u201clonghand\u201d. But, leaving that aside, here are a few points worth bringing up regarding this file, as well as the general architecture of the application:      Within the AudioPlayer module, importing sub-modules (AudioPlayer.X modules) is unrestricted, but content from any other named module is only accessible via its top-level module (eg no reaching into Ports.Msg from AudioPlayer)   Types defined in sub-modules may be exposed via the top-level module as type aliases (eg AudioPlayer, Msg etc). So, as far as other top-level modules are concerned, if they import the AudioPlayer type, the fact that the type is actually defined in AudioPlayer.Model is unknowable implementation detail behind the API wall: they just see the AudioPlayer type coming in from the AudioPlayer module   Wherever possible, I have tried to make types be Opaque Types in order to hide their constructors, and further enforce boundaries on implementation details (even amongst sibling modules; see, for example, the Status type in Audio.Status).  The major exception to this would be the Msg type, which, similar to every other Msg in the application, needed to be exposed as Msg(..) from AudioPlayer.Msg so it could be used specifically for pattern matching in AudioPlayer.Update files, and consequently referenced directly as return values in functions like nextTrackMsg and toggleMuteMsg. But, just like any other type defined in a sub-module, if the Msg is to be exposed via the top-level module, it must only be via a type alias   All of the other modules in the 80sfy application that have enough internal implementation details to split out into sub-modules follow these patterns.   The Elm Guide would probably call all this fa\xe7ade-component application structuring a reflection of my programming \u201cculture shock\u201d. I think the points made in that section of the guide are reasonable, but I honestly just cannot agree with its advice of big files and comment header delimiters. I just want my code to be legible (and hopefully not just to me), and I currently think that this kind of structure can help in that goal.   You can be my wrapped type anytime                 Writing this application got me to become a big fan of Wrapped Custom Types, not just for the extra type safety, but also for the clarity they help give record type alias and Msg constructor definitions.   Before I knew about wrapped types, the AudioPlayer model looked like the following:   src/AudioPlayer/Model.elm   type alias AudioPlayer =     { id : String     , playlist : List Int     , playlistLength : Int     , soundCloudIframeUrl : String     , status : Status     , volume : Int     }   At face value, this could be considered reasonable, but is the AudioPlayer\u2019s id really the same kind of thing as its soundCloudIframeUrl? Are the Ints in the playlist really the same kind of Ints as the volume? Should they be\u2026?   After trying out creating some types to wrap the basic types, the AudioPlayer model was transformed into:   type alias AudioPlayer =     { id : AudioPlayerId     , playlist : List TrackIndex     , playlistLength : Int     , soundCloudIframeUrl : SoundCloudIframeUrl     , status : Status     , volume : AudioPlayerVolume     }   I think that this model with wrapped types conveys more meaning than the one with just basic types. So, I pretty much went all around the application codebase and wrapped every type I could that made sense, resulting in a total of 12 wrapped types created for 80sfy.                 In the land of wrapped types, though, conveying meaning does exert an overhead cost. For example, let\u2019s have a look at the ceremony required to wrap and unwrap a TrackIndex:   src/AudioPlayer/Playlist.elm   module AudioPlayer.Playlist exposing     ( TrackIndex     , -- ...     , rawTrackIndex     , trackIndex     )   type TrackIndex     = TrackIndex Int  -- ...  trackIndex : Int -&gt; TrackIndex trackIndex rawTrackIndexInt =     TrackIndex rawTrackIndexInt  rawTrackIndex : TrackIndex -&gt; Int rawTrackIndex (TrackIndex rawTrackIndexInt) =     rawTrackIndexInt   The AudioPlayer\u2019s playlist field must contain a List TrackIndex, therefore:      every \u201craw\u201d track index Int that goes into the list must first be wrapped by calling Playlist.trackIndex rawTrackIndexInt.   if you ever want to do something with the \u201craw\u201d Int value inside of a track index, then you have to unwrap it by calling Playlist.rawTrackIndex trackIndex   So, wouldn\u2019t it be easier to just\u2026not have wrapped types here? Yes, it would! But, this is the cost of adding (admittedly subjective) clarity to model types, and it is up to you to decide whether doing this is meaningful and worth the cost of admission.   Since the above example acts like some kind of wardrobe for an Int, putting on and taking off a TrackIndex-coloured coat without any change to the underlying raw value, let\u2019s have a look at some other scenarios where constraints or validation for the raw value are being added to the wrapping process.   The SecretConfig model contains the following values that can be populated by user input:   src/SecretConfig/Model.elm   type alias SecretConfig =     { gifDisplayIntervalSeconds : GifDisplayIntervalSeconds     , soundCloudPlaylistUrl : SoundCloudPlaylistUrl     -- ...     }   These types wrap around a Float and a String respectively, but because we cannot trust anything given to us by our hostile, power-suit-toting users, we need conditions on the raw values that serve as barriers to the wrapped types being created:   src/Gif.elm   module Gif exposing     ( GifDisplayIntervalSeconds     , displayIntervalSeconds     , -- ...     )   type GifDisplayIntervalSeconds     = GifDisplayIntervalSeconds Float  -- ...  displayIntervalSeconds : Float -&gt; Maybe GifDisplayIntervalSeconds displayIntervalSeconds rawDisplayIntervalSecondsFloat =     if rawDisplayIntervalSecondsFloat &gt; 0 then         Just (GifDisplayIntervalSeconds rawDisplayIntervalSecondsFloat)      else         Nothing   A non-positive display interval between animated GIFs does not make sense, so we only wrap positive values, and give malicious users Nothing.   Assuming that this is the only function we create to return new GifDisplayIntervalSeconds types, we build in some guarantees around the validity of raw values wrapped in a GifDisplayIntervalSeconds type that we could not get if it was a basic Float type.   Similarly, a SoundCloudPlaylistUrl isn\u2019t just any kind of String: it must have a correct prefix. If the raw value does, it gets wrapped; if not, Nothing:   src/SoundCloud/Url.elm   module SoundCloud.Url exposing     ( SoundCloudPlaylistUrl     , playlistUrl     , -- ...     )   type SoundCloudPlaylistUrl     = SoundCloudPlaylistUrl String  -- ...  playlistUrl : String -&gt; Maybe SoundCloudPlaylistUrl playlistUrl rawSoundCloudPlaylistUrlString =     let         playlistUrlPrefix : String         playlistUrlPrefix =             "https://api.soundcloud.com/"          isValidUrl : Bool         isValidUrl =             String.startsWith playlistUrlPrefix rawSoundCloudPlaylistUrlString     in     if isValidUrl then         Just (SoundCloudPlaylistUrl rawSoundCloudPlaylistUrlString)      else         Nothing   As you can see, Wrapped Types can provide more than just a fancy enclosure to a basic type. Aside from improvements in type readability, they can help assert the validity of the wrapped raw values, so I would highly recommend giving them a try in your own Elm codebases!   Ports? Where we\u2019re going we don\u2019t need ports                 My usage of ports in Elm applications previous to 80sfy was essentially as remote function calls out to the impure badlands of Javascript.   For every kind of operation I needed to leverage Javascript for, I would poke a port-shaped hole in the Elm application boundary, do the minimum amount of work in Javascript-land, and return control quickly to the pure, type-safe Elm application fortress.   For example, previous iterations of port-related code for the AudioPlayer, where communications needed to be sent out to the SoundCloud widget iframe, looked like the following, with functions named in the active voice:   src/AudioPlayer/Ports.elm   port module AudioPlayer.Ports exposing     ( pauseAudio     , playAudio     , skipToTrack     .. ---     )   port pauseAudio : () -&gt; Cmd msg   port playAudio : () -&gt; Cmd msg   port skipToTrack : Int -&gt; Cmd msg   -- and a bunch of other port declarations...   The Elm application would also need to know when the SoundCloud widget controls were used directly so it could update its own internal state. This occurred via subscriptions named in the passive voice:   src/AudioPlayer/Subscriptions.elm   port module AudioPlayer.Subscriptions exposing (Msgs, subscriptions)  import Json.Decode exposing (Value) -- ...   port audioPaused : (Value -&gt; msg) -&gt; Sub msg   port audioPlaying : (Value -&gt; msg) -&gt; Sub msg   port nextTrackNumberRequested : (() -&gt; msg) -&gt; Sub msg   -- ...   Soundcloud-specific details about the widget, and its events (and how to bind to them), can be found in the SoundCloud Widget API documentation. However, the more pointed thing to note about the Javascript code below, is that there are six named Elm app.ports that are having subscribe and send called on them (and this is just a sample; I originally had 28(!) named ports/subscriptions across the application):   src/soundCloudWidget.js   // ... function init(ports) {   // ...   const scPlayer = SC.Widget("track-player") // initialise SoundCloud player   scPlayer.bind(SC.Widget.Events.READY, () =&gt; {     initPlayAudio(scPlayer, ports)     initPauseAudio(scPlayer, ports)     initSkipToTrack(scPlayer, ports)     initTrackFinished(scPlayer, ports)     // other similar init functions...   }) }  function initPlayAudio(scPlayer, ports) {   // Elm tells the SoundCloud widget to play audio   ports.playAudio.subscribe(() =&gt; {     scPlayer.play()   })   // The SoundCloud widget tells Elm its been told to play (non-Elm request)   scPlayer.bind(SC.Widget.Events.PLAY, sound =&gt; {     ports.audioPlaying.send(sound.loadedProgress)   }) }  function initPauseAudio(scPlayer, ports) {   // Elm tells the SoundCloud widget to play audio   ports.pauseAudio.subscribe(() =&gt; {     scPlayer.pause()   })   // The SoundCloud widget tells Elm its been told to pause (non-Elm request)   scPlayer.bind(SC.Widget.Events.PAUSE, sound =&gt; {     ports.audioPaused.send(sound.currentPosition)   }) }  function initSkipToTrack(scPlayer, ports) {   // Elm tells the SoundCloud widget to skip over to a specific track number   ports.skipToTrack.subscribe(trackNumber =&gt; {     scPlayer.skip(trackNumber)   }) }  function initTrackFinished(scPlayer, ports) {   // The SoundCloud widget tells Elm its finished playing an audio track   scPlayer.bind(SC.Widget.Events.FINISH, () =&gt; {     ports.nextTrackNumberRequested.send(null)   }) }  // ...   I wrote the code like this because it was how I understood ports to work, and pretty much all the educational materials I read about ports implemented them essentially like remote function calls into Javascript.   However, while re-reading the Elm Guide\u2019s Ports section, I was greeted by this guidance buried down in the Notes section:      Definitely do not try to make a port for every JS function you need. You may   really like Elm and want to do everything in Elm no matter the cost, but ports   are not designed for that. Instead, focus on questions like \u201cwho owns the   state?\u201d and use one or two ports to send messages back and forth.                  Okay, the Elm Guide and I may currently have our differences with regards to application architecture, but I am open to the idea of being completely wrong about how I have written ports.   The next question was \u201care there examples of how to have all messages running through one or two ports?\u201d. These were not easy to find, but I was able to find two references that dealt with this question, and helped me get to the implementation I ended up running with:      The elm-port-message library   The elm-conf 2017 talk The Importance of Ports by Murphy Randle   From elm-port-message, I stole the idea of a generic \u201ctagged payload\u201d to use for all the kinds of messages that would flow in and out of Javascript.   From The Importance of Ports, I stole the idea of having all outbound port messages typed, and used in an update-style case statement that resulted in a Cmd being sent in a tagged payload through the single outbound application port.   The concept of having a single inbound and a single outbound port for message payloads also made me re-consider where code dealing with ports (and, to a lesser extent, subscriptions), should live in the codebase.   This resulted in a change of thinking about outbound ports themselves. From them just belonging to or being a part of a component (eg AudioPlayer.Ports above), to considering the Elm application boundary itself, where outbound port messages are sent to Javascript, being its own major component in the application, containing its own top-level module and Msg type:   src/Update.elm   module Update exposing (update)  import Msg exposing (Msg) import Ports -- ...   type alias Msgs msgs =     { msgs         | portsMsg : Ports.Msg -&gt; Msg         , -- ...     }   update : Msgs msgs -&gt; Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update parentMsgs msg model =     case msg of         -- ...         Msg.Ports msgForPorts -&gt;             ( model, Ports.cmd msgForPorts )         -- ...   You may have noticed that the view code for the ControlPanel\u2019s play/pause button in a previous section sends a portsMsg Ports.playMsg message when it is clicked. The code above is where that message, and others like it, end up being handled.   There is no model to update for these messages, nor parent message to keep track of: just a Cmd to be sent to the Elm Runtime, whose generation is delegated to the Ports.Cmd module:   src/Ports/Cmd.elm   port module Ports.Cmd exposing     ( cmd     , -- ...     )  import Json.Encode as Encode exposing (Value) import Ports.Msg as Msg exposing (Msg) import Ports.Payload as Payload -- ...   port outbound : Value -&gt; Cmd msg   cmd : Msg -&gt; Cmd msg cmd msg =     case msg of         -- ...         Msg.PauseAudio -&gt;             outbound (Payload.withTag "PAUSE_AUDIO")          Msg.PlayAudio -&gt;             outbound (Payload.withTag "PLAY_AUDIO")          Msg.SkipToTrack trackNumber -&gt;             let                 data : Value                 data =                     Encode.object [ ( "trackNumber", Encode.int trackNumber ) ]                  payload : Value                 payload =                     Payload.withTaggedData ( "SKIP_TO_TRACK", data )             in             outbound payload   Every typed Ports.Msg sends a tagged Payload, with or without some data, through a single outbound port. For the tag name convention, I decided to use Redux\u2019s original action type naming convention of "SCREAMING_SNAKE_CASE" (Elm is one of Redux\u2019s inspirations, after all).   Code for the payload itself lives under Ports.Payload, and specifies a unified way of encoding and decoding a JSON Value for this purpose. Rather than send any raw Elm types as parameters to ports (eg the Int in port skipToTrack : Int -&gt; Cmd msg), we specify that only Values can be sent and received via ports (which can also be enforced by the NoUnsafePorts rule in elm-review-ports):   src/Ports/Payload.elm   module Ports.Payload exposing (Payload, decode, withTag, withTaggedData)  import Json.Decode as Decode exposing (Decoder, Value) import Json.Decode.Pipeline as Pipeline import Json.Encode as Encode exposing (Value)   type alias Payload =     { tag : String     , data : Value     }   decode : Value -&gt; Payload decode value =     value         |&gt; Decode.decodeValue decoder         |&gt; Result.withDefault (Payload "" Encode.null)   withTag : String -&gt; Value withTag tag =     withTaggedData ( tag, Encode.null )   withTaggedData : ( String, Value ) -&gt; Value withTaggedData ( tag, data ) =     Encode.object         [ ( "tag", Encode.string tag )         , ( "data", data )         ]    -- PRIVATE   decoder : Decoder Payload decoder =     Decode.succeed Payload         |&gt; Pipeline.required "tag" Decode.string         |&gt; Pipeline.optional "data" Decode.value Encode.null   Now that we have outbound messages going out to Javascript via a single port, the Javascript code needs to change so that it can deal with these different types of tagged payloads, which is where we lean on our old friend switch:   src/js/soundCloudWidget.js   // ... function init(ports) {   const scPlayer = SC.Widget("track-player")   scPlayer.bind(SC.Widget.Events.READY, () =&gt; {     // ...     initOutboundPortMessageHandling(scPlayer, ports)   }) }  function initOutboundPortMessageHandling(scPlayer, ports) {   ports.outbound.subscribe(({ tag, data }) =&gt; {     switch (tag) {     case "PLAY_AUDIO":       scPlayer.play()       break     case "PAUSE_AUDIO":       scPlayer.pause()       break     case "SKIP_TO_TRACK":       scPlayer.skip(data.trackNumber)       break     }     // ...   }) }                 So, that\u2019s the first half of the story: Elm to Javascript. What about messages going from Javascript to Elm? Let\u2019s follow the journey, starting from Javascript, focusing on the events generated from the SoundCloud widget:   src/js/soundCloudWidget.js   // ... function init(ports) {   const scPlayer = SC.Widget("track-player")   scPlayer.bind(SC.Widget.Events.READY, () =&gt; {     // ...     bindSoundCloudWidgetEvents(scPlayer, ports)   }) }  function bindSoundCloudWidgetEvents(scPlayer, ports) {   scPlayer.bind(SC.Widget.Events.PLAY, sound =&gt; {     ports.inbound.send({       tag: "AUDIO_PLAYING",       data: sound.loadedProgress     })   })   scPlayer.bind(SC.Widget.Events.PAUSE, sound =&gt; {     // ...     ports.inbound.send({       tag: "AUDIO_PAUSED",       data: sound.currentPosition     })   })   scPlayer.bind(SC.Widget.Events.FINISH, () =&gt; {     ports.inbound.send({       tag: "NEXT_TRACK_NUMBER_REQUESTED"     })   }) }   There\u2019s not too much difference in the code here compared to the previous implementation, aside from:      minor code re-structuring to put all the SoundCloud widget bindings together   all messages now being sent via a single inbound port   like the outbound messages, all inbound messages are Payload-shaped objects, rather than raw values   Of particular note, at least for me, is the "NEXT_TRACK_NUMBER_REQUESTED" payload, which can contain only a tag and no data information, and still be valid: essentially just a message telling Elm that \u201cthe next track number has been requested\u201d.      I think that sending this data-less payload object is a preferable option to  the original implementation, which explicitly required needing to send a  null back to Elm, when the objective was really to call send without any  parameters:     What I wanted to do in the original code:     JS:      function initTrackFinished(scPlayer, ports) {    scPlayer.bind(SC.Widget.Events.FINISH, () =&gt; {      // Calling `send` on a port with no parameters is invalid, apparently...      ports.nextTrackNumberRequested.send()    })  }       Elm:      port nextTrackNumberRequested : (() -&gt; msg) -&gt; Sub msg       The port receives no parameters, so having () as the parameter is correct,   right\u2026? (Spoiler: Nope.)     What I ended up needing to do to make it go:     JS:      function initTrackFinished(scPlayer, ports) {    scPlayer.bind(SC.Widget.Events.FINISH, () =&gt; {      // Needing to send an explicit `null` seems a bit strange to me...      ports.nextTrackNumberRequested.send(null)    })  }       The only documentation I could find regarding needing to do this was this   Stack Overflow answer, so this information would be   a nice addition to the Elm Guide.     Anyway, using Payloads means this issue is now irrelevant, so let\u2019s get back   to Elm-land to see how messages coming through on the single inbound port   are being handled.    The inbound port definition lives in the top-level Ports module, making sure that knowledge about port modules (and hence the world outside of the Elm) are kept solely to the Ports and Ports.Cmd family of modules:   src/Ports.elm   port module Ports exposing     ( inbound     , -- ...     )  import Json.Encode exposing (Value) -- ...   port inbound : (Value -&gt; msg) -&gt; Sub msg   Since the different inbound messages will only be relevant for specific parts of the application, code to handle subscriptions still lives as sub-modules of the components the messages are relevant to.   For example, AudioPlayer-specific messages sent in the bindSoundCloudWidgetEvents function are handled in AudioPlayer.Subscriptions:   src/AudioPlayer/Subscriptions.elm   module AudioPlayer.Subscriptions exposing (ParentMsgs, subscriptions)  import AudioPlayer.Model exposing (AudioPlayer) import AudioPlayer.Msg as Msg exposing (Msg) import Json.Decode exposing (Value) import Ports -- ...   type alias ParentMsgs msgs msg =     { msgs         | audioPlayerMsg : Msg -&gt; msg         , noOpMsg : msg     }   subscriptions : ParentMsgs msgs msg -&gt; AudioPlayer -&gt; Sub msg subscriptions parentMsgs audioPlayer =     Ports.inbound (handlePortMessage parentMsgs audioPlayer)    -- PRIVATE   handlePortMessage : ParentMsgs msgs msg -&gt; AudioPlayer -&gt; Value -&gt; msg handlePortMessage { audioPlayerMsg, noOpMsg } audioPlayer payload =     let         { tag, data } =             Ports.decodePayload payload     in     case tag of         "AUDIO_PAUSED" -&gt;             -- Handle "AUDIO_PAUSED" messages          "AUDIO_PLAYING" -&gt;             -- Handle "AUDIO_PLAYING" messages          "NEXT_TRACK_NUMBER_REQUESTED" -&gt;             -- Handle "NEXT_TRACK_NUMBER_REQUESTED" messages          _ -&gt;             noOpMsg   Some notes about this module:      Although stating this might be obvious for some, the handlePortMessage function is the (Value -&gt; msg) function in port inbound (Value -&gt; msg) -&gt; Sub msg   handlePortMessage receives the payload from Javascript-land, and performs  some action depending on the tag value, details of which are not important  here, but they are, of course, available in the codebase   Once it is known how the inbound message is to be handled, the work to generate the subscription is delegated off to the centralised Ports.inbound function                 So, while \u201cwhere we\u2019re going we did actually need ports\u201d, I think that cutting down the number of those ports from 28 to 2 can be considered a win. I hope that the example above, and the 80sfy codebase, can at least serve as an example of how to do centralised port message sending if that is a path you are looking at going down for your own Elm application.   When you code JS your heart dies                 My developer helmet got many dents on it as I repeatedly ran into walls while coding up the Javascript side of the 80sfy application.   Some of these issues were due to browser peculiarities, or undocumented quirks of the SoundCloud Widget API, which I am wagering has probably not received much love in a while. But, since all these issues occurred in Javascript-land, it did, however unfairly, became the target of my frustration.   So, without further adieu, here is a random list of JS-land issues I came across and how they needed to be fixed, which will hopefully save you some time if you ever encounter similar issues.   SoundCloud iframe loading delays   In the 80sfy application, the first request that ends up being made to the SoundCloud widget is to return the list of its sound objects, so that list\u2019s length can be sent back to Elm to form the basis of the shuffled playlist.   However, the SoundCloud iframe seems to require a little bit of time to initialise before it can get its sounds, so in order to avoid any "Uncaught Error: mediaPayload required." errors displaying in the browser JS console, I needed to introduce a one-time delay using setTimeout() before calling scPlayer.getSounds():   src/js/soundCloudWidget.js   function initAudioPlayer(scPlayer, volume, ports) {   // ...   window.setTimeout(() =&gt; {     scPlayer.getSounds(sounds =&gt; {       ports.inbound.send({         tag: "PLAYLIST_LENGTH_FETCHED",         data: sounds.length       })     })   }, 3000) }   The 3000 millisecond delay was the value gleaned from trial and error: values less than this did not seem to be long enough to make the error go away.   Firefox blur event issues   setTimeout() ended up (bafflingly) being the solution to another completely different issue: this time related to Firefox blur events.   In the 80sfy application, if you switch to another browser tab or window, which fires off a blur event, the GIFs stop playing, saving unneeded Giphy API calls when the application is not the centre of attention.   The issue is that, for Firefox only, if you click the SoundCloud widget iframe, it looks like Firefox considers it a different browser window, and fires off a blur event, stopping the GIFs unexpectedly. Scouring the internet for the cause of this issue led to this Gist comment, where:      For me, adding a 0 second timeout\u2026made it work in Firefox. The problem seems   to be that, at the time Firefox fires the blur event, it has not yet updated   the document.activeElement [the iframe], so it evaluates to false.    Trying that led to this code:   src/js/videoPlayer.js   function initWindowEventListeners(ports) {   window.addEventListener("blur", event =&gt; {     window.setTimeout(() =&gt; {       const activeElementId = event.target.document.activeElement.id       ports.inbound.send({         tag: "WINDOW_BLURRED",         data: activeElementId       })     }, 0)   })   // ... }   And\u2026it worked. Same behaviour across browsers now. Go figure \xaf\\(\u30c4)/\xaf                 Skipping tracks un-pauses SoundCloud player   Regardless of whether the SoundCloud iframe widget is paused or not, if you choose to skip to the next track in the playlist, it starts playing.   This may be intended behaviour for the widget, but it was undesired behaviour for me: I wanted to be able to skip tracks while continuing to be in a paused state.   So, since the call to scPlayer.skip forcably un-pauses the player, we need to check if the player was originally paused before the skip command was issued, and if so, keep the SoundCloud widget player paused by re-pausing it:   src/js/soundCloudWidget.js   function initOutboundPortMessageHandling(scPlayer, ports) {   ports.outbound.subscribe(({ tag, data }) =&gt; {     switch (tag) {     // ...     case "SKIP_TO_TRACK":       // Get player\'s original paused state       scPlayer.isPaused(paused =&gt; {         scPlayer.skip(data.trackNumber)         if (paused) {           // *re-pause* player if it was originally paused but got *un-paused*           // by the above call to `scPlayer.skip`.           scPlayer.pause()         }       })       break     }   }) }   Only tell Elm about \u201creal\u201d pause events   The \u201cre-pausing\u201d problem above caused a bit of a cascade of issues back into Elm-land.   There is code that binds to the SC.Widget.Events.PAUSE event, which sends a message to an inbound port to let Elm know that the SoundCloud player has been paused. The problem is that any \u201cforced re-pausing\u201d should not be considered a \u201creal\u201d pause event for Elm notification purposes.   So, the issue now is how can we intercept and interrogate a SoundCloud sound object in the PAUSE event callback to make sure that Elm only gets a "AUDIO_PAUSED" message when a \u201creal\u201d pause occurs?   The first thing we can do is something similar to the handling in the "SKIP_TO_TRACK" message, and only send the "AUDIO_PAUSED" message when the player has been actively paused:   src/js/soundCloudWidget.js   function bindSoundCloudWidgetEvents(scPlayer, ports) {   // ...   scPlayer.bind(SC.Widget.Events.PAUSE, sound =&gt; {     scPlayer.isPaused(paused =&gt; {       if (paused) {         ports.inbound.send({           tag: "AUDIO_PAUSED",           data: sound.currentPosition         })       }     })   })   This code works as expected for track skips that happen while a track is playing (the paused value above will be false when you ask if scPlayer.isPaused while it is playing), but not when the player is in a paused state and a track is skipped (resulting in the forced re-pause), since that will still count as a \u201cpause\u201d! Argh!   So, what needs to be done here is add a guard clause to check the state of the sound.loadedProgress. If it is 0, that means that a \u201cforced re-pause\u201d has occurred after a track skip has happened to a new track, which has not started playing yet, and hence has not recorded any progression:   src/js/soundCloudWidget.js   function bindSoundCloudWidgetEvents(scPlayer, ports) {   // ...   scPlayer.bind(SC.Widget.Events.PAUSE, sound =&gt; {     if (sound.loadedProgress === 0) {       return     }      scPlayer.isPaused(paused =&gt; {       if (paused) {         ports.inbound.send({           tag: "AUDIO_PAUSED",           data: sound.currentPosition         })       }     })   })                 Does all this sound confusing? It was! Please learn from my trial and error, and I hope you save yourself some time if you encounter similar issues!   All this code will be lost in time, like tears in rain                 I spent more time than I intended on architecting, refactoring, re-writing, and polishing this application, but I feel like during this journey I learned significantly more about Elm than I had known before.   It represents a conscientiously-written codebase to me now, but in the future, who knows? Maybe I will come around to the Elm Guide\u2019s way of thinking and abandon my stubborn ideas about application structure, or maybe there is some food for thought in here for other Elm developers (reach out and let me know!).   Anyway, it\u2019s just an application that plays synthwave sounds to animated GIFs, man. Grab an ice tea, don\u2019t think about it too hard, and just \uff52\uff45\uff4c\uff41\uff58.      For anyone who is curious about the glitched images, I used Photo Mosh to   initially add scanlines and some other effects, and then Image Glitch Tool   for the glitching.    ',
categories:[],tags:["elm","synthwave","retrowave","80s","functional-programming","soundcloud","giphy"],url:"/blog/elmsthetics/",teaser:"/assets/images/2021-05-02/synthwave-3941721_1280.jpg"},{title:"Coding Test Review: Sentia",excerpt:'I actually quite like coding tests.   Not whiteboard coding tests, or generic algorithm tests that read more like math problems (usually set by \u201ctech recruiting platforms\u201d, and performed under exam-like conditions), but \u201ctake-home\u201d tests where you get to build something practical in a specific technology stack.   They can be fun and stimulating in the same way as answering questions on Stack Overflow, or solving problems on learning platforms like Exercism, and can also be good fodder for your online coding portfolio. I find I nearly always learn something new, or a different way of doing something I may already know, that makes me re-think the way I have solved a problem.   In this instance, a friend sent me Sentia\u2019s coding test to check out, and simply because I felt like I had not begun a Ruby on Rails application from scratch in a long time, I decided to take a crack at it. So, here is my review of that attempt.   Here are the public links for the deployed application and codebase:      Sentia Coding Test application   Sentia Coding Test codebase      Disclaimer: I am not, nor have ever been, an employee of Sentia, nor have I   ever applied for employment there, nor is this post some kind of attempt to   get them to employ me; I just did their coding test for my own definition of   \u201cfun\u201d.     If you are applying there, or plan to in the future, you may want to stop   reading, and consider pretending that this blog post (and all the other   solutions people have posted) does not exist, so you   can greet their coding test with fresh eyes (assuming this one is still being   used\u2026)    Original Requirements   You will be required to create a Ruby on Rails application with the following features below. The sample CSV data required for the test can be found here. This application can be built in 1 hour.   Below is a list of user stories and requirements for each section of this application.   PART 1   As a user, I should be able to upload this sample CSV and import the data into a database.   IMPORTER REQUIREMENTS      The data needs to load into 3 tables. People, Locations and   Affiliations    A Person can belong to many Locations    A Person can belong to many Affiliations    A Person without an Affiliation should be skipped    A Person should have both a first_name and last_name. All fields need to be validated except for last_name, weapon and vehicle which are optional.    Names and Locations should all be titlecased   PART 2      As a user, I should be able to view these results from the importer in a table.   As a user, I should be able to paginate through the results so that I can see a maximum of 10 results at a time.   As a user, I want to type in a search box so that I can filter the results I want to see.   As a user, I want to be able to click on a table column heading to reorder the visible results.   Once the test has been completed. Please upload to Git Repo/Google Drive/DropBox or zip and email over back to &lt;person&gt; at &lt;person\u2019s email&gt;. \u220e   The sample CSV file contains the following data from a galaxy far, far away\u2026.                  Name       Location       Species       Gender       Affiliations       Weapon       Vehicle                       Darth Vader       Death Star, Tatooine       Human       Male       Sith       Lightsaber       Tiefighter                 Chewbacca       kashyyk       Wookie       m       Rebel Alliance       Bowcaster       Millennium Falcon                 yoda       Yoda\u2019s Hutt       Unknown       Male       Jedi Order       Lightsaber       \xa0                 Sheev Palpatine       Naboo       Human       Male       Galactic Republic       Lightsaber       \xa0                 Princess Leia       Alderaan       Human       Female       Rebel Alliance, Galactic Republic       Blaster Pistol       \xa0                 jabba the Hutt       Tatooine       Hutt       Male       Hutt Clan       \xa0       Jabba\u2019s Sale Barge                 Kylo Ren       chandrila       Human       Male       First Order       Lightsaber       \xa0                 Obi-Wan Kenobi       Stewjon       Human       M       Jedi Order       Lightsaber       Jedi Starfighter                 luke skywalker       Tatooine       Human       M       Rebel Alliance, Jedi Order       Lightsaber~!@@@       X-wing Starfighter                 Jar Jar Binks       Naboo       Gungan       Male       Galactic Republic, Gungan Grand Army       Energy Ball       Gungan Bongo Submarine                 R2-D2       Naboo       Astromech Droid       Other       Rebel Alliance, Galactic Republic       \xa0       X-wing Starfighter                 Han Solo       Corellia       Human       Male       Rebel Alliance       Blaster Pistol       Millennium Falcon                 Boba Fett       Kamino       Human       m       \xa0       Blaster       Slave 1                 Rey       Jakku       Human       f       Jedi Order       Lightsaber       Rey\u2019s Speeder                 padme amidala       naboo       Human       Female       Galactic Republic       \xa0       Naboo N-1 Starfigher                 C-3PO       Tatooine       Protocol Droid       Other       The Resistance       \xa0       -1                 Mace Windu       Haruun Kal       Human       Male       Jedi Order       Lightsaber       \xa0                 Lando calrissian       Cloud City       Human       Male       Rebel Alliance       Blaster Pistol       Millennium Falcon           :elephant:   First thing\u2019s first: let\u2019s address the elephant in the requirements:      This application can be built in 1 hour.    If this is true, then I am a terrible developer.   It took me a fair bit longer than that to write working code as-per requirements, debug the requirements (more on that later\u2026), get it deployed somewhere on the internet, and refactor the code to a state where I would be happy to submit it for public consumption and criticism (I was still refactoring it while writing this post).   If the intention is for someone to complete as many of the requirements as they can within that fixed 1 hour time frame, with the end result considered through the lens of that artificial constraint, then that should be made explicit.   Regardless, I think it would probably be for the best to just remove that line, and allow candidates attempting this test to just focus on submitting their best attempt, and keep imposter syndrome at bay for that little bit longer.   General Approach   Since the requirements around this application focus on it being a Ruby on Rails application, I decided to go as \u201cvanilla\u201d as possible with Rails.   This meant no explicit addition by me of any custom Javascript, or any front-end frameworks that use it, to help out with things like filtering or sorting information.   I also tried to add the least amount of third-party non-Rails-default gems as possible, only using:      ActiveRecord::PGEnum, due to its nice developer ergonomics in dealing with Postgres Enumerated Types (more about why they were even needed later\u2026)   Draper for decorators: I really do not like using Rails helpers for presentation logic, preferring instead to keep it attached to the object being rendered; raw data can come from the Rails model class, while transforming that data for display in a Rails view can come from a decorator   Kaminari for pagination, as I think it is currently the best gem for it   User Interface   Since interface design and making things pretty in general is a weak-point for me, I used this test as an excuse to give Tailwind CSS a try in order to style everything on the page (I have used Tachyons before on other toy projects, so I am generally positive to the utility-first CSS concept), as well as use Tailwind UI to (hopefully) grab ready-made code for certain types of components.      For the most part, this was true for the following parts of the app:      data table   upload button   search bar   pagination widget   But, as would be expected, it was not all quite as simple as plug and play. Integrating Tailwind into the Kaminari-generated pagination views probably took the most amount of time. But, I got there in the end, and am generally pleased with how it looks for the time spent on it.   For the most part, I left any long Tailwind-mnemonic-filled class strings as they were in the Rails view files. However, when those strings became too long, and generally difficult to read, I extracted them into separate SCSS files using Tailwind\u2019s @apply directive (see files under the app/javascript/stylesheets/ directory). I think I will likely continue to use this kind of strategy in the future with Tailwind class strings.   Overall, I am happy to have been able to stand on the Tailwind ecosystem\u2019s shoulders to build out the user interface, and will definitely consider using it again in future projects.   Data Issues   Turning our gaze towards the provided dataset that the application must be able to import, there is no doubt that the CSV file deliberately contains some corrupt/bad data that you are meant to be able to program defensively against.   My general intentions were to only not import an entry where the requirements specifically said not to (i.e. a person without an affiliation should be skipped), and where the data could not be reasonably munged into an acceptable format.                 Mis-spellings   So, this meant that Lightsaber~!@@@ could just be stripped of non-alphanumeric characters and become a valid Lightsaber weapon, but there were also issues around mis-spellings in the data, where I needed to give the application more knowledge around what kind of values it could expect to find in the CSV file, and what those values actually should be.   This occurred in the form of a Hash that maps values known to be found in the CSV file to their correct values:   app/services/data_importer/enum_field_parser.rb   MISSPELLINGS = {   "Yoda\'s Hutt" =&gt; "Yoda\'s Hut",   "Naboo N-1 Starfigher" =&gt; "Naboo N-1 Starfighter" }   I am pretty sure that Yoda does not own a pet Jabba.   Anyway, it is not possible for me to tell whether the introduction of these mis-spellings was deliberate in order to see if a candidate picked up on them, but I am going to wager that these were actually just typos, and the necessity for this kind of handling was not intentional.   Value Validity   Under C-3PO\u2019s entry, the value for the Vehicle is given as -1: an obvious ploy to make sure that you do not actually store this value in a Person\u2019s vehicle field.   However, if -1 is not a valid entry, it then stands to reason that I cannot trust any of those values in the file, and, therefore, need to give the application advance knowledge on what vehicles it can accept as valid.   This meant that for a Person entry, I ended up making every value provided for a non-name-related field an enumerated type: both in the application, and at the database level.   The fact that there was the spelling mistake for Yoda\u2019s location also made me assign enumerated types for the names of Locations and Affiliations. The application really does have too much advance knowledge of the limited scope of valid values it could get from the CSV file, but I did not see any other way around this while still ensuring data correctness.   Names   The requirements assume that the name values in the CSV file can be split out into first_name and last_name, which, taken at face value, they certainly can.   However, this leads to the issue of having a table that looks like this for some values:                  First Name       Last Name                       Princess       Leia                 Darth       Vader                 Kylo       Ren                 Jabba       The Hutt           Some nerds should have looked over this data before it went public because ackchyually\u2026      \u201cPrincess\u201d is a title, not a name, and \u201cLeia\u201d is Leia Organa\u2019s first name   \u201cDarth\u201d is a title, not a name, and \u201cVader\u201d is more like a first name   \u201cRen\u201d is not a last name, but is from Knights of Ren, and Kylo Ren used it more like a title once he became the inheritor of Ren\u2019s Knights   \u201cThe Hutt\u201d is not a last name, but refers to the Hutt species   So, although not part of the requirements, I figured that this meant the application really needed to deal with the concept of name prefixes (titles etc) and suffixes (you may have noticed their inclusion in the screenshot above).   Also, for names like Jabba The Hutt and Jar Jar Binks, without the application knowing in advance that \u201cThe Hutt\u201d is a suffix, it would not be able to tell the which words in either of those names comprise the first_name or last_name.   The ability to deal with the name situation was made a bit more straightforward thanks to Ruby 3.0\u2019s pattern matching capabilities. The parse_name method below returns an array containing [prefix, first_name, last_name, suffix]:   app/services/data_importer/person_parser.rb   def parse_name(name)   name_parts = name.split.map(&amp;:upcase_first)    case name_parts   in [name]     [nil, name, nil, nil]   in ["Darth" | "Princess" =&gt; prefix, *rest]     [prefix, *rest]   in [*first_names, "Ren" =&gt; suffix]     [nil, first_names.join(" "), nil, suffix]   in [*first_names, "The", "Hutt"]     [nil, first_names.join(" "), nil, "The Hutt"]   else     *first_names, last_name = name_parts     [nil, first_names.join(" "), last_name, nil]   end end   Something like the method above is, of course, doable without pattern matching, but I think the terseness above really helps in understanding how specific data shapes are pin-pointed, and then transformed into the desired output.   Application Code   Having spent more time with functional languages like Elixir and Elm recently, I definitely found their influence creeping into the way I want to write Ruby.   I definitely do not consider this a bad thing, nor do I (subjectively) think that the code reads less Ruby/Rails-like as a result (though I have, happily, challenged some Rails conventions). But, let\u2019s have a look at some examples of main the Person-related controller and model of the application and you can judge for yourself.   Controller   app/controllers/people_controller.rb   class PeopleController &lt; ApplicationController   def index     @people =       Person.search(params[:search])         .then(&amp;method(:sort_people))         .then(&amp;method(:paginate_people))         .then(&amp;method(:decorate_people))   end    private    def sort_people(people)     PeopleSorter.sort(people, sort_column, sort_direction)   end    def sort_column     @sort_column ||= Person.sort_column(params[:sort])   end    def sort_direction     @sort_direction ||= SortDirection.determine(params[:direction])   end    def paginate_people(sorted_people)     Paginator.paginate_array(sorted_people, params[:page])   end    def decorate_people(paginated_people)     PersonDecorator.decorate_collection(       paginated_people,       context: {         sort_column: sort_column,         sort_columns: Person.sort_columns,         sort_direction: sort_direction,         params: params       }     )   end end   A few notes about this code:      The code that assigns to the @people instance variable is written in a style mimicking the Elixir pipeline operator, through the use of Ruby\u2019s Kernel#then method (aka Kernel#yield_self). The collection of people that originally gets fetched from the database goes through a series of transformations (filtered via search -&gt; sorted -&gt; paginated -&gt; decorated) before being handed off to the view, so I thought this way of writing the main controller code would indicate that most clearly and explicitly.   I would have liked to have had the database do the sorting for me, rather than do it in Ruby-land, but the fact that sorting needed to happen on values contained in a Person\u2019s associations (locations and affiliations), made it untenable.   I originally had the implementation code for sort_direction up in the ApplicationController, since it is not specific to a Person; putting it there would, I think, be considered Rails convention for code of that nature. But, rather than counting on someone looking at a method call, which has no local definition, and then implicitly knowing that its definition could come from a superclass, I decided to extract it into a small, named service module (SortDirection), so there is an explicit call-out (SortDirection.determine).  I do not generally like using inheritance, and will try and avoid it where I can.   I created a small Paginator service module with the intention of keeping knowledge about Kaminari restricted to it. Who knows, maybe I might want to change over to something like will_paginate one day, and organising the code like this, using the Adapter pattern, will mean no changes will be required in the controller (yes, fine, guilty of YAGNI since this just a coding test, but I have no regrets\u2026).   Both sort_column and sort_direction are needed in the view, as well as in the controller. I have seen many codebases use the encapsulation-busting helper_method method to allow controllers and views to share methods (I even used it in earlier iterations of this code). However, since decorators are being used in this application, this can be avoided by explicitly passing in whatever extra controller information is needed in presentation logic via a context hash, that is only accessible within the confines of the decorator class.   Model   app/models/person.rb   class Person &lt; ApplicationRecord   include PGEnum(     species: Enum::SPECIES,     gender: Enum::GENDERS,     weapon: Enum::WEAPONS,     vehicle: Enum::VEHICLES   )    has_many :loyalties   has_many :affiliations,            -&gt; { order("affiliations.name ASC") },            through: :loyalties   has_many :residences   has_many :locations,            -&gt; { order("locations.name ASC") },            through: :residences    def self.search(search)     query =       includes(:locations, :affiliations)         .references(:locations, :affiliations)      search ? Search.query(query, search) : query   end    def self.sort_column(sort_param)     Sort.column(sort_param)   end    def self.sort_columns     Sort::SORT_COLUMNS   end    def first_affiliation_name     affiliations.first.name   end    def affiliation_names     affiliations.map(&amp;:name)   end    def first_location_name     locations.first.name   end    def location_names     locations.map(&amp;:name)   end end   A few notes about this code:      All methods return data only. Nothing here is responsible for returning formatted strings, or anything else that is meant for display purposes: that is strictly the job of the decorators.        For functionality related to things like searching or sorting people, for the basic implementations I have done, it would probably be considered Rails convention to have that code live in Rails concerns, and include those modules in the Person class to make their methods available.  Like inheritance, I really do not like using composition in this way, as I feel that it is too implicit as well. Perhaps if Ruby had something akin to Elixir\u2019s Kernel.SpecialForms.import/2, where you could explicitly enumerate the methods to import (something like include Search, only: :search_query), then I would probably be more favourably inclined to them.  So, instead, I opted for what I would consider a more Ruby-ish than Rails-ish way of separating the code, through the use of what is apparently called partial classes to achieve separation of concerns: essentially, re-opening the Person class in separate files, and putting code in small private modules for Search, and Sort, and then have the model explicitly call them (eg  Search.query, Sort.column). For example:       app/models/person/search.rb       class Person   module Search     SEARCH_QUERY =       "prefix ILIKE :search "\\       "OR first_name ILIKE :search "\\       "OR last_name ILIKE :search "\\       "OR suffix ILIKE :search "\\       "OR locations.name::text ILIKE :search "\\       "OR species::text ILIKE :search "\\       "OR gender::text ILIKE :search "\\       "OR affiliations.name::text ILIKE :search "\\       "OR weapon::text ILIKE :search "\\       "OR vehicle::text ILIKE :search"     private_constant :SEARCH_QUERY      module_function      def query(query, search)       query.where(SEARCH_QUERY, search: "%#{search}%")     end   end   private_constant :Search end           This module could easily be copy and pasted back into app/models/person.rb, but having it here \u201cremoves the clutter\u201d from the model class itself, while still being encapsulated within it. And yes, private_constant can be used with a module to make sure that code like Person::Search cannot be used outside the Person class.       See the app/models/person/ directory for the other examples.       Conclusion   Although I do think there are areas where the coding test requirements could be improved, particularly in the data set, overall, I am left with an overall positive impression of it since it was the catalyst for me to:      play with Tailwind, which I will definitely use again in the future   re-think some of the ways I have been writing Rails controller and model code   generally learn me some new things   So, if you are looking to up your coding game whilst padding your online portfolio, I can definitely recommend using coding tests as a way to do so!   ',categories:[],tags:["ruby","rails","coding-test","star-wars","data-parsing","tailwind","enum","draper","kaminari","tachyons","pattern-matching"],url:"/blog/coding-test-review-sentia/",teaser:"/assets/images/2021-05-09/jocasta-helps-obi-wan.png"}];