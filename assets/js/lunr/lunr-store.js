var store=[{title:"Hello Blog!",excerpt:"After finishing Learn Enough CSS &amp; Layout to Be Dangerous by Michael Hartl, where you create CSS styling and HTML templates for a Jekyll blog, I decided that it was probably for the best that I finally have my own site to write on, and also use as a sandbox to tinker with front-end programming languages.   The last time I attempted to start up a blog was after reading Technical Blogging a few years ago. Although it was a good read, I didn\u2019t feel much love for the Wordpress site I was left with after finishing, and probably didn\u2019t feel like I had much to write about anyway. It was left neglected, unloved, and eventually taken down with a single \u201cHello Blog!\u201d post to its name. Hopefully things will be a bit different this time as I have more manual control over this Github Pages-hosted Jekyll-powered blog.   I didn\u2019t want to throw away the result of the Learn Enough tutorial, as I made a few changes I think I will want to reference later, so I moved the codebase repository, took it off Github Pages, and instead deployed it using Heroku to its new home.   So, hello (again) blog, and here\u2019s to a new start :beers:   ",categories:[],tags:["jekyll"],url:"https://www.paulfioravanti.com/blog/hello-blog/",teaser:"https://www.paulfioravanti.com/assets/images/paul-teaser.jpg"},{title:"Setting up a Jekyll Blog",excerpt:'TL;DR      Use the Minima theme and customise it if you want to: it works out of the box   Live reload pages with Hawkins and Grip   Lint all files with Sass Lint, htmllint, and markdownlint   Run lints with Guard   Set up a custom domain for the blog   Set up SSL for the blog   You cannot use custom Jekyll plugins when deploying to Github Pages         Setting up this blog, and creating a development environment that I was happy with, took longer than I expected, so I thought I would document the process and other learnings gained along the way.   This assumes that you have read Jekyll\u2019s getting started guide and the quick start instructions on the Jekyll homepage, and have got your new blog generated.   NOTE: I used Jekyll 3.6.2 to originally generate this blog, so your mileage may vary depending on what version you use and when you read this post.   Choosing a theme   If you are hosting outside of Github, then you can get themes from many different sites, but if you are going to use Github Pages for hosting, then you are limited to their supported themes.   After generating a few different test blogs and applying different themes, I found that Minima, the default theme, is the one that works most seamlessly out-of-the-box: it includes all the layouts that a newly-generated site wants by default, as well as integrations for Disqus comments and Google Analytics. This ease of use, coupled with my desire to tinker with the CSS, made the minimalistic Minima a straightforward choice, but I would encourage you to experiment and pick one that best suits the look you want for your site.   Creating a Development Environment   Before starting any coding on the blog itself or making any content, I wanted to make sure I had a development environment I was comfortable with, so here is how I set mine up.   Live Reloading   Hitting refresh every time you want to see your changes reflected on a web page isn\u2019t fun, so let Hawkins and Grip handle that for you.   Hawkins   Hawkins\u2019 live reload applies to any content file in the Jekyll application itself.  Installation and usage of the Hawkins gem is well documented on its README file, so I will just simply add that I\u2019ve set it to watch draft blog posts (markdown files in the _drafts/ folder) as well by running my Jekyll server with the following command:   bundle exec jekyll liveserve --drafts   Grip   Hawkins does not cover any Markdown in a Jekyll application\u2019s README file, so if you change it often, or just want a process to monitor it, install Grip (I use Homebrew), and run it in a separate terminal window:   brew install grip grip --browser   The --browser flag will open a tab in your web browser immediately at http://localhost:6419/ and display the application README file. The page gets live-reloaded as changes are made, but just be warned that if you perform more than 60 live reloads per hour, you will need to authenticate your Github API requests with your Github credentials.   Linting   I\u2019m quite fastidious about code style and quality, but do not want to have to be too cognizant of it while developing, so I want a team of robots to look over my shoulder and let me know when the code I am writing is not up to \u201ccommunity standards\u201d. That team of robots, in this case, takes the form of a set of linters for each of the different file types primarily used in a Jekyll blog: CSS (SASS), HTML, and Markdown.   Find the lints   Since Jekyll is written in Ruby, I started searching for lints at Ruby Gems, where I found SCSS-Lint, Markdown Lint, and no options available for HTML. I found configuring Markdown Lint confusing, and SCSS-Lint recommends using other Javascript-based linting tools over itself, so I came to the conclusion that it was probably best to use front-end language linters that were actually written in front-end languages. They ended up being:      SCSS: Sass Lint   HTML: htmllint (via htmllint-cli)   Markdown: markdownlint (via markdownlint-cli)   Install the lints using npm, and then make sure to update your shims for Node if you\u2019re using a version manager for npm (I use asdf):   npm install -g sass-lint htmllint-cli markdownlint-cli asdf reshim nodejs   Run the lints   Now that the lints are all installed, there needs to be a way to run them when files change. For Ruby and Rails projects, I always use Guard, so I chose it due to my familiarity with it, and because I didn\u2019t want to have to learn how to use another front-end-based task runner at this time. Since the lints are not Ruby gems and hence do not have their own Guard plugins, I used Guard::Process to run the lints as command line processes.   To install Guard and Guard::Process, first add them to the Gemfile:   group :development do   gem "guard", "~&gt; 2.14"   gem "guard-process", "~&gt; 1.2" end   Next, install the gems, and then generate a Guardfile for task configuration:   bundle install bundle exec guard init   Open up the Guardfile with your favourite text editor and insert the following configuration:   guard "process",       command: ["htmllint", "_includes/*.html", "about.html"],       name: "htmllint" do   watch(%r{^_includes/.+\\.html$})   watch(%r{^about\\.html$}) end  guard "process",       command: ["markdownlint", "_posts", "_drafts", "README.md", "index.md"],       name: "markdownlint" do   watch(%r{^_posts/.+\\.md$})   watch(%r{^.+\\.md$}) end  guard "process",       command: ["sass-lint", "--verbose", "--no-exit"],       name: "sass-lint" do   watch(%r{^_sass/.+\\.scss$})   watch(%r{^assets/.+\\.scss$}) end   htmllint needs specificity on what HTML files to lint, otherwise Jekyll-generated HTML files in the _site/ directory also get linted, which just contributes unnecessary noise to the linter output. There are no Markdown files generated in the _site/ directory, but markdownlint also needs a list of files for command line arguments just the same, simply due to them being a required argument for the CLI.   Once configuration is complete, open up a terminal, and run Guard to have it watch your files:   bundle exec guard   Development Environment Summary   So, whenever I open up my Jekyll blog project, I will always currently have four processes running to help me along with development:      Editor: Vim (substitute out your favourite text editor here)   Server: bundle exec jekyll liveserve --drafts   Guard: bundle exec guard   Grip: grip --browser   Overriding Styling   Customising styling of a Jekyll theme is well documented in the Overriding theme defaults section of Jekyll\u2019s documentation, and in the Customization section of the Minima theme\u2019s documentation, so I will just add that since I want to have complete control over the SASS files, I did the following:      Copied over the contents of the Minima _sass/ directory to my local project (this, of course, means I don\u2019t benefit from any updates that may be done to the Minima gem\u2019s styles)   Linted the files with sass-lint, fixed any issues, and built up a set of SASS rules I wanted in a .sass-lint.yml file   Began adding my own minor tweaks to the styles   Overriding include files   I wanted to add an Apple Touch Icon and remove some footer links from the blog, which means I needed access to the application &lt;head&gt; and &lt;footer&gt; tags.   So, I created a local _includes/ directory and began copy and pasting the relevant files from Minima\u2019s _includes/ directory into it, selectively editing the files locally. I have no doubt I will continue to do this over the course of the blog\u2019s life.   Custom Domain Setup   Since I had my own custom name domain, I wanted to use it with the Jekyll blog on Github Pages rather than the default domain of &lt;username&gt;.github.io.   Luckily, Namecheap, my registrar for https://www.paulfioravanti.com, has a fantastic article in their knowledge base that took me through all the steps I needed to link my domain to Github Pages. Although specific to Namecheap, I would wager the information is generic enough to help anyone else wanting to do the same thing.   SSL Setup   At this point, the site may be on a custom domain, but not having the green secure padlock in the address bar, even for a static blog site, won\u2019t make the site look great in search rankings. So, at least for now, get Cloudflare to provide a signed SSL certificate on the blog\u2019s behalf.   Good instructions on creating a Cloudflare account and enabling SSL on a Jekyll site hosted on Github Pages can be found here and here.   No Foreign Plugins   As a post-script to this post, I thought I\u2019d share the result of my time barking up the wrong tree when wanting to have Jekyll use ENV variables.   I wanted to use icons from Font Awesome on my About page, and I wanted to load them from the Font Awesome CDN so I wouldn\u2019t have to download them all into my project directory. Loading them from the Font Awesome CDN requires registering an account, upon which you are allocated an Embed Code.   I mistakenly thought that the Embed Code was \u201csecret information\u201d, and hence should not be stored in the blog git repository but instead loaded into an environment variable using a Ruby gem like dotenv (this is, of course, not true since the Embed Code will be directly visible in HTML files and exists for these reasons).   Anyway, I followed a guide for using ENV variables with Jekyll that involved creating a Jekyll Plugin Generator which can inject values computed at build time into template variables. I deployed the additions out to Github Pages, but it did not seem to work.   Further internet searching led to the realisation that the Github Pages gem only supports a limited list of plugins and always starts Jekyll in safe mode, meaning user-defined plugins are never run.   So, as long as a Jekyll site is hosted up on Github Pages, no custom plugins can be used.   Conclusion   Who would have thought getting a static site and its development environment up and running \u201cproperly\u201d would be so much work? Not me, hence this post, so hopefully it can serve as some reference to someone else setting up their own Jekyll site.   ',categories:[],tags:["jekyll","ruby"],url:"https://www.paulfioravanti.com/blog/set-up-jekyll-blog/",teaser:"https://www.paulfioravanti.com/assets/images/2017-11-17/wesley-caribe-63610-unsplash.jpg"},{title:"Using Python's Bitcoin libraries in Elixir",excerpt:'I\u2019m currently attempting to learn about the technical details of Bitcoin and blockchains by reading Mastering Bitcoin: Programming the Open Blockchain.   All the code examples in the book are in C++ and Python, but I wanted to see if I could port them over to Elixir. There are Bitcoin libraries in Elixir, like bitcoin-elixir, but I could not seem to find equivalents to the ones used in the book. So, I thought that I would try to port as much of the code as possible into Elixir, and then see if I could make API-style callouts to code that I could not.   I have not been able to find a way to get Elixir to talk to C++ libraries like Libbitcoin, which are used in the book (if you have a good method, please let me know in the comments! [Update 14 Dec 2017: I figured it out. See Using C++ Bitcoin Libraries in Elixir]), so this post will focus on getting Elixir to talk to Python\u2019s Pybitcointools library, within the context of the Implementing Keys and Addresses section in Chapter 4 of the book, using the code in Example 4-5.   The Python example uses the Pybitcointools library to generate a private key, and then encode it into different formats like Wallet Import Format (WIF), and Bitcoin Address (which represents a destination for a Bitcoin payment). The full example code from the book is as follows, so see if you can draw some mental lines around what code can come over to Elixir, and what potentially needs to stay in Python:   # key-to-address-ecc-example.py  from __future__ import print_function import bitcoin  # Generate a random private key valid_private_key = False while not valid_private_key:     private_key = bitcoin.random_key()     decoded_private_key = bitcoin.decode_privkey(private_key, \'hex\')     valid_private_key = 0 &lt; decoded_private_key &lt; bitcoin.N  print("Private Key (hex) is: ", private_key) print("Private Key (decimal) is: ", decoded_private_key)  # Convert private key to WIF format wif_encoded_private_key = bitcoin.encode_privkey(decoded_private_key, \'wif\') print("Private Key (WIF) is: ", wif_encoded_private_key)  # Add suffix "01" to indicate a compressed private key compressed_private_key = private_key + \'01\' print("Private Key Compressed (hex) is: ", compressed_private_key)  # Generate a WIF format from the compressed private key (WIF-compressed) wif_compressed_private_key = bitcoin.encode_privkey(     bitcoin.decode_privkey(compressed_private_key, \'hex\'), \'wif\') print("Private Key (WIF-Compressed) is: ", wif_compressed_private_key)  # Multiply the EC generator point G with the private key to get a public key point public_key = bitcoin.fast_multiply(bitcoin.G, decoded_private_key) print("Public Key (x,y) coordinates is:", public_key)  # Encode as hex, prefix 04 hex_encoded_public_key = bitcoin.encode_pubkey(public_key, \'hex\') print("Public Key (hex) is:", hex_encoded_public_key)  # Compress public key, adjust prefix depending on whether y is even or odd (public_key_x, public_key_y) = public_key compressed_prefix = \'02\' if (public_key_y % 2) == 0 else \'03\' hex_compressed_public_key = compressed_prefix + bitcoin.encode(public_key_x, 16) print("Compressed Public Key (hex) is:", hex_compressed_public_key)  # Generate bitcoin address from public key print("Bitcoin Address (b58check) is:", bitcoin.pubkey_to_address(public_key))  # Generate compressed bitcoin address from compressed public key print("Compressed Bitcoin Address (b58check) is:",       bitcoin.pubkey_to_address(hex_compressed_public_key))   Isolate Pybitcointools API calls   At first glance, I would say that everything that is related to I/O (like print statements) and control flow (if/else statements), can safely make the journey over to Elixir-land, while any code that fetches a value from an API callout to Pybitcointools (ie bitcoin.anything) may have to remain in Python-land, which means we need to have Elixir be able to get return values for the following method calls:      bitcoin.random_key()   bitcoin.encode_privkey(decoded_private_key, encoder)   bitcoin.decode_privkey(private_key, decoder)   bitcoin.encode(public_key_x, hex_encoder)   bitcoin.encode_pubkey(public_key, encoder)   bitcoin.pubkey_to_address(public_key)   bitcoin.N   bitcoin.G   Generate Private Key                    Photo by Katy Belcher on Unsplash        To do this, we can use Export, an Elixir wrapper for Erlport, which allows Erlang to talk to Python and Ruby code. After creating a new mix project (mix new mastering_bitcoin) and installing Export, we can get Elixir to start talking to the key-to-address-ecc-example.py file by writing functions that wrap around Export callouts to it. For example, to get a random key from Pybitcointools, we could do the following:   defmodule MasteringBitcoin.KeyToAddressECCExample do   use Export.Python    @python_src :code.priv_dir(:mastering_bitcoin) |&gt; Path.basename()   @python_file "key-to-address-ecc-example"    def private_key do     {:ok, pid} = Python.start(python_path: @python_src)     private_key =       pid       |&gt; Python.call(@python_file, "bitcoin.random_key", [])       |&gt; to_string()     IO.puts("Private Key (hex) is: #{inspect(private_key)}")     Python.stop(pid)   end end   Running this function in a console (iex -S mix) yields the following result:   iex(1)&gt; MasteringBitcoin.KeyToAddressECCExample.private_key Private Key (hex) is: "e473f28e7c9dd8c46d2698ddc73af1017157f2e2979efe3c116dd35b013c0f2b" :ok   A few things to note here:      The @python_src :code.priv_dir(:mastering_bitcoin) |&gt; Path.basename() module attribute is telling Export.Python where to go looking for Python files, so here, the Python example file lives under the top level priv directory in priv/key-to-address-ecc-example.py (as is Elixir convention), so this attribute will evaluate to be simply "priv".   In Python.call(@python_file, "bitcoin.random_key", []), we\u2019re calling the bitcoin.random_key() method with no arguments, hence the empty argument list as the final function parameter.   Piping the result from Export to the to_string() function is needed due to Elixir reading back the string result from Python as a Binary (ie the above example comes back as \'e473f28e7c9dd8c46d2698ddc73af1017157f2e2979efe3c116dd35b013c0f2b\'). More information about this can be found in the \u201cData types mapping\u201d section of the Erlport documentation.   Decode Private Key   Now that we have a Python-side randomly generated private key as an Elixir string, the next step is to pass it back to Python again so we can get Pybitcointools to decode it to get its decimal value (ie call bitcoin.decode_privkey(private_key, "hex") from Elixir), so let\u2019s add that to the current code, refactoring slightly as we go along:   defmodule MasteringBitcoin.KeyToAddressECCExample do   use Export.Python    @python_src :code.priv_dir(:mastering_bitcoin) |&gt; Path.basename()   @python_file "key-to-address-ecc-example"   @hex "hex"    def run do     with {:ok, pid} &lt;- Python.start(python_path: @python_src),          private_key &lt;- random_key(pid),          decoded_private_key &lt;- decode_private_key(pid, private_key) do       IO.puts("Private Key (hex) is: #{inspect(private_key)}")       IO.puts("Private Key (decimal) is: #{inspect(decoded_private_key)}")       Python.stop(pid)   end    defp random_key(pid) do     pid     |&gt; Python.call(@python_file, "bitcoin.random_key", [])     |&gt; to_string()   end    defp decode_private_key(pid, private_key) do     pid     |&gt; Python.call(@python_file, "bitcoin.decode_privkey", [private_key, @hex])     |&gt; to_string()     |&gt; String.to_integer()   end end   The call to decode the private key is similar to generating the random key, except that we\u2019re now passing the parameters [private_key, @hex] to Python, and then doing further parsing of the result from binary -&gt; string -&gt; integer to get the decimal value of the result.   So, let\u2019s run this in a console:   iex(1)&gt; MasteringBitcoin.KeyToAddressECCExample.run ** (ErlangError) Erlang error: {:python, :"builtins.Exception", \'WIF does not represent privkey\', {:"$erlport.opaque", :python, &lt;&lt;128, 2, 99, 116, 114, 97, 99, 101, 98, 97, 99, 107, 10, 83, 116, 97, 99, 107, 83, 117, 109, 109, 97, 114, 121, 10, 113, 0, 41, 129, 113, 1, 40, 99, 116, 114, 97, 99, 101, 98, 97, 99, 107, 10, 70, ...&gt;&gt;}}   Oops! This incredibly cryptic error is actually telling us that Python 3 tried to call bitcoin.decode_privkey(private_key, &lt;a series of bytes instead of the string "hex"&gt;).   When Elixir/Erlang passes binary information to Python 3, it receives the information as b\'information\': a literal sequence of bytes (as opposed to Python 2, which would receive this data as a string; explanation from Erlport data types mapping documentation to the rescue here again), so it looks like we need to write a Python-side wrapper method that will parse Erlang strings before passing them through as parameters to bitcoin.decode_privkey, so let\u2019s do that:   # key-to-address-ecc-example.py  from __future__ import print_function import bitcoin  def decode_privkey(private_key, decoder):   decoder = decoder.decode()   return bitcoin.decode_privkey(private_key, decoder)  # ... the rest of the code ...   Here, we\u2019re using Python\u2019s bytes.decode() method to return a UTF-8 encoded string from the bytes contained in the decoder parameter, so it can then be passed on to bitcoin.decode_privkey safely.   Now, we need to change the Elixir-side Export call slightly so that we\u2019re calling this new Python-side decode_privkey method that we made, rather than call bitcoin.decode_privkey directly:   defmodule MasteringBitcoin.KeyToAddressECCExample do   # ...    defp decode_private_key(pid, private_key) do     pid     |&gt; Python.call(@python_file, "decode_privkey", [private_key, @hex])     |&gt; to_string()     |&gt; String.to_integer()   end end   Now, let\u2019s try that console run again:   iex(1)&gt; MasteringBitcoin.KeyToAddressECCExample.run Private Key (hex) is: "e5c98a1ed360ae5bf71878bc791422861ee73e0b045e53c4ecad7ecd84ed2a8e" Private Key (decimal) is: 103935731857643381135995335933887080576447253573766575295272791689921802611342 :ok   Success! There\u2019s just one more thing to take care of: references to Pybitcointools constant values.   Constants   Pybitcointools constant values like bitcoin.N are Secp256k1 parameters used in Bitcoin\u2019s Elliptic Curve Digital Signature Algorithm (ECDSA), and live in Pybitcointools\u2019 library here. For our purposes, what we need to know about bitcoin.N is that it helps us determine whether a valid private key has been generated or not (valid_private_key = 0 &lt; decoded_private_key &lt; bitcoin.N).   Export only supports calling methods in Python, so it can\u2019t send a request to fetch the value of a constant.  So, I see two choices:      Create a Python-side wrapper method that returns bitcoin.N   Port the constant to Elixir   I think the latter makes sense, so let\u2019s do that, and complete the correct generation of a private key:   defmodule MasteringBitcoin.KeyToAddressECCExample do   use Export.Python    # Elliptic curve parameters (secp256k1)   # REF: https://github.com/vbuterin/pybitcointools/blob/master/bitcoin/main.py   @n 115792089237316195423570985008687907852837564279074904382605163141518161494337    @python_src :code.priv_dir(:mastering_bitcoin) |&gt; Path.basename()   @python_file "key-to-address-ecc-example"   @hex "hex"    def run do     with {:ok, pid} &lt;- Python.start(python_path: @python_src),          [private_key, decoded_private_key] &lt;- generate_private_key(pid) do       IO.puts("Private Key (hex) is: #{inspect(private_key)}")       IO.puts("Private Key (decimal) is: #{inspect(decoded_private_key)}")       Python.stop(pid)     end   end    # Generate a random private key   defp generate_private_key(pid) do     with private_key &lt;- random_key(pid),          decoded_private_key &lt;- decode_private_key(pid, private_key) do       case decoded_private_key do         n when n in 0..@n -&gt;           [private_key, decoded_private_key]         _out_of_range -&gt;           generate_private_key(pid)       end     end   end    defp random_key(pid) do     pid     |&gt; Python.call(@python_file, "bitcoin.random_key", [])     |&gt; to_string()   end    defp decode_private_key(pid, private_key) do     pid     |&gt; Python.call(@python_file, "decode_privkey", [private_key, @hex])     |&gt; to_string()     |&gt; String.to_integer()   end end   Work in Progress   Note that the Elixir code above only actually covers the port of the first part of the original Python code:   from __future__ import print_function import bitcoin  # Generate a random private key valid_private_key = False while not valid_private_key:     private_key = bitcoin.random_key()     decoded_private_key = bitcoin.decode_privkey(private_key, \'hex\')     valid_private_key = 0 &lt; decoded_private_key &lt; bitcoin.N  print("Private Key (hex) is: ", private_key) print("Private Key (decimal) is: ", decoded_private_key)   The Elixir code that covers the rest of this particular Python code can be found at my Mastering Bitcoin Github repository:      Elixir code   Python wrapper methods   The repository is still a work in progress as I read through the book and attempt to port over more code, so keep an eye out for updates!   ',categories:[],tags:["elixir","bitcoin","python"],url:"https://www.paulfioravanti.com/blog/python-bitcoin-libraries-elixir/",teaser:"https://www.paulfioravanti.com/assets/images/2017-12-04/drew-stock-628985-unsplash.jpg"},{title:"Using C++ Bitcoin libraries in Elixir",
excerpt:'Following up from my previous blog post about Using Python\u2019s Bitcoin libraries in Elixir, I initially mentioned that I was having trouble figuring out a way to get Elixir talking to C++ code, specifically to use the Libbitcoin toolkit. After looking through a bunch of libraries that purport to solve this problem, some using Native Implemented Functions (NIFs) under the hood, others using Ports, I finally got the results I was after using an Elixir library called Cure (which uses Ports).   This blog post will focus on getting Elixir to talk to C++ code that will interface with Libbitcoin, within the context of the Creating a Base58Check-encoded bitcoin address from a private key section in Chapter 4 of Mastering Bitcoin: Programming the Open Blockchain, using the code in Example 4-3. We\u2019ll create a new project and create a solution in two main steps:      Confirm that we can simply compile and run the C++ code as-is (read: as a shell command) within Elixir using the Porcelain library, collect the output, and print it to screen: creating essentially an Elixir wrapper around running the C++ code.   Introduce Cure to actually get Elixir and C++ to be able to handle message passing between each other, which will require significant changes to the C++ code.      Disclaimer: I am not a C/C++ programmer and am likely Doing It Wrong when I\u2019m on that side of the fence, so please don\u2019t consider any code there to be in any way idiomatic or the way it Should Be Done.    Install Libbitcoin   Before starting with Elixir, let\u2019s install the Libbitcoin toolkit. For Mac OS, you can simply install it using Homebrew:   brew install libbitcoin   For other operating systems, please refer to Libbitcoin\u2019s installation instructions.   New Project   Create a new mix project:   mix new libbitcoin cd libbitcoin   Install and configure Porcelain   Open up the project in your favourite text editor, and add Porcelain as a dependency to your mix.exs file:   defmodule Libbitcoin.Mixfile do   # ...   defp deps do     [       # Work with external processes       {:porcelain, "~&gt; 2.0"}     ]   end end   Install Porcelain:   mix deps.get   Then, configure the driver to use for Porcelain by adding the following line in config/config.exs:   config :porcelain, driver: Porcelain.Driver.Basic   Porcelain can also be used with the Goon driver, which is not something that seems to be needed for this project, so we just tell Porcelain to use its basic driver.   Confirm C++ code can be compiled and run   Next, create a c_src/ directory in the project, and copy the code from the book\u2019s addr.cpp file into c_src/addr.cpp, and create a priv/ directory, which is where we will output compiled C++ executable files.   Having C source code in a c_src/ directory is Erlang convention for the location of C source code, but for artefacts that are needed in production (ie those compiled C++ executables), the Elixir convention is to have them in a priv/ folder, so that\u2019s how we\u2019ll roll.   According to the book, we should be able to compile the code using g++ in the following way:   g++ -o priv/addr c_src/addr.cpp $(pkg-config --cflags --libs libbitcoin)   If running this command as-is works for you, then that\u2019s great, but on my computer, that runs Mac OS High Sierra, I got a screen full of errors. In order to fix this, I had to add the -std= flag, to determine the standard language for compilation, which in my case needed to be c++11: The 2011 ISO C++ standard plus amendments (see Options Controlling C Dialect for more information). So, the compilation command needed to be changed to:   g++ -std=c++11 -o priv/addr c_src/addr.cpp $(pkg-config --cflags --libs libbitcoin)   Running the generated priv/addr executable outputs the following result:   ./priv/addr Public key: 0202a406624211f2abbdc68da3df929f938c3399dd79fac1b51b0e4ad1d26a47aa Address: 1PRTTaJesdNovgne6Ehcdu1fpEdX7913CK   Create Elixir wrapper around C++ file   Now that we\u2019ve confirmed we can run the C++ file, let\u2019s write the Elixir wrapper that will compile the file and run the executable. Create a lib/libbitcoin directory in your project and then create an addr.ex file inside of it:   defmodule Libbitcoin.Addr do   @moduledoc """   Example 4-3. Creating a Base58Check-encoded bitcoin address from a   private key.   """    @cpp_compile """   g++ -std=c++11 $(pkg-config --cflags --libs libbitcoin) \\   c_src/addr.cpp -o priv/addr   """   @cpp_executable "priv/addr"    def run do     Porcelain.shell(@cpp_compile)      @cpp_executable     |&gt; Porcelain.shell()     |&gt; Map.fetch!(:out)     |&gt; IO.write()   end end   Then, open up an iex console and run the module:   iex -S mix iex(1)&gt; Libbitcoin.Addr.run() Public key: 0202a406624211f2abbdc68da3df929f938c3399dd79fac1b51b0e4ad1d26a47aa Address: 1PRTTaJesdNovgne6Ehcdu1fpEdX7913CK :ok   It works! We\u2019ve now been able to get Elixir to output the result of running the C++ executable, but Elixir isn\u2019t really talking directly (sending and receiving messages) to the code yet, so let\u2019s work on that next.   Install and configure Cure   Add Cure as a dependency to your mix.exs file, and then run mix deps.get:   defp deps do   [     # Interface C-code with Erlang/Elixir using Ports     {:cure, "~&gt; 0.4.0"},     # Work with external processes     {:porcelain, "~&gt; 2.0"}   ] end   Then, get Cure to generate the necessary base files to communicate between C++ and Elixir:   mix cure.bootstrap   This command will add the following files to the c_src directory:   c_src \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 main.c \u2514\u2500\u2500 main.h      Makefile: a template to automatically build a C++ executable including Cure\u2019s libraries. We\u2019ll leave this for now, but get back to it later on.   main.c: Cure\u2019s base C file to communicate between C/C++ and Elixir.   main.h: The header file for main.c   Hello C++   Before going straight into talking to Libbitcoin, let\u2019s do a quick spike to confirm that we are able to pass messages back and forth from Elixir to C++.   We are going to need the original addr.cpp code for reference, so let\u2019s first store a copy of the original:   mv c_src/addr.cpp c_src/addr.cpp.orig   Next, we\u2019ll move over the Cure-generated files to the be the new addr files:   mv c_src/main.h c_src/addr.h mv c_src/main.c c_src/addr.cpp   Yes, it\u2019s okay for the .c file to become a .cpp file for our purposes.   Next, open up each of the files and change them so that they look like the following:   c_src/addr.h   #ifndef ADDR_H #define ADDR_H #include &lt;elixir_comm.h&gt;  // TODO put your own functions/includes here.  #endif   c_src/addr.cpp   #include &lt;string&gt; #include "addr.h"  int main(void) {   int bytes_read;   byte buffer[MAX_BUFFER_SIZE];    while ((bytes_read = read_msg(buffer)) &gt; 0) {     std::string param = (char*) &amp;buffer;     std::string greeting = "Hello " + param + " from C++";      memcpy(buffer, greeting.data(), greeting.length());     send_msg(buffer, greeting.size());   }    return 0; }   The code here reads in the message (an array of bytes) that gets brought in from Elixir via the read_msg function that Cure provides, stores it in a buffer, copies it into a C++ param string, interpolates it into a greeting message, copies the greeting back into the buffer, and finally sends it back to Elixir via the send_msg function, also provided by Cure. More information about the I/O functions provided by Cure can be found here.   Next, change the Elixir code to use Cure to send messages to C++:   defmodule Libbitcoin.Addr do   @moduledoc """   Example 4-3. Creating a Base58Check-encoded bitcoin address from a   private key.   """    alias Cure.Server, as: Cure    @cpp_compile """   g++ -std=c++11 -I./deps/cure/c_src -L./deps/cure/c_src -O3 \\   $(pkg-config --cflags --libs libbitcoin) \\   -x c++ ./deps/cure/c_src/elixir_comm.c \\   c_src/addr.cpp -o priv/addr   """   @cpp_executable "priv/addr"    def run do     Porcelain.shell(@cpp_compile)      with {:ok, pid} &lt;- Cure.start_link(@cpp_executable),          greeting &lt;- hello_world(pid) do       IO.puts(greeting)       :ok = Cure.stop(pid)     end   end    defp hello_world(pid) do     Cure.send_data(pid, "Elixir", :once)     receive do       {:cure_data, response} -&gt;         response     end   end end   Some things to note about this code:      The compile command has changed quite significantly, and getting it to work was mostly a case of going through the c_src/Makefile that Cure generated as part of its bootstrapping process, and reconstructing the compilation command to include all the necessary Cure headers and libraries.   -x c++ ./deps/cure/c_src/elixir_comm.c is telling the compiler to treat Cure\u2019s generated elixir_comm.c file as a C++ file (otherwise the g++ compiler will output warnings).   Cure\u2019s default way of opening a port to a C++ program is by the use of the Cure.load() API, which \u201cstarts a supervisor which supervises all of its children (a child in this case is a GenServer that communicates with a C/C++ program). That seemed like overkill for this situation, so I simply used Cure.Server.start_link() instead to just start a GenServer.   Cure.send_data(pid, "Elixir", :once) will only allow one response to be received back from the C++ code, which is all we need for this case. However, if multiple responses from C++ need to be processed by Elixir, then the :permanent mode flag could be used instead. More examples of the different kinds of modes can be found on Cure\u2019s README.   Let\u2019s now open up an iex console again and see if we have a conversation going:   iex -S mix iex(1)&gt; Libbitcoin.Addr.run() Hello Elixir from C++ :ok   Excellent! Now that we have Elixir and C++ talking to each other, it\u2019s time to actually get Elixir talking with Libbitcoin.   Working with Libbitcoin   Looking at the code in c_src/addr.cpp.orig (the original code from the book), it would seem that it performs two main actions:      Generate a public key from a private key   Create a bitcoin address from a public key   So, let\u2019s separate those two concerns into their own functions in our C++ code, porting over the code mostly as-is:   c_src/addr.h   #ifndef ADDR_H #define ADDR_H #include "elixir_comm.h"  std::string generate_public_key(std::string priv_key); std::string create_bitcoin_address(std::string pub_key);  #endif   c_src/addr.cpp   #include &lt;string&gt; #include "addr.h"  int main(void) {  // ... }  std::string generate_public_key(std::string priv_key) {   bc::ec_secret decoded;   bc::decode_base16(decoded, priv_key);    bc::wallet::ec_private secret(decoded, bc::wallet::ec_private::mainnet_p2kh);    // Get public key.   bc::wallet::ec_public public_key(secret);   return public_key.encoded(); }  std::string create_bitcoin_address(std::string pub_key) {   bc::wallet::ec_public public_key = bc::wallet::ec_public::ec_public(pub_key);   // Compute hash of public key for P2PKH address.   bc::data_chunk public_key_data;   public_key.to_data(public_key_data);   const auto hash = bc::bitcoin_short_hash(public_key_data);    bc::data_chunk unencoded_address;   // Reserve 25 bytes   //   [ version:1  ]   //   [ hash:20    ]   //   [ checksum:4 ]   unencoded_address.reserve(25);   // Version byte, 0 is normal BTC address (P2PKH).   unencoded_address.push_back(0);   // Hash data   bc::extend_data(unencoded_address, hash);   // Checksum is computed by hashing data, and adding 4 bytes from hash.   bc::append_checksum(unencoded_address);   // Finally we must encode the result in Bitcoin\'s base58 encoding.   assert(unencoded_address.size() == 25);   const std::string address = bc::encode_base58(unencoded_address);   return address; }   So, that\u2019s all well and good (probably), but how can we get Elixir to tell C++ to call these functions? It would be nice if there was some kind of Export-style interface where we could pass the C++ function name that we want called as a string from Elixir.  Alas, there aren\u2019t any (that I know of), so we\u2019ll have to get a bit more creative.   While searching Github for examples that used Cure, I came across the elixir-interop-examples repo, which provided me with some inspiration on how to tackle this problem: get Elixir to send an integer as the first byte of the message to C++. This integer will represent the function to be called, and C++ can switch on it to determine what action needs to be performed. Elixir binaries make it straightforward to be able to tinker with the innards of a sequence of bytes, so that\u2019s how we can proceed by updating the C++ code as follows:   c_src/addr.h   // ...  // Helper functions // REF: https://github.com/asbaker/elixir-interop-examples/blob/master/serial_ports/c_src/serial.c void process_command(byte* buffer, int bytes_read); // REF: https://github.com/asbaker/elixir-interop-examples/blob/master/serial_ports/c_src/erl_comm.h void get_string_arg(byte* buffer, char* string, int bytes_read);  #endif   c_src/addr.cpp   #include &lt;bitcoin/bitcoin.hpp&gt; #include "addr.h"  const int GENERATE_PUBLIC_KEY = 1; const int CREATE_BITCOIN_ADDRESS = 2;  int main(void) {   int bytes_read;   byte buffer[MAX_BUFFER_SIZE];    while ((bytes_read = read_msg(buffer)) &gt; 0) {     process_command(buffer, bytes_read);   }    return 0; }  // Process the command dependent on the integer value given in the message // sent from Elixir void process_command(byte* buffer, int bytes_read) {   int function = buffer[0];   char arg[1024];   get_string_arg(buffer, arg, bytes_read);   std::string retval;    if (bytes_read &gt; 0) {     switch (function) {       case GENERATE_PUBLIC_KEY:         retval = generate_public_key(arg);         break;       case CREATE_BITCOIN_ADDRESS:         retval = create_bitcoin_address(arg);         break;       default:         fprintf(stderr, "not a valid function %i\\n", function);         exit(1);     }     memcpy(buffer, retval.data(), retval.length());     send_msg(buffer, retval.size());   } else {     fprintf(stderr, "no command given");     exit(1);   } }  void get_string_arg(byte* buffer, char* arg, int bytes_read) {   buffer[bytes_read] = \'\\0\';   strcpy(arg, (char*) &amp;buffer[1]); }  std::string generate_public_key(std::string priv_key) {   // ... }  std::string create_bitcoin_address(std::string pub_key) {   // ... }   The main function now immediately delegates off to process_command, which extracts the function indicator and arg argument from the bytes passed to it by Elixir, calls the appropriate function, and sends its return value (retval) back to Elixir.   On the Elixir side, the code looks like the following:   defmodule Libbitcoin.Addr do   @moduledoc """   Example 4-3. Creating a Base58Check-encoded bitcoin address from a   private key.   """    alias Cure.Server, as: Cure    @cpp_compile """   g++ -std=c++11 -I./deps/cure/c_src -L./deps/cure/c_src -O3 \\   $(pkg-config --cflags --libs libbitcoin) \\   -x c++ ./deps/cure/c_src/elixir_comm.c \\   c_src/addr.cpp -o priv/addr   """   @cpp_executable "priv/addr"   # Private secret key string as base16   @private_key """   038109007313a5807b2eccc082c8c3fbb988a973cacf1a7df9ce725c31b14776\\   """    # Integers representing C++ methods   @generate_public_key 1   @create_bitcoin_address 2    def run do     Porcelain.shell(@cpp_compile)      with {:ok, pid} &lt;- Cure.start_link(@cpp_executable),          public_key &lt;- generate_public_key(pid),          bitcoin_address &lt;- create_bitcoin_address(pid, public_key) do       IO.puts("Public key: #{inspect(public_key)}")       IO.puts("Address: #{inspect(bitcoin_address)}")       :ok = Cure.stop(pid)     end   end    defp generate_public_key(pid) do     cure_data(pid, &lt;&lt;@generate_public_key, @private_key&gt;&gt;)   end    defp create_bitcoin_address(pid, public_key) do     cure_data(pid, &lt;&lt;@create_bitcoin_address, public_key :: binary&gt;&gt;)   end    defp cure_data(pid, data) do     Cure.send_data(pid, data, :once)     receive do       {:cure_data, response} -&gt;         response     end   end end      Both generate_public_key and create_bitcoin_address send separate requests out to the C++ code via Cure, in the same way that you might call some other external service. Each of the binary messages has an integer as its first byte, and a string taking up the rest of the message.   The @generate_public_key 1 and @create_bitcoin_address 2 module attributes mirror the similarly named constants in the C++ code, so they are coupled quite tightly out of necessity.   We\u2019re now keeping the private key on the Elixir side and passing in to C++ as a parameter, rather than have its definition be on the C++ side.   Before seeing if this actually works, for clarity\u2019s sake, here are the full C++ code samples:   c_src/addr.h   #ifndef ADDR_H #define ADDR_H #include "elixir_comm.h"  std::string generate_public_key(std::string priv_key); std::string create_bitcoin_address(std::string pub_key);  // Helper functions // REF: https://github.com/asbaker/elixir-interop-examples/blob/master/serial_ports/c_src/serial.c void process_command(byte* buffer, int bytes_read); // REF: https://github.com/asbaker/elixir-interop-examples/blob/master/serial_ports/c_src/erl_comm.h void get_string_arg(byte* buffer, char* string, int bytes_read);  #endif   c_src/addr.cpp   #include &lt;bitcoin/bitcoin.hpp&gt; #include "addr.h"  const int GENERATE_PUBLIC_KEY = 1; const int CREATE_BITCOIN_ADDRESS = 2;  int main(void) {   int bytes_read;   byte buffer[MAX_BUFFER_SIZE];    while ((bytes_read = read_msg(buffer)) &gt; 0) {     process_command(buffer, bytes_read);   }    return 0; }  // Process the command dependent on the integer value given in the message // sent from Elixir void process_command(byte* buffer, int bytes_read) {   int function = buffer[0];   char arg[1024];   get_string_arg(buffer, arg, bytes_read);   std::string retval;    if (bytes_read &gt; 0) {     switch (function) {       case GENERATE_PUBLIC_KEY:         retval = generate_public_key(arg);         break;       case CREATE_BITCOIN_ADDRESS:         retval = create_bitcoin_address(arg);         break;       default:         fprintf(stderr, "not a valid function %i\\n", function);         exit(1);     }     memcpy(buffer, retval.data(), retval.length());     send_msg(buffer, retval.size());   } else {     fprintf(stderr, "no command given");     exit(1);   } }  void get_string_arg(byte* buffer, char* string, int bytes_read) {   buffer[bytes_read] = \'\\0\';   strcpy(string, (char*) &amp;buffer[1]); }  std::string generate_public_key(std::string priv_key) {   bc::ec_secret decoded;   bc::decode_base16(decoded, priv_key);    bc::wallet::ec_private secret(decoded, bc::wallet::ec_private::mainnet_p2kh);    // Get public key.   bc::wallet::ec_public public_key(secret);   return public_key.encoded(); }  std::string create_bitcoin_address(std::string pub_key) {   // Create Bitcoin address.   // Normally you can use:   //    bc::wallet::payment_address payaddr =   //        public_key.to_payment_address(   //            bc::wallet::ec_public::mainnet_p2kh);   //  const std::string address = payaddr.encoded();    bc::wallet::ec_public public_key = bc::wallet::ec_public::ec_public(pub_key);   // Compute hash of public key for P2PKH address.   bc::data_chunk public_key_data;   public_key.to_data(public_key_data);   const auto hash = bc::bitcoin_short_hash(public_key_data);    bc::data_chunk unencoded_address;   // Reserve 25 bytes   //   [ version:1  ]   //   [ hash:20    ]   //   [ checksum:4 ]   unencoded_address.reserve(25);   // Version byte, 0 is normal BTC address (P2PKH).   unencoded_address.push_back(0);   // Hash data   bc::extend_data(unencoded_address, hash);   // Checksum is computed by hashing data, and adding 4 bytes from hash.   bc::append_checksum(unencoded_address);   // Finally we must encode the result in Bitcoin\'s base58 encoding.   assert(unencoded_address.size() == 25);   const std::string address = bc::encode_base58(unencoded_address);   return address; }   Now, the moment of truth. Open up an iex console and let\u2019s see if we can talk to Libbitcoin:   iex -S mix iex(1)&gt; Libbitcoin.Addr.run() Public key: "0202a406624211f2abbdc68da3df929f938c3399dd79fac1b51b0e4ad1d26a47aa" Address: "1PRTTaJesdNovgne6Ehcdu1fpEdX7913CK" :ok   Success! This may not be the most elegant way to talk to C++ code, but, for this use case, it works!   Improve Build Automation with a Makefile   Now that we have everything working as expected, we can make the build process more maintainable for the future if we take the compile command that we currently have in the Elixir @cpp_compile module attribute, and put it back in C-land inside the Makefile. So, building on the Makefile that Cure bootstrap provided for us, add some more code so it looks like the following:   c_src/Makefile   CC = g++ -std=c++11 APP_DIR = $(shell dirname $(shell pwd)) CURE_DEPS_DIR = $(APP_DIR)/deps/cure/c_src CURE_DEPS = -I$(CURE_DEPS_DIR) -L$(CURE_DEPS_DIR) ELIXIR_COMM_C = -x c++ $(CURE_DEPS_DIR)/elixir_comm.c LIBBITCOIN_DEPS = $(shell pkg-config --cflags --libs libbitcoin) C_FLAGS = $(CURE_DEPS) $(ELIXIR_COMM_C) $(LIBBITCOIN_DEPS) -O3 PRIV_DIR = $(APP_DIR)/priv C_SRC_DIR = $(APP_DIR)/c_src EXECUTABLES = addr  all: $(EXECUTABLES) # REF: https://www.gnu.org/software/make/manual/html_node/Static-Usage.html#Static-Usage # $&lt; - prerequisite file, $@ - executable file $(EXECUTABLES): %: %.cpp \t$(CC) $(C_FLAGS) $(C_SRC_DIR)/$&lt; -o $(PRIV_DIR)/$@   A few notes about this Makefile that I learned when figuring out its correct incantations:      When you want to call a shell function inside a Makefile that would normally look something like $(ls) on the command line, since the $() syntax is used for Makefile internal variable referencing, the syntax then becomes $(shell ls) (see The shell function).   Set up of the EXECUTABLES statement, and the code below it, means that when make all is run, for each of the filenames in that EXECUTABLES list (ie this list could be added to: EXECUTABLES = addr foo bar), the $(CC) $(C_FLAGS) $(C_SRC_DIR)/$&lt; -o $(PRIV_DIR)/$@ command gets run for each of them (for example $&lt; gets subbed out for addr.cpp and $@ gets subbed out for addr). More information about this code structure for a Makefile can be found in Makefile\u2019s Static Usage documentation.   Now, you can get Cure to compile all your C++ executables for you via mix:   mix compile.cure   If you want to have this done automatically when you compile your Elixir code, you can add the Cure compiler to the list of your project\u2019s compilers in mix.exs:   defmodule Libbitcoin.Mixfile do   use Mix.Project    def project do     [       # ...       compilers: Mix.compilers ++ [:cure, :"cure.deps"]     ]   end    # ... end   Note, though, that if you do this, every time a process calls mix compile, the C++ executables will be re-compiled. So, it may end up slowing down, say, the running of a set of tasks in a mix test.watch process, as each task will end up re-compiling the C++ code (potentially unnecessarily) before it runs. In this case, it may be best to just add a compile.cure task to run before any of the others. For other Cure-based compilation options see its README.   Since we\u2019ve now moved all the responsibility for C compilation into the Makefile, we can cull some code from addr.ex to create the final file:   defmodule Libbitcoin.Addr do   @moduledoc """   Example 4-3. Creating a Base58Check-encoded bitcoin address from a   private key.   """    alias Cure.Server, as: Cure    @cpp_executable "priv/addr"   # Private secret key string as base16   @private_key """   038109007313a5807b2eccc082c8c3fbb988a973cacf1a7df9ce725c31b14776\\   """    # Integers representing C++ methods   @generate_public_key 1   @create_bitcoin_address 2    def run do     with {:ok, pid} &lt;- Cure.start_link(@cpp_executable),          public_key &lt;- generate_public_key(pid),          bitcoin_address &lt;- create_bitcoin_address(pid, public_key) do       IO.puts("Public key: #{inspect(public_key)}")       IO.puts("Address: #{inspect(bitcoin_address)}")       :ok = Cure.stop(pid)     end   end    defp generate_public_key(pid) do     cure_data(pid, &lt;&lt;@generate_public_key, @private_key&gt;&gt;)   end    defp create_bitcoin_address(pid, public_key) do     cure_data(pid, &lt;&lt;@create_bitcoin_address, public_key :: binary&gt;&gt;)   end    defp cure_data(pid, data) do     Cure.send_data(pid, data, :once)     receive do       {:cure_data, response} -&gt;         response     end   end end   Elixir now needs to know nothing about C++ source code compilation: only that it needs to target a @cpp_executable file when it wants to talk with C++. Porcelain also now has nothing specifically to do any more, so it can be safely removed from the project mix.exs file, and its configuration removed from config.exs.   Final Thoughts   This blog post was borne out of a lot of trial and error and frustration, mostly due to me not being able to C++ my way out of a paper bag without a Stack Overflow safety net. Regardless, I hope it at least assists someone who may be attempting to try something similar, or is reading Mastering Bitcoin as well. I have no doubt that I\u2019m doing it wrong when it comes to C++, so if you have any improvement suggestions, please leave a comment. If you want to keep tabs on my gradual port over of Mastering Bitcoin code over to Elixir, check out my Mastering Bitcoin repo.   ',categories:[],tags:["elixir","bitcoin","clang"],url:"https://www.paulfioravanti.com/blog/c-plus-plus-bitcoin-libraries-elixir/",teaser:"https://www.paulfioravanti.com/assets/images/2017-12-14/matt-antonioli-734745-unsplash.jpg"},{title:"Wii Remote is Best Presentation Remote",excerpt:"   I use a Nintendo Wii Remote as my controller whenever I do a presentation.   In my opinion, its form factor, number of configurable buttons, and general whimsiness, make it way more interesting to use than any other commercial remote on the market. It also helps with being remembered after the presentation is finished (\u201cYou\u2019re using a video game controller with your slides\u2026?!\u201d).   However, it took a surprising amount of time and effort to finally figure out how to get a Wiimote connected to my Macbook Pro in 2017, and like plenty of developer tools, the process is certainly not straightforward. So, it is this process that I will attempt to shed some light on.   Old Skool Wiimotes Only   When I first thought about the potential of connecting a Wiimote to my laptop via Bluetooth to use as a presentation remote, I immediately went out and bought a new Wii Remote Plus, because that was what was available at game stores.   Since the connection and configuration of a Wiimote is not a native feature of Mac OS, I bought Remote Buddy to help me with that, since it seemed to be the most fully-featured software of the potential options I found.   I assumed that since the Wii Remote Plus was a superior model to the original Wii Remote, once I got Remote Buddy working, connecting via Bluetooth would be plug \u2018n\u2019 play smooth. That assumption was completely incorrect, and the Wiimote was promptly ignored by Mac OS when I tried to connect it.   Searching the web led me to the site for the Dolphin Emulator, an emulator for the Gamecube and Wii on PC hardware, which has a Wii Remote Plus connection guide. Reading it, I came to the understanding that standard (earlier-model) Wii Remotes and the first batch of released Wii Remote Pluses (both known by their device code RVL-CNT-01), seemed to have different (and incompatible) Bluetooth connection drivers to later batches of Wii Remote Pluses (device code RVL-CNT-01-TR). My Wii Remote Plus registered as the latter device code, so it looked like I\u2019d just purchased a Wii Remote-shaped paperweight since I did not even have a Wii console to use it with.   I was just about to go hunting on auction sites and in second-hand game shops, when a friend reached out via Twitter who was willing to graciously swap his old Wiimote for my latest version.  When we made the swap and I attempted a Bluetooth connection, it showed device code RVL-CNT-01, so it looked like I was perhaps in with a chance.   How to Connect   So, if you\u2019ve managed to get an old RVL-CNT-01 Wiimote and have bought Remote Buddy, here\u2019s how you can get connected (tested on Mac OS High Sierra):      Open Remote Buddy and you will be greeted with the message above telling you to \u201cPlease press 1 and 2 simultaneously on your Wiimote\u201d. You should do so.      Then, you will get a dialog box asking you to put in a passcode to use the Wiimote. This is, of course, impossible since Wiimotes do not have built in keyboards.  Do not attempt to use your keyboard to type anything in, or bother to look up whether there is some kind of master password of button-pressing combination that you should use when you see this dialog box, as there is literally nothing here that you should do with that text box.   Rather, the following options should work (as in, I have had success doing either of the following):      Ignore the dialog box and it will eventually go away   Press the \u201cCancel\u201d button      Regardless of which option you choose, assuming everything goes well, you should get a successful connection dialog, and you can begin configuring the Wiimote button functionality within Remote Buddy.   Troubleshooting   There may be times where the Wii Remote just does not want to connect or re-connect, so here are some things to watch out for that I have experienced:      If, while the Wiimote is connected, the Mac goes to sleep, upon waking up, I have found that the Wiimote connection gets lost and cannot be regained. In this case, either restarting Remote Buddy, restarting Bluetooth, or restarting Mac OS as a last resort, have resulted in being able to connect again.   If, while the Wiimote is connected, you turn off the Wiimote, or it runs out of battery, the Mac tends to not seem to notice and thinks it is still connected. Resetting Bluetooth did not seem to work, but sometimes restarting Remote Buddy did. Otherwise, restart Mac OS.   Overall, I\u2019ve generally found it difficult to re-connect a Wiimote with Remote Buddy after a connection has been lost, so I have pretty much always needed to restart Remote Buddy to do so.   Solutions to other issues can probably be found on Remote Buddy\u2019s Wiimote Support Page.   Do you have a better way to connect a Wii Remote to a computer to use as a Bluetooth remote, or have a favourite non-standard remote you like using for presentations? If so, then please leave a comment as I would love to hear about it!   ",categories:[],tags:["presentations"],url:"https://www.paulfioravanti.com/blog/wii-remote-best-presentation-remote/",teaser:"https://www.paulfioravanti.com/assets/images/2017-12-19/wii-remote.jpg"},{title:"Setting up a Ruby development environment for Exercism",
excerpt:'I\u2019m extremely late to the Exercism party, but I\u2019ve been having lots of fun working my way through its Ruby track (see my Exercism profile). The only thing I have missed while working on the exercises is the automated workflows that I would normally have: specifically, having tests and Rubocop run automatically after any file has changed.   When I work on any Ruby or Rails project, I immediately reach for Guard to help me out with running these kinds of processes, and this time will be no different. However, the structure of a (completed) Ruby Exercism exercise (located by default under ~/exercism/ruby/) does not look like a typical Ruby project:   my_exercise \u251c\u2500\u2500 README.md \u251c\u2500\u2500 my_exercise.rb \u2514\u2500\u2500 my_exercise_test.rb   It is a single directory with both the implementation and test file in it, which is not the kind of project setup that Guard expects will be used with Ruby. So, Guard will need some extra help on the configuration side of things to figure out how to deal with this. But first, let\u2019s install some gems to get started.   Install Gems   As well as Guard itself, we\u2019re going to want to install the following other gems:      Guard::Minitest: Tests in Exercism are written using Minitest, so this gem will make sure Guard launches the tests with the Minitest framework.   guard-rubocop: Runs Rubocop when files are modified.   Since there is no Bundler or Gemfile in sight, we will be installing these gems globally:      If you use the asdf version manager, add these gems to your default gems file so that you don\u2019t need to worry about manually installing them globally again if you update your Ruby version.    gem install guard guard-minitest guard-rubocop   Generate Guardfile   After installing the gems, change into your exercism/ruby directory (wherever it is installed on your system), and generate the Guardfile:   guard init      If you find this command does not work, depending on your Ruby version manager, you may need to perform a reshim of Ruby executables.    Typically, you will have one Guardfile per Ruby project, but rather than have one per Exercism exercise, which will get old very fast, the plan is to have a single Guardfile that any Ruby exercise can use, and that\u2019s why we generated it in the top level Ruby directory.   The generated Guardfile will look something like this:   guard :minitest do   # with Minitest::Unit   watch(%r{^test/(.*)\\/?test_(.*)\\.rb$})   watch(%r{^lib/(.*/)?([^/]+)\\.rb$}) { |m| "test/#{m[1]}test_#{m[2]}.rb" }   watch(%r{^test/test_helper\\.rb$})  { \'test\' }    # with Minitest::Spec   # watch(%r{^spec/(.*)_spec\\.rb$})   # ...    # Rails 4   # watch(%r{^app/(.+)\\.rb$}) { |m| "test/#{m[1]}_test.rb" }   # ...    # Rails &lt; 4   # ... end  guard :rubocop do   watch(%r{.+\\.rb$})   watch(%r{(?:.+/)?\\.rubocop(?:_todo)?\\.yml$}) { |m| File.dirname(m[0]) } end   Guard Minitest configuration   First, delete all the non-Minitest::Unit configuration to get that out of the way, and let\u2019s take a closer look at exactly what the remaining configuration does:   guard :minitest do   # When a test file (defined as a Ruby file that starts with `test_`)   # located under the `test/` directory is modified, run that test.   watch(%r{^test/(.*)\\/?test_(.*)\\.rb$})   # When a Ruby file located under the `lib/` directory is modified,   # run the test file located under the `test/` directory for that Ruby file.   watch(%r{^lib/(.*/)?([^/]+)\\.rb$}) { |m| "test/#{m[1]}test_#{m[2]}.rb" }   # When the `test/test_helper.rb` file is modified, run the entire test suite.   watch(%r{^test/test_helper\\.rb$})  { \'test\' } end   Unfortunately, it looks like we cannot use any of Guard\u2019s default configuration here as-is because:      In Exercism, everything is in the same directory, so there are no lib/ or test/ directories to go looking in.   The naming for Exercism test files is *_test.rb, not test_*.rb.   There is no test_helper.rb file.   So, we\u2019re going to have to re-write the configuration from scratch, but before we do that, let\u2019s determine what we actually want Guard to do for us within an Exercism exercise directory. For me at least, what I would want is:      If I modify the test file under the exercise root directory, run it again   If I modify the implementation file under the exercise root directory, run its test file, which is also located under the exercise root directory   To do that, I came up with the following:   guard :minitest, test_folders: ["."] do   # Re-test test files when they\'re modified.   watch(%r{\\A.+_test\\.rb\\z}) { |m| "./#{m[1]}" }   # Run the test file of the implementation (non-test) file that was modified.   watch(%r{\\A(.+)(?&lt;!_test)\\.rb\\z}) { |m| "./#{m[1]}_test.rb" } end   Let\u2019s examine some of the reasons behind these lines:      The test_folders flag was added to specifically tell Guard::Minitest that test files are located in the current directory (".") because by default it will look inside test or spec directories.   The string values in the blocks for both watch functions need to resemble a path, otherwise no processes would run. For example, watch(%r{\\A.+_test\\.rb\\z}) { |m| "#{m[1]}" } would not work: the block value needs to be "./#{m[1]}" (figuring this out was a painful gotcha).   Since both implementation and test file are in the same directory, the last statement uses a negative lookbehind assertion ((?&lt;!_test)) to make sure that when ./bob.rb is modified, ./bob_test.rb is run, but when ./bob_test.rb is modified, Guard does not attempt to run a non-existent ./bob_test_test.rb file.   Guard Rubocop configuration   Much like it is easier to have one Guardfile that can be used for all Exercism exercises, the same is true for your Rubocop configuration file (.rubocop.yml). If you have a specific .rubocop.yml file that you want to use just for Exercism, then place it under your exercism/ruby directory, and it will get found when you run the rubocop command.   For the guard-rubocop configuration, we will need to re-write the first rule slightly (watch(%r{.+\\.rb$})) because it currently will run Rubocop over all Ruby files, including the Exercism test file, which is not written by us (and therefore we are not responsible for whether it is written to Rubocop\u2019s standards). So, we\u2019ll use a similar negative lookbehind assertion to fix that problem:   guard :rubocop do   # Only run Rubocop over implementation files   # as test files are not written by students.   watch(%r{\\A(.+)(?&lt;!_test)\\.rb\\z})   watch(%r{(?:.+/)?\\.rubocop\\.yml\\z}) { |m| File.dirname(m[0]) } end   Putting it all together   My final ~/exercism/ruby/Guardfile, with some extra bits of configuration, looks like the following:   # frozen_string_literal: true  group :red_green_refactor, halt_on_fail: true do   guard :minitest, all_on_start: false, test_folders: ["."] do     # Re-test test files when they\'re edited.     watch(%r{\\A.+_test\\.rb\\z}) { |m| "./#{m[1]}" }     # Run the test file of the file that was edited.     watch(%r{\\A(.+)(?&lt;!_test)\\.rb\\z}) { |m| "./#{m[1]}_test.rb" }   end    guard :rubocop, all_on_start: false, cli: ["--display-cop-names"] do     # Only run Rubocop over implementation files     # as test files are not written by me.     watch(%r{\\A(.+)(?&lt;!_test)\\.rb\\z})     watch(%r{(?:.+/)?\\.rubocop\\.yml\\z}) { |m| File.dirname(m[0]) }   end end   The optional red_green_refactor group idea is lifted directly from the guard-rubocop README file, and makes perfect sense to me: get your tests passing first, and only then worry about whether your code looks nice.   This configuration might change over time, so you can always get the latest version from my Exercism Github repo.   Running Guard   Now that the Guardfile is set up with Minitest and Rubocop, you will need to make sure to tell Guard where to find this configuration when you run it:   guard --guardfile ~/exercism/ruby/Guardfile   And that should be it! You should now have a pair of friendly robots looking over your shoulder while you\u2019re solving the exercises, helping you to submit the best solution that you can.   ',categories:[],tags:["exercism","ruby","guard","rubocop"],url:"https://www.paulfioravanti.com/blog/ruby-development-environment-exercism/",teaser:"https://www.paulfioravanti.com/assets/images/2018-01-11/toa-heftiba-183789-unsplash.jpg"},{title:"Tmuxinator for Exercism",excerpt:'Vim and tmux are the backbone of all my development environments. tmuxinator is a Ruby gem that enables me to configure sets of terminal windows and panes for tmux sessions in YAML files, resulting in being able to use a single command, mux [project_name], to bring up a terminal-based development environment personalised exactly to me.   I\u2019m currently infatuated with Exercism (see this post about my Exercism setup for Ruby exercises), and I wanted to use tmux with it so that for any exercise I do, I could always open up a project that would provide me windows for:      a text editor   a window for the exercise tests, preferably with a process runner that would run the tests automatically whenever I modified a file   a console   Creating a YAML template that provides this kind of setup is something I do with tmuxinator for every project that I work on, but I did not want to have to create and maintain a new template for every Exercism exercise I pull down: I just wanted a single template that would work for any exercise in any language that I would potentially use on Exercism.   Dynamic tmuxinator templates   tmuxinator supports using ERB and handling command-line arguments in project files, which is something that I initially thought was interesting when I first started using it, but did not have a valid reason to use\u2026until now. The support of command-line arguments would mean that I could use a single template for Exercism that takes a programming language and an exercise name as parameters, and results in being able to use a command like:   mux exercism &lt;programming_language&gt; &lt;exercise_name&gt;   I am currently doing exercises in Ruby, Elixir, and Elm, so the template below reflects that, but you should be able to adapt it to whatever language you may be using (and I\u2019m sure I will adapt it to use others in the future):   ~/.tmuxinator/exercism   &lt;% lang = @args[0] %&gt; &lt;% exercise = @args[1] %&gt;  name: exercism # Eg: mux exercism ruby hello-world =&gt; exercism/ruby/hello-world root: ~/exercism/&lt;%= lang %&gt;/&lt;%= exercise %&gt;  on_project_first_start:   &lt;% if lang == "elm" %&gt;   - npm install   &lt;% end %&gt;  pre_window:   &lt;% if lang == "ruby" %&gt;   - asdf local ruby 2.5.0   &lt;% elsif lang == "elixir" %&gt;   - asdf local elixir 1.5.3   - asdf local erlang 20.2   &lt;% elsif lang == "elm" %&gt;   - asdf local elm 0.18.0   &lt;% end %&gt;  startup_window: editor  windows:   - editor: vim   &lt;% if lang == "ruby" %&gt;   - tests: guard --guardfile ~/exercism/ruby/Guardfile   - console: irb   &lt;% elsif lang == "elixir" %&gt;   - tests: # placeholder window to run tests   - console: iex   &lt;% elsif lang == "elm" %&gt;   - tests: npm run watch   - console: elm repl   &lt;% end %&gt;   A couple of notes on this setup:      @args is the array available in the template where passed-in command line arguments get stored. Arguments can also be taken in as key-value pairs (eg mux exercism lang=ruby exercise=hello-world), which would then be available via a @settings variable (eg @settings["lang"]), but I think the basic array works best for this template.   I use asdf for managing the versions of all languages, but you could use whatever version manager you would like in the pre_window config.   I keep all my tmuxinator templates in my dotfiles repo, so feel free to use them as examples to build on for your own templates, and good luck with your future Exercism-ing!   ',categories:[],tags:["exercism","ruby","tmux","tmuxinator"],url:"https://www.paulfioravanti.com/blog/tmuxinator-exercism/",teaser:"https://www.paulfioravanti.com/assets/images/2018-01-12/rawpixel-788527-unsplash.jpg"},{title:"Connecting Elm to Phoenix 1.3",excerpt:'Want to start using Elm 0.18 on the front end of a Phoenix app (in this case, Phoenix 1.3)? This blog post will go over the steps I use to get these two talking to each other.      Looking to connect Elm to a Phoenix 1.4 app? Go and check out the update to this blog post: Connecting Elm to Phoenix 1.4 with webpack    Assuming you have already installed Phoenix 1.3, let\u2019s kick things off with a new application.   Generate Phoenix app   mix phx.new phoenix_with_elm cd phoenix_with_elm mix ecto.create mix phx.server   Navigate to http://localhost:4000/ and you should see the familiar Phoenix welcome screen.      No surprises here. Close down the server, and let\u2019s move on.   Generate Elm app   First, install Elm if you haven\u2019t already:   npm install elm --global   Next, in order to help us generate an Elm app with a default structure and sensible configuration, we\u2019ll use Create Elm App (inspired by Create React App):   npm install create-elm-app --global   Generate the new Elm app inside the \u201cfront end\u201d of the Phoenix application, which in this case means the assets/ directory:   cd assets create-elm-app elm   You should now have an elm folder alongside your js and css folders. Let\u2019s make sure it works as we expect:   cd elm elm-app start   Starting the Elm app should then automatically open a browser window for you at http://localhost:3000/, and you should see a message saying that\u2026      Note that the Elm app is running independently here: it knows nothing about the Phoenix environment that it\u2019s located in, and is happily using assets, like the image that you see, from its own assets/elm/public/ directory.   Now that we\u2019ve confirmed that both the Phoenix app and the Elm app work of their own accord, it\u2019s time to connect them together. Close down the Elm server and let\u2019s write some config.   Connect Elm to Phoenix   Phoenix uses Brunch out of the box as its asset build tool, so that\u2019s what we\u2019ll use to compile the Elm code. In order to do that, we\u2019ll need the elm-brunch plugin, so let\u2019s install that and get it configured.   First, navigate back to the assets/ folder and install elm-brunch:   npm install --save-dev elm-brunch   Then, open up brunch-config.js in a text editor and make the following changes:   exports.config = {   // ...    // Step 1: Add "elm" to the list of paths being watched.   paths: {     watched: ["static", "css", "elm", "js", "vendor"],   },    // Step 2: Add the elm-brunch plugin configuration.   plugins: {     elmBrunch: {       elmFolder: "elm",       mainModules: ["src/Main.elm"],       outputFolder: "../vendor",       outputFile: "elm.js",       makeParameters: ["--warn"]     },     // ...   }   // ... }   Note here specifically the line outputFolder: "../vendor": this is to ensure that the generated elm.js file gets compiled and imported before the js/app.js file (it is Brunch convention that files in the assets/vendor directory get compiled before code in other folders; see Brunch\u2019s file config documentation for more details).      The brunch-config.js configuration does apparently allow for before and after statements to specify that some files should be compiled before or after others, but I have not had any luck getting them to work, so please consider having the Elm files compiled out into the vendor folder a hack/workaround for now (since code that we write in the elm directory does not constitute an external library). If you have been able to use before/after compilation order statements in a Phoenix/Elm project, please leave a comment with a link to your config! [Update 2018-02-16] See the update below that puts your code back in the js/ directory, where it belongs:    Display Elm app in Phoenix template   So that we show both Phoenix and Elm working together, let\u2019s keep the default generated Phoenix layout template as-is, and replace the content of the page index template with a &lt;div&gt; tag for the Elm app:   lib/phoenix_with_elm_web/templates/page/index.html.eex   &lt;div id="elm-main"&gt;&lt;/div&gt;   Next, we\u2019ll target that &lt;div&gt; tag in the app Javascript file and get it to replace it with the content of the Elm app, so add the following to the end of the file:   assets/js/app.js   const elmDiv = document.getElementById("elm-main"); Elm.Main.embed(elmDiv);   Now, run mix phx.server again and navigate to http://localhost:4000 to see if we\u2019re in business:      Not quite yet, it would seem: we can see that the Elm app is being rendered in the template, but we\u2019ve got a broken image. This is because that image currently lives inside the Elm app at assets/elm/public/logo.svg, and Phoenix doesn\u2019t know anything about compilation of static image assets within Elm applications: it\u2019s looking for assets under its own assets/static/ directory.   The path of least resistance here is, I think, to move all assets to where Phoenix is expecting to find them, and change the Elm code to point to them.   So, first, move the logo image into Phoenix\u2019s image assets directory:   mv assets/elm/public/logo.svg assets/static/images/logo.svg   Then, change the Elm code to look for the image in Phoenix (/images/logo.svg), rather than in Elm (/logo.svg):   assets/elm/src/Main.elm   module Main exposing (..)  -- ...  view : Model -&gt; Html Msg view model =     div []         [ img [ src "/images/logo.svg" ] []         , h1 [] [ text "Your Elm App is working!" ]         ]   Now, at http://localhost:4000/, you should see the following:      Great! You\u2019re now successfully bootstrapped to start building out your new Phoenix-and-Elm powered app!             Update 2018-02-16   To put the Elm-generated Javascript file into the js directory (rather than in vendor, which should only be for third-party code), and then have the app use it properly, edit the codebase in the following way:   assets/brunch-config.js   exports.config = {   // ...   plugins: {     // Specify outputFolder to be in the js/ directory, along with app.js     elmBrunch: {       elmFolder: "elm",       mainModules: ["src/Main.elm"],       outputFolder: "../js",       outputFile: "elm.js",       makeParameters: ["--warn"]     },      // Do not use ES6 compiler in vendor or Elm-generated Javascript code.     babel: {       ignore: [         /vendor/,         "js/elm.js"       ]     },     // ...   }   // ... }   Then, specifically import the Elm variable in from elm.js, now located in the same directory as app.js, rather than just assuming it is available to use:   assets/js/app.js   import Elm from "./elm"  const elmDiv = document.getElementById("elm-main"); Elm.Main.embed(elmDiv);   Back to \u201cDisplay Elm app in Phoenix template\u201d   ',categories:[],tags:["elixir","phoenix","elm"],url:"https://www.paulfioravanti.com/blog/elm-phoenix-13/",teaser:"https://www.paulfioravanti.com/assets/images/2018-02-09/functional_web_wallpaper.jpg"},{title:"Migrating a Phoenix and Elm app from REST to GraphQL",
excerpt:'GraphQL enables consumers of an API to ask for the exact data they want from it. This is as opposed to REST, where the API provider dictates what and how data will be served, and it is up to the consumer to make sense of whatever data it receives.   In an app that uses Phoenix for the back end and Elm for the front end, the flow of data via APIs for a query will usually take the form of:      Elm requests Phoenix for data via an API call   Phoenix provides the requested data via a JSON response   Elm decodes the data from the response and displays it   This blog post will cover migrating the APIs of an existing Phoenix/Elm from using REST to using GraphQL, including:      Adding GraphQL schemas and types to the Phoenix back end   Migrating from Phoenix controllers to resolvers   Migrating Elm-side JSON response decoding from using JSON.Decode to ValueSpec from the elm-graphql Elm package.   Translating GraphQL requests created in GraphiQL into Elm code, and sending them to Phoenix   Starting Point   The app that we are going to use as a baseline to migrate from REST to GraphQL is an Address Book app that was originally created by Ricardo Garc\xeda Vega over a series of blog posts (Ricardo\u2019s Github repo).      I learned a lot from coding up the app while reading those posts, and I thank Ricardo sincerely for putting the time into his write-ups! Afterwards, I upgraded the app to Phoenix 1.3, played around with the codebase, and put my version of it in its own Github repository, so it is this version of the app that we will use. If you are following along at home, please clone my repo and follow the README instructions to get up and running, or you can skip straight to the finished product, which is in the repo\u2019s graphql branch.   Current State of Play   Before jumping into migrating to GraphQL, let\u2019s take a look at some of the application\u2019s current structure and see how communication is done via REST requests.   Back End   First, let\u2019s have a look at the router:   lib/phoenix_and_elm_web/router.ex   defmodule PhoenixAndElmWeb.Router do   # ...   scope "/api", PhoenixAndElmWeb do     pipe_through :api      scope "/v1", V1 do       resources "/contacts", ContactController, only: [:index, :show]     end   end    scope "/", PhoenixAndElmWeb do     pipe_through :browser      get "/*path", AddressBookController, :index   end end   In this app, AddressBook is the Phoenix context behind which Contacts live. So, the AddressBookController\u2019s purpose is solely to render the HTML tag where the Elm app will be embedded:   lib/phoenix_and_elm_web/templates/address_book/index.html.eex   &lt;div id="elm-main"&gt;&lt;/div&gt;   Once the Elm app is embedded, it can make calls out to the versioned (/v1) contact APIs to fetch contact information, which will be handled by the ContactController:   lib/phoenix_and_elm_web/controllers/v1/contact_controller.ex   defmodule PhoenixAndElmWeb.V1.ContactController do   use PhoenixAndElmWeb, :controller   alias PhoenixAndElm.AddressBook    def index(conn, params) do     contacts = AddressBook.list_contacts(params)     json(conn, contacts)   end    def show(conn, %{"id" =&gt; id}) do     contact = AddressBook.get_contact!(id)     json(conn, contact)   end end   There are two APIs that Phoenix provides: listing contacts and showing (retrieving) information for a contact. Each function talks only to the AddressBook context, leaving the responsibility of determining how the information requested is provided up to the Address Book \u201csub-system\u201d: as far as the controller functions are concerned, they provide some parameter to an AddressBook function, and get returned some value which they then serialize into JSON. So, this controller is effectively our REST boundary, and it is these few lines of functionality that will need to be replicated when migrating over to GraphQL.   Front End   The contact API URL (api/v1/contacts), that maps to the ContactController in the Phoenix app, is defined in a common Commands.elm file so that it can be easily shared between the different API calls coming from Elm:   assets/elm/src/Commands.elm   module Commands exposing (contactsApiUrl)   contactsApiUrl : String contactsApiUrl =     "/api/v1/contacts"   The two main models in the Elm app are Contact and ContactList, and code related to how to fetch information to fill the records of these models is kept in Commands files under directories named after the model itself.   Contact via REST   Let\u2019s see how information for a single contact is retrieved:   assets/elm/src/Contact/Commands.elm   module Contact.Commands exposing (fetchContact)  import Commands exposing (contactsApiUrl) import Contact.Decoder as Decoder import Contact.Messages exposing (ContactMsg(FetchContact)) import Http import Messages exposing (Msg(ContactMsg))   fetchContact : Int -&gt; Cmd Msg fetchContact id =     let         apiUrl =             contactsApiUrl ++ "/" ++ toString id     in         Decoder.decoder             |&gt; Http.get apiUrl             |&gt; Http.send FetchContact             |&gt; Cmd.map ContactMsg   When Contact.Commands.fetchContact is called within the Elm app, a Cmd is sent to the Elm Runtime, with a Msg type of ContactMsg FetchContact, telling it to send a request to the apiUrl (looking something like api/v1/contacts/5), and decode the response using Contact.Decoder.   The decoder used for a Contact looks like the following:   assets/elm/src/Contact/Decoder.elm   module Contact.Decoder exposing (decoder)  import Contact.Model exposing (Contact) import Json.Decode as Decode exposing (field, int, string) import Json.Decode.Extra exposing ((|:))   decoder : Decode.Decoder Contact decoder =     Decode.succeed         Contact         |: (field "id" int)         |: (field "first_name" string)         |: (field "last_name" string)         |: (field "gender" int)         |: (field "birth_date" string)         |: (field "location" string)         |: (field "phone_number" string)         |: (field "email" string)         |: (field "headline" string)         |: (field "picture" string)   The ContactMsg FetchContact message gets handled in Contact.Update, which updates the Contact model record:   assets/elm/src/Contact/Update.elm   module Contact.Update exposing (update)  import Contact.Messages exposing (ContactMsg(FetchContact)) import Messages exposing (Msg) import Model exposing (Model, RemoteData(Failure, Success))   update : ContactMsg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         FetchContact (Ok response) -&gt;             ( { model | contact = Success response }, Cmd.none )          FetchContact (Err error) -&gt;             ( { model | contact = Failure "Contact not found" }, Cmd.none )   The use of Cmd.map ContactMsg in Contact.Commands is what enables the FetchContact message to be handled in a \u201cchild\u201d update function (in this case Contact.Update is considered a child of Update), which can help reduce the size of the \u201cparent\u201d update function:   module Update exposing (update, urlUpdate)  import Contact.Update import Messages exposing (Msg(ContactMsg, ContactListMsg, NavigateTo, ...)) import Model exposing (Model, RemoteData(NotRequested, Requesting)) -- ...   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         ContactMsg msg -&gt;             Contact.Update.update msg model          ContactListMsg msg -&gt;             ContactList.Update.update msg model          UpdateSearchQuery value -&gt;             ( { model | search = value }, Cmd.none )          -- ... -- ...   Here, in the \u201cparent\u201d update function, there are messages that are handled directly, like UpdateSearchQuery, while messages that are wrapped in a ContactMsg message, for example, are delegated straight off to the Contact.Update.update function.      See this blog post about \u201cThe Translator Pattern\u201d in Elm for more information about this style of message passing.    Contact List via REST   Now that we know about fetching a single contact to populate a Contact record, what about fetching a list of contacts to populate a ContactList record?   assets/elm/src/ContactList/Commands.elm   module ContactList.Commands exposing (fetchContactList)  import Commands exposing (contactsApiUrl) import ContactList.Messages exposing (ContactListMsg(FetchContactList)) import ContactList.Decoder as Decoder import Http import Messages exposing (Msg(ContactListMsg))   fetchContactList : Int -&gt; String -&gt; Cmd Msg fetchContactList page search =     let         apiUrl =             contactsApiUrl                 ++ "?search="                 ++ search                 ++ "&amp;page="                 ++ (toString page)     in         Decoder.decoder             |&gt; Http.get apiUrl             |&gt; Http.send FetchContactList             |&gt; Cmd.map ContactListMsg   Fetching a list of contacts looks very similar to fetching a single contact from an API callout point of view, except that we are now providing page and search parameters, resulting in an apiUrl that looks something like api/v1/contacts?search=paul&amp;page=2.   Just like with the contact API call, we decode the response, this time using the ContactList.Decoder, and then send a Cmd with a Msg of type ContactListMsg FetchContactList, which will then be handled in the ContactList.Update.update function.   The ContactList.Decoder itself delegates its Contact-decoding logic to Contact.Decoder, defining only fields related to data about a paginated list of records:   assets/elm/src/ContactList/Decoder.elm   module ContactList.Decoder exposing (decoder)  import Contact.Decoder import ContactList.Model exposing (ContactList) import Json.Decode as Decode exposing (field, int, list) import Json.Decode.Extra exposing ((|:))   decoder : Decode.Decoder ContactList decoder =     let         contact =             Contact.Decoder.decoder     in         Decode.succeed             ContactList             |: (field "entries" (list contact))             |: (field "page_number" int)             |: (field "total_entries" int)             |: (field "total_pages" int)   The reason that the field for a list of contacts is specifically named "entries" is due to the Phoenix app using Scrivener.Ecto for pagination. Paginated contact lists are provided in a Scrivener.Page struct, that contains the list of items its paginating under an :entries map key.   And I think that about covers the request/response handling code on the front end. So, it looks like we will need to:      Change the URL in Commands.elm to reference a different GraphQL endpoint URL   Switch out the Http package for a GraphQL client package   Remove decoders, and replace with GraphQL request builders   Migrate Back End to GraphQL   Phew, that is a fair bit to take in for what is a tour of only one conceptual part of a toy app, but at least now we have an idea of the API-related parts of the app that are targets for change in both the front and back ends.   So, without further ado, let\u2019s tackle migration of the back end first.   Absinthe   Absinthe is the go-to toolkit for using GraphQL in Elixir, with its authors pretty much writing the book on the subject, hence we will be use it in this project. So, open up mix.exs, and add the following libraries:   mix.exs   defmodule PhoenixAndElm.Mixfile do   # ...   defp deps do     [       # ...       {:absinthe, "~&gt; 1.4"},       {:absinthe_plug, "~&gt; 1.4"}     ]   end end      Note that even though this is a Phoenix app, for this example we will not need the Absinthe.Phoenix package since we will be sending messages via HTTP, and not via Phoenix channels/websockets.    Types   Once you have run mix deps.get, create a new lib/phoenix_and_elm_web/schema/ directory and let\u2019s create some GraphQL types to describe the data we want to query:   lib/phoenix_and_elm_web/schema/types.ex   defmodule PhoenixAndElmWeb.Schema.Types do   use Absinthe.Schema.Notation   import_types(Absinthe.Type.Custom)    object :contact_list do     field(:total_entries, :integer)     field(:total_pages, :integer)     field(:page_number, :integer)     field(:page_size, :integer)     field(:entries, list_of(:contact))   end    object :contact do     field(:id, :integer)     field(:first_name, :string)     field(:last_name, :string)     field(:gender, :integer)     field(:birth_date, :date)     field(:location, :string)     field(:phone_number, :string)     field(:email, :string)     field(:headline, :string)     field(:picture, :string)   end end   The :contact object almost directly mirrors the contact database schema, with the one small caveat here being that the GraphQL specification does not provide a :date type for the :birth_date field, so the Absinthe.Type.Custom module provides one that we can use.   The :contact_list object essentially describes a Scrivener.Page, though for simplicity\u2019s sake, we are limiting entries to only containing a list_of(:contact) (Scrivener can, of course, paginate other types of things!).   Schema   Now, we need the schema itself to describe the queries we will allow into the Phoenix app, what arguments each query takes, and what execution should happen for each valid query (done here in the form of resolvers).   lib/phoenix_and_elm_web/schema/schema.ex   defmodule PhoenixAndElmWeb.Schema do   use Absinthe.Schema   alias PhoenixAndElmWeb.ContactResolver   import_types(PhoenixAndElmWeb.Schema.Types)    query do     field :contacts, type: :contact_list do       arg(:search, non_null(:string))       arg(:page, non_null(:integer))       resolve(&amp;ContactResolver.list_contacts/3)     end      field :contact, type: :contact do       arg(:id, non_null(:id))       resolve(&amp;ContactResolver.get_contact/3)     end   end end   Resolvers   Resolvers can tend to get quite long, so it is considered good practice to put them into their own top level directory under the web app, so let\u2019s do that and create a ContactResolver:   lib/phoenix_and_elm_web/resolvers/contact_resolver.ex   defmodule PhoenixAndElmWeb.ContactResolver do   alias PhoenixAndElm.AddressBook    def list_contacts(_parent, args, _resolution) do     contacts = AddressBook.list_contacts(args)     {:ok, contacts}   end    def get_contact(_parent, %{id: id}, _resolution) do     contact = AddressBook.get_contact!(id)     {:ok, contact}   end end   This resolver looks suspiciously like the original REST ContactController, and this is mainly thanks to having the AddressBook context hide away all of the complexity around preparing contact data sets for delivery to the front end. Handy!   One extra tiny change that needs to happen before we move on: did you notice in the get_contact() function that the map that comes through as the args parameter has atoms for keys, as opposed to the ContactController, where the keys are strings? We\u2019re handling that fine in the get_contact function, but in list_contacts(), we\u2019re passing args straight through to AddressBook.list_contacts(), which is expecting a map with string keys, so we will have to update it to expect one with atom keys:   lib/phoenix_and_elm/address_book/address_book.ex   defmodule PhoenixAndElm.AddressBook do   # ...   def list_contacts(%{search: query} = params) do     # ...   end end   This small change is the only time we should have to climb over the AddressBook context wall.   Router   Finally, let\u2019s expose our new GraphQL API to the world by changing the router to send /api requests to the new schema, and /api/graphiql requests to GraphiQL.   lib/phoenix_and_elm_web/router.ex   defmodule PhoenixAndElmWeb.Router do   # ...   scope "/api" do     pipe_through :api      forward "/graphiql", Absinthe.Plug.GraphiQL,       schema: PhoenixAndElmWeb.Schema,       interface: :simple      forward "/", Absinthe.Plug, schema: PhoenixAndElmWeb.Schema   end    scope "/", PhoenixAndElmWeb do     pipe_through :browser      get "/*path", AddressBookController, :index   end end   Testing with GraphiQL   Speaking of GraphiQL, let\u2019s use it to help us build the queries that we\u2019re going to want to have Elm send to it. Navigating to http://localhost:4000/api/graphiql will bring up the GraphiQL interface, so let\u2019s start with a GraphQL query for a single contact.   We need a query that will take in a contact ID parameter, and will return all the fields that we currently have defined in the Contact.Decoder Elm file:   query($contactID: ID!) {   contact(id: $contactID) {     id     firstName     lastName     gender     birthDate     location     phoneNumber     email     headline     picture   } }      The exclamation mark on ID! means that the field is non-nullable, so you have to provide an ID or the query will error out.    Let\u2019s now input that in GraphiQL and fire it off to the Phoenix app, along with a contactID parameter:      Looks pretty good to me! Now, how about for a list of contacts?   We need a query that will take in search and page number parameters, and return all the fields that we currently have defined in the ContactList.Decoder Elm file:   query($searchQuery: String!, $pageNumber: Int!) {   contacts(search: $searchQuery, page: $pageNumber) {     entries {       id       firstName       lastName       gender       birthDate       location       phoneNumber       email       headline       picture     },     pageNumber,     totalEntries     totalPages,   } }   And for a search query of "Barn", the results are\u2026      \u2026all of the users with a first name of Barney! Great! We now know the GraphQL queries that we want the front end to send to the back end, and now, it\u2019s time to get them translated into Elm code! (At this point, now that the migration from controllers to resolvers is complete, it is safe to delete ContactController from the app.)   Migrate Front End to GraphQL   Before we start, we will need a GraphQL package for Elm, and for this project, we will use elm-graphql. Let\u2019s install it directly in the Elm app:   cd assets/elm elm-package install jamesmacaulay/elm-graphql   Now, since the Phoenix-side API URL has changed, the first thing we need to do is make our easiest edit, and tell Elm the new location to send requests to:   assets/elm/src/Commands.elm   module Commands exposing (apiUrl)   apiUrl : String apiUrl =     "/api"   Contact via GraphQL   Now, let\u2019s begin the process of getting the display of a single contact working again, starting with changing Contact.Commands to use GraphQL when sending requests:   assets/elm/src/Contact/Commands.elm   module Contact.Commands exposing (fetchContact)  import Commands exposing (apiUrl) import Contact.Messages exposing (ContactMsg(FetchContact)) import Contact.Request as Request import GraphQL.Client.Http as Http import Messages exposing (Msg(ContactMsg)) import Task exposing (Task)   fetchContact : Int -&gt; Cmd Msg fetchContact id =     id         |&gt; Request.fetchContact         |&gt; Http.sendQuery apiUrl         |&gt; Task.attempt FetchContact         |&gt; Cmd.map ContactMsg   Once we\u2019ve built the GraphQL request to fetch a contact (whose Contact.Request module we will create next), we:      use GraphQL.Client.Http.sendQuery to create a Task to send the query off to the apiUrl   ask the Elm runtime to attempt to run that Task   send a Msg of type ContactMsg FetchContact, which gets handled just like before in Contact.Update (no changes needed to that file)   Now, let\u2019s create that Contact.Request module to replace the Contact.Decoder.  Unlike in GraphiQL, we cannot use raw GraphQL queries in Elm-land, so we will have to port the content of the query to Elm (but let\u2019s keep the GraphQL query that we want generated as a comment, just so we can keep our bearings):   assets/elm/src/Contact/Request.elm   module Contact.Request exposing (fetchContact, contactSpec)  import Contact.Model exposing (Contact) import GraphQL.Request.Builder as Builder     exposing         ( Document         , NonNull         , ObjectType         , Query         , Request         , ValueSpec         , field         , int         , object         , string         , with         ) import GraphQL.Request.Builder.Arg as Arg import GraphQL.Request.Builder.Variable as Var   {-| query($contactID: ID!) {   contact(id: $contactID) {     id     firstName     lastName     gender     birthDate     location     phoneNumber     email     headline     picture   } } -} fetchContact : Int -&gt; Request Query Contact fetchContact id =     let         contactID =             Arg.variable (Var.required "contactID" .contactID Var.int)          contactField =             Builder.extract                 (field                     "contact"                     [ ( "id", contactID ) ]                     contactSpec                 )          params =             { contactID = id }     in         contactField             |&gt; Builder.queryDocument             |&gt; Builder.request params   contactSpec : ValueSpec NonNull ObjectType Contact vars contactSpec =     Contact         |&gt; object         |&gt; with (field "id" [] int)         |&gt; with (field "firstName" [] string)         |&gt; with (field "lastName" [] string)         |&gt; with (field "gender" [] int)         |&gt; with (field "birthDate" [] string)         |&gt; with (field "location" [] string)         |&gt; with (field "phoneNumber" [] string)         |&gt; with (field "email" [] string)         |&gt; with (field "headline" [] string)         |&gt; with (field "picture" [] string)   The content of the contactSpec function pretty much lines up logically with the code that we have in Contact.Decoder, while fetchContact:      builds the query step by step with the let expressions   creates a GraphQL.Request.Builder.Document for the query   creates a GraphQL.Request.Builder.Request from the Document that gets sent to the apiUrl in Contact.Commands   One final small change is to make sure that the Contact.Messages file, which has been referencing the Http library, now needs to reference GraphQL.Client.Http instead:   assets/elm/src/Contact/Messages.elm   module Contact.Messages exposing (ContactMsg(..))  import Contact.Model exposing (Contact) import GraphQL.Client.Http as Http   type ContactMsg     = FetchContact (Result Http.Error Contact)   At this point, individual contact detail pages should be displaying, so navigate to the URL of a known contact (eg http://localhost:4000/contacts/4), and you should see a page that looks something like:      The sample data in the app is generated randomly, so the contact you see from the URL above will most likely be different, but, it works! Performing a search, or navigating to the root page of the app, or doing anything that results in displaying a list of contacts will not work just yet, though, so let\u2019s polish that task off and finish up this migration.   Contact List via GraphQL   This process will look (and be) very similar to how we migrated the contacts, so let\u2019s briskly get through how the files will change:   assets/elm/src/ContactList/Commands.elm   module ContactList.Commands exposing (fetchContactList)  import Commands exposing (apiUrl) import ContactList.Messages exposing (ContactListMsg(FetchContactList)) import ContactList.Request as Request import GraphQL.Client.Http as Http import Messages exposing (Msg(ContactListMsg)) import Task exposing (Task)   fetchContactList : Int -&gt; String -&gt; Cmd Msg fetchContactList pageNumber search =     search         |&gt; Request.fetchContactList pageNumber         |&gt; Http.sendQuery apiUrl         |&gt; Task.attempt FetchContactList         |&gt; Cmd.map ContactListMsg   assets/elm/src/ContactList/Messages.elm   module ContactList.Messages exposing (ContactListMsg(..))  import ContactList.Model exposing (ContactList) import GraphQL.Client.Http as Http   type ContactListMsg     = FetchContactList (Result Http.Error ContactList)     | Paginate Int     | ResetSearch     | SearchContacts   assets/elm/src/ContactList/Request.elm   module ContactList.Request exposing (fetchContactList)  import Contact.Request import ContactList.Model exposing (ContactList) import GraphQL.Request.Builder as Builder     exposing         ( NonNull         , ObjectType         , Query         , Request         , ValueSpec         , field         , int         , list         , object         , with         ) import GraphQL.Request.Builder.Arg as Arg import GraphQL.Request.Builder.Variable as Var   {-| query($searchQuery: String!, $pageNumber: Int!) {   contacts(search: $searchQuery, page: $pageNumber) {     entries {       id       firstName       lastName       gender       birthDate       location       phoneNumber       email       headline       picture     },     pageNumber,     totalEntries,     totalPages   } } -} fetchContactList : Int -&gt; String -&gt; Request Query ContactList fetchContactList page search =     let         searchQuery =             Arg.variable (Var.required "searchQuery" .searchQuery Var.string)          pageNumber =             Arg.variable (Var.required "pageNumber" .pageNumber Var.int)          contactsField =             Builder.extract                 (field                     "contacts"                     [ ( "search", searchQuery ), ( "page", pageNumber ) ]                     contactListSpec                 )          params =             { searchQuery = search             , pageNumber = page             }     in         contactsField             |&gt; Builder.queryDocument             |&gt; Builder.request params   contactListSpec : ValueSpec NonNull ObjectType ContactList vars contactListSpec =     let         contact =             Contact.Request.contactSpec     in         ContactList             |&gt; object             |&gt; with (field "entries" [] (list contact))             |&gt; with (field "pageNumber" [] int)             |&gt; with (field "totalEntries" [] int)             |&gt; with (field "totalPages" [] int)   Pretty similar set of changes, right?  The only real differences are the number of parameters for the query, and the contactSpec nesting inside contactListSpec, which is in a similar vein to the nesting of the Contact.Decoder inside a ContactList.Decoder.   Now, you should be able to view any page in the app that displays a list of contacts. The GraphQL migration is complete, and you can safely remove the Decoder files from the application.      Any issues getting things to work? Have a look at the graphql branch and see if there are any differences from your code.    Wrapping Up   There is so much more to GraphQL than what I\u2019ve managed to fit into this admittedly long blog post. We only dealt with queries, and did not even touch other GraphQL fundamentals like mutations, which cover modifying server-side data (though take a look at the Elm hipster stack repo for some good examples of that).   However, I hope that you enjoyed this small taste of Phoenix, Elm, and GraphQL working together, and if you join me in making further inroads with this fully functional tech stack moving forward, I would love to hear about it!   ',categories:[],tags:["elixir","phoenix","elm","rest","graphql","api"],url:"https://www.paulfioravanti.com/blog/migrate-phoenix-elm-app-rest-graphql/",teaser:"https://www.paulfioravanti.com/assets/images/2018-03-07/address-book-contacts-index.png"},{title:"Graph-driven Refactoring in Elm",
excerpt:'After completing the \u201cPhoenix and Elm, a real use case\u201d tutorial by Ricardo Garc\xeda Vega, I went back and refactored parts of the codebase in order to help me really understand it, and get everything straight in my head (I wrote about this in Migrating a Phoenix and Elm app from REST to GraphQL, and you can see the results in my repository versus the original).   Architecting in the Dark   I could not seem to find any generally-accepted ways to architect Elm code in the same way as I would architect Elixir/Phoenix or Ruby/Rails code, so I just let my instincts guide the code architecture direction, which currently lean towards small(er) modules and functions.   So, I thought it would be a good idea to break out code from big Elm files into individual smaller files located under conceptual concerns directories. For example, I extracted application code that looked like it was mostly concerned with a Contact out into a structure like this:   Contact/   Commands.elm   Decoder.elm   Messages.elm   Model.elm   Update.elm   View.elm   Messages to update a Contact would be wrapped in a top level Msg type called ContactMsg, and when that came through the main update function, handling of the update would be immediately delegated out to Contact.Update.   assets/elm/src/Update.elm   module Update exposing (update, ...)  import Messages exposing (Msg(ContactMsg, ...)) import Model exposing (Model, ...) -- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         ContactMsg msg -&gt;             Contact.Update.update msg model  -- ...   The nested message inside a ContactMsg, is completely opaque to Update, and it was only Contact.Update that knew what should happen when, in this case, a FetchContact message is received:   assets/elm/src/Contact/Update.elm   module Contact.Update exposing (update)  import Contact.Messages exposing (ContactMsg(FetchContact)) import Messages exposing (Msg) import Model exposing (Model, RemoteData(Failure, Success))   update : ContactMsg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         FetchContact (Ok response) -&gt;             ( { model | contact = Success response }, Cmd.none )          FetchContact (Err error) -&gt;             ( { model | contact = Failure "Contact not found" }, Cmd.none )   This sort of thing seemed like a good pattern to me in the absence of any others, but there was no way I could really tell if it was actually any good, or if there would be any issues, performance or otherwise, related to coding Elm in this way.   Graphing Dependencies   Until, that is, I was introduced to elm-module-graph, which enables you to visually explore package and module dependencies in an Elm project. It helped me understand that:      My code was not really properly separated out into the concerns I thought it was.   I had the Elm equivalent of a God object-in-the-making: a module that too many other modules had knowledge about. These modules, given enough other modules that have it as a dependency, can lead to longer Elm compile times every time a change is made on them.   Create Graph File   Here is how I generated the needed module-graph.json for the Address Book app (adapt the commands as necessary for your own project, and make sure you have Python installed):   cd assets/elm wget https://raw.githubusercontent.com/justinmimbs/elm-module-graph/master/elm-module-graph.py chmod 744 elm-module-graph.py ./elm-module-graph.py src/Main.elm   Display Graph   Next, navigate to https://justinmimbs.github.io/elm-module-graph/ and upload the generated module-graph.json file, and you will see something like this:      The default graph display includes modules from external libraries, so let\u2019s hide them (by toggling the display of the external packages at the top) so that we can focus on the application code:      Find Long Bars   If a module has a long bar with attached lines in the graph, that means that it is imported by many modules. Here, it is clear that the Messages module, displayed right in the middle of the graph, has the longest bar, so let\u2019s take a clearer look at its dependencies by clicking on it:         The modules in red are the modules that Messages imports into itself. These are not the relationships we need to worry about.   The modules in blue are the modules that import Messages into themselves. Here, we can see that a great many \u201cchild\u201d modules like Contact.Update, have knowledge about \u201cparent\u201d Messages, but Contact.Update should really only know about the type of message it deals with directly, the ContactMsg, and leave knowledge about (and handling of) Msg type messages to the Messages module.   We have some leaking of encapsulation within the concerns, so, let\u2019s see what can be done to fix them, with the initial goal of not having any modules under the Contact concern import the Messages module. The starting point for this refactor will be the rest branch of the Address App, so if you\u2019re following along at home, clone the repo and let\u2019s get refactoring!      If you get stuck while refactoring at any step of the way, have a look at the rest-refactor branch of the Address App for guidance.    Initial Preparation   Extract RemoteData into its own Module   Currently, the RemoteData type is contained in the top-level Model module. Since Contact concern modules needs to know about RemoteData, but not Model (they should only need to know about Contact.Model), let\u2019s remove RemoteData out from Model and into its own top level module:   assets/elm/src/RemoteData.elm   module RemoteData exposing (RemoteData(..))   type RemoteData e a     = Failure e     | NotRequested     | Requesting     | Success a   The Elm compiler should let you know the modules in which you need to change RemoteData references to this new one, but most of the edits will consist of changing references like:   import Model     exposing         ( Model         , RemoteData(NotRequested, Requesting, Failure, Success)         )   to something like:   import Model exposing (Model) import RemoteData     exposing         ( RemoteData(NotRequested, Requesting, Failure, Success)         )   Create Routing Concern   In Contact.View, there is the following line:   assets/elm/src/Contact/View.elm   import Messages exposing (Msg(NavigateTo))   NavigateTo is a message that is sent in onClick link attributes in HTML inside multiple view files. When this message is handled in Update, it only runs a command to navigate to a new URL, and does not return a new model:   assets/elm/src/Update.elm   module Update exposing (update, ...)  import Navigation import Routing exposing (Route(...)) -- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         -- ...          NavigateTo route -&gt;             ( model, Navigation.newUrl (Routing.toPath route) ) -- ...   So, in order to de-couple Contact.View from Messages, it looks like a new extraction of a Routing concern will be in order, so let\u2019s start with defining messages and update handling for Routing:   assets/elm/src/Routing/Messages.elm   module Routing.Messages exposing (RoutingMsg(..))  import Routing exposing (Route)   type RoutingMsg     = NavigateTo Route   assets/elm/src/Routing/Update.elm   module Routing.Update exposing (update)  import Navigation import Routing import Routing.Messages exposing (RoutingMsg(NavigateTo))   update : RoutingMsg -&gt; Cmd msg update msg =     case msg of         NavigateTo route -&gt;             Navigation.newUrl (Routing.toPath route)   We will also need to allow for a RoutingMsg to be handled by the top-level Messages module, so let\u2019s add that (while removing NavigateTo from Messages), and fix Update so it can handle these new RoutingMsg messages:   assets/elm/src/Messages.elm   module Messages exposing (Msg(..))  import Contact.Messages exposing (ContactMsg) import ContactList.Messages exposing (ContactListMsg) import Navigation import Routing.Messages exposing (RoutingMsg)   type Msg     = ContactMsg ContactMsg     | ContactListMsg ContactListMsg     | RoutingMsg RoutingMsg     | UpdateSearchQuery String     | UrlChange Navigation.Location   assets/elm/src/Update.elm   module Update exposing (update, ...)  import Routing.Update -- ...   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         -- ...          RoutingMsg msg -&gt;             ( model, Routing.Update.update msg ) -- ...   Use RoutingMsg in Contact Views   Once this is done, we will start focusing on Contact-related modules. You will find that a number of different view files have been affected by the creation of the RoutingMsg, so some references and type signatures will need to change.   The Elm compiler should let you know about which modules need to have their NavigateTo references changed, but most of the edits will consist of changing references like:   import Messages exposing (Msg(NavigateTo))   to something like:   import Messages exposing (Msg(RoutingMsg))   or (depending on the file):   import Routing.Messages exposing (RoutingMsg(NavigateTo))   as well as changing function declarations to return a RoutingMsg, rather than a Msg:   assets/elm/src/Contact/View.elm   -- ...  import Routing.Messages exposing (RoutingMsg(NavigateTo)) -- ...  view : Model -&gt; Html RoutingMsg -- ...  showView : Contact -&gt; ( String, Html RoutingMsg ) -- ...  -- etc etc change Msg to RoutingMsg for all the functions in this file ...   Again, the Elm compiler will guide you on where the references need to be changed.   Next, there will be some messages across multiple concerns that will need to be Html.mapped into RoutingMsg messages:   assets/elm/src/ContactList/View.elm   module ContactList.View exposing (view)  import Messages exposing (Msg(RoutingMsg, ...)) -- ...  contactsList : Model -&gt; ContactList -&gt; Html Msg contactsList model page =     if page.totalEntries &gt; 0 then         page.entries             |&gt; List.map Contact.View.showView             |&gt; Keyed.node "div" [ class "cards-wrapper" ]             |&gt; Html.map RoutingMsg     else       -- ...   assets/elm/src/View.elm   module View exposing (view)  import Messages exposing (Msg(RoutingMsg)) -- ...   page : Model -&gt; Html Msg page model =     case model.route of         -- ...          ShowContactRoute id -&gt;             model                 |&gt; Contact.View.view                 |&gt; Html.map RoutingMsg          NotFoundRoute -&gt;             Shared.View.warningMessage                 "fa fa-meh-o fa-stack-2x"                 "Page not found"                 (Html.map RoutingMsg Shared.View.backToHomeLink)   One final minor view-related change is in the signature for Shared.View.warningMessage:   assets/elm/src/Shared/View.elm   warningMessage : String -&gt; String -&gt; Html msg -&gt; Html msg warningMessage iconClasses message content =     div [ class "warning" ]         [ span [ class "fa-stack" ]             [ i [ class iconClasses ] [] ]         , h4 []             [ text message ]         , content         ]   The change is ever-so-subtle: Html Msg to Html msg. This function is used in both Contact and ContactList views, and the message wrapped inside the Html could be a ContactMsg or a Msg type. Since the type of message is not consequential for the rendering of the warning message, we make the type signature ambivalent to the type of message provided and then returned back.   And that should take care of View-related code, so on to Contact.Update!   Hide Model from Contact.Update   Currently, in Update, we\u2019re passing the whole Model off to Contact.Update when we receive a ContactMsg, and Contact.Update.update returns back a (Model, Cmd Msg).   However, Contact.Update should only be concerned with returning a new Contact: it does not need to know about the rest of the Model.  Also, Contact.Update should only know how to return messages of its own type: ContactMsg. So, we want:      Contact.Update.update to return back a (Contact, Cmd ContactMsg)   Have the Update module return a model with the new Contact   Have the Update module convert the ContactMsg into a Msg.   assets/elm/src/Update.elm   module Update exposing (update, ...)  import Messages exposing (Msg(ContactMsg, ...)) import Model exposing (Model, ...) -- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         ContactMsg msg -&gt;             let                 ( contact, cmd ) =                     Contact.Update.update msg             in                 ( { model | contact = contact }, Cmd.map ContactMsg cmd )  -- ...   Now that Contact.Update.update doesn\u2019t receive a Model any more, let\u2019s change it so that it returns the (Contact, Cmd ContactMsg) that Update now wants:   assets/elm/src/Contact/Update.elm   module Contact.Update exposing (update)  import Contact.Messages exposing (ContactMsg(FetchContact)) import Contact.Model exposing (Contact) import RemoteData exposing (RemoteData, RemoteData(Failure, Success))   update : ContactMsg -&gt; ( RemoteData String Contact, Cmd ContactMsg ) update msg =     case msg of         FetchContact (Ok response) -&gt;             ( Success response, Cmd.none )          FetchContact (Err error) -&gt;             ( Failure "Contact not found", Cmd.none )   Contact.Commands should return ContactMsgs   Currently, the Contact.Commands.fetchContact function returns a top-level Cmd Msg type. What we want to do is have it instead return a Cmd ContactMsg, and have the caller of the function (in this case Update.urlUpdate) be responsible for Cmd.mapping the ContactMsg to a Msg.   So, this is what we currently have:   assets/elm/src/Contact/Commands.elm   module Contact.Commands exposing (fetchContact)  import Commands exposing (contactsApiUrl) import Contact.Decoder as Decoder import Contact.Messages exposing (ContactMsg(FetchContact)) import Http import Messages exposing (Msg(ContactMsg))   fetchContact : Int -&gt; Cmd Msg fetchContact id =     let         apiUrl =             contactsApiUrl ++ "/" ++ toString id     in         Decoder.decoder             |&gt; Http.get apiUrl             |&gt; Http.send FetchContact             |&gt; Cmd.map ContactMsg   assets/elm/src/Update.elm   module Update exposing (update, urlUpdate)  -- ...  urlUpdate : Model -&gt; ( Model, Cmd Msg ) urlUpdate model =     case model.route of         -- ...          ShowContactRoute id -&gt;             ( { model | contact = Requesting }             , Contact.Commands.fetchContact id             )  -- ...   And this is what we need to change the files to:   assets/elm/src/Contact/Commands.elm   module Contact.Commands exposing (fetchContact)  import Commands exposing (contactsApiUrl) import Contact.Decoder as Decoder import Contact.Messages exposing (ContactMsg(FetchContact)) import Http   fetchContact : Int -&gt; Cmd ContactMsg fetchContact id =     let         apiUrl =             contactsApiUrl ++ "/" ++ toString id     in         Decoder.decoder             |&gt; Http.get apiUrl             |&gt; Http.send FetchContact   assets/elm/src/Update.elm   module Update exposing (update, urlUpdate)  -- ...  urlUpdate : Model -&gt; ( Model, Cmd Msg ) urlUpdate model =     case model.route of         -- ...          ShowContactRoute id -&gt;             ( { model | contact = Requesting }             , id                 |&gt; Contact.Commands.fetchContact                 |&gt; Cmd.map ContactMsg  -- ...   Phew! We\u2019ve made quite a lot of changes across multiple files, so let\u2019s see if it paid off!      Having compilation problems? Compare what you\u2019ve written with code in the rest-refactor branch of the Address App and see if they match up.    Re-generate the module-graph.json file (./elm-module-graph.py src/Main.elm), and re-upload it to https://justinmimbs.github.io/elm-module-graph/ and let\u2019s see what the graph says:      Awesome! Modules in the Contact concern now have no direct dependencies with the top level Messages module!   I have attempted to take this even further by removing ContactList dependencies in the Messages module, and you can see the results of that in the rest-refactor branch of the Address App if you are interested.  Suffice to say, the graph now looks like:      Not bad! With further refactoring and re-architecting, maybe I could remove ContactList.View from this list, but I\u2019m done fighting with types for now :sweat_smile:   Conclusion   I found that using elm-module-graph was helpful in getting a high level overview of my Elm application, determining where potential compilation bottlenecks could appear, and deciding how to structure modules.   Is the way I architected and then refactored the application presented here a \u201cgood\u201d way to do it? At this stage, I do not know. I am very happy to be shown to be wrong about this, but for now, this way of doing things (less massive files; more smaller functions in smaller modules under concern directories) feels right to me, especially since I do not know of any \u201cofficial\u201d guidance on this.   Regardless, on your next Elm project, give generating a graph for it a try for some easy-to-digest information about its dependencies!   ',categories:[],tags:["elm","refactoring","architecture","graphs"],url:"https://www.paulfioravanti.com/blog/graph-driven-refactoring-elm/",teaser:"https://www.paulfioravanti.com/assets/images/2018-03-17/REST-branch-Messages-pre-refactor.png"},{title:"Runtime Language Switching in Elm",
excerpt:'When it comes to creating multilingual web pages, internationali[s|z]ation (I18n) would seem to be a deceptively complex problem using Elm.   I have never had to consider the choice of generating application translations as a pre-build phase of an app (eg elm-i18n), or have them be dynamically loaded (eg elm-i18next) when working with i18n in Rails or Phoenix. To be honest, I still do not know which way of doing things is \u201cbest\u201d in an Elm context. But, I do know that I want to have runtime-switchable languages via a dropdown menu, so the creation of an example page with dynamically loaded translations will be the main focus of this blog post.   I have been using Tachyons a lot lately for styling, and like how it plays with Elm, so we will set about doing the following:      Re-create Tachyons\u2019 Full Screen Centered Title component documentation page in Elm   Add a custom language-switcher dropdown menu to the page   Provide some translations for the page in JSON format, and allow the dropdown menu to switch the language   Store the selected language in localStorage so that any selected language persists through page refreshes and different sessions.   Explore generating Elm modules from the JSON translation files in order to give the translations some type safety   (If you want to skip ahead and see the final result, feel free to clone my elm-i18n-example repo)   Let\u2019s get started!      Update (21 December 2018)     The version of Elm used in this post is 0.18. I still stand by the overall points of the post, but some of the code is now outdated. The master branch of the elm-i18n-example repo has been updated to Elm 0.19, so if you are following along, and you get issues, try reconciling them there with the updated codebase.     The full original 0.18 codebase used in this post can be found on the 0.18 branch of the repo.    Bootstrap a New Elm Application   Create Elm App will help us bootstrap our app, so install it with:   npm install -g create-elm-app   Then, generate a new app, initialise npm (using the default fields provided for the generated package.json file is fine), and install Tachyons:   create-elm-app elm-i18n-example cd elm-i18n-example npm init npm install tachyons   Next, to import Tachyons into the project, change the generated index.js file to look like the following:   src/index.js   import "tachyons" import "./main.css" import { Main } from "./Main.elm"  const appContainer = document.getElementById("root")  if (appContainer) {   Main.embed(appContainer) }   Now, if you run elm-app start, http://localhost:3000/ should open automatically and you should see a familiar splash screen letting you know that your Elm app is working.   Before we get started properly, let\u2019s do a bit of clean-up of some of the generated code Create Elm App gave us:      We do not need src/main.css since Tachyons will take care of styling   This app will not use service workers, so src/registerServiceWorker.js can be removed   We will not be using the Elm logo from the splash screen, so that can be removed, as well as references to it in src/Main.elm   So, run the command below and make the following changes:   rm src/main.css src/registerServiceWorker.js public/logo.svg   src/index.js   import "tachyons" import { Main } from "./Main.elm"  // ...   src/Main.elm   -- ...  view : Model -&gt; Html Msg view model =     div []         [ h1 [] [ text "Your Elm App is working!" ]         ]   You should now be left with a very plain looking (but compilable) page, so let\u2019s brighten it up a bit!   Re-create the Tachyons Documentation Page   Using the sample code on the Full Screen Centered Title page as a guide (but with a few minor edits), change the Main.elm module definitions, import declarations, and view function to re-create the page:   src/Main.elm   module Main exposing (main)  import Html exposing (Html, article, div, h1, main_, text) import Html.Attributes exposing (class)  -- ...  view : Model -&gt; Html Msg view model =     let         classes =             [ "bg-dark-pink"             , "overflow-container"             , "sans-serif"             , "white"             ]                 |&gt; String.join " "                 |&gt; class     in         main_ [ classes ]             [ content ]   content : Html Msg content =     let         articleClasses =             [ "dt"             , "vh-100"             , "w-100"             ]                 |&gt; String.join " "                 |&gt; class          divClasses =             [ "dtc"             , "ph3 ph4-l"             , "tc"             , "v-mid"             ]                 |&gt; String.join " "                 |&gt; class     in         article [ articleClasses ]             [ div [ divClasses ]                 [ heading ]             ]   heading : Html Msg heading =     let         classes =             [ "f6 f2m"             , "f-subheadline-l"             , "fw6"             , "tc"             ]                 |&gt; String.join " "                 |&gt; class     in         h1 [ classes ]             [ text "Vertically centering things in css is easy!" ]   I think that putting Tachyons classes in lists like this makes them easier to scan and maintain, but it also has the side effect of making function definitions really long, so here we have split out the content across three different smaller functions.   Using utility-based CSS frameworks like Tachyons and Tailwind can seem daunting at first, what with all the mnemonics that you seem to have to commit to memory, so I always keep Tachyons\u2019 Table of Styles open in a browser tab for quick reference, and if this is your first look at Tachyons, I would recommend you do the same.   Anyway, your page should now look like the following screen shot:      If it does not, check your code against the 1-recreate-tachyons-doc-page branch of my codebase to see if anything is missing.   Add Language Dropdown Menu   For now, the language dropdown menu will be populated with placeholder values, and will not actually be able to change languages, but what we want from the menu in the end is:      The current language should be shown on the menu by default   When you click the menu, it should open, revealing any other available languages aside from the current language   When you mouse over a menu item, it should be highlighted in some way   When you click on a menu item, it should change the current language of the application (we\u2019ll do that later)   If, while the menu is open, you click anywhere else on the page, the menu should close   Most of these requirements sound like they would be best served in their own module, so let\u2019s create one called LanguageDropdown.elm, and start with rendering just the current language selection so we can get the menu positioning right.   Current Selection   src/LanguageDropdown.elm   module LanguageDropdown exposing (view)  import Html exposing (Html, div, li, p, span, text, ul) import Html.Attributes exposing (class)   view : Html msg view =     let         classes =             [ "center"             , "f3"             , "flex"             , "h3"             , "items-center"             , "justify-end"             , "w-90"             ]                 |&gt; String.join " "                 |&gt; class     in         div [ classes ]             [ currentSelection ]   currentSelection : Html msg currentSelection =     let         classes =             [ "b--white"             , "ba"             , "br2"             , "pa2"             , "pointer"             , "tc"             , "w4"             ]                 |&gt; String.join " "                 |&gt; class          caretClasses =             [ "absolute"             , "ml2"             ]                 |&gt; String.join " "                 |&gt; class     in         p [ classes ]             [ span []                 [ text "English" ]             , span [ caretClasses ]                 [ text "\u25be" ]             ]   Next, we have to import the language dropdown code in the Main module, as well as slightly adjust the styles in the view function, since there is now more on the page than just the message:   src/Main.elm   -- ... import LanguageDropdown  -- ...  view : Model -&gt; Html Msg view model =     let         classes =             [ "bg-dark-pink"             , "overflow-container"             , "pt3"             , "sans-serif"             , "vh-100"             , "white"             ]                 |&gt; String.join " "                 |&gt; class     in         main_ [ classes ]             [ LanguageDropdown.view             , content             ]  content : Html Msg content =     let         articleClasses =             [ "dt"             , "vh-75"             , "w-100"             ]                 |&gt; String.join " "                 |&gt; class          -- ...     in         -- ...   Now, your page should look like this:      The \u201cmenu\u201d here (yes, it is currently just a p tag), currently does nothing, but we can at least confirm that it looks like it is in a good spot on the page. Now, let\u2019s actually give it a dropdownList under the currentSelection!   Language Dropdown List   src/LanguageDropdown.elm   view : Html msg view =     let         -- ...     in         div [ classes ]             [ currentSelection             , dropdownList             ]  -- ...  dropdownList : Html msg dropdownList =     let         classes =             [ "absolute"             , "b--white"             , "bb"             , "bl"             , "br"             , "br--bottom"             , "br2"             , "items-center"             , "list"             , "mt5"             , "pl0"             , "pointer"             , "pr0"             , "pt1"             , "tc"             , "top-0"             , "w4"             ]                 |&gt; String.join " "                 |&gt; class          selectableLanguages =             [ "Italiano", "\u65e5\u672c\u8a9e" ]      in         ul [ classes ]             (List.map dropdownListItem selectableLanguages)   dropdownListItem : String -&gt; Html msg dropdownListItem language =     let         classes =             [ "hover-bg-white"             , "hover-dark-pink"             , "ph1"             , "pv2"             , "pt0"             , "w-100"             ]                 |&gt; String.join " "                 |&gt; class     in         li [ classes ]             [ span [] [ text language ] ]   This results in:         For the dropdown list, we are shoving a HTML unordered list (ul) right underneath the p tag, simulating a menu opening.   When we hover over a menu item, we can tell which item is currently being selected.   Selectable languages currently have strings as their placeholders, but we will change that later on as we introduce the concept of a language to the application.   So, we now know what the menu looks like when it is open, but we need it to respond to mouse clicks to open and close the dropdown list (read: show and hide the list), so let\u2019s do that now.   Show and Hide Available Languages   The application needs to be able to keep track of whether to show or hide the dropdown list, and needs to be able to track clicks on the menu and page, so it sounds like we need the following:      A Boolean flag to tell the app whether to showAvailableLanguages or not   An update Msg that will toggle the visibility of the dropdown list; let\u2019s call it ShowAvailableLanguages   An update Msg that will hide the dropdown list, for when the dropdown is open but a click is registered anywhere else on the page; let\u2019s call it CloseAvailableLanguages   We will start with updating the Msg union type. Both Main.elm and LanguageDropdown.elm are going to need access to Msg, so let\u2019s extract it into its own module:   src/Msg.elm   module Msg exposing (Msg(..))   type Msg     = CloseAvailableLanguages     | ShowAvailableLanguages   Next, extract Model and the init function from Main into a new Model.elm module, making sure that the dropdown is set to be hidden by default:   src/Model.elm   module Model exposing (Model, init)  import Msg exposing (Msg)   type alias Model =     { showAvailableLanguages : Bool }   init : ( Model, Cmd Msg ) init =     ( { showAvailableLanguages = False }, Cmd.none )   Now, we need to update Main.elm and LanguageDropdown.elm to import these modules, and then write some handling code for these Msgs in the update function:   src/Main.elm   -- ... import Model exposing (Model) import Msg exposing (Msg(CloseAvailableLanguages, ShowAvailableLanguages))   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         CloseAvailableLanguages -&gt;             ( { model | showAvailableLanguages = False }, Cmd.none )          ShowAvailableLanguages -&gt;             ( { model                 | showAvailableLanguages = not model.showAvailableLanguages               }             , Cmd.none             )  -- ...  main : Program Never Model Msg main =     Html.program         { view = view         , init = Model.init         , update = update         , subscriptions = always Sub.none         }   In the LanguageDropdown, since we will be now be sending messages of type Msg, all function annotations with Html msg will need to be updated to be Html Msg. We will also be making use of the view function\u2019s model parameter throughout the dropdown in order to determine what to show, as well as how to style the dropdown menu when it is open and closed:   src/LanguageDropdown.elm   -- ... import Html.Events exposing (onClick) import Model exposing (Model) import Msg exposing (Msg(ShowAvailableLanguages))   view : Model -&gt; Html Msg view model =     let         -- ...     in         div [ classes ]             [ currentSelection model             , dropdownList model             ]   currentSelection : Model -&gt; Html Msg currentSelection model =     let         displayClasses =             if model.showAvailableLanguages then                 [ "br--top" ]             else                 []          classes =             [ -- ...             ]                 ++ displayClasses                 |&gt; String.join " "                 |&gt; class          -- ...     in         p [ classes, onClick ShowAvailableLanguages ]             [ -- ...             ]   dropdownList : Model -&gt; Html Msg dropdownList model =     let         displayClasses =             if model.showAvailableLanguages then                 [ "flex", "flex-column" ]             else                 [ "dn" ]          classes =             [ -- ...             ]                 ++ displayClasses                 |&gt; String.join " "                 |&gt; class          -- ...     in        -- ...   dropdownListItem : String -&gt; Html Msg -- ...   Once the above changes are made, you should be able to click on the dropdown menu to open and close it, showing and hiding the available languages. However, if you open the menu and then click anywhere else, the menu stays open.   In order to get it to close (and actually use that CloseAvailableLanguages message), we are going to have to make use of the Elm Mouse package, and a subscription to mouse clicks.   Subscribe to Mouse Clicks   Install the Elm Mouse package:   elm-package install -y elm-lang/mouse   Then, create a subscriptions function in Elm that listens out for mouse clicks only when the dropdown menu is open, and if a click is detected, sends a CloseAvailableLanguages message:   src/Main.elm   -- ... import Mouse  -- ...  subscriptions : Model -&gt; Sub Msg subscriptions model =     if model.showAvailableLanguages then         Mouse.clicks (\\_ -&gt; CloseAvailableLanguages)     else         Sub.none   main : Program Never Model Msg main =     Html.programWithFlags         { view = view         , init = Model.init         , update = update         , subscriptions = subscriptions         }   Now, whenever you click open the dropdown menu, and then click anywhere else, the menu will close, as expected.   If the app so far is not behaving as you would expect, compare your code to the 2-add-language-dropdown branch of my codebase to see if anything is missing.   Now, it\u2019s time to give the application the concept of a language to switch, and replace those placeholder values with actual data!   Language Switching   Time to get some translations into the application, and for that, we will use elm-i18next, along with the HTTP in Elm package, so let\u2019s get installing:   elm-package install -y ChristophP/elm-i18next elm-package install -y elm-lang/http   First, let\u2019s provide some translation JSON files for the message on screen in English, Italian, and Japanese. Create a public/locale/ directory and add the following files under it:   public/locale/translations.en.json   {   "verticallyCenteringInCssIsEasy": "Vertically centering things in css is easy!" }   public/locale/translations.it.json   {   "verticallyCenteringInCssIsEasy": "Centrare verticalmente con css \xe8 facile!" }   public/locale/translations.ja.json   {   "verticallyCenteringInCssIsEasy": "CSS\u3067\u5782\u76f4\u30bb\u30f3\u30bf\u30ea\u30f3\u30b0\u306f\u7c21\u5358\u3060\u3088\uff01" }   Next, let\u2019s create a Translations module where we will define the type for a language, and provide a helper function to convert a string language code into a language:   src/Translations.elm   module Translations exposing (Lang(..), getLnFromCode)   type Lang     = En     | It     | Ja   getLnFromCode : String -&gt; Lang getLnFromCode code =     case code of         "en" -&gt;             En          "it" -&gt;             It          "ja" -&gt;             Ja          _ -&gt;             En   Great! Now we need to add some new Msg types for:      Fetching the translations from the JSON files   Changing the language   src/Msg.elm   module Msg exposing (Msg(..))  import Http exposing (Error) import I18Next exposing (Translations) import Translations exposing (Lang)   type Msg     = ChangeLanguage Lang     | CloseAvailableLanguages     | FetchTranslations (Result Error Translations)     | ShowAvailableLanguages   We now need a way to be able to go and fetch the translations from the JSON files, and return the result back via the FetchTranslations message, so let\u2019s create that in a new module called Cmd:   src/Cmd.elm   module Cmd exposing (fetchTranslations)  import I18Next import Msg exposing (Msg(FetchTranslations)) import Translations exposing (Lang)   fetchTranslations : Lang -&gt; Cmd Msg fetchTranslations language =     language         |&gt; toTranslationsUrl         |&gt; I18Next.fetchTranslations FetchTranslations   toTranslationsUrl : Lang -&gt; String toTranslationsUrl language =     let         translationLanguage =             language                 |&gt; toString                 |&gt; String.toLower     in         "/locale/translations." ++ translationLanguage ++ ".json"   Now, the Model needs to know about what the currentLanguage of the application is in order to determine what translations should be loaded, so let\u2019s add that information, and call the Cmd.fetchTranslations En command to immediately go and fetch the appropriate English translations, which we will also set as the default language:   src/Model.elm   module Model exposing (Model, init)  import Cmd import I18Next exposing (Translations) import Msg exposing (Msg) import Translations exposing (Lang(En))   type alias Model =     { currentLanguage : Lang     , showAvailableLanguages : Bool     , translations : Translations     }   init : ( Model, Cmd Msg ) init =     ( { currentLanguage = En       , showAvailableLanguages = False       , translations = I18Next.initialTranslations       }     , Cmd.fetchTranslations En     )   Next, we need to handle the new ChangeLanguage and FetchTranslations messages in the update function:      When the language is changed, as well as change the currentLanguage, we need to go and fetch the translations for that language in the same way we did in the init function   If fetching the translations succeeds, we will display the new translations, otherwise, for now we will just ignore any errors since we would not expect to fetch translations for a language that we did not create ourselves.   src/Main.elm   -- ... import Cmd import Msg     exposing         ( Msg             ( ChangeLanguage             , CloseAvailableLanguages             , FetchTranslations             , ShowAvailableLanguages             )         )  --- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         -- ...         ChangeLanguage language -&gt;             ( { model | currentLanguage = language }             , Cmd.fetchTranslations language             )          FetchTranslations (Ok translations) -&gt;             ( { model | translations = translations }, Cmd.none )          FetchTranslations (Err msg) -&gt;             ( model, Cmd.none )   At this stage, the application should be back to a point where everything is compiling again, but on the surface there are no changes since the language display still consists of static values, so let\u2019s change that.   First, we will create a Language module that will have some helper functions around generating the string value for a language (eg \u201cEnglish\u201d should always be displayed as \u201cEnglish\u201d, regardless of what the current language is), and keeping a static list of available languages so we can display them in the dropdown menu. Unfortunately, there is no way to generate a list of type values from a type (eg [En, It, Ja] from the Lang type), so it will have to be a separate definition:   src/Language.elm   module Language exposing (availableLanguages, langToString)  import Translations exposing (Lang(En, It, Ja))   availableLanguages : List Lang availableLanguages =     [ En, It, Ja ]   langToString : Lang -&gt; String langToString language =     case language of         En -&gt;             "English"          It -&gt;             "Italiano"          Ja -&gt;             "\u65e5\u672c\u8a9e"   Now that we have our language data setup, let\u2019s go back to the view code and get the page to start displaying it. First, let\u2019s get the correct information displayed on the dropdown menu for both the current language, and for the other available languages in the dropdown:   src/LanguageDropdown.elm   -- ... import Language import Msg exposing (Msg(ChangeLanguage, ShowAvailableLanguages)) import Translations exposing (Lang)  -- ...  currentSelection : Model -&gt; Html Msg currentSelection model =     let         -- ...     in         p [ classes, onClick ShowAvailableLanguages ]             [ span []                 [ text (Language.langToString model.currentLanguage) ]             , span [ caretClasses ]                 [ text "\u25be" ]             ]   dropdownList : Model -&gt; Html Msg dropdownList model =     let         -- ...          selectableLanguages =             List.filter                 (\\language -&gt; language /= model.currentLanguage)                 Language.availableLanguages     in         ul [ classes ]             (List.map dropdownListItem selectableLanguages)   dropdownListItem : Lang -&gt; Html Msg dropdownListItem language =     let         -- ...     in         li [ classes, onClick (ChangeLanguage language) ]             [ span []                 [ text (Language.langToString language) ]             ]   At this point, if you select a new language from the dropdown menu, you will see the current language display change on the menu, and if you open the Elm debugger, you will see that the language of the application is actually changing, and the translations for the language are being loaded into the application:      Great! Now let\u2019s get that translated message showing on the page by letting the content know what translations it is supposed to be displaying:   src/Main.elm   -- ... import Translations exposing (Lang)  -- ...  view : Model -&gt; Html Msg view model =     let         -- ...     in         main_ [ classes ]             [ LanguageDropdown.view model             , content model.translations             ]   content : Translations -&gt; Html Msg content translations =     let        -- ...     in         article [ articleClasses ]             [ div [ divClasses ]                 [ heading translations ]             ]   heading : Translations -&gt; Html Msg heading translations =     let         -- ...     in         h1 [ classes ]             [ text (I18Next.t translations "verticallyCenteringInCssIsEasy") ]   And now, when you change language, you should see the displayed message in that language:      Fantastic! That covers the main functionality of language switching, but there is still more we can do. Before we move on though, if you cannot switch languages, be sure to double-check your code against the 3-add-language-switching branch of my codebase.   Detect User Language   Currently, the application language is set to English by default when it starts, but it would be nice if we at least tried to set the application to initially display in the user\u2019s preferred language. To simplify the idea of a \u201cpreferred language\u201d (because this is not universal amongst browers), we will consider it to be the language of the browser being used. How do we get that? In Javascript, we can use:      navigator.language   navigator.userLanguage (for Internet Explorer)   So, let\u2019s grab this information from Javascript, and pass it into Elm as a flag:   src/index.js   import "tachyons" import { Main } from "./Main.elm"  const appContainer = document.getElementById("root")  if (appContainer) {   Main.embed(appContainer, { language: getLanguage() }) }  function getLanguage() {   return navigator.language || navigator.userLanguage }   Our application cannot currently accept flags from Javascript, so let\u2019s change our program type to programWithFlags to allow that to happen:   src/Main.elm   -- ... import Model exposing (Flags, Model)  -- ...  main : Program Flags Model Msg main =     Html.programWithFlags         { view = view         , init = Model.init         , update = update         , subscriptions = subscriptions         }   Next, we will define what type of flags we will accept in the Model module, and because we do not trust any information passed in from Javascript, we will decode the flag to ensure that we are getting a string.   src/Model.elm   module Model exposing (Flags, Model, init)  -- ... import Json.Decode as Decode exposing (Value) import Language   type alias Flags =     { language : Value }  -- ...  init : Flags -&gt; ( Model, Cmd Msg ) init flags =     let         language =             flags.language                 |&gt; Decode.decodeValue Decode.string                 |&gt; Language.langFromFlag     in         ( { currentLanguage = language           , showAvailableLanguages = False           , translations = I18Next.initialTranslations           }         , Cmd.fetchTranslations language         )   Finally, we will create the Language.langFromFlag function that will return a language if decoding goes well, and return a default language if not:   src/Language.elm   module Language exposing (availableLanguages, langFromFlag, langToString)  -- ...  langFromFlag : Result String String -&gt; Lang langFromFlag language =     case language of         Ok language -&gt;             Translations.getLnFromCode language          Err _ -&gt;             En   If your browser language is English, you will not notice any change as a result of these additions, but if you change your browser language to Italian or Japanese and then refresh the page, you will see that the application will start in that language.   For Chrome, you can change the language setting by opening the browser preferences, opening the Advanced preferences\u2026      \u2026finding the Languages preferences, and then choosing a language to Move to the top of the list:      Default language not changing? Check your code against the 4-detect-user-language branch of my codebase.   Now, having a default language is nice, but if you switch languages and then refresh the page, the application will revert back to the language set in the browser. Plenty of people want to read content in a different language than their system settings, and it would be nice to be able to save their language preference for this application. So, let\u2019s then use the browser\u2019s localStorage to help us do exactly that.   Store Language Preference   Sending Elm data to Javscript requires us to use Elm Ports. All port functions return a Cmd msg, so let\u2019s put the function to remember a language preference in the Cmd module, changing it over to a port module:   src/Cmd.elm   port module Cmd exposing (fetchTranslations, storeLanguage)  -- ...  port storeLanguageInLocalStorage : String -&gt; Cmd msg  -- ...  storeLanguage : Lang -&gt; Cmd msg storeLanguage language =     language         |&gt; toString         |&gt; String.toLower         |&gt; storeLanguageInLocalStorage   Here we have created a storeLanguage command function that takes in a Lang type, stringifies it, and sends it off to Javascript via the storeLanguageInLocalStorage port. On the Javascript side, there is currently no code that is subscribing to messages coming from that port, so we\u2019ll make that next:   src/index.js   // ... if (appContainer) {   const app = Main.embed(appContainer, { language: getLanguage() })    app.ports.storeLanguageInLocalStorage.subscribe((language) =&gt; {     localStorage.setItem("elm-i18n-example-language", language)   }) } // ...   There is no particular reason behind the \u201celm-i18n-example-language\u201d named key; it could have been named anything, but it is best to have it as unique as possible, since many different applications will likely be making use of localStorage.   Okay, we\u2019ve got the pathway to Javascript set up, now we need to make sure that the command is run every time the language is changed (ie the ChangeLanguage message is sent), so let\u2019s make that addition to the update function:   src/Main.elm   -- ...  update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         ChangeLanguage language -&gt;             ( { model | currentLanguage = language }             , Cmd.batch                 [ Cmd.fetchTranslations language                 , Cmd.storeLanguage language                 ]             )     -- ...   The ChangeLanguage branch of the update function has gotten a bit busier, needing to use Cmd.batch to send commands to both fetch new language translations, and store the user language preference.   Now, you should be able to switch languages, and have it stored in localStorage. Open up the Javascript console in your browser\u2019s developer tools to confirm this with the following command: localStorage.getItem("elm-i18n-example-language")      Success! But there is one small lingering issue though: if you refresh the browser, the application is still reverting back to the default language of English. We need to have our Javascript code get the language from localStorage (if it\u2019s there), and pass that in as the Elm language flag, so let\u2019s do that:   src/index.js   // ... function getLanguage() {   return localStorage.getItem("elm-i18n-example-language") ||     navigator.language ||     navigator.userLanguage }   Now, if you change languages and refresh the page, the application should still show you the language that you originally selected! If it doesn\u2019t, check your code against the 5-store-language-preference branch of my codebase.   At this stage, our page is pretty much feature complete. However, there are still a few potential issues that would be worthy of a bit more investigation:      If you refresh the page, you may see the translation key \u201cverticallyCenteringInCssIsEasy\u201d briefly flash before the translation is shown. This is particularly noticeable on the Japanese translation. Perhaps the translations are being loaded too slowly\u2026?   If you accidentally make a typo when requesting a translation by key in a view (eg I18Next.t translations "thisKeyDoesNotExist"), then no error is raised: the key is simply displayed on the page, which may not be what you want.   If you accidentally do not provide a translation for a particular key for a known available language, or make a typo in the translation file (eg delete the translations.ja.json file or change its key name), then, again, no error is raised, and the requested key is displayed on the page as-is.   Elm programmers are spoiled by the Elm compiler always looking over our shoulder and helping us avoid these kinds of mistakes. If you are confident about manually handling the issues outlined or they are not important to you, then all is good and you need not go any further. But, if want Elm to cast more of an eye over your i18n development, what options are available to you?   Type-Safe Translations   Since we have our translation files as JSON, we can use Elm i18n Gen to generate a Translations module containing one function for every translation in the JSON files. So, let\u2019s give it a try.   Install it with the following command:   npm install -g elm-i18n-gen   Generate a new Translations module for the app with the following command:   elm-i18n-gen public/locale src/Translations.elm   And if you open up the Translations module you should see the following:   src/Translations.elm   module Translations exposing (..)   type Lang     = En     | It     | Ja   getLnFromCode : String -&gt; Lang getLnFromCode code =     case code of         "en" -&gt;             En          "it" -&gt;             It          "ja" -&gt;             Ja          _ -&gt;             En   verticallyCenteringInCssIsEasy : Lang -&gt; String verticallyCenteringInCssIsEasy lang =     case lang of         En -&gt;             "Vertically centering things in css is easy!"          It -&gt;             "Centrare verticalmente con css \xe8 facile!"          Ja -&gt;             "CSS\u3067\u5782\u76f4\u30bb\u30f3\u30bf\u30ea\u30f3\u30b0\u306f\u7c21\u5358\u3060\u3088\uff01"   We only have one translation key in our JSON files, so elm-i18n-gen created just one function for us that covers translations for all our languages. You can also see here that I adopted elm-i18n-gen\u2019s specific naming conventions for Lang, and getLnFromCode in advance, and deliberately put that information in the Translations module knowing it would be overwritten when the new Translations file was generated (\u2026I think my Chekhov\u2019s Gun is jammed\u2026).   Anyway, now that we have our function, let\u2019s use it in the view:   src/Main.elm   -- ... import Translations exposing (Lang)  -- ...  view : Model -&gt; Html Msg view model =     let         -- ...     in         main_ [ classes ]             [ LanguageDropdown.view model             , content model.currentLanguage             ]   content : Lang -&gt; Html Msg content language =     let         -- ...     in         article [ articleClasses ]             [ div [ divClasses ]                 [ heading language ]             ]   heading : Lang -&gt; Html Msg heading language =     let         -- ...     in         h1 [ classes ]             [ text (Translations.verticallyCenteringInCssIsEasy language) ]   The effects of this one change are the following:      There is now no need to fetch any translations, and consequently the FetchTranslations Msg, the fetchTranslations function in the Cmd module, the translations entry in the Model, and any trace of the I18Next and Http packages, can now be safely removed.   The issue of a translation key displaying before the translation is loaded has consequently gone away since we are now just calling a function.   Elm will raise a compiler error if a translation is not provided for all languages.   Those are some pretty good benefits! I\u2019m not sure about any downsides to this, aside from maybe having a single module with potentially hundreds of functions in it for any given large JSON translation file. But, I would guess the overhead for maintainability of that module would be the same for the JSON file. Please let me know if I\u2019m wrong about this!   See the 6-type-safe-translations branch of my codebase to see the final form of the application, with all extraneous code removed.   Conclusion   Even after all this, I\u2019m still not really sure what to think when it comes to an ideal solution for I18n in Elm. I am planning on using the methods outlined in this blog post for the time being, but if you have any better ways of doing things (I\u2019d love to see an actual example of an app using the elm-i18n package), please let me know!   ',
categories:[],tags:["elm","i18n","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"https://www.paulfioravanti.com/blog/runtime-language-switching-elm/",teaser:"https://www.paulfioravanti.com/assets/images/2018-05-11/ameet-dhanda-476959-unsplash.jpg"},{title:"Connecting Elm to Phoenix 1.4 with webpack",excerpt:'As of version 1.4, Phoenix has changed its front end configuration framework from Brunch to webpack version 4 (reasons given in this pull request). This means that the way to get Elm connected to Phoenix has also changed since I last wrote about it, so this blog post will re-tread those main steps (read: copy-paste them from the previous blog entry where possible), updating information where relevant.      NOTE: Phoenix 1.4 is in beta at the time of this writing, so if it still is at the time of your reading this, and you would like to follow along, you can install Phoenix 1.4 Beta by doing the following:    mix archive.uninstall phx_new mix archive.install https://github.com/phoenixframework/archives/raw/master/1.4-dev/phx_new.ez      Don\u2019t forget to re-install the latest stable version of Phoenix when you are done experimenting!    mix archive.uninstall phx_new mix archive.install https://github.com/phoenixframework/archives/raw/master/phx_new.ez   Generate Phoenix app   mix phx.new phx_elm_webpack cd phx_elm_webpack mix ecto.create mix phx.server   Navigate to http://localhost:4000/ and you should see the familiar Phoenix welcome screen.      No surprises here. Close down the server, and let\u2019s move on.   Generate Elm app   First, install Elm if you haven\u2019t already:   npm install elm --global   Next, in order to help us generate an Elm app with a default structure and sensible configuration, we\u2019ll use Create Elm App (inspired by Create React App):   npm install create-elm-app --global   Generate the new Elm app inside the \u201cfront end\u201d of the Phoenix application, which in this case means the assets/ directory:   cd assets create-elm-app elm   You should now have an elm folder alongside your js and css folders. Let\u2019s make sure it works as we expect:   cd elm elm-app start   Starting the Elm app should then automatically open a browser window for you at http://localhost:3000/, and you should see a message saying that\u2026      Note that the Elm app is running independently here: it knows nothing about the Phoenix environment that it\u2019s located in, and is happily using assets, like the image that you see, from its own assets/elm/public/ directory.   Now that we\u2019ve confirmed that both the Phoenix app and the Elm app work of their own accord, it\u2019s time to connect them together. Close down the Elm server and let\u2019s write some config.   Connect Elm to Phoenix   In order to get webpack to track our new Elm dependencies, we will need the Elm loader plugin. So, navigate to the assets/ folder and install it:   npm install elm-webpack-loader   Now, open up webpack.config.js in a text editor and add the configuration rule for Elm files underneath the css rule:   assets/webpack.config.js   // ... module.exports = (env, options) =&gt; ({   // ...   module: {     rules: [       {         test: /\\.js$/,         exclude: /node_modules/,         use: {           loader: \'babel-loader\'         }       },       {         test: /\\.css$/,         use: [MiniCssExtractPlugin.loader, \'css-loader\']       },       {         test: /\\.elm$/,         exclude: ["/elm-stuff/", "/node_modules"],         loader: "elm-webpack-loader",         options: {           debug: true,           // NOTE: `warn` option was removed in Elm 0.19.           // Re-enable if desired for use in Elm 0.18.           // warn: true,           cwd: path.resolve(__dirname, "elm")         }       }     ]   },   //... });   Display Elm app in Phoenix template   So that we show both Phoenix and Elm working together, let\u2019s keep the default generated Phoenix layout template as-is, and replace the content of the page index template with a &lt;div&gt; tag for the Elm app:   lib/phx_elm_webpack/templates/page/index.html.eex   &lt;div id="elm-main"&gt;&lt;/div&gt;   Next, we\u2019ll target that &lt;div&gt; tag and replace it with the content of the Elm app:   assets/js/app.js   Elm 0.18   // ... import Elm from "../elm/src/Main.elm"  const elmDiv = document.getElementById("elm-main") Elm.Main.embed(elmDiv)   Elm 0.19   // ... import { Elm } from "../elm/src/Main.elm"  const elmDiv = document.getElementById("elm-main") Elm.Main.init({ node: elmDiv })   Now, run mix phx.server again and navigate to http://localhost:4000 to see if we\u2019re in business:      Well, we\u2019re pretty much there: we can see that the Elm app is being rendered in the template, but we\u2019ve got a broken image. This is because that image currently lives inside the Elm app at assets/elm/public/logo.svg, and Phoenix doesn\u2019t know anything about compilation of static image assets within Elm applications: it\u2019s looking for assets under its own assets/static/ directory.   The path of least resistance here is, I think, to move all assets to where Phoenix is expecting to find them, and change the Elm code to point to them.   So, first, move the logo image into Phoenix\u2019s image assets directory:   mv assets/elm/public/logo.svg assets/static/images/logo.svg   Then, change the Elm code to look for the image in Phoenix (/images/logo.svg), rather than in Elm (/logo.svg):   assets/elm/src/Main.elm   module Main exposing (..)  -- ...  view : Model -&gt; Html Msg view model =     div []         [ img [ src "/images/logo.svg" ] []         , h1 [] [ text "Your Elm App is working!" ]         ]   Now, at http://localhost:4000/, you should see the following:      At this point, everything is technically working, so you can happily continue your application bootstrapping, but if you need to have the styling on this screen pixel perfect before finishing, read on.   Tell webpack about Elm app styling   Currently, the Elm app has some styling in assets/elm/src/main.css, and Phoenix has its styling in assets/css/app.css. However, if we have a look at the top of assets/js/app.js, we can see that only the Phoenix CSS is being imported, and hence loaded, by webpack. So, let\u2019s see what happens when we get webpack to load the Elm application\u2019s CSS file as well:   assets/js/app.js   import css from "../css/app.css" import "../elm/src/main.css"   Re-start the app and let\u2019s see what happened\u2026      Well, the Elm app styling looks like we would expect, but some of the Elm styles would seem to be overriding the Phoenix styles, so let\u2019s see if we can take the path of least resistance in fixing this (since this is all only temporary anyway\u2026).   First, give the Elm logo a HTML id so we can target styling on it directly:   assets/elm/src/Main.elm   module Main exposing (..)  import Html exposing (Html, text, div, h1, img) import Html.Attributes exposing (id, src)  -- ...  view : Model -&gt; Html Msg view model =     div []         [ img [ src "/images/logo.svg", id "elm-logo" ] []         , h1 [] [ text "Your Elm App is working!" ]         ]   Then, give the Elm styles some minor tweaks from their defaults\u2026   assets/elm/src/main.css   /* ... */  body {   text-align: center; }  h1 {   color: #293c4b;   font-family: \'Source Sans Pro\', \'Trebuchet MS\', \'Lucida Grande\', \'Bitstream Vera Sans\', \'Helvetica Neue\', sans-serif;   font-size: 30px; }  img#elm-logo {   margin: 20px 0;   max-width: 200px; }   Re-start the app, and\u2026      That looks about right. Now, you can get down to the business of ripping it all out again, and start building out your own Phoenix-and-Elm powered app!   ',categories:[],tags:["elixir","phoenix","elm"],url:"https://www.paulfioravanti.com/blog/connecting-elm-phoenix-14-webpack/",teaser:"https://www.paulfioravanti.com/assets/images/2018-07-26/functional_web_wallpaper.jpg"},{title:"Escape the defaults and Control your keyboard with QMK",excerpt:'I love mechanical keyboards, and have been using an Ergodox as my daily driver since 2014.      If you are someone who spends a lot of time using a keyboard, and are likely to continue to do so in the future, then I would:      encourage you to learn touch typing if you haven\u2019t already   consider ergonomic keyboard options to increase comfort, as well as reduce strain on your shoulders and wrists (the keyboard you choose does not necessarily have to be mechanical, or a split-hand option like the Ergodox)   If you are programmer or tinkerer, then getting a keyboard with programmable firmware can enable you to personalise how you use your keyboard, allowing your brain (or hand muscle memory) a say in assigning functionality to keys, rather than you having to train yourself to adapt to some product\u2019s specification.      When I got my first Ergodox, I used Massdrop\u2019s Ergodox Configurator to generate firmware for the keyboard. As I got to know my Ergodox better, and my brain started to tell me that it was expecting certain keys to be in different places from the default setup, I was able to use the Configurator\u2019s nice user interface to make basic changes, and then re-generate the firmware in a matter of minutes.   It was only when I started wanting to have a keystroke represent a combination of keys, rather than a single key, that I hit the limitations of what the web-based Configurator enabled me to do. So, I decided to bypass it and go straight to the source code that the Configurator itself was using to generate its firmware: Ben Blazak\u2019s Ergodox Firmware.   I am not a C language programmer, but after a period of tinkering, I was able to cobble together a custom keymap layout, and successfully flash it on to my keyboard firmware. It worked great, and I happily used it for years.   Then, one day, I wanted to make some updates, and realised that some code libraries that the firmware used were now so old and outdated that I was unable to compile a new version of the firmware on my computer.   As of this writing, it looks like development on the firmware has stalled, and so if I really wanted to update my keyboard layout, I would need re-write it for a new platform.   Enter QMK   After some investigation, I came to the conclusion that the Quantum Mechanical Keyboard (QMK) Firmware would likely be my best choice, given its popularity with Ergodox users, and because it supports many other keyboard types. So, I can continue to use it if, somehow, I accidentally end up buying other different types of mechanical keyboards (if you are into mechs, you know how it is\u2026 :money_with_wings:)   So, let\u2019s grab the firmware from Github:   git clone git@github.com:qmk/qmk_firmware.git cd qmk_firmware   Now, open up the QMK Ergodox EZ default layout (so called, I believe, because Ergodox EZ is now the pre-eminent retailer of original version Ergodoxes) to use as a base, and see about getting a feel for how to use it.   Keyboard Layout      Below is an abbreviated part of the default layout, focusing on one layer for the left side of an Ergodox keyboard:   qmk_firmware/keyboards/ergodox_ez/keymaps/default/keymap.c   // ... /* Keymap 0: Basic layer  *  * ,--------------------------------------------------.  * |   =    |   1  |   2  |   3  |   4  |   5  | LEFT |  * |--------+------+------+------+------+-------------|  * | Del    |   Q  |   W  |   E  |   R  |   T  |  L1  |  * |--------+------+------+------+------+------|      |  * | BkSp   |   A  |   S  |   D  |   F  |   G  |------|  * |--------+------+------+------+------+------| Hyper|  * | LShift |Z/Ctrl|   X  |   C  |   V  |   B  |      |  * `--------+------+------+------+------+-------------\'  *   |Grv/L1|  \'"  |AltShf| Left | Right|  *   `----------------------------------\'  *                                        ,-------------.  *                                        | App  | LGui |  *                                 ,------|------|------|  *                                 |      |      | Home |  *                                 | Space|Backsp|------|  *                                 |      |ace   | End  |  *                                 `--------------------\'  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL,          KC_1,        KC_2,          KC_3,    KC_4,    KC_5, KC_LEFT,   KC_DELT,         KC_Q,        KC_W,          KC_E,    KC_R,    KC_T, TG(SYMB),   KC_BSPC,         KC_A,        KC_S,          KC_D,    KC_F,    KC_G,   KC_LSFT,         CTL_T(KC_Z), KC_X,          KC_C,    KC_V,    KC_B, ALL_T(KC_NO),   LT(SYMB,KC_GRV), KC_QUOT,     LALT(KC_LSFT), KC_LEFT, KC_RGHT,                                                         ALT_T(KC_APP), KC_LGUI,                                                                        KC_HOME,                                                KC_SPC,  KC_BSPC,       KC_END,   // .. )   Here, we can see:      Constant variables that begin with KC_. These represent a single basic key code, like the \u201cA\u201d or \u201c1\u201d keys.   Other mappings that do not begin with KC_. These are functions that take arguments, and can represent actions like holding down one key while pressing another.   All these constants and functions (and more representing every key on a keyboard, as well as various key combinations) are enumerated in the QMK Keycodes Documentation, and are available to use in the layout without any further configuration.   That\u2019s all well and good, but what if there is no built-in mapping for a key combination you want to perform?   Custom Key Mappings   Let\u2019s say that on the layout above, instead of having the top left corner key be the \u201c=\u201d character (ie KC_EQL) when tapped, you would like it to perform some custom combination of key presses, which we\u2019ll name MY_KEY_COMBO.   Where does MY_KEY_COMBO get declared, and where do we define what it is supposed to actually do? Well, there are three main steps for this, but before we do them, let\u2019s create a copy of the default keymap folder, put it into a custom directory, and make our edits on that:   cp -r qmk_firmware/keyboards/ergodox_ez/keymaps/default qmk_firmware/keyboards/ergodox_ez/keymaps/custom   First, we need to add a new MY_KEY_COMBO type to the existing custom_keycodes enumerated types list, which is declared towards the top of the keymap file:   qmk_firmware/keyboards/ergodox_ez/keymaps/custom/keymap.c   enum custom_keycodes {   // ...   MY_KEY_COMBO };   Now, we can replace KC_EQL with MY_KEY_COMBO in the keyboard layout:   // ... [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   MY_KEY_COMBO, KC_1, KC_2, KC_3, KC_4, KC_5, KC_LEFT,   // ...   To give this new type some behaviour, we need to register it inside a function called process_record_user(), which can be found towards the bottom of the keymap file:   bool process_record_user(uint16_t keycode, keyrecord_t *record) {   switch (keycode) {     case MY_KEY_COMBO:       if (record-&gt;event.pressed) {         // Do whatever it is that MY_KEY_COMBO is supposed to do when pressed       }       return false;       break;     // other case statements ...   }   return true; }   process_record_user() will get called automatically whenever a key on your keyboard is pressed or released, so there is no need to add any code that specifically calls it. More information about this function, as well as how to define a new key code, can be found on the QMK Custom Quantum Functions documentation page.      You will, of course, see more code and functions in the keymap file, but for what we want to accomplish, we just need to concern ourselves with a limited section of code. If there is anything you see that we do not cover, and that you do not understand, and you want more information about, then definitely give the QMK documentation a search.    So, now that we know where we need to put code for custom key actions, what kind of implementation code can we actually put in there? We will answer this with a few examples of the actions I have in my personal keymap.   Key Requirements   My main use cases for custom key actions pretty much fall into the following categories:      Output a string of characters on screen, which enables single-key mappings to programming-related operators like the pipe operator (|&gt;) from Elixir, ERB tags (&lt;%=, %&gt;) from Ruby, and emoji codes like :+1: (:+1:)   Key Hold/Key Press combinations of varying complexity, which enable single key mappings for application start up or manipulation. For example, Option-Space for Alfred, Shift-Command-Space for Divvy, and Alt-Command-Left/Right for moving web browser tabs to the left or right.   Modifying a key based on its state. For example, re-mapping the Caps Lock key to be Control when held, and Escape when tapped: a popular mod for Vim users.   QMK does have built-in functionality for some of these use-cases:      The Mod Tap function LCTL_T(kc) is Left Control when held, and kc when tapped. So, LCTL_T(KC_ESC) will provide the desired \u201cLeft Control when held, Escape when tapped\u201d functionality. All that needs to be done is assign that function to a key, and you will be a happy Vimmer.   Modifier Key functions like LALT(kc) (apply Left Alt to kc), and SGUI(kc) (Hold Left Shift and GUI \u2014 read: \u2318Command \u2014 and press kc), cover Alfred and Divvy commands (LALT(KC_SPACE) and SGUI(KC_SPACE) respectively).   For the rest though, we will need to write some custom implementation code.   Sending Strings   Let\u2019s get started with the programming-related operators and emoji codes. Like before, first add the new types:   qmk_firmware/keyboards/ergodox_ez/keymaps/custom/keymap.c   enum custom_keycodes {   // ...   FORWARD_PIPE   LEFT_ERB   PLUS_ONE   RIGHT_ERB };   Assign the types to some keys (these key locations are illustrative only, you probably don\u2019t actually want these keys at the top left of the board):   // ... [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   FORWARD_PIPE, LEFT_ERB, PLUS_ONE, RIGHT_ERB, KC_4, KC_5, KC_LEFT,   // ...   And now, let\u2019s use the SEND_STRING Feature Macro to type out the strings:   bool process_record_user(uint16_t keycode, keyrecord_t *record) {   if (record-&gt;event.pressed) {     switch (keycode) {       case FORWARD_PIPE:         SEND_STRING("|&gt;");         return false;       case LEFT_ERB:         SEND_STRING("&lt;%=");         return false;       case PLUS_ONE:         SEND_STRING(":+1:");         return false;       case RIGHT_ERB:         SEND_STRING("%&gt;");         return false;     }   }   return true; }   That wasn\u2019t too bad! All we have left now is getting Alt-Command-Left/Right working for navigating browser tabs. Unfortunately, the list of Modifier Keys, although comprehensive, does not have a function available for holding down Alt, Command, and pressing a key. So, we will have to manually re-create it.   Create two new types, LEFT_PANE and RIGHT_PANE, add them to the custom_keycodes enumerated types list, and assign them to keys, just like with the previous types. Then, their implementation will look something like this:   qmk_firmware/keyboards/ergodox_ez/keymaps/custom/keymap.c   bool process_record_user(uint16_t keycode, keyrecord_t *record) {   if (record-&gt;event.pressed) {     switch (keycode) {       // ...       case LEFT_PANE:         SEND_STRING(SS_DOWN(X_LALT)SS_DOWN(X_LGUI));         SEND_STRING(SS_TAP(X_LEFT));         SEND_STRING(SS_UP(X_LGUI)SS_UP(X_LALT));         return false;       case RIGHT_PANE:         SEND_STRING(SS_DOWN(X_LALT)SS_DOWN(X_LGUI));         SEND_STRING(SS_TAP(X_RIGHT));         SEND_STRING(SS_UP(X_LGUI)SS_UP(X_LALT));         return false;     }   }   return true; }   Let\u2019s take a look at what\u2019s going on here:      SS_DOWN, SS_UP, and SS_TAP are specific Feature Macros that cover pressing (but not releasing) a key, releasing a key, and pressing-and-releasing a key respectively. So, we are issuing three commands in our case statements: press (and hold) Left Alt and Left GUI, then tap the Left (or Right) Arrow key, then release the Left GUI and Left Alt keys.   Keycodes, when used with the SEND_STRING function, apparently need to have an X_ prefix, rather than KC_, \u201cbecause of some pre-processor magic\u201d\u2026 \xaf\\_(\u30c4)_/\xaf   Compile Time   At this point, we should have a compilable program, so if you wanted to generate the firmware, return to the root qmk_firmware directory, and after installing the build tools for your system, run the following command:   make ergodox_ez:custom   This should result in an ergodox_ez_custom.hex file being generated in the qmk_firmware root directory, which can then be used to flash the Ergodox keyboard firmware, instructions for which are in the video on the ErgoDox EZ Graphical Configurator page (consult your keyboard\u2019s documentation for its specific firmware-flashing instructions).   Rather than actually compiling and using the layout we have created here, though, use what we have done as a base for thinking about what custom keys you would like to have, and then creating your own personal keymap layout.   There is plenty of inspiration in the QMK Ergodox EZ keymaps directory (or in the keymaps directory of whatever type of keyboard you may be using), and please feel free to take anything of use from my own keymap layout.   Other Resources      If you like emoji, but would prefer to have your mappings send Unicode characters, rather than emoji codes (eg SEND_STRING(SS_LALT("D83D+DC4D")) rather than SEND_STRING(":+1:")), then check out the One-keystroke Unicode characters in QMK on macOS blog post by Rebecca Le.   Bonus: Software-based Key Mapping for Mac   Sometimes, you just cannot get to an external keyboard and need to use the keyboard built-in to your laptop computer. If you need key mappings in that situation, then I can definitely recommend Karabiner Elements. My mappings look like the following from the user interface:      Some notes on these rules:      In order to get a mirroring \u201cCaps Lock to Control/Escape\u201d key on the right side of the keyboard for Vim, using a combination of rules, I mapped Enter/Return to be \u201cControl when held, Return/Enter when tapped\u201d. Works great for touch typing Vimmers that want to stay close to the home row!   The final rule represents the following mappings: when Left-\u2318 is tapped (not held), send the \u201c\u82f1\u6570\u201d (eis\u016b, alphanumeric) key, and when Right-\u2318  is tapped (not held), send the \u201c\u304b\u306a\u201d (kana, Japanese) key. These two keys are often found on Japanese Mac OS keyboards and make it easy to switch between the inputting English and Japanese. More info here if you are interested.   You can also get the config details in karabiner.json from my Dotfiles.   Happy Clacking!   ',categories:[],tags:["ergodox","keyboards","mechanical-keyboards","qmk","clang","japanese","\u65e5\u672c\u8a9e"],url:"https://www.paulfioravanti.com/blog/escape-defaults-control-keyboard-qmk/",teaser:"https://www.paulfioravanti.com/assets/images/2018-07-31/ergodox-ez.jpg"},{title:"The Curious Incident of the Shadow in the Run-Time",
excerpt:'Coding in Ruby is full of sweetness and light, but where there is light, shadows are cast. So, let\u2019s get out our torches and see if we can illuminate our way through these darker corners of the language.   Variable Shadowing   The use of shadowing in a codebase usually refers to variable shadowing. A basic example of this in Ruby would be:   variable_shadowing.rb   x = 42 3.times { |x| puts "x is #{x}" }   Notice that there are two variables named \u201cx\u201d: the outer variable, and the block variable. Is this an actual problem, though? Let\u2019s try running it:   $ ruby variable_shadowing.rb x is 0 x is 1 x is 2   The output looks reasonable. The call to puts is inside a block, so it outputs the x value that is local to that block: it would definitely be surprising if puts prioritised values that are outside of its local scope, and output \u201cx is 42\u201d three times.   So, does Ruby really care that we are writing our code like this as long as we are getting the output we expect? To answer that, let\u2019s try running the program again, but this time with warnings enabled:   $ ruby -w variable_shadowing.rb variable_shadowing.rb:2: warning: shadowing outer local variable - x variable_shadowing.rb:1: warning: assigned but unused variable - x x is 0 x is 1 x is 2   It looks like Ruby does care: about both the shadowing, as well as declaring an unused variable (not enough to raise an error, but enough to make you feel that perhaps Matz is very mildly frowning at you). But why, though? Well, one reason could be that what if we wanted to change our program to have puts output both the block variable and the outer variable?   variable_shadowing.rb   x = 42 3.times { |x| puts "Local x is #{x} and outer x is #{\'What goes here??\'}" }   Since we already have a local variable named x, there is no way to access some other variable, also called x, that is outside the local scope. In order to get this to work, we would have to change the name of one of the variables:   variable_shadowing.rb   y = 42 3.times { |x| puts "x is #{x} and y is #{y}" }   $ ruby -w variable_shadowing.rb x is 0 and y is 42 x is 1 and y is 42 x is 2 and y is 42   This is why variable shadowing in Ruby is generally considered \u201ca bad habit and should be discouraged\u201d. Aside from Ruby warnings, Rubocop has a ShadowingOuterLocalVariable cop (which mimics Ruby\u2019s warning), so there are ways to enable your tools to help you keep the shadows at bay.   However, there is another kind of shadowy figure lurking at the peripheries of the Ruby language, aside from the variable-on-variable kind, that Ruby tooling does not warn you about. You are probably unlikely to come across it in the wilds of production code, but it is worth knowing about since it can make for some interesting/confusing behaviour.   Instance Method Shadowing                    Photo by Samuel Zeller on Unsplash        The Local Variables and Methods Assignment section of Ruby\u2019s syntax documentation says that:      In Ruby, local variable names and method names are nearly identical. If you have not assigned to one of these ambiguous names, Ruby will assume you wish to call a method. Once you have assigned to the name, Ruby will assume you wish to reference a local variable.     The local variable is created when the parser encounters the assignment, not when the assignment occurs.    Ruby parses code line by line from top to bottom during run time. So, the understood meaning of one of the \u201cnames\u201d mentioned above can change as the parser moves down the file: what was originally considered a method call, can become a reference to a local variable.   Let\u2019s illustrate this using a completely contrived example:   person.rb   class Person   attr_accessor :name    def initialize(name = nil)     @name = name   end    def say_name     if name.nil?       name = "Unknown"     end      puts "My name is #{name.inspect}"   end end   Given what we now know of local variable and method assignment, I would expect the following to happen when we attempt to get a Person to say its name:      In the #say_name instance method, the first occurrence of name, seen in the if name.nil? statement, would refer to the #name instance method provided by attr_accessor   When the Ruby parser sees the name = "Unknown" assignment line, it will, from that point on, consider any reference to name after the assignment to refer to a local variable called name, and not the instance method #name   Therefore, even if an object of Person had a @name assigned to it on initialisation (eg Person.new("Paul")), the name referenced in the final line of the #say_name method (name.inspect) would have a value of nil. This is because at the point of name.inspect, even though name.nil? would have failed, and therefore the name = "Unknown" local variable assignment would not actually be made, the parser still sees that name should now refer to a local variable, which has not been assigned to, and so is nil.   Let\u2019s open up an IRB console and test these assumptions.   $ irb irb(main):001:0&gt; require "./person.rb" true irb(main):002:0&gt; Person.new("Paul").say_name My name is nil nil   Looks like the first assumption is confirmed:      the instance method check of name.nil? fails   a name local variable is not assigned   name.inspect is checking the value of a local variable and not an instance method   name is therefore nil   Now, what happens when we initialise a Person object without a name:   irb(main):003:0&gt; Person.new.say_name My name is "Unknown" nil      name.nil? succeeds   name local variable is assigned to "Unknown"   "Unknown" is that value that gets output.   Great! I mean, kind of weird, but okay! Now, how about we dive a bit deeper and see if we can observe how the referencing of name changes as the Ruby parser reads through the code.   Schrodinger\u2019s Variable                    Photo by Jo\xe3o Silas on Unsplash        We will use the Pry debugger to see if we can follow name\u2019s journey from instance method to local variable. After you      run gem install pry   add require "pry" at the top of person.rb   add a binding.pry breakpoint at the beginning of the #say_name method   open up another IRB console and let\u2019s take a peek at what is going on.   $ irb irb(main):001:0&gt; require "./person.rb" true irb(main):002:0&gt; Person.new("Paul").say_name  From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   if name.nil?     14:     name = "Unknown"     15:   end     16:     17:   puts "My name is #{name.inspect}"     18: end  [1] pry(#&lt;Person&gt;)&gt;   Right, we now have a breakpoint at the point where name.nil? gets checked. At this point, we have not reached the name variable assignment, so name should refer to the instance method, and have a value of "Paul". Let\u2019s check:   irb(main):002:0&gt; Person.new("Paul").say_name  From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   if name.nil?     14:     name = "Unknown"     15:   end     16:     17:   puts "My name is #{name.inspect}"     18: end  [1] pry(#&lt;Person&gt;)&gt; name nil [2] pry(#&lt;Person&gt;)&gt;   Err, what? How does name have a value of nil if we have not reached the variable assignment statement yet? What is name referring to? Is this some weird Pry thing? So many questions\u2026   Well, regardless of having our expectations flipped, let\u2019s follow this through to the end. Since we now have nil, I would expect that our next stop will be at line 14, where "Unknown" does get assigned to name. Let\u2019s get Pry go to the next execution statement:   [1] pry(#&lt;Person&gt;)&gt; name nil [2] pry(#&lt;Person&gt;)&gt; next  From: /person.rb @ line 17 Person#say_name:      10: def say_name     11:   binding.pry     12:     13:   if name.nil?     14:     name = "Unknown"     15:   end     16:  =&gt; 17:   puts "My name is #{name.inspect}"     18: end  [2] pry(#&lt;Person&gt;)&gt;   It\u2026skipped directly to the bottom, and it would seem that the assignment did not happen. Let\u2019s see if that is the case, and what gets output:   From: /person.rb @ line 17 Person#say_name:      10: def say_name     11:   binding.pry     12:     13:   if name.nil?     14:     name = "Unknown"     15:   end     16:  =&gt; 17:   puts "My name is #{name.inspect}"     18: end  [2] pry(#&lt;Person&gt;)&gt; name nil [3] pry(#&lt;Person&gt;)&gt; exit My name is nil nil irb(main):003:0&gt;   This is all quite confusing. We got the expected result from running Person.new("Paul").say_name, but, on the way, did we encounter some kind of spooky quantum Ruby that ended up changing the value of name just because we observed it? Well, before we start handing ourselves honorary doctorates in quantum computing, let\u2019s call on the old traditional Ruby debugger, puts, to see if we can get an impartial view of what the value of name is before the name.nil? check:   $ irb irb(main):001:0&gt; require "./person" true irb(main):002:0&gt; Person.new("Paul").say_name  From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   puts name.inspect     14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end   Now, let\u2019s compare what value we get for name when using Pry, versus the value we get inside the code with puts:   [1] pry(#&lt;Person&gt;)&gt; name nil [2] pry(#&lt;Person&gt;)&gt; next "Paul"  From: /person.rb @ line 14 Person#say_name:      10: def say_name     11:   binding.pry     12:     13:   puts name.inspect  =&gt; 14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end  [2] pry(#&lt;Person&gt;)&gt;   Running next executes the puts name.inspect code, which gives us "Paul", the value we expect, but Pry still says that name is nil. How can the same variable have two values? It can\u2019t, so there must be something else at play here. What version of name exactly are Pry and puts seeing when the code is being stepped through? Well, there is one more Ruby tool that can help us find that out: the defined? keyword, which returns a string describing its argument.   $ irb irb(main):001:0&gt; require "./person" true irb(main):002:0&gt; Person.new("Paul").say_name  From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   puts defined?(name).inspect     14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end   Okay, first, let\u2019s see what what the Ruby code considers name to be:   From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   puts defined?(name).inspect     14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end  [1] pry(#&lt;Person&gt;)&gt; next "method"   Ruby says name is a method! That gels with what we would expect. So what about Pry\u2026?   From: /person.rb @ line 13 Person#say_name:      10: def say_name     11:   binding.pry     12:  =&gt; 13:   puts defined?(name).inspect     14:   if name.nil?     15:     name = "Unknown"     16:   end     17:     18:   puts "My name is #{name.inspect}"     19: end  [1] pry(#&lt;Person&gt;)&gt; defined?(name) "local-variable"   Pry sees name as a local variable! How can this be if we have not reached the assignment statement yet? Can Pry see into the future? Well, Pry itself can\u2019t, and what is happening is not really seeing into the future.   Not even slightly elementary, my dear Ruby   The key to this mystery is the binding part of the binding.pry statement. Ruby\u2019s Binding \u201cencapsulates the execution context at some particular place in the code\u201d, which, in our case, is the entirety of the #say_name method.   When we step through the code with binding.pry, at the point of the name.nil? statement, the Ruby parser sees name as referring to a method, since it knows nothing about any assignment statements yet. Pry, on the other hand, thanks to the binding effectively \u201crushing ahead to read the rest of the method\u201d so it can create its execution context, knows all about the local variable assignments that could happen. Hence, we can now see the discrepancies in the results between running puts inline and using Pry in this case.   How can you avoid falling into these kinds of pits of potential confusion? Well, just don\u2019t shadow, really. Leaving aside the quality issues of the example code (it is meant to illustrative of the problem and not exemplary Ruby code after all), to get expected results, there are enough ways it could be changed to fulfil different objectives like:           Specifically assign to the person\u2019s name attribute if they were not given one:       def say_name   if name.nil?     self.name = "Unknown"   end   puts "My name is #{name.inspect}" end                Output a display name without assigning a name attribute if one was not originally given.                       Using self to refer to the name property:           def say_name   name = self.name || "Unknown"   puts "My name is #{name.inspect}" end                                Using parentheses:           def say_name   name = name() || "Unknown"   puts "My name is #{name.inspect}" end                           So, be kind to your future self and your team mates, and re-consider shadowing in your code. If you ever do find yourself needing to, though, be sure to leave a comment explaining why.   Other Resources      Behaviours of a Ruby local variable shadowing an instance method - A Stack Overflow question I asked regarding this kind of shadowing and that eventually led to the creation of this blog post.   What does \u201cshadowing\u201d mean in Ruby? - A good Stack Overflow question outlining variable shadowing in Ruby.   A Ruby shadowing bug in the wild - The blog post that originally got me scratching the surface of Ruby shadowing.   ',categories:[],tags:["ruby","shadowing"],url:"https://www.paulfioravanti.com/blog/curious-incident-shadow-run-time/",teaser:"https://www.paulfioravanti.com/assets/images/2018-08-20/matthew-ansley-254316-unsplash.jpg"},{title:"Starting Stenography with an Ergodox",
excerpt:"After years of touch typing using everyone\u2019s favourite 19th century keyboard layout (QWERTY), I seem to have capped out my typing speed abilities at about 80-85 words-per-minute (WPM).   This isn\u2019t too bad for my needs as a programmer, but I was curious about whether there were any other ways that could help me improve. So, I did a bit of research on other potential layout options like Dvorak, Colemak, and Workman, all of which purport to increase the speed and efficiency of your typing, as well as cut down the travel distance of your fingers, hence reducing the strain on your hands and wrists.   I cannot vouch personally for any of their claims: I did not find the time-and-effort investment in learning one of those layouts, versus the potential benefits, particularly appealing. So, I gave up and just carried on my merry 80 WPM-way.   That is, until a visit to the Open Steno Project put stenography on my radar as an actual viable choice to potentially supercharge my WPM rate. As of this writing, I have just started learning, so I have no idea if I actually will improve, or whether I will continue down the steno path in the future.   However, just getting my Ergodox set up for stenography was quite an exercise in configuration, so that will be the focus for the remainder of this blog post, in hopes that it will help get the Ergodox-toting steno-curious up and running as quickly as possible.      What You Need      An Ergodox \u2014 if you do not have one already, buy one or wait for the next kit to drop if you want to build one   Quantum Mechanical Keyboard (QMK) Firmware \u2014 see my blog post Escape the defaults and Control your keyboard with QMK for a guide to set up an Ergodox with QMK from scratch.   Plover \u2014 open source software that lets you use your keyboard as a steno machine (installation instructions)      A small note about Plover: if you open it, and it immediately crashes without any kind of error message, you may need to check your operating system-level keyboard input source. If you use Google IME or a symbolic language like Japanese or Korean, you will probably \u201chave to change to a QWERTY/US layout to use Plover for now\u201d.    Initial Setup   For this post, we will use the QMK default Ergodox EZ keymap as a base, and make changes to it to add functionality for stenography. Feel free to follow along as-is, or make appropriate changes to your own custom keymaps. You can also see the finished layouts in this post\u2019s companion keymaps on my QMK example keymaps Github repository:      QWERTY Steno   Default Steno High   Default Steno   (These keymap names will make more sense as you read through the post).   After installing the build tools for your operating system, make a clone of the QMK Firmware repository from Github if you do not have one already. Then, create a copy of the default Ergodox EZ keymaps directory into a new directory that we will call default_steno:   git clone git@github.com:qmk/qmk_firmware.git cd qmk_firmware cp -r keyboards/ergodox_ez/keymaps/default keyboards/ergodox_ez/keymaps/default_steno      If you have had a look through the list of provided QMK Ergodox keymaps, you may have seen that there is already a steno configuration provided, so why not just use that? Why go to the trouble of creating another layout? Well\u2026          The provided layout does not take advantage of QMK\u2019s built-in support for stenography (which we will go over later), and instead re-implements steno functionality from scratch using custom binary key codes and custom functions     The codes would seem to only work with the TX Bolt steno protocol (which, at least for me, resulted in incorrect key press processing, but more about that later as well\u2026)       UPDATE 28-04-2019: The issue with TX Bolt is now fixed, and the current QMK Ergodox EZ steno configuration does now use QMK\u2019s built-in support for stenography. I may be biased, but I think the rest of this post still has value, with the added benefit of now having less configuration to do if you decide to adapt QMK\u2019s current Ergodox steno configuration for your own needs.    N-Key Rollover   Before adding a new keyboard layout to our keymap, the first thing we will need to do is ensure that we have N-Key Rollover (NKRO) enabled.   Stenography involves hitting multiple keys at once in a \u201cchord\u201d-like fashion. Therefore, we need to make sure that all of these key presses are detected by the Ergodox so they can be sent to the computer; keyboards typically detect up to 6 simultaneous key presses (aka \u201c6KRO\u201d), so the \u201cn\u201d in NKRO essentially stands for \u201cas many keys as you like\u201d.   The easiest way to confirm whether you have NKRO enabled is to perform Plover\u2019s Keyboard Ghosting Test. In the Plover in-browser steno demo, if you find that only 6 keys light up on screen when you press the ASDFJKL; keys all at once, then you currently do not have NKRO enabled.   Luckily, the QMK Ergodox firmware has a built-in shortcut that can turn this on for you: hold down Left-Shift + Right-Shift + N. Now, try the steno demo again and you should see 8 keys light up on screen.   Having to turn NKRO on again manually every time you re-flash Ergodox firmware is going to get tiresome and potentially confusing, so let\u2019s create some files to tell the firmware to enable it by default.   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/rules.mk   FORCE_NKRO = yes   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/config.h   #include \"../../config.h\"  #define FORCE_NKRO   You may be wondering why we need a config.h file since rules.mk already has a rule that says to force NKRO to be on.  The best explanation I could find is that NKRO is, apparently, \u201cdisabled by default because some bioses aren\u2019t compatible with NKRO\u201d. So, I would just say to accept it, smile and nod, and just know that if you make these changes and then re-flash your firmware (see the video on the Ergodox EZ Graphical Configurator Page for how to do that), you should see that NKRO is now on without having to manually enable it.   New Steno QWERTY layer   The QMK default Ergodox EZ keymap has three layers: a base layer, a layer for symbols, and a layer for media keys (for our purposes, we can safely ignore the symbol and media keys layers). We cannot use the base QWERTY layer as-is for stenography: we need to move some keys around, and some keys we will not use. So, let\u2019s add a new stripped-down QWERTY-like layer based on the QWERTY-to-steno mapping that Plover is expecting, which we will call STEN.   We will then (arbitrarily) assign the top right-most key on the left hand of the BASE layer to be the toggle to turn the STEN layer on and off, using QMK\u2019s TG(layer) function:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/keymap.c   // ... #define BASE 0 // default layer #define SYMB 1 // symbols #define MDIA 2 // media keys #define STEN 3 // Stenography  // Helper to make keymaps a bit easier to read at a glance #define _x_ KC_NO #define ___ KC_TRNS  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Keymap 0: Basic layer  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  | STEN | ...  * |--------+------+------+------+------+-------------| ...  * ...  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL, KC_1, KC_2, KC_3, KC_4, KC_5, TG(STEN),   // ... ), // ... [SYMB] = LAYOUT_ergodox(   // ... ), // ... [MDIA] = LAYOUT_ergodox(   // ... ), /* Keymap 3: Modified QWERTY for Stenography  *  * ,--------------------------------------------------.  ,--------------------------------------------------.  * |   [x]  |   1  |   2  |   3  |   4  |   5  |      |  |  [x] |   6  |   7  |   8  |   9  |   0  |  [x]   |  * |--------+------+------+------+------+------+------|  |------+------+------+------+------+------+--------|  * |   [x]  |   Q  |   W  |   E  |   R  |   T  |      |  |      |   Y  |   U  |   I  |   O  |   P  |   [    |  * |--------+------+------+------+------+------|  [x] |  |  [x] |------+------+------+------+------+--------|  * |   [x]  |   A  |   S  |   D  |   F  |   G  |------|  |------|   H  |   J  |   K  |   L  |   ;  |   '    |  * |--------+------+------+------+------+------|      |  |      |------+------+------+------+------+--------|  * |   [x]  |  [x] |  [x] |  [x] |  [x] |      |  [x] |  |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |  [x]   |  * `--------+------+------+------+------+-------------'  `-------------+------+------+------+------+--------'  *   | [x]  |  [x] |  [x] |  [x] |  [x] |                              |  [x] |  [x] |  [x] |  [x] |  [x] |  *   `----------------------------------'                              `----------------------------------'  *                                      ,-------------.  ,-------------.  *                                      |  [x] |  [x] |  |  [x] |  [x] |  *                               ,------|------|------|  |------+------+------.  *                               |      |      |  [x] |  |  [x] |      |      |  *                               |  C   |   V  |------|  |------|   N  |   M  |  *                               |      |      |  [x] |  |  [x] |      |      |  *                               `--------------------'  `--------------------'  */ [STEN] = LAYOUT_ergodox(  // layer 3 : Modified QWERTY for Stenography   // left hand   _x_, KC_1, KC_2, KC_3, KC_4, KC_5, ___,   _x_, KC_Q, KC_W, KC_E, KC_R, KC_T, _x_,   _x_, KC_A, KC_S, KC_D, KC_F, KC_G,   _x_, _x_,  _x_,  _x_,  _x_,  _x_,  _x_,   _x_, _x_,  _x_,  _x_,  _x_,                                _x_,  _x_,                                      _x_,                          KC_C, KC_V, _x_,   // right hand   _x_, KC_6, KC_7, KC_8, KC_9, KC_0,    _x_,   _x_, KC_Y, KC_U, KC_I, KC_O, KC_P,    KC_LBRC,        KC_H, KC_J, KC_K, KC_L, KC_SCLN, KC_QUOT,   _x_, _x_,  _x_,  _x_,  _x_,  _x_,     _x_,              _x_,  _x_,  _x_,  _x_,     _x_,   _x_, _x_,   _x_,   _x_, KC_N, KC_M ) }; // ...      Note the uses of _x_and ___ here:          _x_ specifically indicates that pressing the key results in a NOOP: the keystroke is ignored     ___ is a \u201ctransparent\u201d mapping, which in this case for the toggle key, will \u201cfall back\u201d to the TG(STEN) function on the BASE layer. This is really just a convenience so that we don\u2019t need to specify TG(STEN) again on the STEN layer       More information about these two mappings in the QMK Special Keys documentation.    Next, generate the firmware from the qmk_firmware directory root path:   make ergodox_ez:default_steno   This should generate an ergodox_ez_default_steno.hex file, which you can then use to flash your Ergodox firmware. If you get any build issues, check what you have against my example code for this layer.   Once you\u2019ve flashed your keyboard firmware, open up your favourite text editor, press the top right-most key on the left hand to toggle the steno layer, and type some text to confirm that all is working as expected (the thumb clusters using the CVNM keys are a good litmus test).   Now, there is no steno magic happening quite yet, since our keystrokes are being interpreted and output as-is by the computer. What we need now is something to receive our keystrokes, and then translate them what a steno machine would output.   Enter Plover   Open up the Plover application, select the \u201cEnable\u201d radio button, and try typing again.      The output should be completely different than before, which would indicate that everything is working: we are typing in steno! So, what I would recommend doing now is opening up Lesson 1 of the Learn Plover! free text book, try typing some of the one-syllable steno words, and generally have a play around.   Awesome! Are we done now\u2026?   From a keyboard configuration and typing standpoint, we have pretty much achieved our objectives. In order to get back to our base QWERTY layout, we will need to:      Click the \u201cDisable\u201d radio button on the Plover window so that our keystrokes do not get translated into steno output any more   Press the key to toggle the STEN layer off and get back to our BASE layer   If you feel comfortable with this setup, then you are all done!   First-world Steno Problems   For me though, even after a few minutes of using this setup, I ended up being annoyed about having to turn steno functionality \u201coff\u201d at both the hardware and software level. When I toggle my STEN layer off, I want the computer/Plover to consider me out of steno-mode and back into vanilla-keyboard-mode: I do not want to have to remember to manually disable Plover.   So, what can be done about this? You could do something similar to what Waleed Khan did, and create a macro in your keyboard layout that toggles Plover when the steno layer is toggled, bringing hardware and software in sync with each other. This is a very valid option, though I wondered if I could somehow have Plover enabled all the time, but just have it ignore any non-steno input.   As it turns out, we can do exactly this by doing the following:      Have QMK speak to Plover using a steno machine protocol that Plover understands   Have Plover listen only for input in that protocol, ignoring non-steno keyboard chatter   Since our STEN layer currently sends standard key presses to Plover, we will have to completely change the layout to use QMK steno keycodes instead of character key presses. So, back to the text editor!   Steno Layer: Take 2   Open up the keymap file and change the code so that it looks like this:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/keymap.c   // ... #include \"keymap_steno.h\"  #define BASE 0 // default layer #define SYMB 1 // symbols #define MDIA 2 // media keys #define STEN 3 // Stenography  // Helper to make keymaps a bit easier to read at a glance #define _x_ KC_NO #define ___ KC_TRNS  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Keymap 0: Basic layer  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  | STEN | ...  * |--------+------+------+------+------+-------------| ...  * ...  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL, KC_1, KC_2, KC_3, KC_4, KC_5, TG(STEN),   // ... ), // ... [SYMB] = LAYOUT_ergodox(   // ... ), // ... [MDIA] = LAYOUT_ergodox(   // ... ), /* Keymap 3: Stenography  *  * ,--------------------------------------------------.           ,--------------------------------------------------.  * |   [x]  |   #  |   #  |   #  |   #  |   #  |      |           |  [x] |   #  |   #  |   #  |   #  |  #   |   #    |  * |--------+------+------+------+------+------+------|           |------+------+------+------+------+------+--------|  * |   [x]  |   S  |   T  |   P  |   H  |   *  |      |           |      |   *  |   F  |   P  |   L  |   T  |   D    |  * |--------+------+------+------+------+------|  [x] |           |  [x] |------+------+------+------+------+--------|  * |   [x]  |   S  |   K  |   W  |   R  |   *  |------|           |------|   *  |   R  |   B  |   G  |   S  |   Z    |  * |--------+------+------+------+------+------|      |           |      |------+------+------+------+------+--------|  * |   [x]  |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |           |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |  [x]   |  * `--------+------+------+------+------+-------------'           `-------------+------+------+------+------+--------'  *   | [x]  |  [x] |  [x] |  [x] |  [x] |                                       |  [x] |  [x] |  [x] |  [x] |  [x] |  *   `----------------------------------'                                       `----------------------------------'  *                                        ,-------------.       ,-------------.  *                                        |  [x] |  [x] |       |  [x] |  [x] |  *                                 ,------|------|------|       |------+------+------.  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 |  A   |   O  |------|       |------|   E  |   U  |  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 `--------------------'       `--------------------'  */ [STEN] = LAYOUT_ergodox(  // layer 3 : Stenography     // left hand     _x_, STN_N1, STN_N2, STN_N3, STN_N4, STN_N5,  ___,     _x_, STN_S1, STN_TL, STN_PL, STN_HL, STN_ST1, _x_,     _x_, STN_S2, STN_KL, STN_WL, STN_RL, STN_ST2,     _x_, _x_,    _x_,    _x_,    _x_,    _x_,     _x_,     _x_, _x_,    _x_,    _x_,    _x_,                                          _x_,     _x_,                                                   _x_,                                  STN_A,  STN_O,   _x_,   // right hand   _x_, STN_N6,  STN_N7, STN_N8, STN_N9, STN_NA, STN_NB,   _x_, STN_ST3, STN_FR, STN_PR, STN_LR, STN_TR, STN_DR,        STN_ST4, STN_RR, STN_BR, STN_GR, STN_SR, STN_ZR,   _x_, _x_,     _x_,    _x_,    _x_,    _x_,    _x_,                 _x_,    _x_,    _x_,    _x_,    _x_,   _x_, _x_,   _x_,   _x_, STN_E,   STN_U ) };  // ...  // Runs just one time when the keyboard initializes. void matrix_init_user(void) {   // ...   steno_set_mode(STENO_MODE_GEMINI); };   Some notes about these changes:      #include \"keymap_steno.h\" at the top of the file enables us to use QMK steno-specific functionality like keycodes and protocols   The keymap now looks more like a steno machine keymap   The steno_set_mode(STENO_MODE_GEMINI) function sets the steno protocol to be GeminiPR when the keyboard initialises. I initially tried to use TX Bolt (STENO_MODE_BOLT) for the parameter, as QMK apparently speaks that protocol by default, but I found that key presses did not come in (or were not processed) properly, while GeminiPR worked as expected (Update 28-04-2019: This issue has been fixed)   We will also need to update the rules file due to a few quirks of using steno-specific functionality in QMK:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/rules.mk   STENO_ENABLE = yes VIRTSER_ENABLE = yes FORCE_NKRO = yes MOUSEKEY_ENABLE = no   Some notes about these changes:      As you can see, steno mode needs to be specifically enabled in our rules (STENO_ENABLE = yes), and if steno is enabled, then the USB serial driver for the firmware needs to be enabled as well (VIRTSER_ENABLE = yes) or the keymap will not compile   The cost of enabling steno is that it takes up 3 virtual serial ports that would normally be used by mouse-related functionality in our MDIA layer, so we have to explicitly disable mouse keys (MOUSEKEY_ENABLE = no). If you make a lot of use of mouse movements and clicks via your keyboard, you may want to consider going back and using the modified QWERTY steno keymap. For me personally, I can live without using my keyboard as a mouse.   Now, let\u2019s re-generate the ergodox_ez_default_steno.hex and flash our firmware:   make ergodox_ez:default_steno   If you get any build issues, check what you have against my example code for this layer.   Configure Plover for GeminiPR   Now that we have got QMK speaking in GeminiPR protocol, we need to get Plover configured to listen for it.         Click the \u201cConfigure\u2026\u201d button in the Plover window         Select \u201cGemini PR\u201d from the \u201cStenotype Machine\u201d dropdown list   Click the \u201cConfigure\u2026\u201d button next to the dropdown list         Select a port from the \u201cPort\u201d dropdown. The device name may not exactly match what you see in this screen shot. If you see an empty \u201cPort\u201d dropdown list, click the \u201cScan\u201d button to populate it   Change the \u201cBaudrate\u201d dropdown value to 115200 (since QMK can handle that speed)   Click \u201cOK\u201d   Click \u201cSave\u201d on the \u201cPlover Configuration\u201d window         Click \u201cEnable\u201d on the Plover window and you should get a message saying \u201cGemini PR: connected\u201d   You should now be able to just leave Plover enabled: any keystrokes you make when you switch your Ergodox layer over to STEN will be translated to steno, and Plover will ignore keystrokes made when using any other layer.   One Final Hardware Tweak   The key caps on my Ergodox are DCS profile, which means that they are sculptured differently per row on the keyboard, leading to ergonomically-sized gaps between each key row.   Steno keys are meant to be close together since chording will require a single finger to press multiple keys. In order to get the keys closer together, I turned the QWERT and YUIOP[ keys upside down, so they would lean closer to the keys in the layer below, and changed the direction of the large thumb cluster keys so they would face each other.   At this stage, I am not sure how much of an effect this will have, but I think this is the best I can do without buying a potentially more appropriate key cap set.   The Journey Begins   All this effort put towards getting a perfect QMK steno set up has taken time away from actually getting better at steno, so I\u2019d better get back to that. (Just for completeness\u2019 sake, though, here are my current keymaps that I will be using moving forward)   As of this writing, I am currently only at 12 WPM after completing Lesson 1 of Learn Plover!, so when it comes to stenography, I am very much a beginner student with a long road ahead. So, if there are any glaring mistakes or omissions in this post, please let me know in the comments.   Update (8 Nov 2018)   After working my way through Learn Plover!, I have come to the conclusion that I set the steno keys to be one row too high, and that changing keycaps made a big difference.   Move steno keys down a row   Complex key chords for words that, say, require a right thumb press for EU, as well as a stretched right little finger press for DZ, caused a bit of discomfort in my fingers and wrists as I had to awkwardly contort my hand to press all the keys.   So, I moved all the steno keys down a single row on the keyboard, and now all is well again, even with more complex chords. So, in the context of the default_steno keymap, the keymap will now look like this:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/keymap.c   // ... #include \"keymap_steno.h\"  #define BASE 0 // default layer #define SYMB 1 // symbols #define MDIA 2 // media keys #define STEN 3 // Stenography  // Helper to make keymaps a bit easier to read at a glance #define _x_ KC_NO #define ___ KC_TRNS  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Keymap 0: Basic layer  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  | STEN | ...  * |--------+------+------+------+------+-------------| ...  * ...  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL, KC_1, KC_2, KC_3, KC_4, KC_5, TG(STEN),   // ... ), // ... [SYMB] = LAYOUT_ergodox(   // ... ), // ... [MDIA] = LAYOUT_ergodox(   // ... ), /* Keymap 3: Stenography  *  * ,--------------------------------------------------.           ,--------------------------------------------------.  * |   [x]  |  [x] |  [x] |  [x] |  [x] |  [x] |      |           |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |  [x]   |  * |--------+------+------+------+------+------+------|           |------+------+------+------+------+------+--------|  * |   [x]  |   #  |   #  |   #  |   #  |   #  |      |           |      |   #  |   #  |   #  |   #  |   #  |   #    |  * |--------+------+------+------+------+------|  [x] |           |  [x] |------+------+------+------+------+--------|  * |   [x]  |   S  |   T  |   P  |   H  |   *  |------|           |------|   *  |   F  |   P  |   L  |   T  |   D    |  * |--------+------+------+------+------+------|      |           |      |------+------+------+------+------+--------|  * |   [x]  |   S  |   K  |   W  |   R  |   *  |  [x] |           |  [x] |   *  |   R  |   B  |   G  |   S  |   Z    |  * `--------+------+------+------+------+-------------'           `-------------+------+------+------+------+--------'  *   | [x]  |  [x] |  [x] |  [x] |  [x] |                                       |  [x] |  [x] |  [x] |  [x] |  [x] |  *   `----------------------------------'                                       `----------------------------------'  *                                        ,-------------.       ,-------------.  *                                        |  [x] |  [x] |       |  [x] |  [x] |  *                                 ,------|------|------|       |------+------+------.  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 |  A   |   O  |------|       |------|   E  |   U  |  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 `--------------------'       `--------------------'  */ [STEN] = LAYOUT_ergodox(  // layer 3 : Stenography     // left hand     _x_, _x_,    _x_,    _x_,    _x_,    _x_,     ___,     _x_, STN_N1, STN_N2, STN_N3, STN_N4, STN_N5,  _x_,     _x_, STN_S1, STN_TL, STN_PL, STN_HL, STN_ST1,     _x_, STN_S2, STN_KL, STN_WL, STN_RL, STN_ST2, _x_,     _x_, _x_,    _x_,    _x_,    _x_,                                          _x_,     _x_,                                                   _x_,                                  STN_A,  STN_O,   _x_,   // right hand   _x_, _x_,     _x_,    _x_,    _x_,    _x_,    _x_,   _x_, STN_N6,  STN_N7, STN_N8, STN_N9, STN_NA, STN_NB,   _x_, STN_ST3, STN_FR, STN_PR, STN_LR, STN_TR, STN_DR,        STN_ST4, STN_RR, STN_BR, STN_GR, STN_SR, STN_ZR,                 _x_,    _x_,    _x_,    _x_,    _x_,   _x_, _x_,   _x_,   _x_, STN_E,   STN_U ) };  // ...  // Runs just one time when the keyboard initializes. void matrix_init_user(void) {   // ...   steno_set_mode(STENO_MODE_GEMINI); };   I have updated the code on this post\u2019s companion Github repo to reflect these changes, but kept the original \u201chigh\u201d configuration in another directory for your reference. You can also see how I\u2019ve incorporated this change in my current personal keymaps.   Use Steno-Appropriate Keycaps   Based on the Plover Keycap Recommendations, I picked up a set of G20 Blank Keysets and this has made chording much easier.   Switching the direction of my original DCS profile keys helped a little bit, but the flat and wide profile of the G20s makes pressing two keys with the same finger significantly less awkward. So, I can definitely recommend picking up a set if you are going to make a serious attempt at learning steno on an Ergodox, or really any mechanical keyboard.   For Ergodox users, I would recommend picking up both the G20 Ergodox Base and Ergodox Modifier sets that PMK offers. I initially only ordered a modifier set, thinking that I would be fine with having a mix of profiles on the board, but the issues with that I found were:      Having a board with multiple types of keycap profiles is kind of awkward when switching back to QWERTY typing   The Ergodox Modifier set only contains enough keys to cover a base steno layout, and not the steno number key # row (this may not necessarily be a deal breaker for you if you plan on just using the QWERTY number row)   The Ergodox Modifier set does not come with any homing keys (keys with a bar or dot on them to signify to your index finger that you are on home row). My index fingers naturally seek out homing keys, and I could not get over not having them, which is partly what prompted me to pick up the Ergodox Base set (if you want the homing bars/dots but don\u2019t want the base set, you have the option of just buying a set of those keys separately)   Update (8 Jun 2020)   Use Steno-Appropriate Switches (if possible)   A few months ago from this writing, I had occasion to pick up a new Ergodox EZ. While I have played with a variety of keyboard switches on other people\u2019s keyboards, I have only ever used Cherry MX Browns and Gateron Browns on a regular basis.  So, I decided to look into more steno-friendly keyswitch types for the new board.   Based on advice in the Plover keyswitch guide, I looked at the Ergodox EZ keyswitches page to see which ones provide a \u201clight actuation force on a linear switch\u201d. Judging by the page comparison charts, Kailh Speed Silver switches seemed the most appropriate, so that\u2019s what I got.   After practising with Kailh Silvers, I can definitely recommend them over Cherry/Gateron Browns for stenography. Chording is noticeably easier due to the lighter touch, and I have found that my hands are a bit less fatigued after a practice session.   However, I would probably not recommend buying a brand new Ergodox specifically to get new keyswitches, especially if you are still a learner and your current board works fine.  If you have a newer Ergodox that has changeable switches, then you have the option to just buy some Kailh Speed Silvers (or any of the other switches the Plover guide mentions).   If you are like me, though, and your older board needs replacing, or you are considering buying/building your first Ergodox, then the path I took is open to you.   Number \u201cBar\u201d versus Button   I have found chording numbers quite challenging, and have wondered if there was perhaps an easier way to stroke them.   The QMK Ergodox EZ steno configuration, as of this writing, re-creates a stenography machine number bar over 11 separate keys. However, looking at the layout of a modern keyboard made specifically for stenography, the Georgi (QMK layout), it uses a single number key on each of its thumb clusters, presumably to be used in the same vein as the asterisk key.   It makes a lot of sense to me to palm off number duty to your thumbs in order to keep your other fingers from ever moving away from steno home row, so I have modified my own layout to have number keys in two extra places on the Ergodox:      under the R keys on both halves   above the O and E keys   Applied to the layout used above, it would look like the following, using the STN_NC keycode for all the keys since it has not been used yet:   qmk_firmware/keyboards/ergodox_ez/keymaps/default_steno/keymap.c   // ... /* Keymap 3: Stenography  *  * ,--------------------------------------------------.           ,--------------------------------------------------.  * |   [x]  |  [x] |  [x] |  [x] |  [x] |  [x] |      |           |  [x] |  [x] |  [x] |  [x] |  [x] |  [x] |  [x]   |  * |--------+------+------+------+------+------+------|           |------+------+------+------+------+------+--------|  * |   [x]  |   #  |   #  |   #  |   #  |   #  |      |           |      |   #  |   #  |   #  |   #  |   #  |   #    |  * |--------+------+------+------+------+------|  [x] |           |  [x] |------+------+------+------+------+--------|  * |   [x]  |   S  |   T  |   P  |   H  |   *  |------|           |------|   *  |   F  |   P  |   L  |   T  |   D    |  * |--------+------+------+------+------+------|      |           |      |------+------+------+------+------+--------|  * |   [x]  |   S  |   K  |   W  |   R  |   *  |  [x] |           |  [x] |   *  |   R  |   B  |   G  |   S  |   Z    |  * `--------+------+------+------+------+-------------'           `-------------+------+------+------+------+--------'  *   | [x]  |  [x] |  [x] |  [x] |   #  |                                       |   #  |  [x] |  [x] |  [x] |  [x] |  *   `----------------------------------'                                       `----------------------------------'  *                                        ,-------------.       ,-------------.  *                                        |   #  |  [x] |       |  [x] |   #  |  *                                 ,------|------|------|       |------+------+------.  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 |  A   |   O  |------|       |------|   E  |   U  |  *                                 |      |      |  [x] |       |  [x] |      |      |  *                                 `--------------------'       `--------------------'  */ [STEN] = LAYOUT_ergodox(  // layer 3 : Stenography     // left hand     _x_, _x_,    _x_,    _x_,    _x_,    _x_,     ___,     _x_, STN_N1, STN_N2, STN_N3, STN_N4, STN_N5,  _x_,     _x_, STN_S1, STN_TL, STN_PL, STN_HL, STN_ST1,     _x_, STN_S2, STN_KL, STN_WL, STN_RL, STN_ST2, _x_,     _x_, _x_,    _x_,    _x_,    STN_NC,                                          STN_NC,  _x_,                                                   _x_,                                  STN_A,  STN_O,   _x_,   // right hand   _x_, _x_,     _x_,    _x_,    _x_,    _x_,    _x_,   _x_, STN_N6,  STN_N7, STN_N8, STN_N9, STN_NA, STN_NB,   _x_, STN_ST3, STN_FR, STN_PR, STN_LR, STN_TR, STN_DR,        STN_ST4, STN_RR, STN_BR, STN_GR, STN_SR, STN_ZR,                 STN_NC, _x_,    _x_,    _x_,    _x_,   _x_, STN_NC,   _x_,   _x_, STN_E,   STN_U ) // ...   I am not sure which of these thumb-based number keys I will end up using yet (if any), so I am planning on letting my hands decide what feels right. See my personal QMK keymap for more details and code to copy if you want to try this layout as well.   ",
categories:[],tags:["ergodox","keyboards","mechanical-keyboards","qmk","clang","stenography","plover"],url:"https://www.paulfioravanti.com/blog/starting-stenography-ergodox/",teaser:"https://www.paulfioravanti.com/assets/images/2018-10-18/phil-botha-469097-unsplash.jpg"},{title:"Build a CI/CD pipeline for your Jekyll site",excerpt:'Since setting up my Jekyll site, I thought that being disciplined enough to continue writing content regularly would be the main blog-related problem I would be dealing with.   That is, until I ran HTMLProofer over the site, and it spat out a bunch of validation issues that showed me I had a significant amount of problems including:      Some of the links I had in older posts were returning 404 messages, even though the links had worked when I first wrote the posts\u2026   The sitemap generated by jekyll-sitemap apparently contained invalid jekyll-archives-generated archive page links (eg https://www.paulfioravanti.com/tags/jekyll/), which I thought was strange as they all worked in my development environment\u2026   It turns out that:      I had references to code on Github that referred directly to the master branch of a codebase, rather than use a permalink, which would refer to a file at the time I accessed it (always use permalinks when linking to code on Github to avoid this headache)   The list of supported Jekyll plugins on Github Pages does not include jekyll-archives (I forgot/didn\u2019t check), so although the archive links worked in my local development environment, when they were added to the locally-generated sitemap, and then an attempt made to check their production-side links, they all 404-ed.   The issues that HTMLProofer brought up raised some questions around the quality of the site code and post content:      Links in posts could become stale, and I would never know about it, since I do not ever go and manually re-check all the links in every post   I had no process that could stop me from inadvertently deploying bad code, or deploying plugin code that would just be ignored by Github Pages, leading to production environments not matching what I was seeing in development   Limitations on Github Pages plugin availability mean I could also not take advantage of some plugins that could help with search engine optimisation (SEO), like those that minify your HTML/CSS/JS files   I still want to keep Github Pages as the deployment platform for my blog (at least, for now), but it just seems really limiting, so what options do I have?  Well, thanks to Derek Smart and his post Supercharge GitHub Pages with Jekyll and Travis CI, I learned that I should:      Break free of the constricting GitHub Pages Ruby Gem   Replace it with the Jekyll gem, and a list of any Jekyll plugin gems I please   Create a build pipeline using Travis CI.   Have Travis test my code, build the site with all the plugins I want, and then deploy the built site directly to the master branch of my Jekyll Github repository   Let\u2019s see about getting this done!                    Photo originally by Fancycrave on Unsplash        Switch to Jekyll gem   My Gemfile initially looked similar to the Github specification for Jekyll sites that get published to Github Pages:   Gemfile   source "https://rubygems.org" ruby "2.5.3"  group :jekyll_plugins do   gem "github-pages", "192"   gem "jekyll-archives", "~&gt; 2.1"   gem "jekyll-include-cache", "~&gt; 0.1"   gem "jekyll-remote-theme", "~&gt; 0.3" end   After migrating over to the Jekyll gem, it changed over to be something like:   Gemfile   source "https://rubygems.org" ruby "2.5.3"  gem "jekyll", "~&gt; 3.8"  group :jekyll_plugins do   gem "jekyll-archives", "~&gt; 2.1"   gem "jekyll-include-cache", "~&gt; 0.1"   gem "jekyll-remote-theme", "~&gt; 0.3"   gem "jekyll-feed", "~&gt; 0.11"   gem "jekyll-gist", "~&gt; 1.5"   # and a bunch of other jekyll plugin gems... end   In order to determine what other gem plugins I should include under the :jekyll_plugins group, now that the github-pages gem was not bringing them in for me, I referenced the Github Pages gem dependencies, as well as the plugins key in my site\u2019s _config.yml file, and then manually added any that I knew I was using.      For reference, here is my blog\u2019s Gemfile at the time of this writing.    Set up Travis to test and deploy site   The Supercharge GitHub Pages with Jekyll and Travis CI article perfectly describes, with appropriate detail, how to set up Github and Travis to build and deploy a Jekyll site, so I will only repeat a summary here with links to Github and Travis documentation:      Since Github Pages publishes code pushed into the master branch, create a new release branch on your repository and set it to be the default branch. This effectively makes release the new master branch for development purposes, and master will, moving forward, only ever hold the contents of the built Jekyll site   Activate your Jekyll site on Travis   Create a personal access token for use with the Jekyll site   Copy your new personal access token into an environment variable in the Travis repository settings for your Jekyll site (suggested name: GITHUB_TOKEN)   Create a .travis.yml configuration file in the root of your Jekyll site to tell Travis what to do   Build Stages   What Travis should do specifically is run all the lints and tests for the Jekyll site. Then, if everything passes, Travis should build the site, and deploy it to the master branch of the site Github repository, at which point it gets automatically published to Github Pages.   Travis Build Stages enable us to do exactly that, so let\u2019s see how to do that in configuration:   .travis.yml   sudo: false dist: trusty language: ruby cache: bundler rvm:   - 2.5.3 bundler_args: --without development env:   global:     - NOKOGIRI_USE_SYSTEM_LIBRARIES=true addons:   apt:     packages:       - libcurl4-openssl-dev branches:   only:     - release jobs:   include:     - stage: Test       before_script:         - npm install -g sass-lint htmllint-cli markdownlint-cli       script:         - JEKYLL_ENV=production bundle exec jekyll build         - htmllint _includes/stripped_markdown.html         - markdownlint _posts _drafts _pages README.md         - sass-lint --verbose --no-exit         - bundle exec htmlproofer _site --allow-hash-href --assume-extension --url-ignore "/localhost/" --http-status-ignore "999"     - stage: Github Release       script:         - JEKYLL_ENV=production bundle exec jekyll build       deploy:         provider: pages         local-dir: ./_site         target-branch: master         name: Travis Deployment Bot         skip-cleanup: true         github-token: $GITHUB_TOKEN         keep-history: true         on:           branch: release   If you have used Travis to build a Ruby project before, you will no doubt recognise some of the configuration entries listed here, so I will outline some notes only about the potentially unfamiliar parts of this file, and why they\u2019re there:      The NOKOGIRI_USE_SYSTEM_LIBRARIES=true statement and use of the libcurl4-openssl-dev library are for using HTMLProofer on Travis: the former speeds up installation of HTMLProofer, and the latter is so checks on external links referenced in posts can actually be performed   We only ever want to test and deploy the release branch, so make sure we ignore pushes to any other branch   Build stages are defined under the jobs key, and here we have two: Test and Github Release   All the lint checks are described in my previous blog post Setting up a Jekyll Blog. Check it out for more information on what they are linting, so you can get a better idea of whether you should be changing any parameters to suit your own site\u2019s needs   The htmlproofer command line interface (CLI) application has lots of options, but the reasons I use certain options are the following:            --allow-hash-href - The build will fail on the first and last post entries if this isn\u2019t allowed because I have pagination \u201cprevious\u201d and \u201cnext\u201d buttons that have href="#", and hence considered \u2018links to nowhere\u2019       --assume-extension - Jekyll 3 supports extension-less permalinks, and my blog uses them, so this flag needs to be here to prevent errors       --url-ignore "/localhost/" - I have tutorial posts that have explicit link references to localhost, so I don\u2019t want them considered \u201cproper\u201d external links that need to be validated       --http-status-ignore "999" - LinkedIn doesn\u2019t seem to like crawlers, and hence sends back 999 errors, even if a link to them is valid           The configuration under the deploy key is adapted from a Travis example configuration of deploying to Github Pages, and Derek Smart\u2019s example configuration      For reference, here is the .travis.yml file for my own Jekyll site at the time of this writing.    With Travis and Github all set up, you now have a continuous integration and deployment pipeline that can publish a Jekyll site, free of Github\u2019s restrictions, to Github Pages! :tada:   ',categories:[],tags:["jekyll","ruby"],url:"https://www.paulfioravanti.com/blog/build-ci-cd-pipeline-jekyll/",teaser:"https://www.paulfioravanti.com/assets/images/2018-10-29/samuel-sianipar-1082943-unsplash.jpg"},{title:"Elm 0.18 to 0.19 upgrade notes",excerpt:'I upgraded a few toy Elm 0.18 applications I had to 0.19, and along the way, I encountered some things that I felt I needed to jot down for future me (and hopefully current/future you as well) to reference.   They are mostly the results of trawling the Elm Slack, Elm Discourse, Github issues, documentation for upgraded-to-Elm-0.19 libraries, other blog posts, and trial and error.   So, here they are in no particular order. If you are currently going through an Elm 0.18 to 0.19 upgrade, I hope these points save you some time!   Preface   The very first thing you should do before attempting to update any code manually is install elm-upgrade, and run it over your Elm 0.18 app.   There is not much else to add here that is not covered in elm-upgrade\u2019s README file. Follow its instructions until you have implemented its recommendations, and you will be ready to venture out on your own.   RIP partially exposing custom types   In Elm 0.18, if I had a union type (re-named \u201ccustom type\u201d in 0.19) that looked like:   module Language exposing (Lang(..))  type Lang     = En     | It     | Ja   I was able to partially expose values in the type when imported into another module. For example, if I wanted to use Lang in another module, but did not require the It value, I could write:   import Language exposing (Lang(En, Ja))  availableLanguages : List Lang availableLanguages =     [ En, Ja ]   In Elm 0.19, this is no longer permitted, nor is explicitly exposing all values from a custom type i.e. import Language exposing (Lang(En, It, Ja)).   The only options for accessing the types directly are exposing everything from a module (import Language exposing (..)), which I do not like due to its non-explicit nature, or the remaining option, accessing the custom type values through the module name itself:   import Language exposing (Lang)  availableLanguages : List Lang availableLanguages =     [ Language.En, Language.Ja ]   I do miss not being able to explicitly expose imported custom type values, and it feels strange in this case to write Language.En instead of Lang.En (because are we not accessing a value of the type and not of the module?), but this is how I will be using them moving forward. More information about the rationale behind this change can be found at this Elm Discourse thread.   RIP Basics.toString   In Elm 0.18, I used the convenience of toString to stringify custom type values. I had a list of typed languages in an app that looked this this:   Language.elm   type Language     = En     | It     | Ja   In order to keep track of what language a user switched the app to, I wanted to stringify the face values of the type before sending them off via ports to be put in browser local storage. This happened in an update function that looked something like:   Locale/Update.elm   update : Msg -&gt; Locale -&gt; ( Locale, Cmd Msg ) update msg locale =     case msg of         ChangeLanguage language -&gt;             ( { locale | language = language }             , language                 |&gt; toString                 |&gt; String.toLower                 |&gt; Ports.storeLanguage             )          -- ...   When a ChangeLanguage message is received, before sending the Language outside of Elm-land, it would get transformed from En to "En" to "en". I thought this was pretty convenient, but Elm 0.19 put a stop to that, and I needed to change the code to something like this:   Language.elm   type Language     = En     | It     | Ja  toString : Language -&gt; String toString language =     case language of         En -&gt;             "en"          It -&gt;             "it"          Ja -&gt;             "ja"   Update.elm   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         Msg.ChangeLanguage language -&gt;             ( Model.changeLanguage language model             , language                 |&gt; Language.toString                 |&gt; Ports.storeLanguage             )   This change initially felt like Elm was forcing me to write more boilerplate code. But, I now like the extra explicitness, as well as the very hard line approach that conveys to me that types are in no way related to strings.   There is still an escape hatch to stringify a type during development using Elm 0.19\u2019s Debug.toString function, but as its documentation says, \u201c[i]t is not available for use in packages or production\u201d.   &lt;body&gt; tag attributes must still be set via ports   One major change with views in Elm 0.19 is that if you are creating an HTML document that is entirely managed by Elm (using either Browser.document or Browser.application), then your view function now returns Document msg, rather than Html msg.   A Document is a record that looks like this:   type alias Document msg =     { title : String     , body : List (Html msg)     }   What is strange to me, is that unlike the function signatures of all the tags in the Html module, which look like List (Attribute msg) -&gt; List (Html msg) -&gt; Html msg, the body attribute of a Document only takes a List (Html msg) for the children of the &lt;body&gt; tag, and not a List (Attribute msg) for attributes of the &lt;body&gt; tag itself.   So, if I want to, say, set some classes on the &lt;body&gt; tag to get &lt;body class="bg-white sans-serif w-100", I would have to do this using ports, just like in Elm 0.18.  For a Browser.application Elm app, this could look like:   Main.elm   port initBodyClasses : String -&gt; Cmd msg  main : Program Flags Model Msg main =     Browser.application         { init = init         , -- ...         }   init : Flags -&gt; Url -&gt; Key -&gt; ( Model, Cmd Msg ) init flags url key =     ( Model.init flags url key     , Cmd.batch         [ Navigation.pushUrl key (Url.toString url)         , initBodyClasses "bg-white sans-serif w-100"         ]     )   index.js   // ... app.ports.initBodyClasses.subscribe(classes =&gt; {   document.body.className = classes })   Ultimately, this is a minor inconvenience, but I only note it because it is something that I would expect to be able to do in Elm-land. Perhaps in a future version\u2026?   Conditional subscriptions dependent on model attributes   I had a locale dropdown menu in an application which, when clicked, would open a list of languages that could be switched to (i.e. a msg would be sent to update a showAvailableLanguages attribute on a locale record in the model to True).  Whenever you clicked anywhere on the page aside from the menu, it would close (i.e. a msg would be sent to update showAvailableLanguages to False).   This was implemented in the application subscriptions using the elm-lang/mouse package, looking something like this in Elm 0.18 code:   Main.elm   main : Program Flags Model Msg main =     Navigation.programWithFlags         UpdatePage         { -- ...         , subscriptions = subscriptions         }  subscriptions : Model -&gt; Sub Msg subscriptions { locale } =     if locale.showAvailableLanguages then         Mouse.clicks (\\_ -&gt; CloseAvailableLanguages)     else         Sub.none   In Elm 0.18, the model that is passed into the subscriptions function is the post-update new model, and therefore we can make subscriptions conditional based on values in it.   However, as of this writing, in Elm 0.19 it would seem that is no longer the case. Even after updating Mouse.clicks in the above code to use Browser.Events.onClick from elm/browser, the dropdown menu would not close, and showAvailableLanguages would seem to get updated \u201cout-of-sync\u201d to the application state I was seeing in the Elm debugger.   After finding this Github issue, I realised that the problem may be with the Elm compiler itself. So, I ended up completely removing the conditional subscription from the Elm 0.19 version of the app, and replacing it with an Html.Events.onMouseLeave event directly on the dropdown menu div element that would send the CloseAvailableLanguages message, which I now actually prefer. Something like:   LanguageSelector/View.elm   view : Language -&gt; LanguageSelector -&gt; Html msg view language languageSelector =     let         availableLanguagesToggle =             if languageSelector.showAvailableLanguages then                 [ onMouseLeave Msg.CloseAvailableLanguages ]              else                 []     in     div         ([ attribute "data-name" "language-selector"          , -- ..          ]             ++ availableLanguagesToggle         )         [ -- ..         ]   It\u2019s a shame that there is no Html.Events.none to prevent the list concatenation. Regardless, the takeaway is to, at least for now, refrain from having conditional subscriptions that depend on any attributes in your model until the issue mentioned above is fixed.   URL fragment navigation has issues   If you use hashes (#) in your application, either in the form of hash-based routing (e.g. in a URL like http://example.com/store/#/products/1, you parse information in the fragment to determine that you need to display the page for a product with ID of 1), or you use fragments in HTML anchors to link to different parts of the same page (e.g. &lt;a href="#top"&gt;Top&lt;/a&gt;), you will have some decisions to make to get them working as you would expect in Elm 0.19.   Hash-based routing in path-based clothes   evancz/url-parser, often used in Elm 0.18 applications that have navigation, has a UrlParser.parseHash function to help with parsing URL fragments against defined routes. Elm 0.19\u2019s Url.Parser from elm/url no longer supports this. So, your current routing options for Elm 0.19 are:      Change your application to route on URL paths, rather than fragments        Keep your fragment routing, but before you pass your Url, to Url.Parser.parse to run it against your route matchers, send it through a function that will overwrite the path property of the Url with the content of the fragment. Something like:       migrateUrlFragmentToPath : Url -&gt; Url migrateUrlFragmentToPath url =     { url | path = Maybe.withDefault "" url.fragment, fragment = Nothing }           The Github issues to follow with regards to this are here and here. Both provide further explanation and helpful examples of the problem, so be sure to subscribe to them if this is an issue that affects you.   Anchor navigation requires a page load   Even if your application has path-based routing, and you think you are not affected by the issue above, if you use fragments to navigate to different parts of a page, and have used code from the Elm navigation example for handling Internal types of Browser.UrlRequests (since a fragment is certainly not an External type of link), you may be surprised that when your UrlRequest is passed into the Browser.Navigation.pushUrl function\u2026nothing happens.   More information around this problem is contained in this Github issue, but the way I am currently working around this, in an application that is both path-routed and contains fragments in anchor tags for same-page navigation, is through the following clause in my update function:   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         Msg.LinkClicked urlRequest -&gt;             case urlRequest of                 Browser.Internal url -&gt;                     let                         href =                             Url.toString url                          navigation =                             case url.fragment of                                 Nothing -&gt;                                     Navigation.pushUrl model.key href                                  Just _ -&gt;                                     Navigation.load href                     in                     ( model, navigation)                  Browser.External href -&gt;                     ( model, Navigation.load href )   This does result in a page load for anchor fragment links, but in my case this does not seem to have been a noticeable issue, and as of this writing I do not see another way around it.   Testing applications without a Browser.Navigation.Key   When the init function is called in a Browser.application program, one of the parameters that it receives is a Browser.Navigation.Key, which is needed to \u201ccreate navigation commands that change the URL\u201d. For example:   main : Program () Model Msg main =     Browser.application         { init = init         , -- ...         }   type alias Model =     { key : Key     , url : Url     }   init : () -&gt; Url -&gt; Key -&gt; ( Model, Cmd Msg ) init () url key =     ( Model key url, Cmd.none )   You receive this key whether you like it or not; it is passed into the Elm application from Javascript-land, and as of this writing there is no way to generate one yourself on-the-fly in Elm-land. What this means is that the init function, as well as parts of any function that use a key, cannot be tested with elm test.   This is not so great for tests that simulate a click somewhere on a page and check that the right msg is being sent (example). If you have an update function that looks similar to what is in the Elm navigation example, you will see that you need to pass a key into the Browser.Navigation.pushUrl function:   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         LinkClicked urlRequest -&gt;             case urlRequest of                  Browser.Internal url -&gt;                      ( model, Navigation.pushUrl model.key (Url.toString url) )                   Browser.External href -&gt;                      ( model, Navigation.load href )   Assuming that, like in the example above, you keep your key somewhere in your model, what can you do without a key during testing that will allow your application to compile?   The path of least resistance for me was to change what is stored in the model to a Maybe Key, and ensure that functions like Browser.Navigation.pushUrl are never run when the key is Nothing:   type alias Model =     { key : Maybe Key     , url : Url     }  init : () -&gt; Url -&gt; Key -&gt; ( Model, Cmd Msg ) init () url key =     ( Model (Just key) url, Cmd.none )   update : Msg -&gt; Model -&gt; ( Model, Cmd Msg ) update msg model =     case msg of         LinkClicked urlRequest -&gt;             case urlRequest of                 Browser.Internal url -&gt;                     case model.key of                         Just key -&gt;                             ( model, Navigation.pushUrl key (Url.toString url) )                          Nothing -&gt;                             ( model, Cmd.none )                  Browser.External href -&gt;                     ( model, Navigation.load href )   The clause for Nothing will never be matched while you are running your application in development or production: it is there simply so you can test your update function with a key-less model.   There is a Github issue tracking this problem, and the Elm team are \u201cworking on designs for a possible API to address this\u201d, so consider the above solution strictly a temporary workaround until an API is developed. For now, you will just have to deal with a maximum test coverage of 99%.   Upgrading dependencies   Once you have upgraded your Elm application to 0.19, you will probably need a way to determine whether any of its packages are out of date.   As far as I know, Elm itself does not currently have a way to determine this. However, thanks to elm-dependencies-analyzer, you can simply cut and paste the content of your application\u2019s elm.json file into the live version of the program, and it will tell you which packages you are able to version up.   What you should actually do once you know what package(s) you have to upgrade was initially a source of confusion for me, but after reading this Discourse thread, and a bit of trial and error, I now work on this rule of thumb:      If the dependency to be upgraded is a \u201cdirect\u201d dependency, remove the entry from elm.json and then run elm install author/package to re-introduce it back into the elm.json file using the newest version   If the dependency to be upgraded is an \u201cindirect\u201d dependency, then directly edit the entry in elm.json to the target version number, and then run elm make, which will download the new dependency (yes, you are not supposed to directly edit elm.json, but as of this writing I do not see another way around this)   Perhaps an elm install author/package --indirect command will find its way into a future version of Elm\u2026?   Other miscellaneous thoughts      I quite liked the change in the Html.Attributes.style API from its List ( String, String ) -&gt; Attribute msg implementation in elm-lang/html versus the current String -&gt; String -&gt; Attribute msg implementation in elm/html. More readable in my opinion.        I think the Elm Javascript interface is much nicer in 0.19: being able to explicitly specify node and flags elements in a single object to pass in to the Elm application is less cognitive overhead:       index.js       // Elm 0.18 import { Main } from "./Main.elm";  const appContainer = document.querySelector("#root"); Main.embed(appContainer, {   apiUrl: "https://www.example.com/api/endpoint" })  // Elm 0.19 import { Elm } from "./Main.elm";  Elm.Main.init({   node: document.querySelector("#root"),   flags: {     apiUrl: "https://www.example.com/api/endpoint"   } })           For an application that does not accept flags, I like to now be able to write the type signature for its flags with the unit type: main : Program () Model Msg, rather than main : Program Never Model Msg   Being able to update the title of a page in Elm-land, rather than through ports, thanks to the Browser.Document API, is a great addition   The change in API from Html.Events.onWithOptions to Html.Events.custom makes it more readable in my opinion. I found out about the change itself here   A good reference for a bare minimum implementation of each of the 4 different ways to boot an Elm app can be found at this gist   ',categories:[],tags:["elm","upgrade","elm-0.18","elm-0.19"],url:"https://www.paulfioravanti.com/blog/elm-018-019-upgrade-notes/",teaser:"https://www.paulfioravanti.com/assets/images/2019-04-01/david-travis-547046-unsplash.jpg"},{title:"Chording QWERTY with QMK Combos",
excerpt:"As a current learner of stenography and mechanical keyboard enthusiast, I was pretty excited to learn about the Georgi keyboard.      Aside from its cool form factor, one of the things that caught my eye was that although the hardware is dedicated to replicating a steno machine keymap, the Georgi firmware also manages to squeeze a QWERTY layout keymap into its two rows using stenographic-style chording.      Here, in order to output an \u201cA\u201d, you need to press the \u201cQ\u201d and \u201cZ\u201d keys together. As you can see, there are also similar rules for the rest of the standard QWERTY middle row keys.   I do not think I have ever seen QWERTY used this way until now, so I would absolutely like to give it a go. But, I do not feel I can justify a Georgi purchase as of this writing because I would not consider my stenography skills to even be at novice level yet.   What I do have, though, is an Ergodox set up for stenography that uses Quantum Mechanical Keyboard (QMK) firmware, which is coincidentally what the Georgi uses for its firmware as well.   Looking through the Georgi firmware for inspiration (or code to steal) to achieve a chorded QWERTY layout on an Ergodox left me a bit perplexed. I felt a little bit better when I found that authors acknowledge that it \u201cis the most nonQMK layout you will come across\u201d, but that only left me wondering whether there was an \u201cofficial\u201d QMK way to chord keys.   As you may have guessed, there most certainly is.   QMK Combos are \u201ca chording type solution for adding custom actions\u201d that let you \u201chit multiple keys at once and produce a different effect\u201d. This looks like the configuration we are looking for, so let\u2019s try adding them to a layout!   What You Need      A keyboard that at least supports N-Key Rollover (NKRO). The easiest way to confirm whether you have NKRO enabled is to perform Plover\u2019s Keyboard Ghosting Test. In the Plover in-browser steno demo, if you find that only 6 keys light up on screen when you press the ASDFJKL; keys all at once, then you either currently do not have NKRO enabled, or your keyboard does not support it. The default Ergodox QMK firmware does not enable it by default, but we will fix this soon.   For easier chording, the keyboard should also preferably have a matrix layout (read: straight column layout, like the Ergodox or Planck), rather than a staggered layout like most QWERTY keyboards, and use flat keycaps like G20, but these points do not represent blockers to getting QWERTY chording to work as expected.   QMK Firmware \u2014 see my blog post Escape the defaults and Control your keyboard with QMK for a guide to set up an Ergodox with QMK from scratch, otherwise find your firmware from QMK\u2019s list of supported keyboards.   Initial Setup   For this post, we will use the QMK default Ergodox EZ keymap as a base, and make changes to it to add functionality for QWERTY chording. Feel free to follow along as-is, or make appropriate changes to your own custom keymaps. You can also see the finished layout on this post\u2019s companion QMK Ergodox Chorded QWERTY Example keymap.   After installing the build tools for your operating system, make a clone of the QMK Firmware repository from Github if you do not have one already. Then, create a copy of the default Ergodox EZ keymaps directory into a new directory that we will call chorded_qwerty:   git clone git@github.com:qmk/qmk_firmware.git cd qmk_firmware cp -r keyboards/ergodox_ez/keymaps/default keyboards/ergodox_ez/keymaps/chorded_qwerty   Enable NKRO and Combos   Before adding a new keyboard layout to our keymap, the first thing we will need to do is ensure that we have NKRO and combos enabled. We will do this by adding two new files:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/rules.mk   FORCE_NKRO = yes COMBO_ENABLE = yes   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   #include \"../../config.h\"  #define FORCE_NKRO #define COMBO_COUNT 1      The FORCE_NKRO config makes sure that we have NKRO enabled by default   The COMBO_COUNT 1 specifies the number of combos used in the layout. For now, we will keep this at 1 to focus on just getting a \u201cQ and Z to A\u201d combo working, and then add more later.   New Chorded QWERTY layer   The QMK default Ergodox EZ keymap has three layers: a base layer, a layer for symbols, and a layer for media keys (for our purposes, we can safely ignore the symbol and media keys layers). Rather than change the base layer directly, let\u2019s copy it into a new layer we will call CHORD.   We will then (arbitrarily) assign the top right-most key on the left hand of the BASE layer to be the toggle to turn the CHORD layer on and off, using QMK\u2019s TG(layer) function:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... #define BASE 0  // default layer #define SYMB 1  // symbols #define MDIA 2  // media keys #define CHORD 3 // chorded QWERTY layer  // Helpers to make keymaps a bit easier to read at a glance #define ___ KC_TRNS #define _x_ KC_NO  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Keymap 0: Basic layer  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  |CHORD | ...  * |--------+------+------+------+------+-------------| ...  * | Del    |   Q  |   W  |   E  |   R  |   T  |  L1  | ...  * |--------+------+------+------+------+------|      | ...  * | BkSp   |   A  |   S  |   D  |   F  |   G  |------| ...  * |--------+------+------+------+------+------| Hyper| ...  * | LShift |Z/Ctrl|   X  |   C  |   V  |   B  |      | ...  * `--------+------+------+------+------+-------------' ...  * ...  */ [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   KC_EQL,  KC_1,        KC_2, KC_3, KC_4, KC_5, TG(CHORD),   KC_DELT, KC_Q,        KC_W, KC_E, KC_R, KC_T, TG(SYMB),   KC_BSPC, KC_A,        KC_S, KC_D, KC_F, KC_G,   KC_LSFT, CTL_T(KC_Z), KC_X, KC_C, KC_V, KC_B, ALL_T(KC_NO),   // ... ), // ... [SYMB] = LAYOUT_ergodox(   // ... ), // ... [MDIA] = LAYOUT_ergodox(   // ... ), /* Keymap 3: Chorded QWERTY  *  * ,--------------------------------------------------. ...  * |   =    |   1  |   2  |   3  |   4  |   5  |      | ...  * |--------+------+------+------+------+-------------| ...  * | Del    |  [x] |   W  |   E  |   R  |   T  |  L1  | ...  * |--------+------+------+------+------+------|      | ...  * | BkSp   |   Q  |   S  |   D  |   F  |   G  |------| ...  * |--------+------+------+------+------+------| Hyper| ...  * | LShift |   Z  |   X  |   C  |   V  |   B  |      | ...  * `--------+------+------+------+------+-------------' ...  * ...  */ [CHORD] = LAYOUT_ergodox( // Layer 3: Chorded QWERTY   // left hand   KC_EQL,  KC_1, KC_2, KC_3, KC_4, KC_5, ___,   KC_DELT, _x_,  KC_W, KC_E, KC_R, KC_T, TG(SYMB),   KC_BSPC, KC_Q, KC_S, KC_D, KC_F, KC_G,   KC_LSFT, KC_Z, KC_X, KC_C, KC_V, KC_B, ALL_T(KC_NO),   // ... ) }; // ...   Let\u2019s briefly compare the (abbreviated) CHORD layer to the BASE layer:      The right-most key of the first row uses ___ (KC_TRNS) as a \u201ctransparent\u201d mapping.  In this case, it means that the key will \u201cfall back\u201d to the TG(CHORD) function on the BASE layer. This is really just a convenience so that we don\u2019t need to specify TG(CHORD) again on the CHORD layer.   The \u201cQ\u201d key\u2019s original position has been replaced with _x_ (KC_NO) for the time being, specifically indicating that pressing the key results in a NOOP: the keystroke is ignored. We will do something else with this key later.   The \u201cA\u201d key has been removed, and replaced with the \u201cQ\u201d key.   The default base layer of the Ergodox EZ keymap uses the Mod-Tap advanced keycode shortcut CTL_T(KC_Z) to make the \u201cZ\u201d key Left Control when held, and \u201cZ\u201d when pressed. Combos only support QMK basic keycodes, so we\u2019ve changed the \u201cZ\u201d key to be just the \u201cZ\u201d key (KC_Z).   So, now that we are without a way to print \u201cA\u201d to the screen, let\u2019s actually add in configuration for a combo to enable pressing both \u201cQ\u201d and \u201cZ\u201d to do just that.   Opening Combo   The first thing we need to do is give our combo a name. You may have previously created your own custom keycodes, so if you would like, you may add any named combos to your custom_keycodes list.   However, for this example, let\u2019s keep the focus on combos and put them in their own enumerated type list called combos, and place it underneath the custom_keycodes list. Let\u2019s also use a naming convention of &lt;key 1&gt;&lt;key 2&gt;_&lt;output key&gt; for the entries. So, we\u2019ll name a \u201cQ and Z to A\u201d combo as QZ_A:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum custom_keycodes {   // ... };  enum combos {   QZ_A }; // ...   Next, we need to define a sequence of keys for our combo in a list, terminated by COMBO_END. Our sequence will consist of the \u201cQ\u201d and \u201cZ\u201d keys, and let\u2019s use a similar naming convention as combos and call it qz_combo:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum combos {   QZ_A };  const uint16_t PROGMEM qz_combo[] = {KC_Q, KC_Z, COMBO_END}; // ...   The final piece of the combo puzzle is to now create a list of length COMBO_COUNT called key_combos that will map our combo sequences to their resulting actions:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum combos {   QZ_A };  const uint16_t PROGMEM qz_combo[] = {KC_Q, KC_Z, COMBO_END};  combo_t key_combos[COMBO_COUNT] = {   [QZ_A] = COMBO(qz_combo, KC_A) }; // ...      Currently, key_combos only has one element, but when we eventually add more to it, we will need to change the COMBO_COUNT value in config.h accordingly.    Great, we have now configured our first combo! Let\u2019s now generate the firmware from the qmk_firmware directory root path:   make ergodox_ez:chorded_qwerty   This should generate an ergodox_ez_chorded_qwerty.hex file, which you can then use to flash your Ergodox firmware.   Once you have flashed your firmware, switch over to the CHORD layer, press the \u201cQ\u201d and \u201cZ\u201d keys together, and it should output \u201ca\u201d. As expected, if you hold down Shift and press \u201cQ\u201d and \u201cZ\u201d together, it should output uppercase \u201cA\u201d.   Finishing Combos   Now that we have one combo working, the same principles apply in combos for the remaining QWERTY middle row keys. We will end up with 10 combos total, so first, let\u2019s update COMBO_COUNT:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   // ... #define COMBO_COUNT 10   Now, let\u2019s add in configuration for the rest of the combos:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum combos {   QZ_A,   WX_S,   EC_D,   RV_F,   TB_G,   YN_H,   UM_J,   ICOMMA_K,   ODOT_L,   PSLASH_SCOLON };  const uint16_t PROGMEM qz_combo[] = {KC_Q, KC_Z, COMBO_END}; const uint16_t PROGMEM wx_combo[] = {KC_W, KC_X, COMBO_END}; const uint16_t PROGMEM ec_combo[] = {KC_E, KC_C, COMBO_END}; const uint16_t PROGMEM rv_combo[] = {KC_R, KC_V, COMBO_END}; const uint16_t PROGMEM tb_combo[] = {KC_T, KC_B, COMBO_END}; const uint16_t PROGMEM yn_combo[] = {KC_Y, KC_N, COMBO_END}; const uint16_t PROGMEM um_combo[] = {KC_U, KC_M, COMBO_END}; const uint16_t PROGMEM icomma_combo[] = {KC_I, KC_COMMA, COMBO_END}; const uint16_t PROGMEM odot_combo[] = {KC_O, KC_DOT, COMBO_END}; const uint16_t PROGMEM pslash_combo[] = {KC_P, KC_SLASH, COMBO_END};  combo_t key_combos[COMBO_COUNT] = {   [QZ_A] = COMBO(qz_combo, KC_A),   [WX_S] = COMBO(wx_combo, KC_S),   [EC_D] = COMBO(ec_combo, KC_D),   [RV_F] = COMBO(rv_combo, KC_F),   [TB_G] = COMBO(tb_combo, KC_G),   [YN_H] = COMBO(yn_combo, KC_H),   [UM_J] = COMBO(um_combo, KC_J),   [ICOMMA_K] = COMBO(icomma_combo, KC_K),   [ODOT_L] = COMBO(odot_combo, KC_L),   [PSLASH_SCOLON] = COMBO(pslash_combo, KC_SCOLON) };  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { // ... /* Keymap 3: Chorded QWERTY  *  * ,--------------------------------------------------.  ,--------------------------------------------------.  * |   =    |   1  |   2  |   3  |   4  |   5  |CHORD |  | RIGHT|   6  |   7  |   8  |   9  |   0  |   -    |  * |--------+------+------+------+------+-------------|  |------+------+------+------+------+------+--------|  * | Del    |  [x] |  [x] |  [x] |  [x] |  [x] |  L1  |  |  L1  |  [x] |  [x] |  [x] |  [x] |  [x] |   \\    |  * |--------+------+------+------+------+------|      |  |      |------+------+------+------+------+--------|  * | BkSp   |   Q  |   W  |   E  |   R  |   T  |------|  |------|   Y  |   U  |   I  |   O  |   P  |' / Cmd |  * |--------+------+------+------+------+------| Hyper|  | Meh  |------+------+------+------+------+--------|  * | LShift |   Z  |   X  |   C  |   V  |   B  |      |  |      |   N  |   M  |   ,  |   .  |   /  | RShift |  * `--------+------+------+------+------+-------------'  `-------------+------+------+------+------+--------'  * ...  */ [CHORD] = LAYOUT_ergodox( // Layer 3: Chorded QWERTY   // left hand   KC_EQL,  KC_1, KC_2, KC_3, KC_4, KC_5, ___,   KC_DELT, _x_,  _x_,  _x_,  _x_,  _x_,  TG(SYMB),   KC_BSPC, KC_Q, KC_W, KC_E, KC_R, KC_T,   KC_LSFT, KC_Z, KC_X, KC_C, KC_V, KC_B, ALL_T(KC_NO),   // ...    // right hand   KC_RGHT,      KC_6, KC_7, KC_8,    KC_9,   KC_0,    KC_MINS,   TG(SYMB),     _x_,  _x_,  _x_,     _x_,    _x_,     KC_BSLS,                 KC_Y, KC_U, KC_I,    KC_O,   KC_P,    GUI_T(KC_QUOT),   MEH_T(KC_NO), KC_N, KC_M, KC_COMM, KC_DOT, KC_SLSH, KC_RSFT,   // ... ) }; // ...   Now, re-generate your firmware:   make ergodox_ez:chorded_qwerty   Flash your firmware and you should now have a chorded middle QWERTY row!   You now have a full row of keys to re-assign values as you please. You could bring the number keys down a row, or perhaps create some more custom_keycodes to assign to them. Just for fun, let\u2019s get those keys to mimic a stenotype number bar.   Steno Number Combos   To successfully imitate a stenotype number bar and the chords for stenotype numbers, we will need to do the following:      create a new custom keycode that represents a number bar press - let\u2019s call it NUM   assign NUM to all of the keys we are currently not using   create the following combos:            Pressing NUM and each of the QWER keys will output numbers 1-4       Pressing NUM and each of the UIOP keys will output numbers 6-9       Pressing NUM and the Space key will output 5       Pressing NUM and the Backspace key will output 0              The Space and Backspace keys here represent where I would place the stenotype keyboard \u201cA\u201d and \u201cO\u201d keys respectively on an Ergodox using the default QMK layout we have been modifying.    Here is what those changes will entail:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   // ... #define COMBO_COUNT 20   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum custom_keycodes {   // ...   NUM }  enum combos {   // ...   NUMQ_1,   NUMW_2,   NUME_3,   NUMR_4,   NUMSPACE_5,   NUMU_6,   NUMI_7,   NUMO_8,   NUMP_9,   NUMBSPACE_0 };  // ... const uint16_t PROGMEM numq_combo[] = {NUM, KC_Q, COMBO_END}; const uint16_t PROGMEM numw_combo[] = {NUM, KC_W, COMBO_END}; const uint16_t PROGMEM nume_combo[] = {NUM, KC_E, COMBO_END}; const uint16_t PROGMEM numr_combo[] = {NUM, KC_R, COMBO_END}; const uint16_t PROGMEM numspace_combo[] = {NUM, KC_SPACE, COMBO_END}; const uint16_t PROGMEM numu_combo[] = {NUM, KC_U, COMBO_END}; const uint16_t PROGMEM numi_combo[] = {NUM, KC_I, COMBO_END}; const uint16_t PROGMEM numo_combo[] = {NUM, KC_O, COMBO_END}; const uint16_t PROGMEM nump_combo[] = {NUM, KC_P, COMBO_END}; const uint16_t PROGMEM numbspace_combo[] = {NUM, KC_BSPACE, COMBO_END};  combo_t key_combos[COMBO_COUNT] = {   // ...   [NUMQ_1] = COMBO(numq_combo, KC_1),   [NUMW_2] = COMBO(numw_combo, KC_2),   [NUME_3] = COMBO(nume_combo, KC_3),   [NUMR_4] = COMBO(numr_combo, KC_4),   [NUMSPACE_5] = COMBO(numspace_combo, KC_5),   [NUMU_6] = COMBO(numu_combo, KC_6),   [NUMI_7] = COMBO(numi_combo, KC_7),   [NUMO_8] = COMBO(numo_combo, KC_8),   [NUMP_9] = COMBO(nump_combo, KC_9),   [NUMBSPACE_0] = COMBO(numbspace_combo, KC_0) };  // ... const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { // ... /* Keymap 3: Chorded QWERTY  *  * ,--------------------------------------------------.           ,--------------------------------------------------.  * |   =    |   1  |   2  |   3  |   4  |   5  |CHORD |           | RIGHT|   6  |   7  |   8  |   9  |   0  |   -    |  * |--------+------+------+------+------+-------------|           |------+------+------+------+------+------+--------|  * | Del    |  NUM |  NUM |  NUM |  NUM |  NUM |  L1  |           |  L1  |  NUM |  NUM |  NUM |  NUM |  NUM |   \\    |  * |--------+------+------+------+------+------|      |           |      |------+------+------+------+------+--------|  * | BkSp   |   Q  |   W  |   E  |   R  |   T  |------|           |------|   Y  |   U  |   I  |   O  |   P  |' / Cmd |  * |--------+------+------+------+------+------| Hyper|           | Meh  |------+------+------+------+------+--------|  * | LShift |   Z  |   X  |   C  |   V  |   B  |      |           |      |   N  |   M  |   ,  |   .  |   /  | RShift |  * `--------+------+------+------+------+-------------'           `-------------+------+------+------+------+--------'  *   |Grv/L1|  '\"  |AltShf| Left | Right|                                       |  Up  | Down |   [  |   ]  | ~L1  |  *   `----------------------------------'                                       `----------------------------------'  *                                        ,-------------.       ,-------------.  *                                        | App  | LGui |       | Alt  |Ctrl/Esc|  *                                 ,------|------|------|       |------+--------+------.  *                                 |      |      | Home |       | PgUp |        |      |  *                                 | Space|Backsp|------|       |------|  Tab   |Enter |  *                                 |      |ace   | End  |       | PgDn |        |      |  *                                 `--------------------'       `----------------------'  */ [CHORD] = LAYOUT_ergodox( // Layer 3: Chorded QWERTY   // left hand   KC_EQL,          KC_1,        KC_2,          KC_3,    KC_4,    KC_5,    ___,   KC_DELT,         NUM,         NUM,           NUM,     NUM,     NUM,     TG(SYMB),   KC_BSPC,         KC_Q,        KC_W,          KC_E,    KC_R,    KC_T,   KC_LSFT,         KC_Z,        KC_X,          KC_C,    KC_V,    KC_B,    ALL_T(KC_NO),   LT(SYMB,KC_GRV), KC_QUOT,     LALT(KC_LSFT), KC_LEFT, KC_RGHT,                                                            ALT_T(KC_APP), KC_LGUI,                                                                           KC_HOME,                                                          KC_SPC, KC_BSPC, KC_END,   // right hand   KC_RGHT,      KC_6,          KC_7,    KC_8,    KC_9,    KC_0,    KC_MINS,   TG(SYMB),     NUM,           NUM,     NUM,     NUM,     NUM,     KC_BSLS,                 KC_Y,          KC_U,    KC_I,    KC_O,    KC_P,    GUI_T(KC_QUOT),   MEH_T(KC_NO), KC_N,          KC_M,    KC_COMM, KC_DOT,  KC_SLSH, KC_RSFT,                                KC_UP,   KC_DOWN, KC_LBRC, KC_RBRC, TT(SYMB),   KC_LALT,      CTL_T(KC_ESC),   KC_PGUP,   KC_PGDN,      KC_TAB,        KC_ENT ) }; // ...   Re-generate and re-flash the firmware, and you will now have combos approximating number input on a stenotype keyboard!   Multi-key Combos   Although all of the combos we have created so far have been two-key combos, you are certainly not limited to just two keys. To demonstrate this, let\u2019s create a combo that mimics the chord needed to output a full stop (.) on a stenotype keyboard (yes, I know this is not particularly practical on this layout, but play along just for this example).   The chord for a full stop in steno is TP-LT, meaning that the \u201cT\u201d and \u201cP\u201d keys on the left half of the keyboard, and the \u201cL\u201d and \u201cT\u201d keys on the right half of the keyboard are pressed together. This corresponds to pressing the WEIO keys together in the chorded QWERTY layout, so let\u2019s configure that in:   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/config.h   // ... #define COMBO_COUNT 21   qmk_firmware/keyboards/ergodox_ez/keymaps/chorded_qwerty/keymap.c   // ... enum combos {   // ...   WEIO_DOT };  // ... const uint16_t PROGMEM weio_combo[] = {KC_W, KC_E, KC_I, KC_O, COMBO_END};  combo_t key_combos[COMBO_COUNT] = {   // ...   [WEIO_DOT] = COMBO(weio_combo, KC_DOT) };   No need to change any of the keymaps for this combo. If you now re-generate and re-flash your firmware, you will have a chorded full stop.   Conclusion   Learning about QMK combos was pretty useful, but should anyone actually consider chording their QWERTY layout if they are on a keyboard with enough keys to support each letter, or will doing this hinder more than help?   After putting in the effort to write this blog post, it pains me to say that, at least for me, at the time of this writing, it hinders more than helps for probably the following reasons:      I have too many years worth of touch typing muscle memory invested into the standard QWERTY layout: fighting back against inertia is hard.   I am learning stenography, and my brain seems to have siloed chorded key presses to the stenotype layout. There would seem to now be a trigger in my brain that fires when I move my fingers from QWERTY home row to steno home row, and I got very confused when I attempted to try and type QWERTY when my brain was in \u201csteno mode\u201d. I would wager that perhaps this might be worth re-visiting if I become more competent/confident in steno and/or end up using a keyboard like the Georgi, where there is no physical full-size QWERTY keyboard available, and I am forced to adapt.   So, ultimately, your mileage may vary for chorded QWERTY, but I really like QMK combos themselves, and look forward to experimenting with them: perhaps by replacing some keyboard shortcuts with chords instead.   If you do use QMK combos for anything interesting, please do reach out and let me know!   ",categories:[],tags:["ergodox","keyboards","mechanical-keyboards","qmk","clang","stenography"],url:"https://www.paulfioravanti.com/blog/chording-qwerty-qmk-combos/",teaser:"https://www.paulfioravanti.com/assets/images/2019-04-28/samuel-ramos-1319769-unsplash.jpg"},{title:"Resume as Code",
excerpt:'I recently got back on the job market after a lengthy hiatus, and so had to re-visit the content of my humble resume.   As a developer, if the first recipient of your resume in a new organisation is a non-technical person, then you will probably need to be bound by convention and send along a PDF file of some sort. However, if that person is technical, it could be worth playing around with those conventions using the skills you know best because\u2026   Resumes are Boring   No one really likes to read or write resumes: you may have a duty to read them as part of your job if you are an interviewer, and you likely begrudgingly write them if you are an interviewee. Regardless, they are still the most widely accepted (and expected) artefact used to sell a person at the point of first contact.   They serve a single-use purpose: to convince someone that you are worth the time, effort, and money to begin an interview process with. An interviewer may use your resume as a reference to quiz you in more detail about your past work experience, but at that point you are already through the door, so its job is done.   But, it\u2019s that first step that\u2019s the hardest: having your resume, in a sea of similar resumes, get the attention and curiosity of someone in a position of authority, and convincing them that they should interview you.   In an attempt to achieve that goal, I chose Ruby to be in my corner to add some :sparkles:sparkles:sparkles: to a bland resume submission process.   Resume as Script                    Photo by Alice Pasqual on Unsplash        My actual resume is still ultimately a PDF document (I don\u2019t have the skills to do something extremely cool), but the method used to make that document come into existence is where I hope to get potential new colleagues on side.   That method is a Ruby application, using the Prawn gem under the hood for PDF generation. I send the generated PDF result to human resource contacts, but send only the application to technical contacts, and let them run it. The application ended up being a lot of fun for me to write and continue tweaking, and I hope that it ends up being at least a little bit fun for those I send it to. The intention is that it will lead to follow-on effects like:      The resume actually getting read since some minor effort was needed to generate it: pretty much an attempt to harness the IKEA effect, which would lead to\u2026   A positive response, which will then hopefully lead to an interview in a shorter time frame and\u2026   Potentially skip any coding tests, as the resume itself would also be a showcase code sample   You can get the resume application from Github and try it out yourself.   Design   I am not a designer, but there were a few things I did want to have in the resume document so that it looked familiar, yet not too pedestrian:      2 pages maximum because of low attention spans; no one needs to know my life story, and the details of any position can be discussed in an interview.   A line of image links at the top of the first page to various contact information, social media, professional, technical, and hobby accounts that I think are worth sharing on a resume but don\u2019t want taking up too much space    Buzzword bingo below the image links to make it easier to matchmake my abilities at a glance with any position requirements   LinkedIn-style position and education listings with links and images (regardless of what I may think of LinkedIn, most people know of it and are familiar with the way they lay out information, so I figured it was worth mimicking)   My hope is that most people will get all the re-reference-able information they really want to know out of the image links and Buzzword bingo (ie the first half of the first page of the resume), with all the rest of the information for the most part being read-once supplementary.   Technical Overview   The codebase of the resume has changed greatly as I\u2019ve tinkered with it, but as it stands now, it consists of two major parts:      The command line interface (CLI) program, which handles user input, and what needs to happen before and after the resume gets created   The resume itself: a series of modules that use Prawn to define individual parts of the resume document   Content   There is no content in the resume app at all, so you can\u2019t just open up the code to read the resume in plain text. Rather, the content comes from JSON files hosted in the project Github repo. All text there is encoded in Base64, so you really do need to generate the resume to read any of its content, and this is deliberate.   resources/resume.en.json   {   // ...   "social_media_logo_set": {     "logos": {       "email": {         "image": "aHR0cHM6Ly93d3cuZHJvcGJveC5jb20vcy8yYnQwOGw5MDg0YzR3NnkvcmVzdW1lX2VtYWlsLnBuZz9kbD0x",         "link": "bWFpbHRvOnBhdWwuZmlvcmF2YW50aUBnbWFpbC5jb20/c3ViamVjdD1Zb3VyJTIwcmVzdW1lJTIwaXMlMjBhd2Vzb21lISZib2R5PUklMjB3YW50JTIwdG8lMjBnaXZlJTIweW91JTIwYSUyMGpvYiUyMHJpZ2h0JTIwbm93IQ=="       },       "linked_in": {         "image": "aHR0cHM6Ly93d3cuZHJvcGJveC5jb20vcy9sdDY3NGNycnF3Y293bHcvcmVzdW1lX2xpbmtlZGluLnBuZz9kbD0x",         "link": "aHR0cHM6Ly9saW5rZWRpbi5jb20vaW4vcGF1bGZpb3JhdmFudGk="       },       "twitter": {         "image": "aHR0cHM6Ly93d3cuZHJvcGJveC5jb20vcy80cWo5YnVsem4wd200MWgvcmVzdW1lX3R3aXR0ZXIucG5nP2RsPTE=",         "link": "aHR0cHM6Ly90d2l0dGVyLmNvbS9wYXVsZmlvcmF2YW50aQ=="       },     // ...   },   // ... }   I love internationalisation, so aside from English, the content is available in Italian and Japanese. Japanese was a tough language to get working with Prawn initially since none of Prawn\u2019s bundled fonts support it, but I got there eventually, and will provide further details below.   Assets   Image assets are hosted on my Dropbox account, and when you run the resume application for the first time, it downloads all those files and stores them in your tmp directory. So, when you have generated the resume once, it will generate quicker subsequent times (or until your system clears out your tmp directory). Want to know exactly where those files are being stored? You can find out in IRB with Dir.tmpdir:   $ irb irb(main):001:0&gt; require "tmpdir" true irb(main):002:0&gt; Dir.tmpdir "/var/folders/g0/2s3h_j8n0rqcjjcmyr3v8cwh0000gn/T" irb(main):003:0&gt; exit $ ls /var/folders/g0/2s3h_j8n0rqcjjcmyr3v8cwh0000gn/T | grep resume resume_10fastfingers.png resume_background.jpg resume_duolingo.png resume_email.png resume_exercism.png # ...   Structure   The directory structure of the resume is pretty much standard for any Ruby project, which is fine for development, but I didn\u2019t want to package up multiple files when sending the resume to someone. So, there is a rake task that reads in all the files, and writes them to a single file (which I call the \u201cone-sheet\u201d resume), making it much more straightforward to, say, attach it to an email.   Testing and Code Quality   The application is fully tested using RSpec, and since it\u2019s showcase code, I have tried to add developer niceties like:      100% Simplecov test coverage   Rubocop is generally happy with it   Fully documented with Yard   The tests are also bundled into the one-sheet resume, so you can run both the application itself and the tests from the same file. When you generate the one-sheet resume, it also makes sure to test itself and check its own quality:   $ rake resume Generating one-sheet resume... Successfully generated one-sheet resume Running specs... Run options: include {:focus=&gt;true}  All examples were filtered out; ignoring {:focus=&gt;true}  115/115 |======================== 100 ========================&gt;| Time: 00:00:00  Finished in 0.72365 seconds (files took 0.24667 seconds to load) 115 examples, 0 failures Running code quality check...  1/1 file |======================= 100 ========================&gt;| Time: 00:00:00  1 file inspected, no offenses detected   Technical Challenges   During development, I came across a quite a few challenges, but simulating image links and getting internationalisation to work were ones that I needed to actively get community assistance for, so I will expand upon them below.   Prawn and Image Links   Prawn\u2019s README states:      One thing Prawn is not, and will never be, is an HTML to PDF generator. [\u2026] We do have basic support for inline styling but it is limited to a very small subset of functionality and is not suitable for rendering rich HTML documents.    I wanted to add a set of clickable image links to the resume; Prawn supports text links in PDFs, as you would expect, but it would seem that image links are considered \u201crich HTML\u201d, and outside the scope of Prawn\u2019s API. So, I wondered if there was a way to potentially simulate the effect that I wanted, and it turns out that there is. The high level explanation is to:      insert an image into the PDF   Move the document cursor up to the top of the image   draw some text over the image   make that text a link to somewhere   make that text transparent   And voil\xe0, it kind of looks like you are clicking the image.      An abbreviated code sample would look something like this:   # bounding_box provide bounds for flowing text, starting at a given point bounding_box([0, cursor], width: 35) do   image(     open("path/to/image.jpg"),     fit: [35, 35],     align: :center   )   # moves page "cursor" up   move_up(35)   # 0 is transparent, 1 is opaque   transparent(0) do     formatted_text(       [         {           text: "|||", # placeholder text           size: 40,           link: "http://example.com/"         }       ],       align: :center     )   end   # ... end   More details about this can be found in this StackOverflow question, and you can see how it is used in the resume codebase here.   Displaying Japanese Text   Japanese text cannot be rendered with Prawn\u2019s built-in fonts, and you will need to rely on external TrueType font files (extension .ttf) to display text.   When you attempt to generate my resume in Japanese, Ruby goes and fetches font files from my Dropbox account, and downloads them into your tmp directory. These files were originally provided by the Information-Technology Promotion Agency (IPA), but are now the concern of the Character Information Technology &amp; Promotion Council (CITPC). The specific set of font files are the \u201c4 fonts package\u201d (4\u66f8\u4f53\u30d1\u30c3\u30af) listed on this page, which contains the IPA Mincho and IPA Gothic fonts. The latest versions of these fonts can be found on the IPAex Font Downloads page.   I used the IPAPMincho font (ipamp.ttf) for \u201cnormal\u201d font, and IPAPGothic (ipagp.ttf) for \u201cbold\u201d; they are different fonts, but one worked for me as the \u201cbold version\u201d of the other. These fonts are configured in Prawn on-the-fly using code that looks something like this:   Prawn::Document.generate("MyJapaneseDocument.pdf") do |pdf|   # assume `font_name` here is something like "IPA",   # ie not a font that is shipped with the Prawn gem   unless Prawn::Font::AFM::BUILT_INS.include?(font_name)     pdf.font_families.update(       font_name =&gt; {         normal: "path/to/ipamp.ttf",         bold: "path/to/ipagp.ttf"       }     )   end   pdf.font font_name end   Japanese font then displays quite nicely, including half-width kana.      More details about this can be found in this StackOverflow question, and you can see how it is used in the resume codebase here.   Final Thoughts   Coding my resume ended up becoming one of my longest, most consistently maintained and developed projects (still going since 2013), small as it is. I certainly did not expect this to be the case when I started, but I would end up using it as a sandbox for ideas I wanted to test out in Ruby, and they ended up becoming features.   Sometimes, those features would result in \u201cbugs in production\u201d, and technical people would end up requesting the generated PDF from me when they would get errors trying to run the one-sheet Ruby script (though I\u2019m pretty sure it\u2019s okay now\u2026). But, at least they would usually laugh them off and acknowledge the effort to try something different (and then usually push me forward for an interview, anyway).   Creating your resume doesn\u2019t have to be a chore: it can be as fun and rewarding as any other software that you write, and that\u2019s all the better if doing something a bit different can help you in your job hunting as well.   Feel free to use any or all of my resume if you want to generate PDFs, and happy interviewing!   ',categories:[],tags:["pdf","prawn","resume","ruby","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"https://www.paulfioravanti.com/blog/resume-code/",teaser:"https://www.paulfioravanti.com/assets/images/2019-06-22/drew-beamer-692664-unsplash.jpg"},{title:"Internationalisation with Phoenix LiveView",
excerpt:'This blog post is the first in a series on the creation of a small I18n application using Phoenix LiveView, which updates page content based on the language chosen from a dropdown menu:      Internationalisation with Phoenix LiveView   Internationalisation with Phoenix LiveComponents   Internationalisation with Phoenix Live Layouts      In a previous blog post, Runtime Language Switching in Elm, I re-created the Tachyons Full Screen Centered Title component documentation page in Elm, and added a language dropdown menu to change the page language.      The page is deployed here, and you can find the code here, but to save a click, the animated GIF above shows all of its use cases:      Click on the current language, and the menu opens, showing a list of selectable languages   Click the current language again, or anywhere else on the page, and the menu closes   If you select a different language, the language of the page content and title will change, and the list of selectable languages in the dropdown menu will update   Refresh the page, and you will see that your choice of language is remembered   The blog post goes through different methods I used to get internationalisation (i18n) working, but, in my opinion, the options in Elm as of this writing are not quite as nice as Elixir\u2019s gettext-based API.   However, when I have previously implemented language switching for a standard Phoenix application, compared with frontend-only Elm, needing to make a request back to the server to change the application locale means that a bit more time is needed before the update is visible on screen.   Granted, changing application locale is not something a typical user would perform very often, and so, needing a page refresh for it is probably not a pain point for anyone. But, with the advent of Phoenix LiveView, I wondered whether I would be able to exactly replicate the snappiness of the Elm example application with Phoenix, just for fun.   And so, the rest of this post will focus on porting over/re-creating the Elm application in Phoenix, evolving over four stages:      Straight client-server   Augmenting client-server with Javascript \u201csprinkles\u201d   Letting Javascript take over   Swapping out Javascript for LiveView      The software versions we will use to build out this application are:          Elixir: 1.9.2     Erlang: 22.0.7     Phoenix: 1.4.10     Gettext: 0.7.10     LiveView: 0.3.1     Node: 12.12.0     Tachyons: 4.11.1      Let\u2019s get started!   Initial Setup   No Ecto   Generate and install dependencies of a new Phoenix application. We will not be using a database, so pass in the --no-ecto flag to make sure we do not generate any unneeded Ecto configuration:   mix phx.new phx_i18n_example --no-ecto cd phx_i18n_example mix deps.get   Gettext   Next, we will need to tell Gettext about what locales we want to use in the application (in our case English, Italian, and Japanese), and what locale should be the default (English). Add the following lines to your configuration:   config/config.exs   config :phx_i18n_example, PhxI18nExampleWeb.Gettext,   default_locale: "en",   locales: ~w(en it ja)   Tachyons   Since we will use Tachyons for styling, we have to install it and make it available in Phoenix.   First, install it with npm:   npm install --save-dev tachyons@4.11.1 --prefix assets   Then, import it into Phoenix:   assets/js/app.js   // ... // import css from "../css/app.css" // ... import "phoenix_html" import "tachyons" // ...   Make sure you also comment out or remove the default Phoenix-generated import css from "../css/app.css" line since we will not be using those default styles, and we do not want anything in app.css to overwrite Tachyons styling.   Client-Server   Dealing with Params   For this first development step, the goal will be to go as far as we can in building out the main use cases of the application using just Phoenix, and no Javascript.  This means we will have to start using URL parameters to send information to the server in order to tell it about the desired state of the application.   For example, if we want the locale to be Japanese, we could send a locale URL parameter to tell the application to switch to Japanese:   http://localhost:4000/?locale=ja   Since we are not using Javascript, we will also have to use URL parameters to let the application know if we want to open or close the locale dropdown menu:   http://localhost:4000/?show_available_locales=true http://localhost:4000/?show_available_locales=false   I think the best way for dealing with these parameters as they come in to the application is to use a Plug, so let\u2019s add a LocalePlug to our :browser pipeline:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   use PhxI18nExampleWeb, :router   alias PhxI18nExampleWeb.LocalePlug    pipeline :browser do     # ...     plug LocalePlug   end   # ... end   We need this LocalePlug to do the following:      Fetch and set the locale:            First, check the parameters for the locale       If it cannot be found in the parameters, check the browser cookies       If it cannot be found in the browser cookies, return the default locale       Update the global application locale to the retrieved locale value, but only if that locale value is actually different to the global application locale           Determine the dropdown menu state:            If the parameters have a show_available_locales=true value, indicate that the dropdown should be open       If there is any other value for show_available_locales, including false, or if show_available_locales is not present in the params, the dropdown should display as closed           Persist the locale in the cookies            If the locale value is already stored in the cookie, do nothing       Otherwise, if the cookie value is different from the locale value, or the cookie value is not present, store the locale value in the cookie           Let\u2019s see what this looks like in code:   lib/phx_i18n_example_web/plugs/locale_plug.ex   defmodule PhxI18nExampleWeb.LocalePlug do   alias Plug.Conn   @behaviour Plug    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @cookie "phxi18nexamplelanguage"   @ten_days 10 * 24 * 60 * 60    defguard known_locale?(locale) when locale in @locales    @impl Plug   def init(_opts), do: nil    @impl Plug   def call(conn, _opts) do     locale = fetch_and_set_locale(conn)      conn     |&gt; determine_language_dropdown_state()     |&gt; persist_locale(locale)   end    defp fetch_and_set_locale(conn) do     case locale_from_params(conn) || locale_from_cookies(conn) do       nil -&gt;         # This will fallback to the default locale set in `config.exs`         Gettext.get_locale()        locale -&gt;         # Update the global locale only if the `locale` value         # is different to it         if locale != Gettext.get_locale() do           Gettext.put_locale(locale)         end          locale     end   end    defp locale_from_params(%Conn{params: %{"locale" =&gt; locale}})        when known_locale?(locale) do     locale   end    defp locale_from_params(_conn), do: nil    defp locale_from_cookies(%Conn{cookies: %{@cookie =&gt; locale}})        when known_locale?(locale) do     locale   end    defp locale_from_cookies(_conn), do: nil    defp determine_language_dropdown_state(conn) do     show_available_languages =       case conn.params["show_available_locales"] do         "true" -&gt;           true          _ -&gt;           # `false`, `nil`, `blah` etc           false       end      Conn.assign(conn, :show_available_locales, show_available_languages)   end    defp persist_locale(%Conn{cookies: %{@cookie =&gt; locale}} = conn, locale) do     # Cookie locale is the same as the current locale, so do nothing and just     # return the original `conn`     conn   end    defp persist_locale(conn, locale) do     Conn.put_resp_cookie(conn, @cookie, locale, max_age: @ten_days)   end end   A few notes on this Plug file:      We are using Gettext.get_locale/0 as the source of truth for the application locale. It \u201cgets the global Gettext locale for the current process\u201d, and since we\u2019re doing a single process client-server implementation, it suits our purposes. There is no need to assign a separate locale value in the conn: whenever we want the application locale, we will ask Gettext to provide it to us   We are following Elixir\u2019s rule of thumb and deliberately using ||, and not or, in fetch_and_set_locale/1, since the values returned on either side are non-boolean   Having the cookie be valid for ten days is completely arbitrary. Feel free to change as you see fit   From Route to Template   Now that we have our application state set up, our flow from here towards the view layer is exactly as Phoenix provides out-of-the-box:   The root path gets routed to the PageController:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   use PhxI18nExampleWeb, :router   alias PhxI18nExampleWeb.LocalePlug    pipeline :browser do     # ...     plug LocalePlug   end    # ...    scope "/", PhxI18nExampleWeb do     pipe_through :browser     get "/", PageController, :index   end end   Then, the PageController renders the index.html template:   lib/phx_i18n_example_web/controllers/page_controller.ex   defmodule PhxI18nExampleWeb.PageController do   use PhxI18nExampleWeb, :controller    def index(conn, _params) do     render(conn, "index.html")   end end   \u2026which we need to change to the following code:   lib/phx_i18n_example_web/templates/page/index.html.eex   &lt;article class="&lt;%= article() %&gt;"&gt;   &lt;div class="&lt;%= heading_container() %&gt;"&gt;     &lt;h1 class="&lt;%= heading() %&gt;"&gt;       &lt;%= gettext("Vertically centering things in css is easy!") %&gt;     &lt;/h1&gt;   &lt;/div&gt; &lt;/article&gt;      The Phoenix-generated lib/phx_i18n_example_web/gettext.ex file enables us to use a gettext macro to search for translated strings depending on the Gettext locale setting. We do not have any translations at the moment, so this call will just return the \u201cVertically centering things in css is easy!\u201d string itself (we will get to generating translations later)   All the functions that you see interpolated in the various tag class attribute values exist to make it easier for us to manage sets of Tachyons utility classes   Modules Specifically for Styling   Functions declared without qualified module names in templates will be attempted to be resolved in the view that renders them, which, in index.html.eex\u2019s case, as per Phoenix convention, is the PageView.   Since the functions that are being referenced here will all thematically relate to styling, and be quite verbose, I think we should put them inside their own specific \u201cstyle\u201d modules, and have PageView delegate to them. This, to me at least, makes the PageView explicitly say:      \u201cI know I am meant to respond to these functions, but their details are not my responsibility, so please go and look in this other module\u201d    lib/phx_i18n_example_web/views/page_view.ex   defmodule PhxI18nExampleWeb.PageView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.PageStyle    defdelegate article, to: PageStyle   defdelegate heading, to: PageStyle   defdelegate heading_container, to: PageStyle end   lib/phx_i18n_example_web/views/styles/page_style.ex   defmodule PhxI18nExampleWeb.PageStyle do   @article_classes ~w[     dt     vh-75     w-100   ] |&gt; Enum.join(" ")    @heading_container_classes ~w[     dtc     ph-3 ph4-l     tc     v-mid   ] |&gt; Enum.join(" ")    @heading_classes ~w[     f6 f2-m f-subheadline-l     fw6     tc   ] |&gt; Enum.join(" ")    def article, do: @article_classes   def heading_container, do: @heading_container_classes   def heading, do: @heading_classes end      In order to make the Tachyons mnemonics easier to manage, they are in lists contained in module attributes, which get joined into a single string at compile time   The attributes are then wrapped in functions so they become a part of the module\u2019s public interface   I think this is a nicer way to deal with CSS utility classes, rather than modify them directly in a template. But, as with any subjective opinion, your mileage may vary.   Page Layout   Now, every template gets rendered inside of a layout, so let\u2019s look at the main application layout next, and mark where we will make changes from the Phoenix-generated defaults:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html&gt;   &lt;head&gt;     &lt;!-- ... --&gt;     &lt;title&gt;&lt;%= gettext("Multilingualisation in Phoenix") %&gt;&lt;/title&gt;     &lt;!-- ... --&gt;   &lt;/head&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= render LanguageDropdownView,                "language_dropdown.html",                show_available_locales: @show_available_locales %&gt;     &lt;main role="main"&gt;       &lt;%= render @view_module, @view_template, assigns %&gt;     &lt;/main&gt;     &lt;!-- ... --&gt;   &lt;/body&gt; &lt;/html&gt;   Like the index.html.eex template, the &lt;title&gt; uses the gettext macro to get its translation, and the &lt;body&gt; calls out to a body/0 view function in LayoutView to fetch its Tachyons style classes:   lib/phx_i18n_example_web/views/layout_view.ex   defmodule PhxI18nExampleWeb.LayoutView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.{LanguageDropdownView, LayoutStyle}    defdelegate body, to: LayoutStyle end   lib/phx_i18n_example_web/views/styles/layout_style.ex   defmodule PhxI18nExampleWeb.LayoutStyle do   @body_classes ~w[     bg-dark-pink     overflow-container     pt3     sans-serif     vh-100     white   ] |&gt; Enum.join(" ")    def body, do: @body_classes end   Language Dropdown Menu   Above the main section of app.html.eex, within which in this case index.html.eex is rendered, we render a separate view and template for the locale dropdown, passing in a @show_available_locales value, available here as a module attribute due to show_available_locales being assigned in the Plug.Conn in LocalePlug:   lib/phx_i18n_example_web/templates/language_dropdown/language_dropdown.html.eex   &lt;div class="&lt;%= dropdown_container() %&gt;"&gt;   &lt;%= render LanguageDropdownView,              "_current_locale_link.html",              show_available_locales: @show_available_locales %&gt;   &lt;ul class="&lt;%= dropdown_list(@show_available_locales) %&gt;"&gt;     &lt;%= render_many selectable_locales(),                     LanguageDropdownView,                     "_locale_link.html",                     as: :locale %&gt;   &lt;/ul&gt; &lt;/div&gt;   Using the same LanguageDropdownView, we render two partial templates:      _current_locale_link.html, passing in the @show_available_locales value we received from app.html.eex   _locale_link.html, which we are rendering for each of the non-current selectable locales, which we get from the selectable_locales/0 function, using Phoenix.View.render_many/4   Let\u2019s have a look at each of the partial templates:   lib/phx_i18n_example_web/templates/language_dropdown/_current_locale_link.html.eex   &lt;a href="?show_available_locales=&lt;%= !@show_available_locales %&gt;"    class="&lt;%= current_selection_link() %&gt;"&gt;   &lt;p class="&lt;%= current_selection(@show_available_locales) %&gt;"&gt;     &lt;span&gt;&lt;%= current_locale_string() %&gt;&lt;/span&gt;     &lt;span class="&lt;%= caret() %&gt;"&gt;\u25be&lt;/span&gt;   &lt;/p&gt; &lt;/a&gt;      The &lt;a&gt; tag here links to the opposite value of whatever the passed-in @show_available_locales value is, so that we can implement a toggle-like action   The styling of the dropdown is dependant on the value in @show_available_locales, which gets passed into the current_selection/1 function   lib/phx_i18n_example_web/templates/language_dropdown/_locale_link.html.eex   &lt;a href="?locale=&lt;%= @locale %&gt;" class="&lt;%= dropdown_list_item_link() %&gt;"&gt;   &lt;li class="&lt;%= dropdown_list_item() %&gt;"&gt;     &lt;%= locale_string(@locale) %&gt;   &lt;/li&gt; &lt;/a&gt;      The @locale attribute comes from the as: :locale option used in the render_many/4 function in language_dropdown.html.eex: each locale from the selectable_locales/0 function (see below) that is passed in to the partial is referenced as @locale   The &lt;a&gt; tag here links to its own locale as the target locale   Displays the humanised version of the locale (eg locale "en" displays as \u201cEnglish\u201d)   All the functions in the previous two partial templates are contained in the LanguageDropdownView:   lib/phx_i18n_example_web/views/language_dropdown_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.LanguageDropdownStyle   alias __MODULE__, as: LanguageDropdownView    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_strings %{     "en" =&gt; "English",     "it" =&gt; "Italiano",     "ja" =&gt; "\u65e5\u672c\u8a9e"   }    defdelegate caret, to: LanguageDropdownStyle   defdelegate current_selection(show_available_locales), to: LanguageDropdownStyle   defdelegate current_selection_link, to: LanguageDropdownStyle   defdelegate dropdown_container, to: LanguageDropdownStyle   defdelegate dropdown_list(show_available_locales), to: LanguageDropdownStyle   defdelegate dropdown_list_item, to: LanguageDropdownStyle   defdelegate dropdown_list_item_link, to: LanguageDropdownStyle    def locale_string(locale), do: @locale_strings[locale]   def current_locale_string, do: locale_string(Gettext.get_locale())   def selectable_locales, do: List.delete(@locales, Gettext.get_locale()) end      The Tachyons style-related functions are all delegated off to this view\u2019s style module, LanguageDropdownStyle   The locale_string/1 and current_locale_string/0 functions simply perform a lookup of the @locale_strings map to get the value to show in the menu: note that these strings are static, and the menu itself is not internationalised at all   Notice that the current_locale_string/0 function immediately calls the locale_string/1 function, passing in the result of the Gettext.get_locale/0 function as a parameter: we are always using Gettext as the source of truth for the application locale   In the same way, to get the list of selectable locales to populate the locale menu, we are subtracting the current locale from the list of known locales that we configured in config.exs   The LanguageDropdownStyle module contains the following:   lib/phx_i18n_example_web/views/styles/language_dropdown_style.ex   defmodule PhxI18nExampleWeb.LanguageDropdownStyle do   @caret_classes ~w[     absolute     ml2   ] |&gt; Enum.join(" ")    @current_selection_classes ~w[     b--white     ba     br2     pa2     pointer     tc     w4   ]    @current_selection_border_radius_classes "br--top"    @current_selection_link_classes ~w[     no-underline     white   ] |&gt; Enum.join(" ")    @dropdown_container_classes ~w[     center     f3     flex     h3     items-center     justify-end     w-90   ] |&gt; Enum.join(" ")    @dropdown_list_classes ~w[     absolute     b--white     bb     bl     br     br--bottom     br2     items-center     list     mt5     pl0     pointer     pr0     pt1     tc     top-0     w4   ]    @dropdown_show_classes ~w[     flex     flex-column   ] |&gt; Enum.join(" ")    @dropdown_hide_classes "dn"    @dropdown_list_item_classes ~w[     hover-bg-white     hover-dark-pink     ph1     pv2     pt0     w-100   ] |&gt; Enum.join(" ")    @dropdown_list_item_link_classes ~w[     no-underline     w-100     white   ] |&gt; Enum.join(" ")    def caret, do: @caret_classes    def current_selection(show_available_locales) do     display_classes =       if show_available_locales do         [@current_selection_border_radius_classes | @current_selection_classes]       else         @current_selection_classes       end      Enum.join(display_classes, " ")   end    def current_selection_link, do: @current_selection_link_classes    def dropdown_container, do: @dropdown_container_classes    def dropdown_list(show_available_locales) do     display_classes =       if show_available_locales do         [@dropdown_show_classes | @dropdown_list_classes]       else         [@dropdown_hide_classes | @dropdown_list_classes]       end      Enum.join(display_classes, " ")   end    def dropdown_list_item, do: @dropdown_list_item_classes   def dropdown_list_item_link, do: @dropdown_list_item_link_classes end   You can see that things here are quite verbose, and hence extracting these functions out into their own module creates a hard concern barrier between style-related functions, and other utility-like functions that are typically needed in view modules.   Generate Translations   Now that we know all of the two places where we need the gettext macro, we can generate translation placeholders for all of our known locales using the following commands:   mix gettext.extract mix gettext.merge priv/gettext --locale en mix gettext.merge priv/gettext --locale it mix gettext.merge priv/gettext --locale ja   Now that we have our locale placeholders, let\u2019s put some translations in them! The English locale file can be left as-is:   priv/gettext/en/LC_MESSAGES/default.po   # ...  #, elixir-format #: lib/phx_i18n_example_web/templates/layout/app.html.eex:7 msgid "Multilingualisation in Phoenix" msgstr ""  #, elixir-format #: lib/phx_i18n_example_web/templates/page/index.html.eex:4 msgid "Vertically centering things in css is easy!" msgstr ""   priv/gettext/it/LC_MESSAGES/default.po   # ...  #, elixir-format #: lib/phx_i18n_example_web/templates/layout/app.html.eex:7 msgid "Multilingualisation in Phoenix" msgstr "Multilingualizzazione in Phoenix"  #, elixir-format #: lib/phx_i18n_example_web/templates/page/index.html.eex:4 msgid "Vertically centering things in css is easy!" msgstr "Centrare verticalmente con css \xe8 facile!"   priv/gettext/ja/LC_MESSAGES/default.po   # ...  #, elixir-format #: lib/phx_i18n_example_web/templates/layout/app.html.eex:7 msgid "Multilingualisation in Phoenix" msgstr "Phoenix\u306b\u304a\u3051\u308b\u591a\u8a00\u8a9e\u5316"  #, elixir-format #: lib/phx_i18n_example_web/templates/page/index.html.eex:4 msgid "Vertically centering things in css is easy!" msgstr "CSS\u3067\u5782\u76f4\u30bb\u30f3\u30bf\u30ea\u30f3\u30b0\u306f\u7c21\u5358\u3060\u3088\uff01"   And now, when you change your locale, you should see the language change on the page content, as well as the page title!      You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 01-client-server branch. The branch is also deployed here in its own environment.   Client-Server Issues   So, we have language switching working, but what is wrong here?      It takes time to open and close the menu, and to change locale, since we are doing a round trip to the server   We cannot make the menu close if we click elsewhere on the page, since we cannot use Javascript onclick handlers. We also cannot make the entire &lt;body&gt; content a link, since we would have the dropdown links inside that body content link, and HTML does not do nested links.   Since we are missing a use case from the Elm implementation, let\u2019s compromise and allow some Javascript \u201csprinkles\u201d into the application.   Javascript Sprinkles   For this next step, aside from introducing some Javascript code, the main functionality of the application will not change very much.   Add Tag Metadata   We will need to allow Javascript to target certain page elements in order to manipulate them or perform some other actions, and that will take the form of adding some ids and roles to tags. So, let\u2019s open up the following files and make those small changes:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!-- ... --&gt;   &lt;body class="&lt;%= body() %&gt;" id="body"&gt;     &lt;!-- ... --&gt;   &lt;/body&gt; &lt;!-- ... --&gt;   lib/phx_i18n_example_web/templates/language_dropdown/language_dropdown.html.eex   &lt;!-- ... --&gt; &lt;ul class="&lt;%= dropdown_list(@show_available_locales) %&gt;" id="locale_dropdown"&gt;   &lt;!-- ... --&gt; &lt;/ul&gt; &lt;!-- ... --&gt;   lib/phx_i18n_example_web/templates/language_dropdown/_current_locale_link.eex   &lt;a href="?show_available_locales=&lt;%= !@show_available_locales %&gt;"    class="&lt;%= current_selection_link() %&gt;"    id="current_locale_link"&gt;   &lt;p class="&lt;%= current_selection(@show_available_locales) %&gt;" id="current_locale"&gt;     &lt;!-- ... --&gt;   &lt;/p&gt; &lt;/a&gt;   lib/phx_i18n_example_web/templates/language_dropdown/_locale_link.eex   &lt;a href="?locale=&lt;%= @locale %&gt;"    class="&lt;%= dropdown_list_item_link() %&gt;"    role="locale_link"&gt;   &lt;!-- ... --&gt; &lt;/a&gt;   Add Javascript   Now, in the main Javascript entry point for a Phoenix application, we are going to add a click-handler to the &lt;body&gt; that tells the dropdown to hide itself:   assets/js/app.js   // ... // Import local files // // Local files can be imported directly using relative paths, for example: // import socket from "./socket" import { LocaleDropdown } from "./locale_dropdown"  document.getElementById("body").onclick = () =&gt; {   LocaleDropdown.hide() }   I prefer Javascript with an interface that looks like it follows an Elixir-like Module.function() convention. This was able to be done using an Immediately Invoked Function Expression (IIFE; pronounced \u201ciffy\u201d) that returns an object containing functions in its values:   assets/js/locale_dropdown.js   export { LocaleDropdown }  const LocaleDropdown = ((document, window) =&gt; {   const LOCALE_DROPDOWN_CLASSES = document.getElementById("locale_dropdown").classList   const CURRENT_LOCALE_CLASSES = document.getElementById("current_locale").classList   const CURRENT_LOCALE_LINK = document.getElementById("current_locale_link")   const LOCALE_DROPDOWN_LINKS =     document.querySelectorAll(\'[role="locale_link"], #current_locale_link\')    // REF: https://tachyons.io/docs/table-of-styles/   const TOP_BORDER_RADIUS_ONLY = "br--top"   const DROPDOWN_VISIBLE_CLASSES = ["flex", "flex-column"]   const DROPDOWN_HIDDEN_CLASS = "dn"    initLocaleDropdownLinks()    return Object.freeze({     hide: hide   })    function initLocaleDropdownLinks() {     LOCALE_DROPDOWN_LINKS.forEach(link =&gt; {       // NOTE: Prevent propagation to the onclick handler for the `body` tag.       link.onclick = event =&gt; { event.stopPropagation() }     })   }    function hide() {     if (isVisible()) {       hideLocaleDropdown()       setCurrentLocaleLinkToOpenDropdownMenu()       resetCurrentLocaleBottomBorderRadius()       updateShowAvailableLocalesToHidden()     }   }    function isVisible() {     return (       DROPDOWN_VISIBLE_CLASSES.some(value =&gt; {         return LOCALE_DROPDOWN_CLASSES.contains(value)       })     )   }    function hideLocaleDropdown() {     LOCALE_DROPDOWN_CLASSES.remove(...DROPDOWN_VISIBLE_CLASSES)     LOCALE_DROPDOWN_CLASSES.add(DROPDOWN_HIDDEN_CLASS)   }    function setCurrentLocaleLinkToOpenDropdownMenu() {     CURRENT_LOCALE_LINK.setAttribute("href", "/?show_available_locales=true")   }    function resetCurrentLocaleBottomBorderRadius() {     CURRENT_LOCALE_CLASSES.remove(TOP_BORDER_RADIUS_ONLY)   }    function updateShowAvailableLocalesToHidden() {     // NOTE: This is done purely from a UX standpoint: If the locale dropdown is     // closed, do not have the search parameter say that it\'s open.     if (window.location.search === "?show_available_locales=true") {       window.history.pushState(         {}, document.title, "/?show_available_locales=false"       )     }   } })(document, window)   Yes, this is a pretty liberal helping of Javascript \u201csprinkles\u201d, but, we needed it. We won\u2019t go through all the details of this code, but there a few peculiarities worth bringing up briefly:      As the IIFE executes, it \u201cinitialises\u201d itself by calling initLocaleDropdownLinks(). This sets up event handlers to make sure all links in the dropdown menu, including the current locale link, do not have events generated by their clicks inadvertently propagate down to &lt;body&gt; tag, causing LocaleDropdown.hide() to also be called   The returned frozen object contains what is essentially the \u201cpublic interface\u201d for the IIFE: the hide function, which, as you can see, is called in app.js   The document and window do not technically need to be passed into the IIFE as arguments since they are globally available, but I think encapsulation is always a goal worth striving for. It is probably also better to have as many variables as possible resolve locally within the IIFE, rather than have to go out and get global variables every time you want to use them   Now, when you open the dropdown menu, and click anywhere else on the page, the menu closes.      You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 02-js-sprinkles branch. The branch is also deployed here in its own environment.   Javascript Sprinkles Issues   We are now technically on-par feature-wise with the Elm implementation, but there are still some lingering issues:      It still takes time to open and close the menu and change the locale   Closing the menu via clicking somewhere else on the page is snappier than clicking the current locale, even though their function is the same, which is a bit awkward   You can really feel now that we are perhaps unnecessarily forcing the back end to do things that the front end really wants us to do, so let\u2019s acquiesce to Javascript and let it take over more functionality. Further, let\u2019s get rid of any mandatory state management via URL parameters: like the Elm app, I don\u2019t want to see parameters that I don\u2019t have to.   Javascript Takeover   Remove Language Dropdown State Parameter   Dropdown state is currently managed via the @show_available_locales attribute, which is initially set in the LocalePlug, and then used throughout the templates and views. So, let\u2019s first purge our plug of this param: open up locale_plug.ex, and delete the determine_language_dropdown_state/1 function entirely, since we are not determining the language dropdown state in the plug anymore. Then, remove that function call from the call/2 function as follows:   lib/phx_i18n_example_web/plugs/locale_plug.ex   defmodule PhxI18nExampleWeb.LocalePlug do   # ...    @impl Plug   def call(conn, _opts) do     locale = fetch_and_set_locale(conn)     persist_locale(conn, locale)   end    # ... end   Great! Now, let\u2019s go and remove any trace of the @show_available_locales in our templates and views. First, in the layout:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!-- ... --&gt; &lt;%= render LanguageDropdownView, "language_dropdown.html" %&gt; &lt;!-- ... --&gt;   Then, in the dropdown menu template:   lib/phx_i18n_example_web/templates/language_dropdown/language_dropdown.html.eex   &lt;div class="&lt;%= dropdown_container() %&gt;"&gt;   &lt;%= render LanguageDropdownView, "_current_locale.html" %&gt;   &lt;ul class="&lt;%= dropdown_list() %&gt;" id="locale_dropdown"&gt;     &lt;%= render_many selectable_locales(),                     LanguageDropdownView,                     "_locale_list_item.html",                     as: :locale %&gt;   &lt;/ul&gt; &lt;/div&gt;   Here, you can see that we have renamed the _current_locale_link.html and _locale_link.html partials to _current_locale.html and _locale_list_item.html respectively, as we will use handlers for click events in them, rather than &lt;a&gt; links   The partials themselves look like the following:   lib/phx_i18n_example_web/templates/language_dropdown/_current_locale.html.eex   &lt;p class="&lt;%= current_selection() %&gt;" id="current_locale"&gt;   &lt;span&gt;&lt;%= current_locale_string() %&gt;&lt;/span&gt;   &lt;span class="&lt;%= caret() %&gt;"&gt;\u25be&lt;/span&gt; &lt;/p&gt;   lib/phx_i18n_example_web/templates/language_dropdown/_locale_list_item.html.eex   &lt;li class="&lt;%= dropdown_list_item() %&gt;" id="&lt;%= @locale %&gt;" role="selectable_locale"&gt;   &lt;%= locale_string(@locale) %&gt; &lt;/li&gt;   The number of styling-related functions has also decreased as a result of these changes, so we change the view and styling module code accordingly:   lib/phx_i18n_example_web/views/language_dropdown_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownView do   # ...    defdelegate caret, to: LanguageDropdownStyle   defdelegate current_selection, to: LanguageDropdownStyle   defdelegate dropdown_container, to: LanguageDropdownStyle   defdelegate dropdown_list, to: LanguageDropdownStyle   defdelegate dropdown_list_item, to: LanguageDropdownStyle    # ... end   lib/phx_i18n_example_web/views/styles/language_dropdown_style.ex   defmodule PhxI18nExampleWeb.LanguageDropdownStyle do   @caret_classes ~w[     absolute     ml2   ] |&gt; Enum.join(" ")    @current_selection_classes ~w[     b--white     ba     br2     pa2     pointer     tc     w4   ] |&gt; Enum.join(" ")    @dropdown_container_classes ~w[     center     f3     flex     h3     items-center     justify-end     w-90   ] |&gt; Enum.join(" ")    # NOTE: Default visibility is `display: none` (`dn`).   @dropdown_list_classes ~w[     absolute     b--white     bb     bl     br     br--bottom     br2     dn     items-center     list     mt5     pl0     pointer     pr0     pt1     tc     top-0     w4   ] |&gt; Enum.join(" ")    @dropdown_list_item_classes ~w[     hover-bg-white     hover-dark-pink     ph1     pv2     pt0     w-100   ] |&gt; Enum.join(" ")    def caret, do: @caret_classes   def current_selection, do: @current_selection_classes   def dropdown_container, do: @dropdown_container_classes   def dropdown_list, do: @dropdown_list_classes   def dropdown_list_item, do: @dropdown_list_item_classes end   Increase Javascript Responsibility   Finally, we update the locale dropdown Javascript so that it can:      Open the dropdown, as well as close it   Handle click events for each locale in the dropdown list, including the current locale   Prompt a locale change by sending an AJAX request, and then update the page with the server response   assets/js/locale_dropdown.js   export { LocaleDropdown }  const LocaleDropdown = ((document, window) =&gt; {   const LOCALE_DROPDOWN_CLASSES = document.getElementById("locale_dropdown").classList   const CURRENT_LOCALE = document.getElementById("current_locale")   const SELECTABLE_LOCALES = document.querySelectorAll("[role=\'selectable_locale\']")    // REF: https://tachyons.io/docs/table-of-styles/   const TOP_BORDER_RADIUS_ONLY = "br--top"   const DROPDOWN_VISIBLE_CLASSES = ["flex", "flex-column"]   const DROPDOWN_HIDDEN_CLASS = "dn"    initCurrentLocale()   initSelectableLocales()    return Object.freeze({     hide: hide   })    function initCurrentLocale() {     const currentLocaleClassList = CURRENT_LOCALE.classList     CURRENT_LOCALE.onclick = event =&gt; {       // NOTE: Prevent propagation to the onclick handler for the `body` tag.       event.stopPropagation()       if (isVisible()) {         hideLocaleDropdown()         removeCurrentLocaleBottomBorderRadius(currentLocaleClassList)       } else {         showLocaleDropdown()         addCurrentLocaleBottomBorderRadius(currentLocaleClassList)       }     }   }    function initSelectableLocales() {     SELECTABLE_LOCALES.forEach(locale =&gt; {       locale.onclick = () =&gt; {         changeLocale(locale)       }     })   }    function hide() {     const currentLocaleClassList = CURRENT_LOCALE.classList     if (isVisible()) {       hideLocaleDropdown()       removeCurrentLocaleBottomBorderRadius(currentLocaleClassList)     }   }    function changeLocale(locale) {     // Clear params in case the locale was originally set using them.     window.history.replaceState({}, document.title, "/")     const xhr = new XMLHttpRequest()     xhr.open("GET", document.location.origin + `?locale=${locale.id}`)     xhr.onreadystatechange = () =&gt; {       document.open()       document.write(xhr.responseText)       document.close()     }     xhr.send()   }    function isVisible() {     return (       DROPDOWN_VISIBLE_CLASSES.some(value =&gt; {         return LOCALE_DROPDOWN_CLASSES.contains(value)       })     )   }    function hideLocaleDropdown() {     LOCALE_DROPDOWN_CLASSES.remove(...DROPDOWN_VISIBLE_CLASSES)     LOCALE_DROPDOWN_CLASSES.add(DROPDOWN_HIDDEN_CLASS)   }    function showLocaleDropdown() {     LOCALE_DROPDOWN_CLASSES.add(...DROPDOWN_VISIBLE_CLASSES)     LOCALE_DROPDOWN_CLASSES.remove(DROPDOWN_HIDDEN_CLASS)   }    function removeCurrentLocaleBottomBorderRadius(currentLocaleClassList) {     currentLocaleClassList.remove(TOP_BORDER_RADIUS_ONLY)   }    function addCurrentLocaleBottomBorderRadius(currentLocaleClassList) {     currentLocaleClassList.add(TOP_BORDER_RADIUS_ONLY)   } })(document, window)   After applying those changes, you can see that the application is now as snappy as the Elm version.      You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 03-js-takeover branch. The branch is also deployed here in its own environment.   Javascript Takeover Issues   In order to fetch translations, the application is still making a call out to the server, so it will never be quite as fast as Elm there, but that\u2019s fine: I would rather not give up using the gettext API for a potential front-end-based solution.   But, the issue now is\u2026we have a lot of Javascript :wink:! Wouldn\u2019t it be nicer if we could handle all this \u201cfront-end\u201d functionality in Elixir-land? Well, let\u2019s see how much LiveView can help us in achieving that goal!   LiveView   It feels like it\u2019s been a long evolution for this application, but we are finally at the main event: leveraging the power of LiveView!   Before we begin changing our application logic, we have some new dependencies to add and some configuration ceremony to perform, so let\u2019s do that.   Installation and Configuration      NOTE: The method of installation/configuration below is current as of LiveView 0.3.1, but since LiveView is a rapidly evolving project as of this writing, make sure to check the Phoenix LiveView README file for the latest information if you run into any issues.    First, we need to install the LiveView hex package, so add the following entries to your mix file:   mix.exs   defmodule PhxI18nExample.MixProject do   # ...    defp deps do     [       # ...       {:phoenix_live_view, "~&gt; 0.3.0"},       {:floki, "&gt;= 0.0.0", only: :test}     ]   end   Then, run mix deps.get.   Next, we need to add configuration for a signing salt. Generate one by running mix phx.gen.secret 32, and then add it as follows:   config/config.exs   config :phx_i18n_example, PhxI18nExampleWeb.Endpoint,   # ...   live_view: [     signing_salt: "&lt;YOUR_SECRET_SALT&gt;"   ]   Add the LiveView flash to the browser pipeline:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   # ...    pipeline :browser do     # ...     plug :fetch_flash     plug Phoenix.LiveView.Flash     # ...   end    # ... end   Add some LiveView configuration to your controllers, views, and router in your web file:   lib/phx_i18n_example_web.ex   defmodule PhxI18nExampleWeb do   # ...    def controller do     quote do       # ...       import Phoenix.LiveView.Controller     end   end    def view do     quote do       # ...       import Phoenix.LiveView,         only: [           live_render: 2,           live_render: 3,           live_link: 1,           live_link: 2         ]     end   end    def router do     quote do       # ...       import Phoenix.LiveView.Router     end   end    # ... end   Expose a new websocket for LiveView updates:   lib/phx_i18n_example_web/endpoint.ex   defmodule PhxI18nExampleWeb.Endpoint do   use Phoenix.Endpoint, otp_app: :phx_i18n_example    socket "/live", Phoenix.LiveView.Socket    # ... end   Add LiveView to the Node dependencies:   assets/package.json   {   // ...   "dependencies": {     // ...     "phoenix_live_view": "file:../deps/phoenix_live_view"   },   // ... }   Install the dependencies with:   npm install --prefix assets   Finally, enable connecting to a LiveView socket from Javascript:   assets/js/app.js   // ...  import { Socket } from "phoenix" import LiveSocket from "phoenix_live_view"  let liveSocket = new LiveSocket("/live", Socket) liveSocket.connect()   Okay, configuration ceremony complete! Now, let\u2019s move over to actually changing the application.   From Conn to Session   We will start, yet again, with the locale plug, where we find that there are some significant changes from before:   lib/phx_i18n_example_web/plugs/locale_plug.ex   defmodule PhxI18nExampleWeb.LocalePlug do   alias Plug.Conn   @behaviour Plug    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @cookie "phxi18nexamplelanguage"    defguard known_locale?(locale) when locale in @locales    @impl Plug   def init(_opts), do: nil    @impl Plug   def call(conn, _opts) do     locale = fetch_locale(conn)      conn     |&gt; Conn.assign(:locale, locale)     |&gt; Conn.put_session(:locale, locale)   end    defp fetch_locale(conn) do     case locale_from_params(conn) || locale_from_cookies(conn) do       nil -&gt;         # NOTE: This will fallback to the default locale set in `config.exs`         Gettext.get_locale()        locale -&gt;         locale     end   end    defp locale_from_params(%Conn{params: %{"locale" =&gt; locale}})        when known_locale?(locale) do     locale   end    defp locale_from_params(_conn), do: nil    defp locale_from_cookies(%Conn{cookies: %{@cookie =&gt; locale}})        when known_locale?(locale) do     locale   end    defp locale_from_cookies(_conn), do: nil end   A few notes on this file:      In the fetch_locale/1 function, we are still attempting to fetch the locale from values potentially given in the params, or in the cookies. If we cannot find it, we ask gettext to give us the default locale; that part has not changed. However, if we do find the locale, we are simply returning it, without calling Gettext.put_locale/1 to set the locale globally, because LiveViews run in their own process. As opposed to before, where the application was essentially single process, the application will now be multi-process, which means that there is no global locale for a LiveView to refer to, even if we do set it: each process can only rely on its own encapsulated state, and hence will need a local reference to a locale   This relates directly to why we are using Plug.Conn.put_session/3: we provide session data to LiveViews, not conn data, to initialise their state   We are also providing the exact same locale data to the conn assigns, though. Why store the same data in two different places? Because the layout template the LiveView is rendered in, app.html.eex, needs it. A layout, or at least the main layout (I have not tested nested layouts), as far as I can gather, can have LiveViews rendered within in it, but cannot itself be a LiveView (this took me far too long to finally figure out)   All code related to persisting the locale value in the cookie has been removed since a Phoenix.LiveView.Socket does not have the ability to directly access or assign values to cookies. So how do we make sure the application can remember our locale choice? Using a Javascript escape hatch called \u201chooks\u201d to get at the cookies, which we will see more of later\u2026   Goodbye Controller, Hello LiveView   Now, let\u2019s see about getting a LiveView rendered. First, to the router:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   # ...    scope "/", PhxI18nExampleWeb do     pipe_through :browser     live "/", PageLive, session: [:locale]   end end      Rather than routing the root path to the PageController, we can route directly to a LiveView with Phoenix.LiveView.Router.live/3. LiveViews are responsible for setting up state within their own process, so they pretty much fulfil the role that a controller would. So, if you would like, you can safely delete the lib/phx_i18n_example_web/controllers/page_controller.ex file. (Note that we could have continued to use PageController, and just converted the index function\u2019s render/3 to a live_render/3, but it\u2019s purpose would have only been to manually extract the locale out of conn.assigns and assign it to the session, so I figured going straight to a live route would feel more \u201cLiveView-y\u201d, if that\u2019s even a thing\u2026)   The session: [:locale] option here indicates that we want to pass the session locale value we populated in the LocalePlug to PageLive, our named LiveView   Speaking of which, let\u2019s create a PageLive module, which, by what seems like an emerging convention, should be placed in a live/ web directory:   lib/phx_i18n_example_web/live/page_live.ex   defmodule PhxI18nExampleWeb.PageLive do   use Phoenix.LiveView   alias PhxI18nExampleWeb.PageView    def mount(%{locale: locale}, socket) do     socket = assign(socket, locale: locale)     {:ok, socket}   end    def render(assigns) do     PageView.render("index.html", assigns)   end end   A LiveView has two main callback functions that you must implement:      mount/2, where you set up your initial state from session values and assign them to the socket state   render/1, which is responsible for returning rendered content, which in this case is the index.html template, passing it the assigns information, which comes from the socket. So, in this case, assigns could contain %{locale: "en"} if that is what was set in the socket, either from mount/2, or an event handler, which we will look at later   As for the index.html template that gets rendered in the LiveView, it looks fairly similar to before, but we now need to give it a .leex extension for Live Embedded Elixir:   lib/phx_i18n_example_web/templates/page/index.html.leex   &lt;%= with_locale(@locale, fn -&gt; %&gt;   &lt;article class="&lt;%= article() %&gt;" phx-click="hide-dropdown"&gt;     &lt;div class="&lt;%= heading_container() %&gt;"&gt;       &lt;h1 class="&lt;%= heading() %&gt;"&gt;         &lt;%= gettext("Vertically centering things in css is easy!") %&gt;       &lt;/h1&gt;     &lt;/div&gt;   &lt;/article&gt; &lt;% end) %&gt;      As mentioned previously, we can no longer rely on Gettext.get_locale/0 to be our global source of truth for the application locale, since each LiveView is its own process. So, we need to specifically provide a locale to every template that needs translating. I initially thought that I could use Gettext.get_locale/0 and Gettext.put_locale/1 within a LiveView to set a global locale within the LiveView process: I tried using them in mount/2, render/1, and even within the above template, but I had no luck in getting the string-to-translate to re-evaluate until I used Gettext.with_locale/2 with the @locale that was set in the socket.assigns.  So, please be aware of that potentially time-consuming gotcha, or, if you found a way to use them in LiveView, please let me know!   The &lt;article&gt; tag now has a phx-click="hide-dropdown" binding on it, which will send PageLive a "hide-dropdown" message when it is clicked (remember that clicking outside the dropdown menu while it is open should close the menu). We haven\u2019t put the message-handling code in PageLive just yet, but we will come back to it   In order to get with_locale/2 available in the template, make sure to update the PageView:   lib/phx_i18n_example_web/views/page_view.ex   defmodule PhxI18nExampleWeb.PageView do   use PhxI18nExampleWeb, :view   import Gettext, only: [with_locale: 2]    # ... end   Every LiveView in its own Process   In the layout, the standard &lt;%= render @view_module, @view_template, assigns %&gt; statement renders the PageLive LiveView, but that is not the only place where we need dynamic functionality. The language dropdown needs to open, close, and change locale, and the page title needs to change when the locale changes.   We cannot wrap the entire page in a single LiveView (there\u2019s no equivalent for document.getElementById("body").onclick for us here), so we are going to need separate LiveViews for the dropdown menu and title, rendered from the layout:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html&gt;   &lt;head&gt;     &lt;!-- ... --&gt;     &lt;%= live_render @conn, TitleLive, session: %{locale: @locale} %&gt;   &lt;/head&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= live_render @conn, LanguageDropdownLive, session: %{locale: @locale} %&gt;     &lt;main role="main"&gt;       &lt;%= render @view_module, @view_template, assigns %&gt;     &lt;/main&gt;     &lt;!-- ... --&gt;   &lt;/body&gt; &lt;/html&gt;   The live_render/3 function \u201crenders a LiveView within an originating plug request or within a parent LiveView\u201d. If we were rendering these LiveViews from another LiveView, we would pass in the parent LiveView\u2019s @session attribute. But, since the layout is within a plug request, we do not have a session yet, and, therefore, need to create one for the new LiveViews. Hence, we use @conn as the first argument, and make sure to pass in the @locale attribute from the conn, that we set up in the LocalePlug (remember, we set the same locale value in both the conn and in the session), into both the TitleLive and LanguageDropdownLive\u2019s session.   In order to have TitleLive aliased properly in the layout template, make sure to make the following minor change to the LayoutView:   lib/phx_i18n_example_web/views/layout_view.ex   # ... alias PhxI18nExampleWeb.{LanguageDropdownLive, LayoutStyle, TitleLive}   We will get into the details of TitleLive and LanguageDropdownLive soon, but an important thing to understand is that we now have 3 LiveViews, each running in their own separate process, which conceptually looks like this:      Now, even though each of these LiveViews exist in isolated processes, they still need to be able to talk to each other when certain events occur:      When LocaleDropdownLive changes the locale, PageLive and TitleLive need to know what the locale has been changed to so they can re-render themselves with the correct string for the locale   When the current locale is clicked, it needs to look at what the state of the available locales dropdown menu is, open or closed, and toggle it   If the dropdown menu is open in LocaleDropdownLive, and a click occurs either in PageLive or in LocaleDropdownLive outside of the dropdown menu, LocaleDropdownLive needs to know so that it can re-render itself with a closed menu      In order to get these LiveViews chatting, we will call on Phoenix PubSub to help us out.   LiveView Event Handling   Since we\u2019re already most familiar with PageLive, let\u2019s code up message handling there first:   lib/phx_i18n_example_web/live/page_live.ex   defmodule PhxI18nExampleWeb.PageLive do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageView}    @locale_changes "locale-changes"   @dropdown_changes "dropdown-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@locale_changes)     socket = assign(socket, locale: locale)     {:ok, socket}   end    def render(assigns) do     PageView.render("index.html", assigns)   end    def handle_event("hide-dropdown", _value, socket) do     Endpoint.broadcast_from(self(), @dropdown_changes, "hide-dropdown", %{})     {:noreply, socket}   end    def handle_info(%{event: "change-locale", payload: %{locale: locale}}, socket) do     socket = assign(socket, :locale, locale)     {:noreply, socket}   end end         There are two different types of messages that PageView has to concern itself with: locale change messages, and dropdown change messages, which we have set up as two different Phoenix Channel names: @locale_changes and @dropdown_changes. Not all LiveViews will need to care about all kinds of messages, which is why we are not using a single channel for all message types   When the PageView mounts, it calls Phoenix.Endpoint.subscribe/2 to set up a subscription to @locale_changes messages, since it needs to be told when the locale changes so it can render the correct language string. The message we are looking out for from @locale_changes is called "change-locale", which we handle with Phoenix.LiveView.handle_info/2. When we get the "change-locale" message, we extract the locale from its payload, and assign it to the socket. render/1 will then be called automatically, and any necessary template re-rendering will occur   The PageView also needs to listen out for "hide-dropdown" messages that its own template, index.html.leex could send to it (remember we set phx-click="hide-dropdown" on the &lt;article&gt; tag). When a "hide-dropdown" message is received by Phoenix.LiveView.handle_event/3, the PageView does not need to do anything to itself, but it instead calls Phoenix.Endpoint.broadcast_from/4 to send out a broadcast to anything that\u2019s listening on the @dropdown_changes channel telling it that they should hide their dropdown; you can probably guess what would be listening out for that   Let\u2019s now create a TitleLive module:   lib/phx_i18n_example_web/live/title_live.ex   defmodule PhxI18nExampleWeb.TitleLive do   use Phoenix.LiveView   import PhxI18nExampleWeb.Gettext, only: [gettext: 1]   import Gettext, only: [with_locale: 2]   alias PhxI18nExampleWeb.Endpoint    @locale_changes "locale-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@locale_changes)     socket = assign(socket, locale: locale)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= with_locale(@locale, fn -&gt; %&gt;       &lt;title&gt;         &lt;%= gettext("Multilingualisation in Phoenix") %&gt;       &lt;/title&gt;     &lt;% end) %&gt;     """   end    def handle_info(%{event: "change-locale", payload: %{locale: locale}}, socket) do     socket = assign(socket, :locale, locale)     {:noreply, socket}   end end         As you can see, the mount/1 and handle_info/2 functions are identical to PageView: they both subscribe to the @locale_changes channel and specifically handle "change-locale" messages to change their own locales   For render/1, though, because there is not much code, we will render it inline rather than create a new template just for the &lt;title&gt; tag   When I initially wrote the inline template, I figured that I could get away with leaving the &lt;title&gt; tag in app.html.eex, and just render the gettext macro, since that\u2019s the only thing that changes. However, a LiveView must contain at least one HTML tag in order to render, so just be aware of that gotcha   Let\u2019s now create our last, and busiest, LiveView: LanguageDropdownLive.   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownView}    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_changes "locale-changes"   @dropdown_changes "dropdown-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@dropdown_changes)     socket = init_dropdown_state(socket, locale)     {:ok, socket}   end    def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end    # Event handling code will go here...    defp init_dropdown_state(socket, locale) do     selectable_locales = List.delete(@locales, locale)      assign(       socket,       %{         locale: locale,         selectable_locales: selectable_locales,         show_available_locales: false       }     )   end end   For the time-being, we will leave out any event handling code, and instead gradually add it in as we look through the templates that will fire off the events that LanguageDropdownLive needs to handle. The major points we need to know about at this stage are:      LanguageDropdownLive subscribes to the @dropdown_changes channel, since clicks could occur within itself, outside of the actual dropdown menu, as well as from PageLive, that would necessitate it to close the dropdown menu   We have also set up a @locale_changes channel, that we will broadcast on to let PageLive and TitleLive know about locale changes, and which we will use in an event handler soon   On mount, the init_dropdown_state/2 function is called to\u2026initialise the dropdown state. Note that we have brought back the show_available_locales attribute that we initially got rid of when we migrated from client-server to Javascript. It is now back to being a part of the overall language dropdown state, and so we need to deal with it here in the LiveView   A Quick Styling Detour   The re-emergence of show_available_locales affects the way we deal with the Tachyons styling, so we will make a quick detour to handle re-writing of the LanguageDropdownView and LanguageDropdownStyle files to re-incorporate the show_available_locales attribute:   lib/phx_i18n_example_web/views/language_dropdown_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.LanguageDropdownStyle   alias __MODULE__, as: LanguageDropdownView    @locale_strings %{     "en" =&gt; "English",     "it" =&gt; "Italiano",     "ja" =&gt; "\u65e5\u672c\u8a9e"   }    defdelegate caret, to: LanguageDropdownStyle   defdelegate current_selection(show_available_locales), to: LanguageDropdownStyle   defdelegate dropdown_container, to: LanguageDropdownStyle   defdelegate dropdown_list(show_available_locales), to: LanguageDropdownStyle   defdelegate dropdown_list_item, to: LanguageDropdownStyle    def locale_string(locale), do: @locale_strings[locale] end   lib/phx_i18n_example_web/views/styles/language_dropdown_style.ex   defmodule PhxI18nExampleWeb.LanguageDropdownStyle do   @caret_classes ~w[     absolute     ml2   ] |&gt; Enum.join(" ")    @current_selection_classes ~w[     b--white     ba     br2     pa2     pointer     tc     w4   ]    @current_selection_border_radius_classes "br--top"    @current_selection_link_classes ~w[     no-underline     white   ] |&gt; Enum.join(" ")    @dropdown_container_classes ~w[     center     f3     flex     h3     items-center     justify-end     w-90   ] |&gt; Enum.join(" ")    @dropdown_list_classes ~w[     absolute     b--white     bb     bl     br     br--bottom     br2     items-center     list     mt5     pl0     pointer     pr0     pt1     tc     top-0     w4   ]    @dropdown_show_classes ~w[     flex     flex-column   ] |&gt; Enum.join(" ")    @dropdown_hide_classes "dn"    @dropdown_list_item_classes ~w[     hover-bg-white     hover-dark-pink     ph1     pv2     pt0     w-100   ] |&gt; Enum.join(" ")    @dropdown_list_item_link_classes ~w[     no-underline     w-100     white   ] |&gt; Enum.join(" ")    def caret, do: @caret_classes    def current_selection(show_available_locales) do     display_classes =       if show_available_locales do         [@current_selection_border_radius_classes | @current_selection_classes]       else         @current_selection_classes       end      Enum.join(display_classes, " ")   end    def current_selection_link, do: @current_selection_link_classes    def dropdown_container, do: @dropdown_container_classes    def dropdown_list(show_available_locales) do     display_classes =       if show_available_locales do         [@dropdown_show_classes | @dropdown_list_classes]       else         [@dropdown_hide_classes | @dropdown_list_classes]       end      Enum.join(display_classes, " ")   end    def dropdown_list_item, do: @dropdown_list_item_classes   def dropdown_list_item_link, do: @dropdown_list_item_link_classes end   Language Dropdown Event Handling   Back to our scheduled event handling programming. Let\u2019s dive straight into the language dropdown template:   lib/phx_i18n_example_web/templates/language_dropdown/language_dropdown.html.leex   &lt;div class="&lt;%= dropdown_container() %&gt;" phx-click="hide"&gt;   &lt;%= render LanguageDropdownView,              "_current_locale.html",              locale: @locale,              show_available_locales: @show_available_locales %&gt;   &lt;ul class="&lt;%= dropdown_list(@show_available_locales) %&gt;"&gt;     &lt;%= render_many @selectable_locales,                     LanguageDropdownView,                     "_locale_list_item.html",                     as: :locale %&gt;   &lt;/ul&gt; &lt;/div&gt;      As expected, the language dropdown template is now a .leex file since it is being rendered by a LiveView   The full set of dropdown state that was set in the socket is on display here, with the @locale and @show_available_locales attributes now being passed into the _current_locale.html partial, and @selectable_locales now being used to determine what locales need to have _locale_list_items.html partials rendered for them, rather than a selectable_locales/0 view function that we used previously   Notice that the partials are being render-ed \u201cnormally\u201d, as in, they are not being live_rendered. This is because the partials are not meant to be run in a separate process to the parent template and they are essentially \u201ca part\u201d of the parent template itself, and hence are automatically \u201clive rendered\u201d. Nested LiveViews are possible, but that is not what is occurring in this case   We can see the first event that LanguageDropdownLive needs to handle is a "hide" event, occurring whenever somewhere in the template that is not the dropdown menu is clicked, so let\u2019s write the function to handle that:   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...    def handle_event("hide", _value, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    # ... end      Okay, first event handled! Let\u2019s now see what the _current_locale.html needs us to do:   lib/phx_i18n_example_web/templates/language_dropdown/_current_locale.html.eex   &lt;p class="&lt;%= current_selection(@show_available_locales) %&gt;"    name="current_locale"    id="&lt;%= @locale %&gt;"    phx-click="toggle"    phx-hook="currentLocale"&gt;   &lt;span&gt;&lt;%= locale_string(@locale) %&gt;&lt;/span&gt;   &lt;span class="&lt;%= caret() %&gt;"&gt;\u25be&lt;/span&gt; &lt;/p&gt;   Compared to before, the &lt;p&gt; tag now:      has an id attribute containing the @locale passed into it from its parent template   fires a "toggle" message when clicked   has a binding to a hook named "currentLocale"   Let\u2019s handle the message first, and then the hook.   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...    def handle_event("toggle", _value, socket) do     %{assigns: %{show_available_locales: show_available_locales}} = socket     socket = assign(socket, :show_available_locales, !show_available_locales)     {:noreply, socket}   end    # ... end   To handle the "toggle" message, we take the current value of the show_available_locales attribute from the socket, flip the value, and then re-assign it back to the socket.      Hooks   LiveView provides life-cycle callback functions to handle custom client-side Javascript when an element is added, updated, or removed by the server. In our case, we are going to want to use two of those callback functions, mounted and updated, for the exact same purpose:   assets/js/app.js   // ...  import { Socket } from "phoenix" import LiveSocket from "phoenix_live_view" import { Cookie } from "./cookie"  const Hooks = {   currentLocale: {     mounted() {       Cookie.set(this.el.id)       // Clear params in case the locale was originally set using them.       window.history.replaceState({}, document.title, "/")     },     updated() {       Cookie.set(this.el.id)     }   } }  let liveSocket = new LiveSocket("/live", Socket, { hooks: Hooks }) liveSocket.connect()      In the mounted() callback, executed when the current locale has been mounted into the DOM (eg when first opening the application or after a page refresh), we are able to access the &lt;p&gt; tag element from _current_locale.html.eex itself in by calling this.el.  Since we set an id attribute on the &lt;p&gt; tag containing the current locale, we can access it using this.el.id.   Since we have not explicitly disallowed setting the locale by params, but we do not want them to hang around after mounting, we clear them out using History.replaceState   Since we want to make sure that the locale is stored in cookies on every locale change, which could happen during a mount (application first starts), and an update (locale is selected from the dropdown menu), we set the cookie in the updated() callback as well   Make sure you pass a { hooks: Hooks } options object to LiveSocket in order to initialise the hooks   The Javascript to set the cookie looks like the following:   assets/js/cookie.js   export { Cookie }  const Cookie = (document =&gt; {   const NAME = "phxi18nexamplelanguage"    return { set: set }    function set(locale) {     document.cookie = `${NAME}=${locale}; expires=${expires()}`   }    function expires() {     let expiry = new Date()     // Set expiry to ten days     expiry.setDate(expiry.getDate() + 10)     return expiry.toGMTString()   } })(document)   For some reason, it took me longer than expected to get the Document.cookie code working properly. Setting the cookie did not seem to work unless its name only contained letters and numbers, and no other characters. Maybe you will have better luck if you decide to re-write any of this code.   Passing Values in Bindings   Back in Elixir-land, we now need to look at what messages should sent when a locale in the language dropdown menu gets clicked:   lib/phx_i18n_example_web/templates/language_dropdown/_locale_list_item.html.eex   &lt;li class="&lt;%= dropdown_list_item() %&gt;"     id="&lt;%= @locale %&gt;"     role="selectable_locale"     phx-click="locale-changed"     phx-value-locale="&lt;%= @locale %&gt;"&gt;   &lt;%= locale_string(@locale) %&gt; &lt;/li&gt;   When a locale is clicked, it fires a "locale-changed" message, and in order to tell the LiveView what the new locale should be, it uses a phx-value- prefixed attribute called, unsurprisingly, locale. So, let\u2019s handle this message and parameter in LanguageDropdownLive:   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(self(), @locale_changes, "change-locale", %{locale: locale})     socket = init_dropdown_state(socket, locale)     {:noreply, socket}   end    # ... end      Here, we get told that \u201cthe locale has changed\u201d (passive voice), at which point we broadcast out to anything that is listening on the @locale_changes channel that they should \u201cchange their locale\u201d (active voice) to the specified locale value   Then, we re-use the init_dropdown_state/2 function, that we also used in mount/2, to reset the language dropdown menu to its initial state, and re-render it      The final message that LanguageDropdownLive needs to deal with, is the "hide-dropdown" message that it would receive when a click is registered on PageLive. The implementation for this is the same as handling the "hide" message we did earlier, so let\u2019s just include it in for the final version of the full LanguageDropdownLive code:   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownView}    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_changes "locale-changes"   @dropdown_changes "dropdown-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@dropdown_changes)     socket = init_dropdown_state(socket, locale)     {:ok, socket}   end    def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end    def handle_event("hide", _value, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    def handle_event("toggle", _value, socket) do     %{assigns: %{show_available_locales: show_available_locales}} = socket     socket = assign(socket, :show_available_locales, !show_available_locales)     {:noreply, socket}   end    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(self(), @locale_changes, "change-locale", %{       locale: locale     })      socket = init_dropdown_state(socket, locale)     {:noreply, socket}   end    def handle_info(%{event: "hide-dropdown"}, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    defp init_dropdown_state(socket, locale) do     selectable_locales = List.delete(@locales, locale)      assign(       socket,       %{         locale: locale,         selectable_locales: selectable_locales,         show_available_locales: false       }     )   end end   We have now completed our LiveView implementation, and the application\u2019s final form :tada:! Open up a browser and give it and try, and hopefully you should see or feel no discernable difference between the Javascript takeover version of the application and the LiveView version.   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 04-liveview branch. The branch is also deployed here in its own environment.   Conclusion   So, after all this, was using LiveView to implement locale switching worth it? As a toy application to learn all about and get more of an intuitive feel for LiveView, absolutely! How about a production application? Now that I have spent so much time on this application, chances are the next time I do a LiveView project, development may not take me quite as long, so, maybe! Is it overkill for functionality like locale switching, which will likely be done very rarely? Probably!   Regardless of the actual value of this example application, I think that on my next Phoenix project, where possible, I will very likely be reaching for LiveView first before Javascript, and only resort to the Javascript when I hit the limits of what LiveView is able to do, wherever they happen to be.   Update (18 January 2020)   It was brought to my attention that the application, as it stands, has a bit of an issue. Open up the application in two separate browsers and see if you can spot it.      That\u2019s right: if you change the locale in one browser, then the locale changes for every client that is using the application. If we are using the application at the same time, I really should not be able to control what language you are viewing, and vice versa.   Furthermore, the language dropdown menu itself is not aware of what is going on because it is not listening out for locale-change events; it believes that it is the sole source of locale-change events, and not some other parallel-universe language dropdown menu that is reaching across its barrier and pulling the language rug out from underneath it.   So, what is the cause of this issue?   Static PubSub Channels   Currently, all the LiveView files are broadcasting and subscribing to exactly the same static channels. For example:   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...    @locale_changes "locale-changes"   @dropdown_changes "dropdown-changes"    def mount(%{locale: locale}, socket) do     Endpoint.subscribe(@dropdown_changes)     # ...   end    # ...    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(self(), @locale_changes, "change-locale", %{       locale: locale     })     # ..   end    # ... end   Endpoint.subscribe/1 and Endpoint.broadcast_from/4 are using only the static string channel names defined in the @locale_changes and @dropdown_changes module attributes. Consequently, all clients are subscribing and broadcasting message changes to the same channel, resulting in all the unexpected state sharing issues.   Arbitrary User IDs   This kind of behaviour might be desired in some situations, but for this application, we want PubSub actions to be siloed to specific users: channel names should look something like @locale_changes &lt;&gt; id, where id is some identifier unique to the browser client or user, so that PubSub messages and updates would only apply for that client/user.   In some Phoenix applications, this could take the form of the database ID of a User or Account, but for something as trivial as this application, we do not have a concept of \u201cusers\u201d or \u201caccounts\u201d.   So, in the absence of database-backed users with unique IDs, let\u2019s create the next best thing with the lowest barrier to entry, and arbitrarily assign a unique \u201cuser_id\u201d to each application browser connection. We will need this ID in both the conn and the session to make sure all the application LiveViews can utilise it. So, let\u2019s handle the user_id problem in a similar way to how we handled the locale: generate it in a Plug.   First, tell the router that we will use a UserIdPlug in the browser pipeline:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   use PhxI18nExampleWeb, :router   alias PhxI18nExampleWeb.{LocalePlug, UserIdPlug}    pipeline :browser do     # ...     plug UserIdPlug     plug LocalePlug   end    # ... end   Next define the plug: generate a random ID and assign it to the conn and the session:   lib/phx_i18n_example_web/plugs/user_id_plug.ex   defmodule PhxI18nExampleWeb.UserIdPlug do   alias Plug.Conn   @behaviour Plug    @num_bytes 16    @impl Plug   def init(_opts), do: nil    @impl Plug   def call(conn, _opts) do     random_id = generate_random_id()      conn     |&gt; Conn.assign(:user_id, random_id)     |&gt; Conn.put_session(:user_id, random_id)   end    defp generate_random_id do     @num_bytes     |&gt; :crypto.strong_rand_bytes()     |&gt; Base.encode64()   end end   Then, provide the user_id to the LiveView session:   lib/phx_i18n_example_web/router.ex   defmodule PhxI18nExampleWeb.Router do   # ...    scope "/", PhxI18nExampleWeb do     pipe_through :browser     live "/", PageLive, session: [:locale, :user_id]   end end   The user_id is now available in PageLive via the session, and in the app.html.eex layout via the conn, so we can pass it off to TitleLive and LanguageDropdownLive. Let\u2019s first make sure that the LiveViews rendered from the layout get given a user_id:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt;   &lt;head&gt;     &lt;!-- ... --&gt;     &lt;%= live_render @conn,                     TitleLive,                     session: %{locale: @locale, user_id: @user_id} %&gt;     &lt;!-- ... --&gt;   &lt;/head&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= live_render @conn,                     LanguageDropdownLive,                     session: %{locale: @locale, user_id: @user_id} %&gt;     &lt;!-- ... --&gt;   &lt;/body&gt; &lt;/html&gt;   Now, for each LiveView, add the user_id to the static PubSub channel names, as well as make any other minor adjustments to make everything work:   lib/phx_i18n_example_web/live/title_live.ex   defmodule PhxI18nExampleWeb.TitleLive do   # ...    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, :locale, locale)     {:ok, socket}   end    # ... end   lib/phx_i18n_example_web/live/language_dropdown_live.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLive do   # ...   @locale_changes "locale-changes:"   @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@dropdown_changes &lt;&gt; user_id)     state = init_state(locale, user_id)     socket = assign(socket, state)     {:ok, socket}   end    # ...    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(       self(),       @locale_changes &lt;&gt; socket.assigns.user_id,       "change-locale",       %{locale: locale}     )      state = init_dropdown_state(locale)     socket = assign(socket, state)     {:noreply, socket}   end    defp init_state(locale, user_id) do     Map.merge(       %{user_id: user_id},       init_dropdown_state(locale)     )   end    defp init_dropdown_state(locale) do     selectable_locales = List.delete(@locales, locale)      %{       locale: locale,       selectable_locales: selectable_locales,       show_available_locales: false     }   end end   lib/phx_i18n_example_web/live/page_live.ex   defmodule PhxI18nExampleWeb.PageLive do   # ...    @locale_changes "locale-changes:"   @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, locale: locale, user_id: user_id)     {:ok, socket}   end    def handle_event("hide-dropdown", _value, socket) do     Endpoint.broadcast_from(       self(),       @dropdown_changes &lt;&gt; socket.assigns.user_id,       "hide-dropdown",       %{}     )      {:noreply, socket}   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   Note that user_id is deliberately not passed into the socket in TitleLive, since it is only ever used in mount/2 when setting up its subscriptions, as opposed to the other LiveViews which need the user_id when they send out broadcasts.   Now, when you use the application with multiple browsers, you should see that it works as expected:      You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 05-liveview-fix branch. The branch is also deployed here in its own environment.   Follow the next steps of this application\u2019s journey in Internationalisation with Phoenix LiveComponents!   ',
categories:[],tags:["elixir","phoenix","liveview","i18n","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"https://www.paulfioravanti.com/blog/internationalisation-phoenix-liveview/",teaser:"https://www.paulfioravanti.com/assets/images/2019-11-03/nareeta-martin-vF1YCoLHMpg-unsplash.jpg"},{title:"Employee Sans Office",excerpt:"   I originally wrote this blog post for RemoteBase on   December 15, 2016.  It seems that RemoteBase shut   down in 2018, and since my thoughts on remote working have not changed, I   figure this post can now live on the internet here.    I\u2019m a company employee, but I can\u2019t go to my office, even for a visit. It simply doesn\u2019t exist.   At reinteractive, a digital consultancy, \u201cremote-first\u201d is trumped by \u201cremote-only\u201d: all employees, regardless of their role in the organisation, work remotely.  Our team chat software is the virtual roof that houses us, and it is our primary method of communication, both internally and with our clients.   Before starting at reinteractive, I had worked at other technology companies where very occasional remote work was permitted, but it was generally outside of the norm, and the principal mindsets were that work was done at the workplace.  Now, all my work is done wherever I can use my laptop and get a 4G signal: my physical location is completely detached from the work output I provide.   Remote mindset   Changing to the remote-style of long term full time work did require a transition period for me in order to find a work rhythm that I was comfortable with.   The first issue that I had was how to convince myself that I was \u201cat work\u201d, when I was physically at home.  Previously, getting from a \u201chome\u201d to a \u201cwork\u201d mindset involved lots of different unconscious triggers over a period of time: putting on \u201cworkplace clothes\u201d, physically leaving my home, commuting, entering an office, and seeing and interacting with people that I associate with work.   All that was gone: what I wear is irrelevant, the commute is ten steps to a desk, and at home there\u2019s no one else around.  I had to find a new trigger, and for me this was our team chat software.  When it\u2019s open, and I say \u201cgood morning\u201d to my team, then I\u2019m at work.  When I\u2019m done with work for the day, say \u201cgood night\u201d, and close team chat, then my desk magically stops being for work, and becomes my personal desk.  Doing this every day eventually made it routine, and hence easier to switch between the mindsets as time went by.   Proving you exist   When you\u2019re working with a team or for a client on-site, then you\u2019re assumed to be doing your job by anyone that can physically see you, because otherwise why else would you be there?  When your team only knows you as text/video on a screen, and there is no constant visual feedback for them that tells them you are working, I\u2019ve found that I\u2019ve needed to kick my communication levels into overdrive.  This includes asking lots of questions, raising potential issues early, periodic one-line status updates, and insisting that someone sign-off on the work performed, usually via a project/work tracker.   This last point in particular forces acknowledgement of work being done, and brings a reality to the value it provides.  If you can get to a point where you\u2019re overloading someone with finished work to approve, it can help people overcome any anxiety or trust issues that they may have with wondering if you are actually doing any work because they can\u2019t physically see you doing it.  The worst thing that can happen is to, say, get stuck on a problem all day and not say anything about it because you\u2019re afraid of being the barer of bad news.  If you\u2019re feeling pain, your team/client should also feel it, and I\u2019ve found that concrete pain is far more manageable than uncertainty.   Keeping up appearances   Although I love the freedom to be able to work where I please, and to be able to focus on tasks without the distractions that an office environment can cause, I still really like face-to-face interactions.  After a certain period of time working from home, I can start to really crave just talking to people, anyone, face-to-face (we are social animals, after all).  Meetups have really helped me fulfil this need, both professionally and personally, and have been great catalysts to be able to just get out of the house and get a change of scenery.   Just for tech?   I\u2019m a software engineer and hence my line of work is generally very compatible with remote working, but I don\u2019t think it should be limited there. There are plenty of knowledge workers in non-technical fields who could potentially work remotely, and the barriers to giving it a try are lower than they\u2019ve ever been.  A great resource on getting further information about remote work, and arming yourself with great reasons to give it a try to your bosses, is Remote: Office not Required, by Jason Fried and David Heinemeier Hansson.   So, if remote is something that you, as an employee, want to explore further with your company, I\u2019d highly encourage you to trail blaze a path for yourself and your colleagues.  I think that any roadblocks incurred along the way will be worth the satisfaction that you will get by gaining more freedom around one of the most important activities in your life.   ",categories:[],tags:["remote-working"],url:"https://www.paulfioravanti.com/blog/employee-sans-office/",teaser:"https://www.paulfioravanti.com/assets/images/2020-01-08/allie-smith-vuWCq1bXZy0-unsplash.jpg"},{title:"Internationalisation with Phoenix LiveComponents",
excerpt:'This blog post is the second in a series on the creation of a small I18n application using Phoenix LiveView, which updates page content based on the language chosen from a dropdown menu:      Internationalisation with Phoenix LiveView   Internationalisation with Phoenix LiveComponents   Internationalisation with Phoenix Live Layouts      Development on LiveView is currently proceeding at a cracking pace, and one of the newer additions to it is the ability to \u201ccompartmentalize state, markup, and events in LiveView\u201d using LiveComponent. So, let\u2019s introduce LiveComponents to the application, and see what effect it has on the codebase.      The software versions used for this version of the application have changed slightly, and are now the following:          Elixir: 1.9.4     Erlang: 22.2.1     Phoenix: 1.4.11     Gettext: 0.17.4     LiveView: 0.4.1     Node: 13.6.0     Tachyons: 4.11.1      Current State of Play   We are going to pick the application up where we left off from the end of Internationalisation with Phoenix LiveView, which is its state on the 05-liveview-fix branch of the phx_i18n_example Github repository. So, if you do not have the repository already, just run these commands and the internet shall provide it to you:   git clone git@github.com:paulfioravanti/phx_i18n_example.git cd phx_i18n_example git checkout 05-liveview-fix   Housekeeping   Upgrading dependencies   Before beginning, we will need to upgrade the version of LiveView being used in the application from 0.3.1 to 0.4.1:   mix.exs   defmodule PhxI18nExample.MixProject do   # ...   defp deps do     [       # ...       {:phoenix_live_view, "~&gt; 0.4.1"},       # ...     ]   end end   Then, upgrade the Elixir dependencies with mix:   mix deps.upgrade --all   Updating Javascript asset dependencies should not be an issue for introducing LiveComponents, but if you do find you have front end issues, or you just need to have all the latest packages all the time, then by all means, check what\u2019s outdated and update to your heart\u2019s content:   npm outdated --prefix assets   Enabling LiveComponent Functions   In order to use LiveComponents from LiveViews, we are going to need access to the Phoenix.LiveView.Helpers.live_component/4 function (and its lower arity cousins), so add it to the list of LiveView-related imports:   lib/phx_i18n_example_web.ex   defmodule PhxI18nExampleWeb do   # ...   def view do     quote do       # ...       import Phoenix.LiveView,         only: [           live_render: 2,           live_render: 3,           live_link: 1,           live_link: 2,           live_component: 2,           live_component: 3,           live_component: 4         ]     end   end   # ... end   File Structure and Naming Changes   It would seem that there has been an informal(?) convention to name LiveView files with a pattern of FooLive and BarLive, and place them inside a directory called live/ directly under the Phoenix application web/ directory. The application currently follows this convention.   However, with the advent of LiveComponents, we now have more than one type of \u201cLiveThing\u201d, with the likely potential for more \u201cLiveThings\u201d in the future. So, in the absence of any set conventions, we shall:      Move all LiveView files under a new live/views/ directory   Re-name all LiveView files from FooLive to FooLiveView, and change all of their references throughout the application (specifically, do search and replaces for TitleLive -&gt; TitleLiveView, LanguageDropdownLive -&gt; LanguageDropdownLiveView, and PageLive -&gt; PageLiveView)   Create an empty live/components/ directory to store LiveComponent files   Once you have done that, check to see that the application still runs without error, and you will be ready to start the actual fun component-y stuff!   LiveComponent Flavours   There are two different officially-named types of LiveComponents: Stateless and Stateful.   Personally, I find this naming quite confusing as both types of component do hold some kind of state, and the difference would seem to lie rather in the degree of independence that the LiveComponent has from its parent LiveView in updating its state, handling messages etc:      Stateless, in diapers, is completely dependent on its parent for any changes   Stateful is moved out of home, doing most things independently, but occasionally needs help from its parent for things it cannot do   Anyway, regardless of my opinions about the current naming, use of shared language is important to convey information coherently, so Stateless and Stateful it is.   Update to Stateless Component   Let\u2019s first update the LiveViews to Stateless Components, starting with the one that has the least amount of logic in it: the TitleLiveView.   It is currently responsible for:      Setting up a subscription to locale-change messages, so it knows when it should change languages, and then handling those locale-change events   Keeping track of the locale in its socket   Rendering a LiveView template, in this case inline   At present, the code looks like this:   lib/phx_i18n_example_web/live/views/title_live_view.ex   defmodule PhxI18nExampleWeb.TitleLiveView do   use Phoenix.LiveView   import PhxI18nExampleWeb.Gettext, only: [gettext: 1]   import Gettext, only: [with_locale: 2]   alias PhxI18nExampleWeb.Endpoint    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, :locale, locale)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= with_locale(@locale, fn -&gt; %&gt;       &lt;title&gt;         &lt;%= gettext("Multilingualisation in Phoenix") %&gt;       &lt;/title&gt;     &lt;% end) %&gt;     """   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   In introducing a stateless component, we are not interested in giving the component very much agency or responsibility: we just want to offload view-related functionality to it, and have it render the inline template. So, let\u2019s extract out some code into our first new LiveComponent!   lib/phx_i18n_example_web/live/components/title_live_component.ex   defmodule PhxI18nExampleWeb.TitleLiveComponent do   use Phoenix.LiveComponent   import PhxI18nExampleWeb.Gettext, only: [gettext: 1]   import Gettext, only: [with_locale: 2]    def render(assigns) do     ~L"""     &lt;%= with_locale(@locale, fn -&gt; %&gt;       &lt;title&gt;         &lt;%= gettext("Multilingualisation in Phoenix") %&gt;       &lt;/title&gt;     &lt;% end) %&gt;     """   end end   Not much to it, is there? Every component does actually require a mount/1 and an update/2 function, but LiveComponent provides default implementations of those functions that look something like this:   def mount(socket) do   {:ok, socket} end  def update(assigns, socket) do   {:ok, assign(socket, assigns)} end   If any finer-grained control over mounting and updating is needed, these functions would need to be overridden, but for this LiveComponent, the defaults work just fine.   Back in TitleLiveView, we make a call out to live_component to spawn off the child LiveComponent:   lib/phx_i18n_example_web/live/views/title_live_view.ex   defmodule PhxI18nExampleWeb.TitleLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, TitleLiveComponent}    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, :locale, locale)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket, TitleLiveComponent, locale: @locale %&gt;     """   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   A Quick Detour   A few things initially confused me as I was implementing this.   I thought that because the locale had already been assigned to the socket belonging to TitleLiveView in mount/2, it would flow through automatically to the @socket that gets passed into the live_component function. This is because if you inspect the @socket in the render/1 function like so:   def render(assigns) do   ~L"""   &lt;% IO.inspect(@socket) %&gt;   &lt;%= live_component @socket, TitleLiveComponent, locale: @locale %&gt;   """ end   The output you get is:   #Phoenix.LiveView.Socket&lt;   assigns: %{locale: "en", user_id: "mlZvNkbr/5DxyM9hq2TS0w=="},   changed: %{locale: true, user_id: true},   endpoint: PhxI18nExampleWeb.Endpoint,   id: "phx-VwPm6nt2",   parent_pid: nil,   view: PhxI18nExampleWeb.PageLiveView,   ... &gt;   So, I would have thought that the assigns would carry through to the socket in TitleLiveComponent, but when I overrode the mount/1 function there to inspect the state of the socket like so:   def mount(socket) do   IO.inspect(socket)   {:ok, socket} end   The output was:   #Phoenix.LiveView.Socket&lt;   assigns: %{},   changed: %{locale: true, user_id: true},   endpoint: PhxI18nExampleWeb.Endpoint,   id: "phx-VwPm6nt2",   parent_pid: nil,   view: PhxI18nExampleWeb.PageLiveView,   ... &gt;   The information in the assigns disappears\u2026? But the socket id ("phx-VwPm6nt2" in this case) is the same in the LiveView and the LiveComponent! What happened here?  This is when a part of the live_component documentation finally clicked:      \u201cA LiveComponent provides similar functionality to LiveView, except   they run in the same process as the LiveView, with its own encapsulated state\u201d    So, if my understanding is correct, the id for the socket is the same since it is the same process, but the assigns states of the LiveView and LiveComponent are isolated from each other, and we essentially get a \u201cblank slate\u201d socket assigns in the LiveComponent.   The assigns values we pass in to the live_component function (in this case locale: @locale), become available to us in update/2 (which the parent LiveView will call during the initialisation process), where we can then assign them to the LiveComponent socket.   Finishing Up Stateless   Now that we have cleared up some LiveComponent socket-related gotchas, let\u2019s finish up porting over the remaining two LiveViews to use Stateless components. The way we will do this will be very similar to TitleLiveView, with the content in the render/1 functions being extracted out into LiveComponents:   LanguageDropdownLiveView   lib/phx_i18n_example_web/live/views/language_dropdown_live_view.ex   Before:   defmodule PhxI18nExampleWeb.LanguageDropdownLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownView}    # ...   def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end   # ... end   After:   defmodule PhxI18nExampleWeb.LanguageDropdownLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownLiveComponent}    # ...   def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        LanguageDropdownLiveComponent,                        locale: @locale,                        selectable_locales: @selectable_locales,                        show_available_locales: @show_available_locales %&gt;     """   end   # ... end   lib/phx_i18n_example_web/live/components/language_dropdown_live_component.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.LanguageDropdownView    def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end end   PageLiveView   lib/phx_i18n_example_web/live/views/page_live_view.ex   Before:   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageView}    # ...   def render(assigns) do     PageView.render("index.html", assigns)   end   # ... end   After:   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageLiveComponent}    # ...   def render(assigns) do     ~L"""     &lt;%= live_component @socket, PageLiveComponent, locale: @locale %&gt;     """   end   # ... end   lib/phx_i18n_example_web/live/components/page_live_component.ex   defmodule PhxI18nExampleWeb.PageLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.PageView    def render(assigns) do     PageView.render("index.html", assigns)   end end   And that\u2019s it! The application is now using Stateless LiveComponents!   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 06-live-stateless branch. The branch is also deployed here in its own environment.   Optional Refactor   Before we move on to stateful components, I would just like to bring up that if you do not like to have inline LiveView templates (aka Live Embedded Elixir (leex), ie ~L""" code) in any of your LiveViews, then it is possible to refactor them out completely into separate files. For example, in PageLiveView, our render/1 function looks like:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   # ...   def render(assigns) do     ~L"""     &lt;%= live_component @socket, PageLiveComponent, locale: @locale %&gt;     """   end   # ... end   Rather than have this inline template, we could refactor this into something like the following:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageLiveViewView}    # ...   def render(assigns) do     PageLiveViewView.render("component.html", assigns)   end   # ... end   And then create a new view and template to call the component:   lib/phx_i18n_example_web/views/page_live_view_view.ex   defmodule PhxI18nExampleWeb.PageLiveViewView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.PageLiveComponent end   lib/phx_i18n_example_web/templates/page_live_view/component.html.leex   &lt;%= live_component @socket, PageLiveComponent, locale: @locale %&gt;   This refactor works, but, to me at least, it just feels awkward to have such few lines of code spread out over multiple files, not to mention the even more awkward PageLiveViewView naming.   I do like having longer templates in their own file, with their own dedicated view file, but for a live_component one-liner like this, I think inline is fine. But, your mileage may vary, and by all means use your best judgement to determine if this kind of refactor is to your benefit or liking.   Update to Stateful Components   Now, we will move on to giving our LiveComponents more responsibility for managing their own state, by making them Stateful Components. Like before, let\u2019s start with the least complex LiveView/LiveComponent set for the page title. Here is the finished product:   lib/phx_i18n_example_web/live/views/title_live_view.ex   defmodule PhxI18nExampleWeb.TitleLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, TitleLiveComponent}    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, :locale, locale)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        TitleLiveComponent,                        id: :title,                        locale: @locale %&gt;     """   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   No, your eyes do not deceive you: literally the only change from before has been the addition of the id: title keyword argument in the live_component function call. No changes to TitleLiveComponent were necessary. And now it is stateful.   If you are thinking that this does not really represent a change in responsibilities of the TitleLiveComponent, you would be absolutely correct.   Although I would very much like to allow the TitleLiveComponent to receive and handle "change-locale" messages, \u201ccomponents do not have a handle_info/2 callback\u201d, and so this is one of the areas where a stateful LiveComponent must depend on its parent.   Technically, we could have moved the Endpoint.subscribe/1 function call into the LiveComponent, and it would have worked, but I think the demarcation lines of responsibility are clearer if we say that the parent LiveView is entirely responsible for handling external PubSub communication.   Therefore, for this particular LiveView/LiveComponent set, there is probably not much value in making it Stateful.   Moving on   So, that was rather anti-climactic. Let\u2019s move on to the PageLiveView where we will hopefully have more luck with making at least some consequential changes.  Currently, it looks like:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageLiveComponent}    @locale_changes "locale-changes:"   @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, locale: locale, user_id: user_id)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket, PageLiveComponent, locale: @locale %&gt;     """   end    def handle_event("hide-dropdown", _value, socket) do     Endpoint.broadcast_from(       self(),       @dropdown_changes &lt;&gt; socket.assigns.user_id,       "hide-dropdown",       %{}     )      {:noreply, socket}   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     socket = assign(socket, :locale, payload.locale)     {:noreply, socket}   end end   Like TitleLiveView, there is some external PubSub message handling here around "change-locale" events that we need to leave in the parent LiveView, but handling "hide-dropdown" events is definitely something that a LiveComponent can perform, so let\u2019s extract the handle_event/3 code out to PageLiveComponent:   lib/phx_i18n_example_web/live/components/page_live_component.ex   defmodule PhxI18nExampleWeb.PageLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.{Endpoint, PageView}    @dropdown_changes "dropdown-changes:"    def render(assigns) do     PageView.render("index.html", assigns)   end    def handle_event("hide-dropdown", _value, socket) do     Endpoint.broadcast_from(       self(),       @dropdown_changes &lt;&gt; socket.assigns.user_id,       "hide-dropdown",       %{}     )      {:noreply, socket}   end end   Great! The LiveComponent is now broadcasting out "hide-dropdown" messages if it, itself, receives a "hide-dropdown" event. This extraction leaves the parent LiveView with slightly less code, and one less thing to worry about:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, PageLiveComponent}    @locale_changes "locale-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)     socket = assign(socket, locale: locale, user_id: user_id)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        PageLiveComponent,                        id: :page,                        locale: @locale,                        user_id: @user_id %&gt;     """   end    def handle_info(%{event: "change-locale", payload: payload}, socket) do     send_update(PageLiveComponent, id: :page, locale: payload.locale)     {:noreply, socket}   end end   Note that as opposed to the TitleLiveView, in which we only passed the @locale parameter into the call to live_component, in the PageLiveView, we are also passing through the @user_id, since PageLiveComponent needs it to perform the "hide-dropdown" broadcasts. Parent LiveViews can keep a tight leash on what information child LiveComponents need to know about.   Filial Piety   We have been taking baby-steps towards LiveComponent independence, but now it\u2019s time to take a bigger step: let\u2019s move on to the busiest LiveView in the application, LanguageDropdownLiveView, and see how much we can lighten its load. Currently, it does quite a lot:   lib/phx_i18n_example_web/live/views/language_dropdown_live_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownLiveComponent}    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_changes "locale-changes:"   @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@dropdown_changes &lt;&gt; user_id)     state = init_state(locale, user_id)     socket = assign(socket, state)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        LanguageDropdownLiveComponent,                        locale: @locale,                        selectable_locales: @selectable_locales,                        show_available_locales: @show_available_locales %&gt;     """   end    def handle_event("hide", _value, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    def handle_event("toggle", _value, socket) do     socket =       assign(         socket,         :show_available_locales,         !socket.assigns.show_available_locales       )      {:noreply, socket}   end    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(       self(),       @locale_changes &lt;&gt; socket.assigns.user_id,       "change-locale",       %{locale: locale}     )      state = init_dropdown_state(locale)     socket = assign(socket, state)     {:noreply, socket}   end    def handle_info(%{event: "hide-dropdown"}, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    defp init_state(locale, user_id) do     Map.merge(       %{user_id: user_id},       init_dropdown_state(locale)     )   end    defp init_dropdown_state(locale) do     selectable_locales = List.delete(@locales, locale)      %{       locale: locale,       selectable_locales: selectable_locales,       show_available_locales: false     }   end end   Like the other LiveViews, there is external PubSub communication that we must keep as-is, but I would say every other function can be shipped out wholesale to LanguageDropdownLiveComponent, lightening LanguageDropdownLiveView\u2019s load considerably:   lib/phx_i18n_example_web/live/views/language_dropdown_live_view.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveView do   use Phoenix.LiveView   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownLiveComponent}    @dropdown_changes "dropdown-changes:"    def mount(%{locale: locale, user_id: user_id}, socket) do     Endpoint.subscribe(@dropdown_changes &lt;&gt; user_id)     socket = assign(socket, locale: locale, user_id: user_id)     {:ok, socket}   end    def render(assigns) do     ~L"""     &lt;%= live_component @socket,                        LanguageDropdownLiveComponent,                        id: :language_dropdown,                        locale: @locale,                        user_id: @user_id %&gt;     """   end    def handle_info(%{event: "hide-dropdown"}, socket) do     send_update(       LanguageDropdownLiveComponent,       id: :language_dropdown,       show_available_locales: false     )      {:noreply, socket}   end end   It now does not need to worry about setting up internal state for the dropdown menu, nor handle any of its events. It does still continue to handle external PubSub messages, but it completely delegates responsibility of what action should be performed to LanguageDropdownLiveComponent via the send_update/2 function.   So, let\u2019s see where all that logic has gone:   lib/phx_i18n_example_web/live/components/language_dropdown_live_component.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.{Endpoint, LanguageDropdownView}    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)   @locale_changes "locale-changes:"    def update(%{locale: locale} = assigns, socket) do     state = Map.merge(assigns, init_dropdown_state(locale))     socket = assign(socket, state)     {:ok, socket}   end    def update(%{show_available_locales: false}, socket) do     socket = assign(socket, :show_available_locales, false)     {:ok, socket}   end    def render(assigns) do     LanguageDropdownView.render("language_dropdown.html", assigns)   end    def handle_event("hide", _value, socket) do     socket = assign(socket, :show_available_locales, false)     {:noreply, socket}   end    def handle_event("toggle", _value, socket) do     socket =       assign(         socket,         :show_available_locales,         !socket.assigns.show_available_locales       )      {:noreply, socket}   end    def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     Endpoint.broadcast_from(       self(),       @locale_changes &lt;&gt; socket.assigns.user_id,       "change-locale",       %{locale: locale}     )      state = update_locale_changed_state(socket.assigns, locale)     socket = assign(socket, state)     {:noreply, socket}   end    defp update_locale_changed_state(assigns, locale) do     assigns     |&gt; Map.merge(%{locale: locale})     |&gt; Map.merge(init_dropdown_state(locale))   end    defp init_dropdown_state(locale) do     selectable_locales = List.delete(@locales, locale)      %{       selectable_locales: selectable_locales,       show_available_locales: false     }   end end   The LiveComponent now has responsibilities over:      Manually handling updating its state by overriding the update/2 function, since the LiveComponent default implementation does not cut it any more   Handling the two different flavours of update that the component needs to know about (via the update function heads), which are:            when the locale is updated, upon which it needs to re-initialise its state (which, by the by, the parent LiveView does not need to know anything about)       when show_available_locales is explicitly set to false (ie from when LanguageDropdownLiveView calls send_update/2), at which point the menu needs to be hidden           Handling all its local events   Broadcasting "change-locale" messages when it gets a "locale-changed" message   Easily the most independent of the three LiveComponents in the application.   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 07-live-stateful branch. The branch is also deployed here in its own environment.   Stateless or Stateful?   In this application, I think the benefits of using Stateless versus Stateful LiveComponents are largely subjective, and really depend on personal preferences about how to divide up logic between LiveViews and LiveComponents.   If you have an application that has more moving parts and complexity, like fetching from a database to populate multiple LiveComponents on a page, in which you may need to consider preloading using preload/1 (not covered in this blog post), then the decision to specifically use Stateful components may become clearer.   Regardless of your preferred flavour of LiveComponent, I think they are a welcome addition to the Phoenix\u2019s Live Toolbox, and I\u2019m sure I will be making more use of them in the future.   Update (29-01-2020)   Well, the cracking pace of development on new libraries like LiveView can mean that even minor version changes can result in having the rug pulled out from under you, and this application is no exception.   On updating the application to LiveView version 0.6.0, everything stopped working, and my LiveComponents mysteriously stopped handling events.   If you are following along, here is the diff between the 07-live-stateful branch you have already seen, and a new 08-live-stateful-0-6 branch, all updated and working with LiveView 0.6.0 (with a couple of small refactors).   It is not worth going into the deep details of how to upgrade, since I think the diff, as well as the LiveView 0.6 Installation instructions and the Changelog, provide enough information, but I will outline a few points:      The socket session now accepts only string keys. This affected code in Plugs as well as LiveViews. It does seem a bit strange now to have Conn.assign(:locale, locale) with an atom key, and Conn.put_session("locale", locale) with a string key   I think it\u2019s great that any session variables set in plugs are available automatically in LiveViews now, without having to explicitly indicate a set of session keys in the route. (eg live "/", PageLiveView, session: [:locale, :user_id]). You could explicitly override values here using a map, though, if you wanted to (eg live "/", PageLiveView, session: %{"locale" =&gt; "en"})   Targeting Component Events is where the Stateful LiveComponent trip ups occurred. With 0.6.0, if template code managed by a LiveComponent does not have a phx-target attribute, then the LiveComponent\u2019s handle_event/3 function that previously may have worked will now not pick up the event, and instead event handling will go straight to the parent LiveView. In this case, I got an error complaining that I did not have handle_event/3 implementations in the LiveView to handle the events that it was receiving. See the Targeting Component Events documentation and the .eex/.leex template files in the diff for details on getting your Stateful LiveComponents back on the job of handling events   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 08-live-stateful-0-6 branch. The branch is also deployed here in its own environment.   Follow the next steps of this application\u2019s journey in Internationalisation with Phoenix Live Layouts!   ',categories:[],tags:["elixir","phoenix","liveview","live-components","i18n","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"https://www.paulfioravanti.com/blog/internationalisation-phoenix-live-components/",teaser:"https://www.paulfioravanti.com/assets/images/2020-01-27/jason-leung-jCBzW_Q_UGI-unsplash.jpg"},{title:"Internationalisation with Phoenix Live Layouts",
excerpt:'This blog post is the third in a series on the creation of a small I18n application using Phoenix LiveView, which updates page content based on the language chosen from a dropdown menu:      Internationalisation with Phoenix LiveView   Internationalisation with Phoenix LiveComponents   Internationalisation with Phoenix Live Layouts      LiveView version 0.5.0 introduced Live Layouts, a mechanism that allows LiveViews to move view-specific layout code into separate sub-layout files. This enables an individual LiveView\u2019s template to nest itself within content that can dynamically update.   We will continue developing the application where we left off from the end of Internationalisation with Phoenix LiveComponents, which is its state on the 08-live-stateful-0-6 branch of the phx_i18n_example Github repository. That branch does not use Live Layouts, so we will see what the issues are with not using them, and then proceed to implement them.   If you do not have the repository already, just run these commands and it shall find its way to you:   git clone git@github.com:paulfioravanti/phx_i18n_example.git cd phx_i18n_example git checkout 08-live-stateful-0-6      The software versions used for this version of the application are the following:          Elixir: 1.10.0     Erlang: 22.2.1     Phoenix: 1.4.12     Gettext: 0.17.4     LiveView: 0.6.0     Node: 13.6.0     Tachyons: 4.11.1      Current State of Play   There are three LiveViews in the application, each operating independently, containing their own LiveComponent, and communicating with each other by PubSub where needed:      LanguageDropdownLiveView and TitleLiveView are live rendered from the (static) layout:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt;   &lt;head&gt;     &lt;!-- ... --&gt;     &lt;%= live_render @conn,                     TitleLiveView,                     session: %{"locale" =&gt; @locale, "user_id" =&gt; @user_id} %&gt;     &lt;!-- ... --&gt;   &lt;/head&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= live_render @conn,                     LanguageDropdownLiveView,                     session: %{"locale" =&gt; @locale, "user_id" =&gt; @user_id} %&gt;     &lt;main role="main"&gt;       &lt;%= render @view_module, @view_template, assigns %&gt;     &lt;/main&gt;   &lt;/body&gt; &lt;/html&gt;   The Problem   For the application in its current form, this presents no issue. However, what if we wanted to add another routed LiveView (a LiveView used from router.ex) to the application to complement PageLiveView? What if we wanted to have this new LiveView set its own page title, or what if its content did not need to be internationalised, and hence we would not need the language dropdown menu to display?   The app.html.eex file is the main layout template within which all other template content is embedded, which means that any new LiveView would not have any control over the content that surrounds its template code:      its title would be set according to whatever TitleLiveView renders, rather than being able to provide its own page title logic   LanguageDropdownLiveView will always be rendered (meaning also that the new LiveView would have to unnecessarily implement handlers for the "change-locale" events that the dropdown menu emits)   So, let\u2019s set about giving our routed LiveView, in this case PageLiveView, more control over its surrounding content, starting with the page title.   LiveView-Controlled Page Title Updates   With LiveView 0.5.0, updating the HTML document title of a page becomes possible through specific use of an assigns variable called @page_title. Normally, the content of app.html.eex, or any non-.leex template, cannot be dynamically changed. But, Phoenix LiveView special-cases the page title, enabling a LiveView module to set the page title in Phoenix.LiveView.mount/3, and update it in any event handling callback functions.   So, in the layout, let\u2019s switch out TitleLiveView for @page_title:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt;   &lt;head&gt;     &lt;!-- ... --&gt;      &lt;title&gt;&lt;%= @page_title %&gt;&lt;/title&gt;     &lt;!-- ... --&gt;   &lt;/head&gt;   &lt;!-- ... --&gt; &lt;/html&gt; &lt;!DOCTYPE html&gt;   Now, in PageLiveView, let\u2019s initialise the page_title assigns in mount/3, and update its value when the locale changes (ie we receive an external "change-locale" PubSub message):   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   # ...   require Gettext   require PhxI18nExampleWeb.Gettext    @title "Multilingualisation in Phoenix"   @locale_changes "locale-changes:"    def mount(         %{} = _params,         %{"locale" =&gt; locale, "user_id" =&gt; user_id},         socket       ) do     Endpoint.subscribe(@locale_changes &lt;&gt; user_id)      socket =       assign(         socket,         locale: locale,         user_id: user_id,         page_title: page_title(locale)       )      {:ok, socket}   end    # ...    def handle_info(         %{event: "change-locale", payload: %{locale: locale}},         socket       ) do     send_update(PageLiveComponent, id: :page, locale: locale)     socket = assign(socket, locale: locale, page_title: page_title(locale))     {:noreply, socket}   end    defp page_title(locale), do: Gettext.with_locale(locale, &amp;title/0)   defp title, do: PhxI18nExampleWeb.Gettext.gettext(@title) end   You should now see that the application continues to work as expected.   Just by virtue of setting and updating the page_title assigns value, Phoenix does all the heavy lifting of dynamically updating the @page_title module attribute. PageLiveView now has complete control over the page title when its template is rendered, which means the TitleLiveView and TitleLiveComponent modules have become completely obsolete. So, we can reduce our maintenance burden by removing them entirely. Hurray!   Live Layouts   Let\u2019s now move our focus over to enabling LiveViews to choose whether they want to display a language selection dropdown menu or not, by extracting code for it into a separate layout.   We will start by removing the call to live render the LanguageDropdownLiveView from the main layout\u2019s &lt;body&gt; tag:   lib/phx_i18n_example_web/templates/layout/app.html.eex   &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt;   &lt;!-- ... --&gt;   &lt;body class="&lt;%= body() %&gt;"&gt;     &lt;%= render @view_module, @view_template, assigns %&gt;   &lt;/body&gt; &lt;/html&gt;   That code will now go directly inside a new page Live Layout file (note the .leex filename):   lib/phx_i18n_example_web/templates/layout/page.html.leex   &lt;%= live_render @socket,                 LanguageDropdownLiveView,                 id: :language_dropdown,                 session: %{"locale" =&gt; @locale, "user_id" =&gt; @user_id} %&gt; &lt;main role="main"&gt;   &lt;%= @live_view_module.render(assigns) %&gt; &lt;/main&gt;   In this case, the @live_view_module attribute refers to the PageLiveView module.   Now, we need to specify that PageLiveView will be using this layout to wrap its template content:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   alias PhxI18nExampleWeb.{Endpoint, LayoutView, PageLiveComponent}   use Phoenix.LiveView, layout: {LayoutView, "page.html"}   # ... end   Note that the LayoutView is doing double-duty here as the view file for both app.html.eex and page.html.leex. If we were to extract the template code inline with the view code, it would look like this (also note the differences in sigils used; ~E for standard embedded Elixir templates vs ~L for LiveView templates):   lib/phx_i18n_example_web/views/layout_view.ex   defmodule PhxI18nExampleWeb.LayoutView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.{LanguageDropdownLiveView, LayoutStyle}    defdelegate body, to: LayoutStyle    def render("app.html", assigns) do     ~E"""     &lt;!DOCTYPE html&gt;     &lt;html lang="en"&gt;       &lt;head&gt;         &lt;meta charset="utf-8"/&gt;         &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"/&gt;         &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"/&gt;         &lt;%= csrf_meta_tag() %&gt;         &lt;title&gt;&lt;%= @page_title %&gt;&lt;/title&gt;         &lt;link rel="stylesheet"               href="&lt;%= Routes.static_path(@conn, "/css/app.css") %&gt;"/&gt;         &lt;script type="text/javascript"                 src="&lt;%= Routes.static_path(@conn, "/js/app.js") %&gt;"&gt;         &lt;/script&gt;       &lt;/head&gt;       &lt;body class="&lt;%= body() %&gt;"&gt;         &lt;%= render @view_module, @view_template, assigns %&gt;       &lt;/body&gt;     &lt;/html&gt;     """   end    def render("page.html", assigns) do     ~L"""     &lt;%= live_render @socket,                     LanguageDropdownLiveView,                     id: :language_dropdown,                     session: %{"locale" =&gt; @locale, "user_id" =&gt; @user_id} %&gt;     &lt;main role="main"&gt;       &lt;%= @live_view_module.render(assigns) %&gt;     &lt;/main&gt;     """   end end   The layout code extraction is now complete, and the application works as expected! Or, at least I thought it did, until I tried out the specific use case of opening the language dropdown menu, and then clicking the text on the page, which closes it:      Looks like there is a glitch in the LiveView Matrix\u2026 Why is the open language dropdown menu disappearing momentarily before re-appearing closed? Ultimately, all we did was cut code from one file, and paste it in another\u2026right?   Although I\u2019m not entirely sure of the specifics, it looks like perhaps the communication processes via PubSub between PageLiveView and DropdownLanguageLiveView are clobbering each other, and thus a re-think of how these two LiveViews and their LiveComponents talk to each other is in order, as well as deciding whether all these LiveView modules are even needed at all.   Too Many LiveViews?   Each of the LiveViews we had in the application at the beginning of this blog post, PageLiveView, LanguageDropdownLiveView, and TitleLiveView, were like isolated islands, functionality-wise.      There was no coupling between any of them; naturally, there was coupling between parent LiveViews and their child LiveComponents, but not between the LiveViews themselves.   With the introduction of Live Layouts, this has changed: now, PageLiveView, as well as being the parent of its own PageLiveComponent, is also, via the Live Layout, the parent of LanguageDropdownLiveView, which renders LanguageDropdownLiveComponent.      With TitleLiveView gone, the only place that LanguageDropdownLiveComponent needs to notify about locale changes is the PageLiveView, its \u201cgrandparent\u201d. Similarly, LanguageDropdownLiveView would only seem to exist to let its child, LanguageDropdownLiveComponent, know about any "hide-dropdown" messages that it receives.   Given that the "hide-dropdown" messages come from PageLiveComponent, wouldn\u2019t it be easier, and maybe less message-clobbery, to:      get rid of the LanguageDropdownLiveView middleman   let LanguageDropdownLiveComponent be PageLiveView\u2019s child, rather than grandchild   have PageLiveComponent and LanguageDropdownLiveComponent talk to each other as siblings through PageLiveView?   Let\u2019s find out!   Family Tree Engineering   Okay, first thing\u2019s first, LanguageDropdownLiveView is now gone. What do we need to do to get this working again? Let\u2019s start with PageLiveView\u2019s Live Layout, which now needs to directly render LanguageDropdownLiveComponent:   lib/phx_i18n_example_web/views/layout_view.ex   defmodule PhxI18nExampleWeb.LayoutView do   use PhxI18nExampleWeb, :view   alias PhxI18nExampleWeb.{LanguageDropdownLiveComponent, LayoutStyle}   # ... end   lib/phx_i18n_example_web/templates/layout/page.html.leex   &lt;%= live_component @socket,                    LanguageDropdownLiveComponent,                    id: :language_dropdown,                    locale: @locale,                    user_id: @user_id %&gt; &lt;main role="main"&gt;   &lt;%= @live_view_module.render(assigns) %&gt; &lt;/main&gt;   Now, in the LanguageDropdownLiveComponent, whenever we get a local "locale-changed" event, rather than blast out a PubSub message, we instead want to send that message to the now-direct parent, PageLiveView:   lib/phx_i18n_example_web/live/components/language_dropdown_live_component.ex   defmodule PhxI18nExampleWeb.LanguageDropdownLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.LanguageDropdownView    @locales Gettext.known_locales(PhxI18nExampleWeb.Gettext)    # ...   def handle_event("locale-changed", %{"locale" =&gt; locale}, socket) do     send(self(), {:change_locale, locale})      state = update_locale_changed_state(socket.assigns, locale)     socket = assign(socket, state)     {:noreply, socket}   end   # ... end   Note here that because the LiveComponent and the LiveView run in the same process, sending a message to self() sends the message from the component to the parent LiveView.   While we are purging PubSub message passing, let\u2019s go next to PageLiveView\u2019s other child, PageLiveComponent, and perform a similar refactor for when it receives "hide-dropdown" messages:   lib/phx_i18n_example_web/live/components/page_live_component.ex   defmodule PhxI18nExampleWeb.PageLiveComponent do   use Phoenix.LiveComponent   alias PhxI18nExampleWeb.PageView    # ...   def handle_event("hide-dropdown", _value, socket) do     send(self(), :hide_dropdown)      {:noreply, socket}   end end   All message-passing from child LiveComponents to parent LiveViews is now being done without PubSub. Finally, we need to make changes in the parent PageLiveView to swap any PubSub-related subscription and message-handling code for taking messages directly from children:   lib/phx_i18n_example_web/live/views/page_live_view.ex   defmodule PhxI18nExampleWeb.PageLiveView do   alias PhxI18nExampleWeb.{     LanguageDropdownLiveComponent,     LayoutView,     PageLiveComponent   }    # ...   def mount(         %{} = _params,         %{"locale" =&gt; locale, "user_id" =&gt; user_id},         socket       ) do     socket =       assign(         socket,         locale: locale,         user_id: user_id,         page_title: page_title(locale)       )      {:ok, socket}   end    # ...    def handle_info(:hide_dropdown, socket) do     send_update(       LanguageDropdownLiveComponent,       id: :language_dropdown,       show_available_locales: false     )      {:noreply, socket}   end    def handle_info({:change_locale, locale}, socket) do     send_update(PageLiveComponent, id: :page, locale: locale)     socket = assign(socket, locale: locale, page_title: page_title(locale))     {:noreply, socket}   end   # ... end   Notice that in the handle_info/2 functions, the parameters are now atoms or tuples, and not the maps (eg %{event: "change-locale", payload: %{locale: locale}}) that we had before.   The application should now be flicker-less when hiding an open dropdown by clicking the page.   You can find the code for this iteration of the application in this post\u2019s companion Github repo on the 09-live-layout branch. The branch is also deployed here in its own environment.   Wrapping Up   The use of Live Layouts, even in this small application, has affected its architecture greatly. It has been interesting, at least for myself as the author, to have seen the codebase expand initially with lots of LiveViews and LiveComponents, and now contract back as we purge half of them away.   Deleted code is the easiest kind to maintain, though, so I do not mourn for it. Rather, I think it\u2019s great that Live Layouts have enabled more flexibility in architecting LiveView functionality, and I look forward to using them more moving forward!   ',categories:[],tags:["elixir","phoenix","liveview","live-components","live-layout","i18n","japanese","italian","\u65e5\u672c\u8a9e","italiano"],url:"https://www.paulfioravanti.com/blog/internationalisation-phoenix-live-layouts/",teaser:"https://www.paulfioravanti.com/assets/images/2020-02-03/kyle-glenn-nXt5HtLmlgE-unsplash.jpg"},{title:"I Completed Typey Type",excerpt:"I first got into stenography in late 2018, and wrote up a blog post about Starting Stenography with an Ergodox, which outlines how I started my steno journey using an Ergodox EZ mechanical keyboard.   One of the learning resources I used was Typey Type, an awesome web-based typing application by Diana MacDonald. I would use it occasionally over the course of a few months until, unfortunately, my steno learning fell by the wayside some time in early 2019. I then completely neglected it for the rest of the year.   Come 2020, one of my New Year\u2019s resolutions was to get my steno learning back on track, and Typey Type was going to be key. Typey Type keeps track of your progress through its lessons, and provides you with a percentage score based on how many words you have typed without mis-strokes. It was this number that I latched on to: I wanted it to be 100%.   But, what was to stop yet another lapse in practice, resulting in writing off yet another year of potential progress? Accountability! I was able to find another person who wanted to kick-start their steno-related activities, and we became accountability buddies!   Define Success and Establish Cadence   First of all, we each defined and declared what success in our steno endeavours would look like. Here is what I wrote back in January:      30 minutes minimum steno practice a day, preferably an hour   I want to hit 100% progress on Typey Type this year (maybe this can take 6 months on this schedule\u2026?)   It would be nice to have my steno speeds match, or at least approach, my QWERTY typing speeds by the end of the year, so I can justify integrating it with my everyday workflows   Every week, without fail, I would need to send my accountability buddy an email outlining what I had done in the last week to move forward towards completing those goals.   I do not think I can possibly stress enough how beneficial it was to have this system in place:      I had a deadline, every week, where someone was expecting to hear from me   I did not want to have to report a lack of or no progress, which helped force me to keep up my routines   Being able to report percentage gains towards the completion goal to an interested party felt great, and helped propel me forward   I took an \u201ceat that frog\u201d approach to the timing of the 30 minutes practice being first thing in the morning before breakfast, so I would not worry about it for the rest of the day, or while at work   For the first three months, I kept a schedule of 30 minutes steno practice a day, every day, even if I did not want to do it, which, initially, was often. Then, from the fourth month, I made a small increase to doing an hour a day on weekends. Finally, seeing this r/plover post spurred me to go up to an hour steno practice every day, which I have been able to keep as of this writing.   And so, after five months of practice, I finally reached 100% completion, meaning I have been able to type 10,000 words without mis-strokes.   I was initially worried that I was not hitting goals fast enough since I read of people who were, say, getting up to 50 words-per-minute (WPM) after just a month or two of steno practice. Maybe they had the luxury to dedicate their entire full-time schedule to stenography, or maybe they were super-geniuses, or maybe a bit of both\u2026.   Regardless, I needed to consciously ignore all this, not compare myself to anyone else (real or imagined), and just keep up the routine. It may have taken a while, but I do not mind; the journey has been beneficial and being able to hit a goal feels great!   Contributing Back   Aside from learning stenography through Typey Type, one of the other goals I had was that if I find dictionary issues in Typey Type (incorrect or missing words etc), I would make notes of them, and set aside time to file issues and pull requests (PRs) to Typey Type\u2019s dictionary Github repository as close to finishing steno practice as possible.   This is particularly important to me. Typey Type is a massively valuable piece of open source software that is being provided for free.  Given the value I personally get from it, the least I can do is to help improve it where I can.   As a software engineer, I use Git and Github daily, so contributing back does not require any extra effort to learn new tools; just the time to make notes and craft them into issues/PRs (there are other ways to get your proposals in, so do not let not knowing Git or caring about Github stop you from proposing a dictionary entry improvement!).   The process of contributing back also had the great knock-on effects of gaining a deeper understanding about Plover theory through researching discrepancies between Typey Type and Plover dictionary entries, and receiving expert knowledge from Diana in the interesting discussion threads on Github.   Now What?   I may have \u201ccompleted\u201d Typey Type, but, there is still a long, long road ahead of me. I now know viscerally that steno is not something that I can casually pick up: success is going to require continuous pushing until I can use steno in daily typing in the way I currently use QWERTY. Steno feels more like learning a new language than just a keyboard layout.   Since Typey Type has lots of activities outside of those scored 10,000 words, I\u2019m planning to continue doing them to learn ever more and hopefully build up more muscle memory.   Just as important, though, is that I did not focus on gaining speed at all during my practice, so I am still currently a very slow steno typist (read: less than 20 WPM slow). I think the lack of gains I made in speed were made up for with an increase in stroke intuition, but getting higher speeds remains a major goal.   So, the grind may not be over, but I am still energised. I\u2019m looking forward to keeping up my current steno pace, and then taking stock again in another six months to hopefully realise what could be my first successful completion of a New Year\u2019s resolution.     Postscript: Typey Type Tips   This section did not really fit within the body of the blog post, so it gets tacked on at the end\u2026   If you are currently using Typey Type or about to start, and maybe even thinking of contributing back, here are some things I have learned along the way, in no particular order.      After downloading Plover, if you find that you are not getting the expected output when stroking words in Typey Type, chances are that this is because you are using Plover version 3.1.1 (the current stable release), while Typey Type dictionary entries are more optimised to favour Plover version 4 pre-release (the latest as of this writing being weekly-v4.0.0.dev8+66.g685bd33) entries. So, I would currently recommend downloading pre-release versions to have a smoother steno experience. The latest information about installing Plover can always be found in its Installation Guide   Your Typey Type progress file is stored in your browser, which means there is a non-zero chance you may accidentally delete it if you are ever too eager with clearing your browser data. Having lost my progress file once, I can recommend having backups. I back mine up to Dropbox after every practice session.   Plover\u2019s Lookup functionality has been my constant companion when using Typey Type. Whenever a word came up in Typey Type whose outline did not \u201cfeel quite right\u201d to me, I would look the word up in Plover to see if there were any other outlines for that word that fit my brain better. If there were, I would sometimes submit these to the Typey Type dictionary Github repo as a potential change for consideration. Sometimes, an outline I thought better suited for a word would turn out to be a mis-stroke. So, it\u2019s also worth checking Typey Type\u2019s mis-stroke dictionary to test your suspicions   Many entries from Typey Type\u2019s Top 1000 Project Gutenberg Words dictionary, which appear in Typey Type practice exercises, use British English spelling. This means that there is a high chance that American-English-based Plover dictionaries will not have corresponding entries for those words. Typey Type does not necessarily need you to load up any other dictionaries aside from those that come bundled with Plover, but I would recommend that you download Di\u2019s dict-en-AU-with-extra-stroke.json dictionary and add it to your list of default Plover dictionaries (user.json, commands.json, main.json etc) so you can stroke these words with ease   If you cannot seem to get past a particular entry no matter what word you attempt to stroke, fingerspelling the word will get you past it, and it will be logged as a successfully typed word in your progress   Good luck in your steno adventures!   ",categories:[],tags:["stenography","keyboards","ergodox","mechanical-keyboards","plover"],url:"https://www.paulfioravanti.com/blog/completed-typey-type/",teaser:"https://www.paulfioravanti.com/assets/images/2020-06-10/stenotype.jpg"},{title:"All I want is a Timestamp",
excerpt:'Inserting the current date and time into a Google Sheets cell can be done with the following keyboard shortcut:                  Platform       Shortcut                       PC       Ctrl + Alt + Shift + ;                 Mac       \u2318 + Option + Shift + ;           If you have found this page via searching specifically for this information, then please consider your objective fulfilled. You\u2019re welcome!   There is a story around me getting to this point, though, since behind the simple table above is a small journey involving Google Sheets\u2019 functions and macros, Javascript, and eventually QMK Firmware for mechanical keyboards. Still with me? Read on\u2026   To-Do List      Using Google Sheets, I wanted to have a task list, similar to this screenshot, where I could log the start and end times of my tasks.   I made the assumption that there was a built-in function that could generate a timestamp for me, and when I went looking, I found NOW.      Using it in the spreadsheet would seem to have given me what I wanted, formatted in the way that I expect. Great!   When a task is finished, all I should have to do is make another call to NOW, and I would get a new generated date and time, right? Well, that happened, but also\u2026      \u2026the start time also got re-generated, ending up the same value as the finish time!   I thought that surely this could not be correct behaviour, but deleting the finish time caused the start time to be re-generated yet again!   So, it would seem that cells that use the NOW function get re-calculated whenever any change occurs in the spreadsheet. Perhaps there is a way to adjust this behaviour\u2026?      In the Spreadsheet Settings, located under the File &gt; Spreadsheet Settings &gt; Calculation menu options, there are three re-calculation options for the spreadsheet, but none of them turn off re-calculation.   Looking back at the documentation for NOW, which I really should have viewed in more detail earlier, brings into focus that I\u2019m using the wrong tool for the job:           Note that NOW is a volatile function, updating on every edit made to the spreadsheet, and can hurt spreadsheet performance.     NOW will always represent the current date and time the last time the spreadsheet was recalculated, rather than remaining at the date and time when it was first entered.      Now that I know I have a dynamic values problem, I wonder if there is any way to get a static datetime value, rather than what seems like a reference to a function that gets executed periodically?   At first glance, it looks like there are potentially two other functions that could fit the bill, since they return \u201cvalues\u201d:      DATEVALUE   TIMEVALUE   However, both of these functions require a static string parameter, and \u201creturn integers that can be used in formulas\u201d, those integers being a serial number representation of the date or time.   I definitely know that this is not what I want, so no need to go further down this rabbit hole.   Custom Behaviour with Macros   At this stage, it looks like I will need to create my own custom function/behaviour to get what I want. In Google Sheets, you do this with Macros.   Since what I wanted was a NOW value, I will call the macro the next best thing: _now, and get it to do the following:      When I type _now into a cell, and the cell loses \u201cfocus\u201d (ie I move the cursor to another cell), the value of that cell changes from the string _now, to the current date and time.    In Google Sheets, custom functions are created using Javascript, and are written in the Script Editor (Tools &gt; Script Editor).   To get the desired behaviour, the _now function will need to hook into Sheets\u2019 Simple Triggers, specifically the onEdit(e) trigger function, which \u201cruns when a user changes a value in a spreadsheet.\u201d   Opening up the Script Editor provides a default file called macros.gs, so that\u2019s where the function will go:   macros.gs   /** @OnlyCurrentDoc */ function onEdit(e) {   if (e.range.getValue() == "_now") {     let date = new Date();     let formattedDate =       date         .toLocaleString("en-AU", { timeZone: "Australia/Sydney", hour12: false })         .replace(",", "");     e.range.setValue(formattedDate);   } }   This function does the following:      Whenever an edit occurs in the spreadsheet, the content of the cell is checked to see if it contains the string "_now" (technically, the value of the range of the event object e is checked)   If it does contain "_now", then it uses Javascript to create a new date   From that date object, a new date string is created and formatted according to my current locale (Sydney, Australia), and in 24-hour time   The content of the cell is then set to the formatted date string   Let\u2019s see how this works back in the spreadsheet:      Looks good to me! We\u2019re done here now, right?   Well, something about this still did not sit right with me: surely the desire for a current date and time could not be so uncommon that all this ceremony and customisation was needed\u2026?   The punch line is that, as you already know, if I had just looked into Google Sheets\u2019 keyboard shortcuts, I could have saved myself all this time (though I would probably not have learned about all the things I\u2019ve covered here, nor written this blog post at all, so I guess that is a good thing\u2026?).   Opening up the shortcut search modal (\u2318 + /) and searching for \u201ctime\u201d displays the following:      The solution was unfortunately hidden away from me, but it was simpler than what I had created. So, rather than keep the custom function, I removed it in favour of using the \u201cInsert current date and time\u201d shortcut.   The only issue I can see now, though, is that a 4-key \u201cshortcut\u201d is a bit unwieldy, and since I will be using this a lot moving forward, I want it to be shorter. And, just for fun, I want to actually map it to a key on my keyboard.   So, it\u2019s time to crack open QMK and make this happen!   (I know I could potentially make the shortcut a bit shorter using an operating-system level custom keyboard shortcut, rather than go down to the metal of my keyboard firmware, but where\u2019s the fun in that?)   Configuring a Google Sheets Datetime Key   I have gone into the details on how to create new keyboard keycodes that map to custom actions in a couple of other blog posts:      Escape the defaults and Control your keyboard with QMK   Chording QWERTY with QMK Combos   So, I will just summarise the changes I needed to make to get a datetime appearing on a key press of my Ergodox EZ, and the blog posts above should be able to fill in any areas you may be uncertain about. You can also view the final result in my QMK Keymaps.   Custom Keycode   Add a custom keycode for a Google Sheets timestamp, which I will call GS_TIMESTAMP, to the custom_keycodes list:   enum custom_keycodes {   // ....   GS_TIMESTAMP,   // ... };   My custom_keycodes.   Custom Action   Add a custom action for when the key corresponding to the GS_TIMESTAMP is pressed. In this case, I want to map it to the Google Sheets shortcut: \u2318 + Option + Shift + ;.   This gets coded up in the process_record_user() function as one of the case options in the switch statement:   bool process_record_user(uint16_t keycode, keyrecord_t *record) {   if (record-&gt;event.pressed) {     switch (keycode) {       // ...       case GS_TIMESTAMP:         SEND_STRING(SS_DOWN(X_LGUI)SS_DOWN(X_LALT)SS_DOWN(X_LSHIFT));         SEND_STRING(SS_TAP(X_SCOLON));         SEND_STRING(SS_UP(X_LGUI)SS_UP(X_LALT)SS_UP(X_LSHIFT));         return false;       // ...     }   }   return true; }   My process_record_user function.   Assign Keycode to Key   Now that GS_TIMESTAMP has a definition and an action that it performs, it needs to be assigned to a key on the keyboard:   // ... [BASE] = LAYOUT_ergodox(  // layer 0 : default   // left hand   GS_TIMESTAMP, KC_1, KC_2, KC_3, KC_4, KC_5, KC_LEFT,   // ... ), // ...   Note that the positioning of the GS_TIMESTAMP keycode on the top left key of the keyboard, before the \u201c1\u201d key, is just meant to be illustrative of the kind of code change required. I ended up defining it somewhere else on my keymap.   If you followed along with your own QMK keyboard mapping, you can now re-compile your keymap, and enjoy one-key timestamp-ing in any of your Google Sheets!   And remember, if you come across a problem in Google Sheets that surely should have a solution, make sure to read every bit of documentation you can find before reaching for that text editor!   ',categories:[],tags:["google-sheets","javascript","keyboards","ergodox","mechanical-keyboards"],url:"https://www.paulfioravanti.com/blog/google-sheets-timestamp/",teaser:"https://www.paulfioravanti.com/assets/images/2020-07-25/all-i-want-is-a-timestamp.png"}];